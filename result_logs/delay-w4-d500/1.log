SUBMITTED
/opt/src/lenet5.py --action train --dataPath /opt/data --batchSize 120 --endTriggerType epoch --endTriggerNum 20
2019-10-23 19:10:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-23 19:10:07 INFO  SparkContext:54 - Running Spark version 2.4.0
2019-10-23 19:10:07 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-23 19:10:07 INFO  SecurityManager:54 - Changing view acls to: root
2019-10-23 19:10:07 INFO  SecurityManager:54 - Changing modify acls to: root
2019-10-23 19:10:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-23 19:10:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-23 19:10:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2019-10-23 19:10:07 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 34317.
2019-10-23 19:10:07 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-23 19:10:07 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-23 19:10:07 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-23 19:10:07 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-23 19:10:07 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-86850c36-c51f-4152-83c8-b17b16c16510
2019-10-23 19:10:07 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-23 19:10:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-23 19:10:08 INFO  log:192 - Logging initialized @1957ms
2019-10-23 19:10:08 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-10-23 19:10:08 INFO  Server:419 - Started @2023ms
2019-10-23 19:10:08 INFO  AbstractConnector:278 - Started ServerConnector@46b6adb3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 19:10:08 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@e28e10e{/jobs,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@542653ac{/jobs/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55d37f2e{/jobs/job,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@740e93a1{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@125315bf{/stages,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c3722d4{/stages/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@592d0b50{/stages/stage,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@360eb915{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@748430f{/stages/pool,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e1dcfd9{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2dd55170{/storage,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e5093ce{/storage/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b45e530{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b669486{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c3f064b{/environment,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69b36e1{/environment/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2732f67{/executors,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5d6e490b{/executors/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@497701b3{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16040a42{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d9707f2{/static,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@91a237e{/,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fc92808{/api,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@576e7304{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e00e4b2{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://6354fcec1c38:4040
2019-10-23 19:10:08 INFO  SparkContext:54 - Added JAR file:///opt/big_dl/lib/bigdl-SPARK_2.4-0.9.0-jar-with-dependencies.jar at spark://6354fcec1c38:34317/jars/bigdl-SPARK_2.4-0.9.0-jar-with-dependencies.jar with timestamp 1571857808212
2019-10-23 19:10:08 INFO  SparkContext:54 - Added file file:///opt/big_dl/lib/bigdl-0.9.0-python-api.zip at spark://6354fcec1c38:34317/files/bigdl-0.9.0-python-api.zip with timestamp 1571857808237
2019-10-23 19:10:08 INFO  Utils:54 - Copying /opt/big_dl/lib/bigdl-0.9.0-python-api.zip to /tmp/spark-746d0644-ce69-4525-9e22-184368315d20/userFiles-7199e9c3-2b90-480c-a661-b7fa31275f94/bigdl-0.9.0-python-api.zip
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://spark-master:7077...
2019-10-23 19:10:08 INFO  TransportClientFactory:267 - Successfully created connection to spark-master/172.19.0.2:7077 after 32 ms (0 ms spent in bootstraps)
2019-10-23 19:10:08 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191023191008-0037
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191023191008-0037/0 on worker-20191023153541-172.19.0.8-32881 (172.19.0.8:32881) with 1 core(s)
2019-10-23 19:10:08 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191023191008-0037/0 on hostPort 172.19.0.8:32881 with 1 core(s), 1024.0 MB RAM
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191023191008-0037/1 on worker-20191023153540-172.19.0.3-43023 (172.19.0.3:43023) with 1 core(s)
2019-10-23 19:10:08 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191023191008-0037/1 on hostPort 172.19.0.3:43023 with 1 core(s), 1024.0 MB RAM
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191023191008-0037/2 on worker-20191023153540-172.19.0.5-42611 (172.19.0.5:42611) with 1 core(s)
2019-10-23 19:10:08 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191023191008-0037/2 on hostPort 172.19.0.5:42611 with 1 core(s), 1024.0 MB RAM
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191023191008-0037/3 on worker-20191023153540-172.19.0.7-41783 (172.19.0.7:41783) with 1 core(s)
2019-10-23 19:10:08 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191023191008-0037/3 on hostPort 172.19.0.7:41783 with 1 core(s), 1024.0 MB RAM
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191023191008-0037/1 is now RUNNING
2019-10-23 19:10:08 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36705.
2019-10-23 19:10:08 INFO  NettyBlockTransferService:54 - Server created on 6354fcec1c38:36705
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191023191008-0037/0 is now RUNNING
2019-10-23 19:10:08 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191023191008-0037/2 is now RUNNING
2019-10-23 19:10:08 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 6354fcec1c38, 36705, None)
2019-10-23 19:10:08 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 6354fcec1c38:36705 with 366.3 MB RAM, BlockManagerId(driver, 6354fcec1c38, 36705, None)
2019-10-23 19:10:08 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 6354fcec1c38, 36705, None)
2019-10-23 19:10:08 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 6354fcec1c38, 36705, None)
2019-10-23 19:10:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ed6367b{/metrics/json,null,AVAILABLE,@Spark}
2019-10-23 19:10:08 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191023191008-0037/3 is now RUNNING
2019-10-23 19:10:10 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.3:35378) with ID 1
2019-10-23 19:10:10 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.19.0.3:44921 with 366.3 MB RAM, BlockManagerId(1, 172.19.0.3, 44921, None)
2019-10-23 19:10:11 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.8:50756) with ID 0
2019-10-23 19:10:11 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.5:56694) with ID 2
2019-10-23 19:10:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.19.0.8:41909 with 366.3 MB RAM, BlockManagerId(0, 172.19.0.8, 41909, None)
2019-10-23 19:10:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.19.0.5:39967 with 366.3 MB RAM, BlockManagerId(2, 172.19.0.5, 39967, None)
2019-10-23 19:10:15 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.7:50770) with ID 3
2019-10-23 19:10:15 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-23 19:10:15 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-23 19:10:15 INFO  Engine$:114 - Executor number is 4 and executor cores number is 1
2019-10-23 19:10:16 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 19
2019-10-23 19:10:16 INFO  Engine$:404 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
('Extracting', '/opt/data/train-images-idx3-ubyte.gz')
('Extracting', '/opt/data/train-labels-idx1-ubyte.gz')
('Extracting', '/opt/data/t10k-images-idx3-ubyte.gz')
('Extracting', '/opt/data/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-23 19:10:17 INFO  DistriOptimizer$:791 - caching training rdd ...
2019-10-23 19:10:19 ERROR TransportRequestHandler:293 - Error sending result StreamResponse{streamId=/jars/bigdl-SPARK_2.4-0.9.0-jar-with-dependencies.jar, byteCount=146830010, body=FileSegmentManagedBuffer{file=/opt/big_dl/lib/bigdl-SPARK_2.4-0.9.0-jar-with-dependencies.jar, offset=0, length=146830010}} to /172.19.0.5:56710; closing connection
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:145)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:355)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:224)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:382)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:934)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:368)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:639)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
