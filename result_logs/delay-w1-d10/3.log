SUBMITTED
/opt/src/lenet5.py --action train --dataPath /opt/data --batchSize 120 --endTriggerType epoch --endTriggerNum 20
2019-10-23 15:52:52 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-23 15:52:52 INFO  SparkContext:54 - Running Spark version 2.4.0
2019-10-23 15:52:52 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-23 15:52:52 INFO  SecurityManager:54 - Changing view acls to: root
2019-10-23 15:52:52 INFO  SecurityManager:54 - Changing modify acls to: root
2019-10-23 15:52:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-23 15:52:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-23 15:52:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2019-10-23 15:52:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 37279.
2019-10-23 15:52:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-23 15:52:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-23 15:52:53 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-23 15:52:53 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-23 15:52:53 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-d6193526-0673-43db-8fc3-0d03164c2a48
2019-10-23 15:52:53 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-23 15:52:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-23 15:52:53 INFO  log:192 - Logging initialized @1972ms
2019-10-23 15:52:53 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-10-23 15:52:53 INFO  Server:419 - Started @2036ms
2019-10-23 15:52:53 INFO  AbstractConnector:278 - Started ServerConnector@3ab526ae{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 15:52:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51314b2d{/jobs,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a59f9eb{/jobs/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61477e14{/jobs/job,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d9261d4{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@881572c{/stages,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52ec2ff6{/stages/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d10637{/stages/stage,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2fc9481d{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27a1136d{/stages/pool,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@23af963a{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75af5b39{/storage,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10436c31{/storage/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3fd63f2f{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@601760a9{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fee9901{/environment,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64475229{/environment/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ae626c9{/executors,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31af1114{/executors/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a92a0b1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@749a69d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f11c9e4{/static,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c4b383{/,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a6439d6{/api,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@131f3df8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1c8b964c{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-23 15:52:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://8738b9bb63c9:4040
2019-10-23 15:52:53 INFO  SparkContext:54 - Added JAR file:///opt/big_dl/lib/bigdl-SPARK_2.4-0.9.0-jar-with-dependencies.jar at spark://8738b9bb63c9:37279/jars/bigdl-SPARK_2.4-0.9.0-jar-with-dependencies.jar with timestamp 1571845973495
2019-10-23 15:52:53 INFO  SparkContext:54 - Added file file:///opt/big_dl/lib/bigdl-0.9.0-python-api.zip at spark://8738b9bb63c9:37279/files/bigdl-0.9.0-python-api.zip with timestamp 1571845973512
2019-10-23 15:52:53 INFO  Utils:54 - Copying /opt/big_dl/lib/bigdl-0.9.0-python-api.zip to /tmp/spark-3d76e141-dcee-496a-a5e4-73c1139e7069/userFiles-2ecc2353-0af2-4fb4-aac7-bbcfd0bfdfa5/bigdl-0.9.0-python-api.zip
2019-10-23 15:52:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://spark-master:7077...
2019-10-23 15:52:53 INFO  TransportClientFactory:267 - Successfully created connection to spark-master/172.19.0.2:7077 after 36 ms (0 ms spent in bootstraps)
2019-10-23 15:52:53 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191023155253-0002
2019-10-23 15:52:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191023155253-0002/0 on worker-20191023153541-172.19.0.8-32881 (172.19.0.8:32881) with 1 core(s)
2019-10-23 15:52:53 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36443.
2019-10-23 15:52:53 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191023155253-0002/0 on hostPort 172.19.0.8:32881 with 1 core(s), 1024.0 MB RAM
2019-10-23 15:52:53 INFO  NettyBlockTransferService:54 - Server created on 8738b9bb63c9:36443
2019-10-23 15:52:53 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-23 15:52:53 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191023155253-0002/0 is now RUNNING
2019-10-23 15:52:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 8738b9bb63c9, 36443, None)
2019-10-23 15:52:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 8738b9bb63c9:36443 with 366.3 MB RAM, BlockManagerId(driver, 8738b9bb63c9, 36443, None)
2019-10-23 15:52:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 8738b9bb63c9, 36443, None)
2019-10-23 15:52:53 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 8738b9bb63c9, 36443, None)
2019-10-23 15:52:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27c9e2b3{/metrics/json,null,AVAILABLE,@Spark}
2019-10-23 15:52:55 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.8:40570) with ID 0
2019-10-23 15:52:55 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-23 15:52:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.19.0.8:34087 with 366.3 MB RAM, BlockManagerId(0, 172.19.0.8, 34087, None)
2019-10-23 15:52:55 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-23 15:52:55 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-23 15:52:56 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 19
2019-10-23 15:52:56 INFO  Engine$:404 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
('Extracting', '/opt/data/train-images-idx3-ubyte.gz')
('Extracting', '/opt/data/train-labels-idx1-ubyte.gz')
('Extracting', '/opt/data/t10k-images-idx3-ubyte.gz')
('Extracting', '/opt/data/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-23 15:52:57 INFO  DistriOptimizer$:791 - caching training rdd ...
2019-10-23 15:53:05 INFO  DistriOptimizer$:629 - Cache thread models...
2019-10-23 15:53:05 INFO  DistriOptimizer$:631 - Cache thread models... done
2019-10-23 15:53:05 INFO  DistriOptimizer$:148 - Count dataset
2019-10-23 15:53:05 INFO  DistriOptimizer$:152 - Count dataset complete. Time elapsed: 0.152013735s
2019-10-23 15:53:05 INFO  DistriOptimizer$:160 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-23 15:53:05 INFO  DistriOptimizer$:164 - Shuffle data
2019-10-23 15:53:05 INFO  DistriOptimizer$:167 - Shuffle data complete. Takes 0.021862405s
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 120/60000][Iteration 1][Wall Clock 0.321218751s] Trained 120 records in 0.321218751 seconds. Throughput is 373.57718 records/second. Loss is 2.3061583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.01. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 240/60000][Iteration 2][Wall Clock 0.462798068s] Trained 120 records in 0.141579317 seconds. Throughput is 847.5814 records/second. Loss is 2.2915337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009998000399920017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 360/60000][Iteration 3][Wall Clock 0.581413566s] Trained 120 records in 0.118615498 seconds. Throughput is 1011.6722 records/second. Loss is 2.3070896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009996001599360257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 480/60000][Iteration 4][Wall Clock 0.682798992s] Trained 120 records in 0.101385426 seconds. Throughput is 1183.602 records/second. Loss is 2.3044558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009994003597841297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 600/60000][Iteration 5][Wall Clock 0.781186648s] Trained 120 records in 0.098387656 seconds. Throughput is 1219.6652 records/second. Loss is 2.2823997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009992006394884094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 720/60000][Iteration 6][Wall Clock 0.878783284s] Trained 120 records in 0.097596636 seconds. Throughput is 1229.5505 records/second. Loss is 2.3013198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009990009990009992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 840/60000][Iteration 7][Wall Clock 0.981107662s] Trained 120 records in 0.102324378 seconds. Throughput is 1172.741 records/second. Loss is 2.2963088. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00998801438274071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 960/60000][Iteration 8][Wall Clock 1.094803067s] Trained 120 records in 0.113695405 seconds. Throughput is 1055.4517 records/second. Loss is 2.2975152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009986019572598362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 1080/60000][Iteration 9][Wall Clock 1.194017519s] Trained 120 records in 0.099214452 seconds. Throughput is 1209.5012 records/second. Loss is 2.3009315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009984025559105431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:06 INFO  DistriOptimizer$:406 - [Epoch 1 1200/60000][Iteration 10][Wall Clock 1.276281653s] Trained 120 records in 0.082264134 seconds. Throughput is 1458.716 records/second. Loss is 2.3087757. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009982032341784788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 1320/60000][Iteration 11][Wall Clock 1.357270884s] Trained 120 records in 0.080989231 seconds. Throughput is 1481.6785 records/second. Loss is 2.2998495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00998003992015968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 1440/60000][Iteration 12][Wall Clock 1.444059541s] Trained 120 records in 0.086788657 seconds. Throughput is 1382.6692 records/second. Loss is 2.308475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009978048293753742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 1560/60000][Iteration 13][Wall Clock 1.520513393s] Trained 120 records in 0.076453852 seconds. Throughput is 1569.5743 records/second. Loss is 2.2951152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009976057462090982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 1680/60000][Iteration 14][Wall Clock 1.624260849s] Trained 120 records in 0.103747456 seconds. Throughput is 1156.6549 records/second. Loss is 2.2979429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009974067424695792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 1800/60000][Iteration 15][Wall Clock 1.696737229s] Trained 120 records in 0.07247638 seconds. Throughput is 1655.7118 records/second. Loss is 2.292708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009972078181092942. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 1920/60000][Iteration 16][Wall Clock 1.774977879s] Trained 120 records in 0.07824065 seconds. Throughput is 1533.7296 records/second. Loss is 2.2873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009970089730807579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 2040/60000][Iteration 17][Wall Clock 1.849807366s] Trained 120 records in 0.074829487 seconds. Throughput is 1603.6459 records/second. Loss is 2.2985194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00996810207336523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 2160/60000][Iteration 18][Wall Clock 1.920617706s] Trained 120 records in 0.07081034 seconds. Throughput is 1694.6677 records/second. Loss is 2.299205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009966115208291807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 2280/60000][Iteration 19][Wall Clock 1.992542802s] Trained 120 records in 0.071925096 seconds. Throughput is 1668.4023 records/second. Loss is 2.2944505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00996412913511359. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 2400/60000][Iteration 20][Wall Clock 2.080970747s] Trained 120 records in 0.088427945 seconds. Throughput is 1357.0371 records/second. Loss is 2.2885902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009962143853357242. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 2520/60000][Iteration 21][Wall Clock 2.16516558s] Trained 120 records in 0.084194833 seconds. Throughput is 1425.2656 records/second. Loss is 2.284295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0099601593625498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:07 INFO  DistriOptimizer$:406 - [Epoch 1 2640/60000][Iteration 22][Wall Clock 2.24136286s] Trained 120 records in 0.07619728 seconds. Throughput is 1574.8594 records/second. Loss is 2.2903094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009958175662218682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 2760/60000][Iteration 23][Wall Clock 2.31577006s] Trained 120 records in 0.0744072 seconds. Throughput is 1612.7472 records/second. Loss is 2.288827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009956192751891677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 2880/60000][Iteration 24][Wall Clock 2.394965873s] Trained 120 records in 0.079195813 seconds. Throughput is 1515.2317 records/second. Loss is 2.2810848. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009954210631096954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3000/60000][Iteration 25][Wall Clock 2.465700029s] Trained 120 records in 0.070734156 seconds. Throughput is 1696.4929 records/second. Loss is 2.2787492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009952229299363059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3120/60000][Iteration 26][Wall Clock 2.542920233s] Trained 120 records in 0.077220204 seconds. Throughput is 1553.9976 records/second. Loss is 2.2836723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009950248756218907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3240/60000][Iteration 27][Wall Clock 2.608582198s] Trained 120 records in 0.065661965 seconds. Throughput is 1827.542 records/second. Loss is 2.2912245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00994826900119379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3360/60000][Iteration 28][Wall Clock 2.677925948s] Trained 120 records in 0.06934375 seconds. Throughput is 1730.5092 records/second. Loss is 2.2717428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009946290033817386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3480/60000][Iteration 29][Wall Clock 2.743877293s] Trained 120 records in 0.065951345 seconds. Throughput is 1819.5231 records/second. Loss is 2.2854433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00994431185361973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3600/60000][Iteration 30][Wall Clock 2.806496379s] Trained 120 records in 0.062619086 seconds. Throughput is 1916.3488 records/second. Loss is 2.2835877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00994233446013124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3720/60000][Iteration 31][Wall Clock 2.871405809s] Trained 120 records in 0.06490943 seconds. Throughput is 1848.7299 records/second. Loss is 2.2887025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009940357852882704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3840/60000][Iteration 32][Wall Clock 2.942209179s] Trained 120 records in 0.07080337 seconds. Throughput is 1694.8347 records/second. Loss is 2.2784603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009938382031405287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 3960/60000][Iteration 33][Wall Clock 3.009123855s] Trained 120 records in 0.066914676 seconds. Throughput is 1793.3285 records/second. Loss is 2.2843177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009936406995230525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 4080/60000][Iteration 34][Wall Clock 3.07565404s] Trained 120 records in 0.066530185 seconds. Throughput is 1803.6926 records/second. Loss is 2.2646208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009934432743890324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 4200/60000][Iteration 35][Wall Clock 3.13470724s] Trained 120 records in 0.0590532 seconds. Throughput is 2032.0659 records/second. Loss is 2.2755742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009932459276916966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 4320/60000][Iteration 36][Wall Clock 3.19880408s] Trained 120 records in 0.06409684 seconds. Throughput is 1872.1672 records/second. Loss is 2.2806714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0099304865938431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:08 INFO  DistriOptimizer$:406 - [Epoch 1 4440/60000][Iteration 37][Wall Clock 3.264465197s] Trained 120 records in 0.065661117 seconds. Throughput is 1827.5656 records/second. Loss is 2.2755952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009928514694201746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 4560/60000][Iteration 38][Wall Clock 3.336637645s] Trained 120 records in 0.072172448 seconds. Throughput is 1662.6843 records/second. Loss is 2.2783294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009926543577526304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 4680/60000][Iteration 39][Wall Clock 3.42073385s] Trained 120 records in 0.084096205 seconds. Throughput is 1426.9371 records/second. Loss is 2.2778306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009924573243350535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 4800/60000][Iteration 40][Wall Clock 3.48192206s] Trained 120 records in 0.06118821 seconds. Throughput is 1961.1621 records/second. Loss is 2.2737985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009922603691208573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 4920/60000][Iteration 41][Wall Clock 3.551869539s] Trained 120 records in 0.069947479 seconds. Throughput is 1715.5729 records/second. Loss is 2.2733145. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00992063492063492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5040/60000][Iteration 42][Wall Clock 3.615332554s] Trained 120 records in 0.063463015 seconds. Throughput is 1890.865 records/second. Loss is 2.2773883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009918666931164452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5160/60000][Iteration 43][Wall Clock 3.6730257s] Trained 120 records in 0.057693146 seconds. Throughput is 2079.9697 records/second. Loss is 2.2696607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009916699722332408. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5280/60000][Iteration 44][Wall Clock 3.738408851s] Trained 120 records in 0.065383151 seconds. Throughput is 1835.3352 records/second. Loss is 2.2775955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009914733293674401. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5400/60000][Iteration 45][Wall Clock 3.816365562s] Trained 120 records in 0.077956711 seconds. Throughput is 1539.3158 records/second. Loss is 2.2731538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009912767644726409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5520/60000][Iteration 46][Wall Clock 3.87956539s] Trained 120 records in 0.063199828 seconds. Throughput is 1898.7394 records/second. Loss is 2.2785609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009910802775024779. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5640/60000][Iteration 47][Wall Clock 3.943573749s] Trained 120 records in 0.064008359 seconds. Throughput is 1874.755 records/second. Loss is 2.2769916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009908838684106223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5760/60000][Iteration 48][Wall Clock 4.001811618s] Trained 120 records in 0.058237869 seconds. Throughput is 2060.515 records/second. Loss is 2.2666502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009906875371507825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 5880/60000][Iteration 49][Wall Clock 4.063548425s] Trained 120 records in 0.061736807 seconds. Throughput is 1943.7351 records/second. Loss is 2.2604125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009904912836767036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 6000/60000][Iteration 50][Wall Clock 4.129490908s] Trained 120 records in 0.065942483 seconds. Throughput is 1819.7677 records/second. Loss is 2.2700791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009902951079421667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 6120/60000][Iteration 51][Wall Clock 4.204310055s] Trained 120 records in 0.074819147 seconds. Throughput is 1603.8676 records/second. Loss is 2.2535968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009900990099009901. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:09 INFO  DistriOptimizer$:406 - [Epoch 1 6240/60000][Iteration 52][Wall Clock 4.271193558s] Trained 120 records in 0.066883503 seconds. Throughput is 1794.1643 records/second. Loss is 2.2645478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009899029895070284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 6360/60000][Iteration 53][Wall Clock 4.330959278s] Trained 120 records in 0.05976572 seconds. Throughput is 2007.84 records/second. Loss is 2.2654366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009897070467141727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 6480/60000][Iteration 54][Wall Clock 4.390202195s] Trained 120 records in 0.059242917 seconds. Throughput is 2025.5587 records/second. Loss is 2.2666538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009895111814763508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 6600/60000][Iteration 55][Wall Clock 4.450942025s] Trained 120 records in 0.06073983 seconds. Throughput is 1975.6394 records/second. Loss is 2.2663758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009893153937475268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 6720/60000][Iteration 56][Wall Clock 4.517546471s] Trained 120 records in 0.066604446 seconds. Throughput is 1801.6816 records/second. Loss is 2.2539976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009891196834817014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 6840/60000][Iteration 57][Wall Clock 4.574746504s] Trained 120 records in 0.057200033 seconds. Throughput is 2097.901 records/second. Loss is 2.2563345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009889240506329113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 6960/60000][Iteration 58][Wall Clock 4.646072986s] Trained 120 records in 0.071326482 seconds. Throughput is 1682.4047 records/second. Loss is 2.263082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009887284951552304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7080/60000][Iteration 59][Wall Clock 4.702958315s] Trained 120 records in 0.056885329 seconds. Throughput is 2109.507 records/second. Loss is 2.2640219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009885330170027679. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7200/60000][Iteration 60][Wall Clock 4.765748128s] Trained 120 records in 0.062789813 seconds. Throughput is 1911.1381 records/second. Loss is 2.2565339. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0098833761612967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7320/60000][Iteration 61][Wall Clock 4.826806654s] Trained 120 records in 0.061058526 seconds. Throughput is 1965.3275 records/second. Loss is 2.2560346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009881422924901186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7440/60000][Iteration 62][Wall Clock 4.884422889s] Trained 120 records in 0.057616235 seconds. Throughput is 2082.7463 records/second. Loss is 2.2559683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009879470460383323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7560/60000][Iteration 63][Wall Clock 4.939603187s] Trained 120 records in 0.055180298 seconds. Throughput is 2174.6892 records/second. Loss is 2.2602813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009877518767285659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7680/60000][Iteration 64][Wall Clock 5.003098837s] Trained 120 records in 0.06349565 seconds. Throughput is 1889.8932 records/second. Loss is 2.2558663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009875567845151097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7800/60000][Iteration 65][Wall Clock 5.067614325s] Trained 120 records in 0.064515488 seconds. Throughput is 1860.0186 records/second. Loss is 2.2507298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009873617693522907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 7920/60000][Iteration 66][Wall Clock 5.129705067s] Trained 120 records in 0.062090742 seconds. Throughput is 1932.6553 records/second. Loss is 2.2510056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00987166831194472. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 8040/60000][Iteration 67][Wall Clock 5.184337063s] Trained 120 records in 0.054631996 seconds. Throughput is 2196.515 records/second. Loss is 2.2524517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00986971969996052. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:10 INFO  DistriOptimizer$:406 - [Epoch 1 8160/60000][Iteration 68][Wall Clock 5.240934101s] Trained 120 records in 0.056597038 seconds. Throughput is 2120.2522 records/second. Loss is 2.244821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009867771857114663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 8280/60000][Iteration 69][Wall Clock 5.296769255s] Trained 120 records in 0.055835154 seconds. Throughput is 2149.1836 records/second. Loss is 2.251251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009865824782951855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 8400/60000][Iteration 70][Wall Clock 5.357100084s] Trained 120 records in 0.060330829 seconds. Throughput is 1989.0328 records/second. Loss is 2.2510998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009863878477017163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 8520/60000][Iteration 71][Wall Clock 5.416627823s] Trained 120 records in 0.059527739 seconds. Throughput is 2015.867 records/second. Loss is 2.2370806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009861932938856016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 8640/60000][Iteration 72][Wall Clock 5.470540378s] Trained 120 records in 0.053912555 seconds. Throughput is 2225.8267 records/second. Loss is 2.2497644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009859988168014198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 8760/60000][Iteration 73][Wall Clock 5.530031669s] Trained 120 records in 0.059491291 seconds. Throughput is 2017.1019 records/second. Loss is 2.2300482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009858044164037856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 8880/60000][Iteration 74][Wall Clock 5.590840889s] Trained 120 records in 0.06080922 seconds. Throughput is 1973.3849 records/second. Loss is 2.2387908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009856100926473488. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9000/60000][Iteration 75][Wall Clock 5.648949152s] Trained 120 records in 0.058108263 seconds. Throughput is 2065.1108 records/second. Loss is 2.244568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009854158454867956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9120/60000][Iteration 76][Wall Clock 5.707273615s] Trained 120 records in 0.058324463 seconds. Throughput is 2057.4558 records/second. Loss is 2.2365108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009852216748768475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9240/60000][Iteration 77][Wall Clock 5.773423254s] Trained 120 records in 0.066149639 seconds. Throughput is 1814.069 records/second. Loss is 2.2399735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009850275807722615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9360/60000][Iteration 78][Wall Clock 5.836275408s] Trained 120 records in 0.062852154 seconds. Throughput is 1909.2426 records/second. Loss is 2.2294707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009848335631278314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9480/60000][Iteration 79][Wall Clock 5.891351375s] Trained 120 records in 0.055075967 seconds. Throughput is 2178.8088 records/second. Loss is 2.2313619. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009846396218983852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9600/60000][Iteration 80][Wall Clock 5.946178011s] Trained 120 records in 0.054826636 seconds. Throughput is 2188.7173 records/second. Loss is 2.237715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009844457570387872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9720/60000][Iteration 81][Wall Clock 6.002043886s] Trained 120 records in 0.055865875 seconds. Throughput is 2148.0017 records/second. Loss is 2.2311926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00984251968503937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9840/60000][Iteration 82][Wall Clock 6.056540661s] Trained 120 records in 0.054496775 seconds. Throughput is 2201.965 records/second. Loss is 2.2234683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0098405825624877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 9960/60000][Iteration 83][Wall Clock 6.120080863s] Trained 120 records in 0.063540202 seconds. Throughput is 1888.568 records/second. Loss is 2.229847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009838646202282567. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 10080/60000][Iteration 84][Wall Clock 6.177044091s] Trained 120 records in 0.056963228 seconds. Throughput is 2106.6223 records/second. Loss is 2.226559. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009836710603974032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:11 INFO  DistriOptimizer$:406 - [Epoch 1 10200/60000][Iteration 85][Wall Clock 6.232122711s] Trained 120 records in 0.05507862 seconds. Throughput is 2178.7039 records/second. Loss is 2.2303722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009834775767112511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 10320/60000][Iteration 86][Wall Clock 6.287734526s] Trained 120 records in 0.055611815 seconds. Throughput is 2157.815 records/second. Loss is 2.2293317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009832841691248772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 10440/60000][Iteration 87][Wall Clock 6.343648019s] Trained 120 records in 0.055913493 seconds. Throughput is 2146.1724 records/second. Loss is 2.2328694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009830908375933936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 10560/60000][Iteration 88][Wall Clock 6.399054422s] Trained 120 records in 0.055406403 seconds. Throughput is 2165.8147 records/second. Loss is 2.2278562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00982897582071948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 10680/60000][Iteration 89][Wall Clock 6.461670989s] Trained 120 records in 0.062616567 seconds. Throughput is 1916.4258 records/second. Loss is 2.2132313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009827044025157232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 10800/60000][Iteration 90][Wall Clock 6.520065007s] Trained 120 records in 0.058394018 seconds. Throughput is 2055.005 records/second. Loss is 2.2172732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009825112988799371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 10920/60000][Iteration 91][Wall Clock 6.573956726s] Trained 120 records in 0.053891719 seconds. Throughput is 2226.6873 records/second. Loss is 2.2258615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009823182711198428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11040/60000][Iteration 92][Wall Clock 6.627873579s] Trained 120 records in 0.053916853 seconds. Throughput is 2225.6492 records/second. Loss is 2.209525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009821253191907287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11160/60000][Iteration 93][Wall Clock 6.681500492s] Trained 120 records in 0.053626913 seconds. Throughput is 2237.6824 records/second. Loss is 2.2124472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009819324430479184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11280/60000][Iteration 94][Wall Clock 6.736215561s] Trained 120 records in 0.054715069 seconds. Throughput is 2193.1802 records/second. Loss is 2.2133136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009817396426467702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11400/60000][Iteration 95][Wall Clock 6.799816312s] Trained 120 records in 0.063600751 seconds. Throughput is 1886.7703 records/second. Loss is 2.213063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009815469179426778. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11520/60000][Iteration 96][Wall Clock 6.86224507s] Trained 120 records in 0.062428758 seconds. Throughput is 1922.191 records/second. Loss is 2.209239. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009813542688910697. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11640/60000][Iteration 97][Wall Clock 6.918497502s] Trained 120 records in 0.056252432 seconds. Throughput is 2133.2412 records/second. Loss is 2.2230175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009811616954474096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11760/60000][Iteration 98][Wall Clock 6.974356138s] Trained 120 records in 0.055858636 seconds. Throughput is 2148.2803 records/second. Loss is 2.2149422. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009809691975671964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 11880/60000][Iteration 99][Wall Clock 7.032829092s] Trained 120 records in 0.058472954 seconds. Throughput is 2052.231 records/second. Loss is 2.206114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00980776775205963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 12000/60000][Iteration 100][Wall Clock 7.092050058s] Trained 120 records in 0.059220966 seconds. Throughput is 2026.3094 records/second. Loss is 2.2052019. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009805844283192783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 12120/60000][Iteration 101][Wall Clock 7.147694077s] Trained 120 records in 0.055644019 seconds. Throughput is 2156.566 records/second. Loss is 2.2078362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00980392156862745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:12 INFO  DistriOptimizer$:406 - [Epoch 1 12240/60000][Iteration 102][Wall Clock 7.225193799s] Trained 120 records in 0.077499722 seconds. Throughput is 1548.3926 records/second. Loss is 2.2164586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009801999607920015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 12360/60000][Iteration 103][Wall Clock 7.286617644s] Trained 120 records in 0.061423845 seconds. Throughput is 1953.6387 records/second. Loss is 2.1978962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009800078400627205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 12480/60000][Iteration 104][Wall Clock 7.343443667s] Trained 120 records in 0.056826023 seconds. Throughput is 2111.7087 records/second. Loss is 2.1959314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009798157946306094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 12600/60000][Iteration 105][Wall Clock 7.40340183s] Trained 120 records in 0.059958163 seconds. Throughput is 2001.3955 records/second. Loss is 2.1953669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009796238244514107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 12720/60000][Iteration 106][Wall Clock 7.46081699s] Trained 120 records in 0.05741516 seconds. Throughput is 2090.0403 records/second. Loss is 2.195514. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009794319294809012. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 12840/60000][Iteration 107][Wall Clock 7.52452164s] Trained 120 records in 0.06370465 seconds. Throughput is 1883.693 records/second. Loss is 2.199906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009792401096748922. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 12960/60000][Iteration 108][Wall Clock 7.580033853s] Trained 120 records in 0.055512213 seconds. Throughput is 2161.6865 records/second. Loss is 2.2027433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009790483649892304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13080/60000][Iteration 109][Wall Clock 7.641398432s] Trained 120 records in 0.061364579 seconds. Throughput is 1955.5255 records/second. Loss is 2.1796699. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009788566953797963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13200/60000][Iteration 110][Wall Clock 7.702881842s] Trained 120 records in 0.06148341 seconds. Throughput is 1951.746 records/second. Loss is 2.188375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009786651008025053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13320/60000][Iteration 111][Wall Clock 7.757669782s] Trained 120 records in 0.05478794 seconds. Throughput is 2190.263 records/second. Loss is 2.1785579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009784735812133072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13440/60000][Iteration 112][Wall Clock 7.811293856s] Trained 120 records in 0.053624074 seconds. Throughput is 2237.8008 records/second. Loss is 2.1857533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009782821365681862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13560/60000][Iteration 113][Wall Clock 7.864794315s] Trained 120 records in 0.053500459 seconds. Throughput is 2242.9714 records/second. Loss is 2.2033095. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009780907668231613. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13680/60000][Iteration 114][Wall Clock 7.919582056s] Trained 120 records in 0.054787741 seconds. Throughput is 2190.271 records/second. Loss is 2.1668882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009778994719342852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13800/60000][Iteration 115][Wall Clock 7.975345355s] Trained 120 records in 0.055763299 seconds. Throughput is 2151.953 records/second. Loss is 2.1639369. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009777082518576457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 13920/60000][Iteration 116][Wall Clock 8.035679277s] Trained 120 records in 0.060333922 seconds. Throughput is 1988.9309 records/second. Loss is 2.174249. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009775171065493648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 14040/60000][Iteration 117][Wall Clock 8.095640958s] Trained 120 records in 0.059961681 seconds. Throughput is 2001.2782 records/second. Loss is 2.1623063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009773260359655981. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 14160/60000][Iteration 118][Wall Clock 8.152513186s] Trained 120 records in 0.056872228 seconds. Throughput is 2109.993 records/second. Loss is 2.1848993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009771350400625366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:13 INFO  DistriOptimizer$:406 - [Epoch 1 14280/60000][Iteration 119][Wall Clock 8.212578198s] Trained 120 records in 0.060065012 seconds. Throughput is 1997.8352 records/second. Loss is 2.1740286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009769441187964047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 14400/60000][Iteration 120][Wall Clock 8.272973075s] Trained 120 records in 0.060394877 seconds. Throughput is 1986.9236 records/second. Loss is 2.1771903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009767532721234616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 14520/60000][Iteration 121][Wall Clock 8.327385443s] Trained 120 records in 0.054412368 seconds. Throughput is 2205.3809 records/second. Loss is 2.1816218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009765625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 14640/60000][Iteration 122][Wall Clock 8.381580582s] Trained 120 records in 0.054195139 seconds. Throughput is 2214.2207 records/second. Loss is 2.1777015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009763718023823472. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 14760/60000][Iteration 123][Wall Clock 8.436681497s] Trained 120 records in 0.055100915 seconds. Throughput is 2177.8223 records/second. Loss is 2.1592507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009761811792268645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 14880/60000][Iteration 124][Wall Clock 8.49978901s] Trained 120 records in 0.063107513 seconds. Throughput is 1901.5168 records/second. Loss is 2.1611803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009759906304899474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15000/60000][Iteration 125][Wall Clock 8.562297631s] Trained 120 records in 0.062508621 seconds. Throughput is 1919.7352 records/second. Loss is 2.1556227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00975800156128025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15120/60000][Iteration 126][Wall Clock 8.619304189s] Trained 120 records in 0.057006558 seconds. Throughput is 2105.021 records/second. Loss is 2.1706913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009756097560975611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15240/60000][Iteration 127][Wall Clock 8.673880171s] Trained 120 records in 0.054575982 seconds. Throughput is 2198.7693 records/second. Loss is 2.1351228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009754194303550527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15360/60000][Iteration 128][Wall Clock 8.728614843s] Trained 120 records in 0.054734672 seconds. Throughput is 2192.3945 records/second. Loss is 2.1614168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009752291788570313. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15480/60000][Iteration 129][Wall Clock 8.782947812s] Trained 120 records in 0.054332969 seconds. Throughput is 2208.6038 records/second. Loss is 2.1320884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009750390015600624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15600/60000][Iteration 130][Wall Clock 8.836170376s] Trained 120 records in 0.053222564 seconds. Throughput is 2254.6829 records/second. Loss is 2.1401937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009748488984207448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15720/60000][Iteration 131][Wall Clock 8.888999073s] Trained 120 records in 0.052828697 seconds. Throughput is 2271.4927 records/second. Loss is 2.1506076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009746588693957114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15840/60000][Iteration 132][Wall Clock 8.953804017s] Trained 120 records in 0.064804944 seconds. Throughput is 1851.7107 records/second. Loss is 2.16107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009744689144416294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 15960/60000][Iteration 133][Wall Clock 9.016352076s] Trained 120 records in 0.062548059 seconds. Throughput is 1918.5249 records/second. Loss is 2.1583607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009742790335151987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 16080/60000][Iteration 134][Wall Clock 9.070602773s] Trained 120 records in 0.054250697 seconds. Throughput is 2211.9531 records/second. Loss is 2.1503184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009740892265731542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 16200/60000][Iteration 135][Wall Clock 9.122653686s] Trained 120 records in 0.052050913 seconds. Throughput is 2305.435 records/second. Loss is 2.1550224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009738994935722634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 16320/60000][Iteration 136][Wall Clock 9.177597507s] Trained 120 records in 0.054943821 seconds. Throughput is 2184.049 records/second. Loss is 2.1316016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009737098344693282. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:14 INFO  DistriOptimizer$:406 - [Epoch 1 16440/60000][Iteration 137][Wall Clock 9.235367059s] Trained 120 records in 0.057769552 seconds. Throughput is 2077.2188 records/second. Loss is 2.141656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009735202492211837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 16560/60000][Iteration 138][Wall Clock 9.292564056s] Trained 120 records in 0.057196997 seconds. Throughput is 2098.0122 records/second. Loss is 2.1351418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009733307377846992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 16680/60000][Iteration 139][Wall Clock 9.347622651s] Trained 120 records in 0.055058595 seconds. Throughput is 2179.4963 records/second. Loss is 2.1076534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009731413001167769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 16800/60000][Iteration 140][Wall Clock 9.400935906s] Trained 120 records in 0.053313255 seconds. Throughput is 2250.8474 records/second. Loss is 2.1318445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00972951936174353. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 16920/60000][Iteration 141][Wall Clock 9.459212003s] Trained 120 records in 0.058276097 seconds. Throughput is 2059.1633 records/second. Loss is 2.105639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009727626459143969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17040/60000][Iteration 142][Wall Clock 9.517218419s] Trained 120 records in 0.058006416 seconds. Throughput is 2068.7366 records/second. Loss is 2.12179. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009725734292939117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17160/60000][Iteration 143][Wall Clock 9.570755388s] Trained 120 records in 0.053536969 seconds. Throughput is 2241.4417 records/second. Loss is 2.1273637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009723842862699339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17280/60000][Iteration 144][Wall Clock 9.63533507s] Trained 120 records in 0.064579682 seconds. Throughput is 1858.1696 records/second. Loss is 2.1169717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009721952167995334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17400/60000][Iteration 145][Wall Clock 9.689148341s] Trained 120 records in 0.053813271 seconds. Throughput is 2229.933 records/second. Loss is 2.1060398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009720062208398135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17520/60000][Iteration 146][Wall Clock 9.741532524s] Trained 120 records in 0.052384183 seconds. Throughput is 2290.7678 records/second. Loss is 2.103026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009718172983479108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17640/60000][Iteration 147][Wall Clock 9.792172902s] Trained 120 records in 0.050640378 seconds. Throughput is 2369.6506 records/second. Loss is 2.092611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009716284492809951. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17760/60000][Iteration 148][Wall Clock 9.843170051s] Trained 120 records in 0.050997149 seconds. Throughput is 2353.0728 records/second. Loss is 2.108758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009714396735962695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 17880/60000][Iteration 149][Wall Clock 9.89320694s] Trained 120 records in 0.050036889 seconds. Throughput is 2398.2307 records/second. Loss is 2.1118076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009712509712509712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 18000/60000][Iteration 150][Wall Clock 9.952969303s] Trained 120 records in 0.059762363 seconds. Throughput is 2007.9528 records/second. Loss is 2.0896268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009710623422023694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 18120/60000][Iteration 151][Wall Clock 10.009634453s] Trained 120 records in 0.05666515 seconds. Throughput is 2117.7039 records/second. Loss is 2.1016135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009708737864077669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 18240/60000][Iteration 152][Wall Clock 10.061796428s] Trained 120 records in 0.052161975 seconds. Throughput is 2300.5264 records/second. Loss is 2.0893054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009706853038245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 18360/60000][Iteration 153][Wall Clock 10.115165897s] Trained 120 records in 0.053369469 seconds. Throughput is 2248.4766 records/second. Loss is 2.1071084. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00970496894409938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 18480/60000][Iteration 154][Wall Clock 10.166549845s] Trained 120 records in 0.051383948 seconds. Throughput is 2335.3596 records/second. Loss is 2.0926154. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009703085581214826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:15 INFO  DistriOptimizer$:406 - [Epoch 1 18600/60000][Iteration 155][Wall Clock 10.21689726s] Trained 120 records in 0.050347415 seconds. Throughput is 2383.4392 records/second. Loss is 2.1039312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009701202949165696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 18720/60000][Iteration 156][Wall Clock 10.26937733s] Trained 120 records in 0.05248007 seconds. Throughput is 2286.5823 records/second. Loss is 2.0769427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009699321047526674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 18840/60000][Iteration 157][Wall Clock 10.320588142s] Trained 120 records in 0.051210812 seconds. Throughput is 2343.2551 records/second. Loss is 2.0843542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00969743987587277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 18960/60000][Iteration 158][Wall Clock 10.371453802s] Trained 120 records in 0.05086566 seconds. Throughput is 2359.1555 records/second. Loss is 2.0779364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009695559433779328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19080/60000][Iteration 159][Wall Clock 10.422236497s] Trained 120 records in 0.050782695 seconds. Throughput is 2363.0098 records/second. Loss is 2.0751054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009693679720822024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19200/60000][Iteration 160][Wall Clock 10.478298717s] Trained 120 records in 0.05606222 seconds. Throughput is 2140.4788 records/second. Loss is 2.0692017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009691800736576855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19320/60000][Iteration 161][Wall Clock 10.538042954s] Trained 120 records in 0.059744237 seconds. Throughput is 2008.5619 records/second. Loss is 2.0713716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009689922480620155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19440/60000][Iteration 162][Wall Clock 10.588182319s] Trained 120 records in 0.050139365 seconds. Throughput is 2393.329 records/second. Loss is 2.0631988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00968804495252858. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19560/60000][Iteration 163][Wall Clock 10.639091908s] Trained 120 records in 0.050909589 seconds. Throughput is 2357.1196 records/second. Loss is 2.051657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009686168151879117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19680/60000][Iteration 164][Wall Clock 10.689842175s] Trained 120 records in 0.050750267 seconds. Throughput is 2364.5195 records/second. Loss is 2.0419192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00968429207824908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19800/60000][Iteration 165][Wall Clock 10.740723151s] Trained 120 records in 0.050880976 seconds. Throughput is 2358.4453 records/second. Loss is 2.0533822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009682416731216113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 19920/60000][Iteration 166][Wall Clock 10.790040056s] Trained 120 records in 0.049316905 seconds. Throughput is 2433.2427 records/second. Loss is 2.0637596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009680542110358181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20040/60000][Iteration 167][Wall Clock 10.84097591s] Trained 120 records in 0.050935854 seconds. Throughput is 2355.9043 records/second. Loss is 2.0464468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009678668215253582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20160/60000][Iteration 168][Wall Clock 10.891397866s] Trained 120 records in 0.050421956 seconds. Throughput is 2379.9155 records/second. Loss is 2.0638957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009676795045480935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20280/60000][Iteration 169][Wall Clock 10.943461967s] Trained 120 records in 0.052064101 seconds. Throughput is 2304.851 records/second. Loss is 2.0585268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009674922600619194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20400/60000][Iteration 170][Wall Clock 10.994415157s] Trained 120 records in 0.05095319 seconds. Throughput is 2355.1028 records/second. Loss is 2.0424438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009673050880247629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20520/60000][Iteration 171][Wall Clock 11.056653473s] Trained 120 records in 0.062238316 seconds. Throughput is 1928.0728 records/second. Loss is 2.048445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009671179883945842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20640/60000][Iteration 172][Wall Clock 11.109018185s] Trained 120 records in 0.052364712 seconds. Throughput is 2291.6196 records/second. Loss is 2.0494468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009669309611293754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20760/60000][Iteration 173][Wall Clock 11.164939878s] Trained 120 records in 0.055921693 seconds. Throughput is 2145.858 records/second. Loss is 2.0148168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009667440061871617. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:16 INFO  DistriOptimizer$:406 - [Epoch 1 20880/60000][Iteration 174][Wall Clock 11.227636631s] Trained 120 records in 0.062696753 seconds. Throughput is 1913.9746 records/second. Loss is 2.0146372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009665571235260004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21000/60000][Iteration 175][Wall Clock 11.280778134s] Trained 120 records in 0.053141503 seconds. Throughput is 2258.122 records/second. Loss is 2.0226264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009663703131039815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21120/60000][Iteration 176][Wall Clock 11.330814731s] Trained 120 records in 0.050036597 seconds. Throughput is 2398.2446 records/second. Loss is 2.0372403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009661835748792272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21240/60000][Iteration 177][Wall Clock 11.382403025s] Trained 120 records in 0.051588294 seconds. Throughput is 2326.1091 records/second. Loss is 2.0050623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00965996908809892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21360/60000][Iteration 178][Wall Clock 11.433574374s] Trained 120 records in 0.051171349 seconds. Throughput is 2345.0623 records/second. Loss is 1.9950911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009658103148541626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21480/60000][Iteration 179][Wall Clock 11.48317276s] Trained 120 records in 0.049598386 seconds. Throughput is 2419.4336 records/second. Loss is 2.0137467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009656237929702587. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21600/60000][Iteration 180][Wall Clock 11.533302867s] Trained 120 records in 0.050130107 seconds. Throughput is 2393.771 records/second. Loss is 2.0223596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009654373431164317. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21720/60000][Iteration 181][Wall Clock 11.58593203s] Trained 120 records in 0.052629163 seconds. Throughput is 2280.1047 records/second. Loss is 1.9950097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009652509652509652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21840/60000][Iteration 182][Wall Clock 11.646251403s] Trained 120 records in 0.060319373 seconds. Throughput is 1989.4106 records/second. Loss is 2.0036533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009650646593321753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 21960/60000][Iteration 183][Wall Clock 11.702891917s] Trained 120 records in 0.056640514 seconds. Throughput is 2118.6248 records/second. Loss is 1.9912864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0096487842531841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22080/60000][Iteration 184][Wall Clock 11.753618748s] Trained 120 records in 0.050726831 seconds. Throughput is 2365.612 records/second. Loss is 2.0051372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009646922631680495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22200/60000][Iteration 185][Wall Clock 11.807416289s] Trained 120 records in 0.053797541 seconds. Throughput is 2230.5852 records/second. Loss is 1.9766695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009645061728395063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22320/60000][Iteration 186][Wall Clock 11.863070379s] Trained 120 records in 0.05565409 seconds. Throughput is 2156.1758 records/second. Loss is 1.9648354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009643201542912247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22440/60000][Iteration 187][Wall Clock 11.915369786s] Trained 120 records in 0.052299407 seconds. Throughput is 2294.4812 records/second. Loss is 1.9755461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009641342074816815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22560/60000][Iteration 188][Wall Clock 11.970853614s] Trained 120 records in 0.055483828 seconds. Throughput is 2162.7922 records/second. Loss is 1.9569918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009639483323693849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22680/60000][Iteration 189][Wall Clock 12.020745287s] Trained 120 records in 0.049891673 seconds. Throughput is 2405.211 records/second. Loss is 1.9672227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009637625289128758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22800/60000][Iteration 190][Wall Clock 12.071522203s] Trained 120 records in 0.050776916 seconds. Throughput is 2363.2786 records/second. Loss is 1.9815687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009635767970707265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 22920/60000][Iteration 191][Wall Clock 12.123140157s] Trained 120 records in 0.051617954 seconds. Throughput is 2324.7725 records/second. Loss is 1.9791417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009633911368015413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 23040/60000][Iteration 192][Wall Clock 12.176621491s] Trained 120 records in 0.053481334 seconds. Throughput is 2243.7734 records/second. Loss is 1.9854864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009632055480639569. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:17 INFO  DistriOptimizer$:406 - [Epoch 1 23160/60000][Iteration 193][Wall Clock 12.233115505s] Trained 120 records in 0.056494014 seconds. Throughput is 2124.119 records/second. Loss is 1.9923484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009630200308166411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 23280/60000][Iteration 194][Wall Clock 12.289911707s] Trained 120 records in 0.056796202 seconds. Throughput is 2112.8174 records/second. Loss is 1.9524366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00962834585018294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 23400/60000][Iteration 195][Wall Clock 12.340993538s] Trained 120 records in 0.051081831 seconds. Throughput is 2349.1719 records/second. Loss is 1.9234167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009626492106276474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 23520/60000][Iteration 196][Wall Clock 12.390255738s] Trained 120 records in 0.0492622 seconds. Throughput is 2435.9448 records/second. Loss is 1.9380485. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00962463907603465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 23640/60000][Iteration 197][Wall Clock 12.439808972s] Trained 120 records in 0.049553234 seconds. Throughput is 2421.6382 records/second. Loss is 1.9829171. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009622786759045421. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 23760/60000][Iteration 198][Wall Clock 12.49399869s] Trained 120 records in 0.054189718 seconds. Throughput is 2214.4421 records/second. Loss is 1.9622716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009620935154897056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 23880/60000][Iteration 199][Wall Clock 12.549864784s] Trained 120 records in 0.055866094 seconds. Throughput is 2147.9934 records/second. Loss is 1.907168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009619084263178144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24000/60000][Iteration 200][Wall Clock 12.600927196s] Trained 120 records in 0.051062412 seconds. Throughput is 2350.0652 records/second. Loss is 1.9048258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009617234083477592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24120/60000][Iteration 201][Wall Clock 12.650482006s] Trained 120 records in 0.04955481 seconds. Throughput is 2421.561 records/second. Loss is 1.9374436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009615384615384616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24240/60000][Iteration 202][Wall Clock 12.699963741s] Trained 120 records in 0.049481735 seconds. Throughput is 2425.1372 records/second. Loss is 1.9077522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009613535858488752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24360/60000][Iteration 203][Wall Clock 12.749391574s] Trained 120 records in 0.049427833 seconds. Throughput is 2427.782 records/second. Loss is 1.9138074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009611687812379853. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24480/60000][Iteration 204][Wall Clock 12.800230046s] Trained 120 records in 0.050838472 seconds. Throughput is 2360.4172 records/second. Loss is 1.947592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009609840476648089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24600/60000][Iteration 205][Wall Clock 12.849369559s] Trained 120 records in 0.049139513 seconds. Throughput is 2442.0266 records/second. Loss is 1.9458774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009607993850883937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24720/60000][Iteration 206][Wall Clock 12.910725727s] Trained 120 records in 0.061356168 seconds. Throughput is 1955.7936 records/second. Loss is 1.898183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009606147934678195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24840/60000][Iteration 207][Wall Clock 12.960897907s] Trained 120 records in 0.05017218 seconds. Throughput is 2391.7637 records/second. Loss is 1.9109433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009604302727621975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 24960/60000][Iteration 208][Wall Clock 13.011488331s] Trained 120 records in 0.050590424 seconds. Throughput is 2371.9902 records/second. Loss is 1.8946198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009602458229306702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 25080/60000][Iteration 209][Wall Clock 13.06184681s] Trained 120 records in 0.050358479 seconds. Throughput is 2382.9155 records/second. Loss is 1.8750894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009600614439324116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 25200/60000][Iteration 210][Wall Clock 13.111781844s] Trained 120 records in 0.049935034 seconds. Throughput is 2403.1223 records/second. Loss is 1.9108632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00959877135726627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 25320/60000][Iteration 211][Wall Clock 13.161604942s] Trained 120 records in 0.049823098 seconds. Throughput is 2408.5215 records/second. Loss is 1.8106765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009596928982725527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:18 INFO  DistriOptimizer$:406 - [Epoch 1 25440/60000][Iteration 212][Wall Clock 13.213136574s] Trained 120 records in 0.051531632 seconds. Throughput is 2328.6667 records/second. Loss is 1.9071152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009595087315294569. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 25560/60000][Iteration 213][Wall Clock 13.262100851s] Trained 120 records in 0.048964277 seconds. Throughput is 2450.7664 records/second. Loss is 1.8356833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009593246354566386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 25680/60000][Iteration 214][Wall Clock 13.314525967s] Trained 120 records in 0.052425116 seconds. Throughput is 2288.9792 records/second. Loss is 1.9160732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00959140610013428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 25800/60000][Iteration 215][Wall Clock 13.366382265s] Trained 120 records in 0.051856298 seconds. Throughput is 2314.0874 records/second. Loss is 1.889767. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009589566551591868. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 25920/60000][Iteration 216][Wall Clock 13.415782683s] Trained 120 records in 0.049400418 seconds. Throughput is 2429.1292 records/second. Loss is 1.8760391. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009587727708533078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26040/60000][Iteration 217][Wall Clock 13.464392687s] Trained 120 records in 0.048610004 seconds. Throughput is 2468.6277 records/second. Loss is 1.8061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00958588957055215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26160/60000][Iteration 218][Wall Clock 13.51974424s] Trained 120 records in 0.055351553 seconds. Throughput is 2167.961 records/second. Loss is 1.8620347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009584052137243625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26280/60000][Iteration 219][Wall Clock 13.5738981s] Trained 120 records in 0.05415386 seconds. Throughput is 2215.9084 records/second. Loss is 1.8720797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009582215408202376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26400/60000][Iteration 220][Wall Clock 13.629871169s] Trained 120 records in 0.055973069 seconds. Throughput is 2143.8882 records/second. Loss is 1.866502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009580379383023568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26520/60000][Iteration 221][Wall Clock 13.682464436s] Trained 120 records in 0.052593267 seconds. Throughput is 2281.661 records/second. Loss is 1.7915974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009578544061302681. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26640/60000][Iteration 222][Wall Clock 13.734199728s] Trained 120 records in 0.051735292 seconds. Throughput is 2319.4998 records/second. Loss is 1.8574488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00957670944263551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26760/60000][Iteration 223][Wall Clock 13.78924692s] Trained 120 records in 0.055047192 seconds. Throughput is 2179.9478 records/second. Loss is 1.8431593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009574875526618154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 26880/60000][Iteration 224][Wall Clock 13.839498667s] Trained 120 records in 0.050251747 seconds. Throughput is 2387.9766 records/second. Loss is 1.8647636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009573042312847023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 27000/60000][Iteration 225][Wall Clock 13.901162805s] Trained 120 records in 0.061664138 seconds. Throughput is 1946.0258 records/second. Loss is 1.8309749. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009571209800918837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 27120/60000][Iteration 226][Wall Clock 13.953428194s] Trained 120 records in 0.052265389 seconds. Throughput is 2295.9744 records/second. Loss is 1.907118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009569377990430623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 27240/60000][Iteration 227][Wall Clock 14.004149017s] Trained 120 records in 0.050720823 seconds. Throughput is 2365.8923 records/second. Loss is 1.8393868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009567546880979718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 27360/60000][Iteration 228][Wall Clock 14.061402832s] Trained 120 records in 0.057253815 seconds. Throughput is 2095.9302 records/second. Loss is 1.8322369. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009565716472163765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 27480/60000][Iteration 229][Wall Clock 14.111813083s] Trained 120 records in 0.050410251 seconds. Throughput is 2380.4683 records/second. Loss is 1.7902046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009563886763580718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 27600/60000][Iteration 230][Wall Clock 14.163962898s] Trained 120 records in 0.052149815 seconds. Throughput is 2301.063 records/second. Loss is 1.7722759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009562057754828839. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:19 INFO  DistriOptimizer$:406 - [Epoch 1 27720/60000][Iteration 231][Wall Clock 14.218712032s] Trained 120 records in 0.054749134 seconds. Throughput is 2191.8154 records/second. Loss is 1.7484472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009560229445506692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 27840/60000][Iteration 232][Wall Clock 14.286533251s] Trained 120 records in 0.067821219 seconds. Throughput is 1769.3578 records/second. Loss is 1.7598166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009558401835213153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 27960/60000][Iteration 233][Wall Clock 14.340549606s] Trained 120 records in 0.054016355 seconds. Throughput is 2221.5493 records/second. Loss is 1.8283455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0095565749235474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28080/60000][Iteration 234][Wall Clock 14.391994982s] Trained 120 records in 0.051445376 seconds. Throughput is 2332.571 records/second. Loss is 1.8258301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009554748710108925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28200/60000][Iteration 235][Wall Clock 14.451320053s] Trained 120 records in 0.059325071 seconds. Throughput is 2022.7537 records/second. Loss is 1.7679688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009552923194497517. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28320/60000][Iteration 236][Wall Clock 14.508825344s] Trained 120 records in 0.057505291 seconds. Throughput is 2086.7644 records/second. Loss is 1.7630174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009551098376313277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28440/60000][Iteration 237][Wall Clock 14.565096311s] Trained 120 records in 0.056270967 seconds. Throughput is 2132.5383 records/second. Loss is 1.7734827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00954927425515661. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28560/60000][Iteration 238][Wall Clock 14.615803389s] Trained 120 records in 0.050707078 seconds. Throughput is 2366.5334 records/second. Loss is 1.7652967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009547450830628221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28680/60000][Iteration 239][Wall Clock 14.66409032s] Trained 120 records in 0.048286931 seconds. Throughput is 2485.1445 records/second. Loss is 1.7621235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009545628102329133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28800/60000][Iteration 240][Wall Clock 14.712796263s] Trained 120 records in 0.048705943 seconds. Throughput is 2463.7651 records/second. Loss is 1.7488277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00954380606986066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 28920/60000][Iteration 241][Wall Clock 14.762210511s] Trained 120 records in 0.049414248 seconds. Throughput is 2428.4495 records/second. Loss is 1.7649539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009541984732824428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29040/60000][Iteration 242][Wall Clock 14.810383575s] Trained 120 records in 0.048173064 seconds. Throughput is 2491.0188 records/second. Loss is 1.7572455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009540164090822362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29160/60000][Iteration 243][Wall Clock 14.860834074s] Trained 120 records in 0.050450499 seconds. Throughput is 2378.569 records/second. Loss is 1.7765737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009538344143456697. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29280/60000][Iteration 244][Wall Clock 14.908324177s] Trained 120 records in 0.047490103 seconds. Throughput is 2526.8423 records/second. Loss is 1.733756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009536524890329964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29400/60000][Iteration 245][Wall Clock 14.963011548s] Trained 120 records in 0.054687371 seconds. Throughput is 2194.291 records/second. Loss is 1.7644986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009534706331045004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29520/60000][Iteration 246][Wall Clock 15.01935666s] Trained 120 records in 0.056345112 seconds. Throughput is 2129.7322 records/second. Loss is 1.8076015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009532888465204958. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29640/60000][Iteration 247][Wall Clock 15.068885062s] Trained 120 records in 0.049528402 seconds. Throughput is 2422.8523 records/second. Loss is 1.6747639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009531071292413268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29760/60000][Iteration 248][Wall Clock 15.118993082s] Trained 120 records in 0.05010802 seconds. Throughput is 2394.8262 records/second. Loss is 1.7339894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009529254812273681. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:20 INFO  DistriOptimizer$:406 - [Epoch 1 29880/60000][Iteration 249][Wall Clock 15.186447067s] Trained 120 records in 0.067453985 seconds. Throughput is 1778.9905 records/second. Loss is 1.727425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009527439024390244. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30000/60000][Iteration 250][Wall Clock 15.250732543s] Trained 120 records in 0.064285476 seconds. Throughput is 1866.6735 records/second. Loss is 1.7703959. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009525623928367307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30120/60000][Iteration 251][Wall Clock 15.30283064s] Trained 120 records in 0.052098097 seconds. Throughput is 2303.3472 records/second. Loss is 1.6590694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009523809523809523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30240/60000][Iteration 252][Wall Clock 15.358063156s] Trained 120 records in 0.055232516 seconds. Throughput is 2172.6333 records/second. Loss is 1.7287488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009521995810321843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30360/60000][Iteration 253][Wall Clock 15.413275199s] Trained 120 records in 0.055212043 seconds. Throughput is 2173.439 records/second. Loss is 1.6898707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00952018278750952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30480/60000][Iteration 254][Wall Clock 15.468034556s] Trained 120 records in 0.054759357 seconds. Throughput is 2191.4062 records/second. Loss is 1.6879703. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009518370454978109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30600/60000][Iteration 255][Wall Clock 15.518847424s] Trained 120 records in 0.050812868 seconds. Throughput is 2361.6067 records/second. Loss is 1.7562885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00951655881233346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30720/60000][Iteration 256][Wall Clock 15.570842778s] Trained 120 records in 0.051995354 seconds. Throughput is 2307.8984 records/second. Loss is 1.6907675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009514747859181733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30840/60000][Iteration 257][Wall Clock 15.628655594s] Trained 120 records in 0.057812816 seconds. Throughput is 2075.6643 records/second. Loss is 1.655762. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009512937595129377. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 30960/60000][Iteration 258][Wall Clock 15.689444433s] Trained 120 records in 0.060788839 seconds. Throughput is 1974.0465 records/second. Loss is 1.7250841. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009511128019783146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31080/60000][Iteration 259][Wall Clock 15.742080578s] Trained 120 records in 0.052636145 seconds. Throughput is 2279.8022 records/second. Loss is 1.6556382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009509319132750094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31200/60000][Iteration 260][Wall Clock 15.791489344s] Trained 120 records in 0.049408766 seconds. Throughput is 2428.7188 records/second. Loss is 1.609172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009507510933637574. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31320/60000][Iteration 261][Wall Clock 15.839823745s] Trained 120 records in 0.048334401 seconds. Throughput is 2482.7039 records/second. Loss is 1.6749636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009505703422053232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31440/60000][Iteration 262][Wall Clock 15.891580703s] Trained 120 records in 0.051756958 seconds. Throughput is 2318.5288 records/second. Loss is 1.6883106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009503896597605019. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31560/60000][Iteration 263][Wall Clock 15.941431168s] Trained 120 records in 0.049850465 seconds. Throughput is 2407.1992 records/second. Loss is 1.6217633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00950209045990118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31680/60000][Iteration 264][Wall Clock 15.991381193s] Trained 120 records in 0.049950025 seconds. Throughput is 2402.4011 records/second. Loss is 1.6510507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009500285008550257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31800/60000][Iteration 265][Wall Clock 16.042459328s] Trained 120 records in 0.051078135 seconds. Throughput is 2349.342 records/second. Loss is 1.6307942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009498480243161096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 31920/60000][Iteration 266][Wall Clock 16.092763032s] Trained 120 records in 0.050303704 seconds. Throughput is 2385.5103 records/second. Loss is 1.6575925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009496676163342831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 32040/60000][Iteration 267][Wall Clock 16.14144779s] Trained 120 records in 0.048684758 seconds. Throughput is 2464.8372 records/second. Loss is 1.6502538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0094948727687049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:21 INFO  DistriOptimizer$:406 - [Epoch 1 32160/60000][Iteration 268][Wall Clock 16.198348973s] Trained 120 records in 0.056901183 seconds. Throughput is 2108.9192 records/second. Loss is 1.6479366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009493070058857035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 32280/60000][Iteration 269][Wall Clock 16.254302338s] Trained 120 records in 0.055953365 seconds. Throughput is 2144.643 records/second. Loss is 1.6020243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009491268033409262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 32400/60000][Iteration 270][Wall Clock 16.311259387s] Trained 120 records in 0.056957049 seconds. Throughput is 2106.8508 records/second. Loss is 1.6384474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00948946669197191. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 32520/60000][Iteration 271][Wall Clock 16.360394529s] Trained 120 records in 0.049135142 seconds. Throughput is 2442.244 records/second. Loss is 1.6999168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009487666034155597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 32640/60000][Iteration 272][Wall Clock 16.412773775s] Trained 120 records in 0.052379246 seconds. Throughput is 2290.9836 records/second. Loss is 1.6315476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00948586605957124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 32760/60000][Iteration 273][Wall Clock 16.465622426s] Trained 120 records in 0.052848651 seconds. Throughput is 2270.635 records/second. Loss is 1.6202906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009484066767830045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 32880/60000][Iteration 274][Wall Clock 16.521970815s] Trained 120 records in 0.056348389 seconds. Throughput is 2129.6084 records/second. Loss is 1.5901083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009482268158543524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33000/60000][Iteration 275][Wall Clock 16.570158045s] Trained 120 records in 0.04818723 seconds. Throughput is 2490.2864 records/second. Loss is 1.6774975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009480470231323474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33120/60000][Iteration 276][Wall Clock 16.62079988s] Trained 120 records in 0.050641835 seconds. Throughput is 2369.5823 records/second. Loss is 1.6163633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009478672985781991. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33240/60000][Iteration 277][Wall Clock 16.676548123s] Trained 120 records in 0.055748243 seconds. Throughput is 2152.5342 records/second. Loss is 1.6017984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009476876421531465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33360/60000][Iteration 278][Wall Clock 16.730014424s] Trained 120 records in 0.053466301 seconds. Throughput is 2244.4043 records/second. Loss is 1.6021477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009475080538184574. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33480/60000][Iteration 279][Wall Clock 16.776476979s] Trained 120 records in 0.046462555 seconds. Throughput is 2582.725 records/second. Loss is 1.5661628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0094732853353543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33600/60000][Iteration 280][Wall Clock 16.824420307s] Trained 120 records in 0.047943328 seconds. Throughput is 2502.955 records/second. Loss is 1.5833558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009471490812653912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33720/60000][Iteration 281][Wall Clock 16.871314606s] Trained 120 records in 0.046894299 seconds. Throughput is 2558.9463 records/second. Loss is 1.6768993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00946969696969697. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33840/60000][Iteration 282][Wall Clock 16.919462879s] Trained 120 records in 0.048148273 seconds. Throughput is 2492.3013 records/second. Loss is 1.6000731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00946790380609733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 33960/60000][Iteration 283][Wall Clock 16.967322659s] Trained 120 records in 0.04785978 seconds. Throughput is 2507.3245 records/second. Loss is 1.5391608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00946611132146914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 34080/60000][Iteration 284][Wall Clock 17.017311922s] Trained 120 records in 0.049989263 seconds. Throughput is 2400.5154 records/second. Loss is 1.5464312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00946431951542684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 34200/60000][Iteration 285][Wall Clock 17.06581665s] Trained 120 records in 0.048504728 seconds. Throughput is 2473.9856 records/second. Loss is 1.5851653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009462528387585163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 34320/60000][Iteration 286][Wall Clock 17.115684502s] Trained 120 records in 0.049867852 seconds. Throughput is 2406.3599 records/second. Loss is 1.5061386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00946073793755913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:22 INFO  DistriOptimizer$:406 - [Epoch 1 34440/60000][Iteration 287][Wall Clock 17.163629847s] Trained 120 records in 0.047945345 seconds. Throughput is 2502.8499 records/second. Loss is 1.6598217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009458948164964056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 34560/60000][Iteration 288][Wall Clock 17.211777688s] Trained 120 records in 0.048147841 seconds. Throughput is 2492.3235 records/second. Loss is 1.4880484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00945715906941555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 34680/60000][Iteration 289][Wall Clock 17.259327674s] Trained 120 records in 0.047549986 seconds. Throughput is 2523.6602 records/second. Loss is 1.5303962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0094553706505295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 34800/60000][Iteration 290][Wall Clock 17.307040547s] Trained 120 records in 0.047712873 seconds. Throughput is 2515.0444 records/second. Loss is 1.4925635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009453582907922102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 34920/60000][Iteration 291][Wall Clock 17.354208686s] Trained 120 records in 0.047168139 seconds. Throughput is 2544.09 records/second. Loss is 1.5515155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00945179584120983. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35040/60000][Iteration 292][Wall Clock 17.411796635s] Trained 120 records in 0.057587949 seconds. Throughput is 2083.7693 records/second. Loss is 1.4969271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00945000945000945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35160/60000][Iteration 293][Wall Clock 17.473645824s] Trained 120 records in 0.061849189 seconds. Throughput is 1940.2034 records/second. Loss is 1.4996026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00944822373393802. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35280/60000][Iteration 294][Wall Clock 17.525103826s] Trained 120 records in 0.051458002 seconds. Throughput is 2331.9988 records/second. Loss is 1.4992645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009446438692612885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35400/60000][Iteration 295][Wall Clock 17.574980918s] Trained 120 records in 0.049877092 seconds. Throughput is 2405.914 records/second. Loss is 1.6026605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009444654325651681. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35520/60000][Iteration 296][Wall Clock 17.623744174s] Trained 120 records in 0.048763256 seconds. Throughput is 2460.8694 records/second. Loss is 1.5410644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009442870632672334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35640/60000][Iteration 297][Wall Clock 17.670778207s] Trained 120 records in 0.047034033 seconds. Throughput is 2551.344 records/second. Loss is 1.543518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009441087613293053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35760/60000][Iteration 298][Wall Clock 17.71969659s] Trained 120 records in 0.048918383 seconds. Throughput is 2453.0657 records/second. Loss is 1.5290169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00943930526713234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 35880/60000][Iteration 299][Wall Clock 17.772520073s] Trained 120 records in 0.052823483 seconds. Throughput is 2271.7168 records/second. Loss is 1.4417374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009437523593808984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36000/60000][Iteration 300][Wall Clock 17.820599452s] Trained 120 records in 0.048079379 seconds. Throughput is 2495.8726 records/second. Loss is 1.4596788. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009435742592942064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36120/60000][Iteration 301][Wall Clock 17.877092891s] Trained 120 records in 0.056493439 seconds. Throughput is 2124.1404 records/second. Loss is 1.4475058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009433962264150943. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36240/60000][Iteration 302][Wall Clock 17.928478237s] Trained 120 records in 0.051385346 seconds. Throughput is 2335.2961 records/second. Loss is 1.5590003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009432182607055273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36360/60000][Iteration 303][Wall Clock 17.976962672s] Trained 120 records in 0.048484435 seconds. Throughput is 2475.0212 records/second. Loss is 1.5719693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00943040362127499. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36480/60000][Iteration 304][Wall Clock 18.022902272s] Trained 120 records in 0.0459396 seconds. Throughput is 2612.1255 records/second. Loss is 1.5578052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009428625306430323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36600/60000][Iteration 305][Wall Clock 18.068962134s] Trained 120 records in 0.046059862 seconds. Throughput is 2605.3052 records/second. Loss is 1.4888078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009426847662141781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36720/60000][Iteration 306][Wall Clock 18.115144883s] Trained 120 records in 0.046182749 seconds. Throughput is 2598.3728 records/second. Loss is 1.4510438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009425070688030161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:23 INFO  DistriOptimizer$:406 - [Epoch 1 36840/60000][Iteration 307][Wall Clock 18.163029257s] Trained 120 records in 0.047884374 seconds. Throughput is 2506.0366 records/second. Loss is 1.4788464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009423294383716549. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 36960/60000][Iteration 308][Wall Clock 18.215974317s] Trained 120 records in 0.05294506 seconds. Throughput is 2266.5005 records/second. Loss is 1.5221213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009421518748822312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37080/60000][Iteration 309][Wall Clock 18.264112635s] Trained 120 records in 0.048138318 seconds. Throughput is 2492.8167 records/second. Loss is 1.450591. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009419743782969102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37200/60000][Iteration 310][Wall Clock 18.319821607s] Trained 120 records in 0.055708972 seconds. Throughput is 2154.0518 records/second. Loss is 1.4270805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009417969485778865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37320/60000][Iteration 311][Wall Clock 18.366439101s] Trained 120 records in 0.046617494 seconds. Throughput is 2574.141 records/second. Loss is 1.522164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009416195856873822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37440/60000][Iteration 312][Wall Clock 18.414999527s] Trained 120 records in 0.048560426 seconds. Throughput is 2471.148 records/second. Loss is 1.4038024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009414422895876483. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37560/60000][Iteration 313][Wall Clock 18.465990502s] Trained 120 records in 0.050990975 seconds. Throughput is 2353.3577 records/second. Loss is 1.5046581. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00941265060240964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37680/60000][Iteration 314][Wall Clock 18.514073399s] Trained 120 records in 0.048082897 seconds. Throughput is 2495.69 records/second. Loss is 1.4493871. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009410878976096368. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37800/60000][Iteration 315][Wall Clock 18.560143435s] Trained 120 records in 0.046070036 seconds. Throughput is 2604.73 records/second. Loss is 1.4997007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00940910801656003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 37920/60000][Iteration 316][Wall Clock 18.609043154s] Trained 120 records in 0.048899719 seconds. Throughput is 2454.002 records/second. Loss is 1.4510814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009407337723424272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38040/60000][Iteration 317][Wall Clock 18.671093271s] Trained 120 records in 0.062050117 seconds. Throughput is 1933.9207 records/second. Loss is 1.4654288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009405568096313018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38160/60000][Iteration 318][Wall Clock 18.726069124s] Trained 120 records in 0.054975853 seconds. Throughput is 2182.7766 records/second. Loss is 1.4690927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00940379913485048. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38280/60000][Iteration 319][Wall Clock 18.777693573s] Trained 120 records in 0.051624449 seconds. Throughput is 2324.48 records/second. Loss is 1.5028704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00940203083866115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38400/60000][Iteration 320][Wall Clock 18.825477951s] Trained 120 records in 0.047784378 seconds. Throughput is 2511.281 records/second. Loss is 1.4330578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009400263207369806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38520/60000][Iteration 321][Wall Clock 18.871569003s] Trained 120 records in 0.046091052 seconds. Throughput is 2603.5422 records/second. Loss is 1.4803317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009398496240601503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38640/60000][Iteration 322][Wall Clock 18.917269338s] Trained 120 records in 0.045700335 seconds. Throughput is 2625.8013 records/second. Loss is 1.453447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009396729937981583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38760/60000][Iteration 323][Wall Clock 18.96345342s] Trained 120 records in 0.046184082 seconds. Throughput is 2598.2979 records/second. Loss is 1.312275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009394964299135663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 38880/60000][Iteration 324][Wall Clock 19.010810218s] Trained 120 records in 0.047356798 seconds. Throughput is 2533.955 records/second. Loss is 1.3040885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00939319932368965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 39000/60000][Iteration 325][Wall Clock 19.05743968s] Trained 120 records in 0.046629462 seconds. Throughput is 2573.4802 records/second. Loss is 1.4872196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009391435011269723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 39120/60000][Iteration 326][Wall Clock 19.112376793s] Trained 120 records in 0.054937113 seconds. Throughput is 2184.3157 records/second. Loss is 1.3935316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009389671361502348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:24 INFO  DistriOptimizer$:406 - [Epoch 1 39240/60000][Iteration 327][Wall Clock 19.160977339s] Trained 120 records in 0.048600546 seconds. Throughput is 2469.108 records/second. Loss is 1.3527486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009387908374014271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 39360/60000][Iteration 328][Wall Clock 19.207404549s] Trained 120 records in 0.04642721 seconds. Throughput is 2584.6912 records/second. Loss is 1.4331423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009386146048432515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 39480/60000][Iteration 329][Wall Clock 19.255238493s] Trained 120 records in 0.047833944 seconds. Throughput is 2508.6787 records/second. Loss is 1.4205204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009384384384384385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 39600/60000][Iteration 330][Wall Clock 19.302588167s] Trained 120 records in 0.047349674 seconds. Throughput is 2534.3364 records/second. Loss is 1.3769405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009382623381497467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 39720/60000][Iteration 331][Wall Clock 19.35031371s] Trained 120 records in 0.047725543 seconds. Throughput is 2514.3767 records/second. Loss is 1.375815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009380863039399624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 39840/60000][Iteration 332][Wall Clock 19.398860638s] Trained 120 records in 0.048546928 seconds. Throughput is 2471.835 records/second. Loss is 1.2928195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009379103357719002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 39960/60000][Iteration 333][Wall Clock 19.449538084s] Trained 120 records in 0.050677446 seconds. Throughput is 2367.9172 records/second. Loss is 1.3478621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009377344336084021. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40080/60000][Iteration 334][Wall Clock 19.498045969s] Trained 120 records in 0.048507885 seconds. Throughput is 2473.8247 records/second. Loss is 1.3311393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009375585974123383. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40200/60000][Iteration 335][Wall Clock 19.546433784s] Trained 120 records in 0.048387815 seconds. Throughput is 2479.9631 records/second. Loss is 1.3840048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009373828271466067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40320/60000][Iteration 336][Wall Clock 19.594627686s] Trained 120 records in 0.048193902 seconds. Throughput is 2489.9417 records/second. Loss is 1.30735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009372071227741332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40440/60000][Iteration 337][Wall Clock 19.642044085s] Trained 120 records in 0.047416399 seconds. Throughput is 2530.77 records/second. Loss is 1.3591949. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009370314842578711. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40560/60000][Iteration 338][Wall Clock 19.689969813s] Trained 120 records in 0.047925728 seconds. Throughput is 2503.8743 records/second. Loss is 1.4000182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00936855911560802. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40680/60000][Iteration 339][Wall Clock 19.73791746s] Trained 120 records in 0.047947647 seconds. Throughput is 2502.7297 records/second. Loss is 1.5003743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009366804046459348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40800/60000][Iteration 340][Wall Clock 19.784672954s] Trained 120 records in 0.046755494 seconds. Throughput is 2566.5435 records/second. Loss is 1.370741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009365049634763064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 40920/60000][Iteration 341][Wall Clock 19.830392889s] Trained 120 records in 0.045719935 seconds. Throughput is 2624.6755 records/second. Loss is 1.3651178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009363295880149813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 41040/60000][Iteration 342][Wall Clock 19.886224966s] Trained 120 records in 0.055832077 seconds. Throughput is 2149.302 records/second. Loss is 1.3426356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009361542782250515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 41160/60000][Iteration 343][Wall Clock 19.940804188s] Trained 120 records in 0.054579222 seconds. Throughput is 2198.639 records/second. Loss is 1.3543864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009359790340696368. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 41280/60000][Iteration 344][Wall Clock 19.990375679s] Trained 120 records in 0.049571491 seconds. Throughput is 2420.746 records/second. Loss is 1.478061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009358038555118848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 41400/60000][Iteration 345][Wall Clock 20.036155724s] Trained 120 records in 0.045780045 seconds. Throughput is 2621.2295 records/second. Loss is 1.3514371. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009356287425149701. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 41520/60000][Iteration 346][Wall Clock 20.082218641s] Trained 120 records in 0.046062917 seconds. Throughput is 2605.1326 records/second. Loss is 1.3501562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009354536950420956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 41640/60000][Iteration 347][Wall Clock 20.127518383s] Trained 120 records in 0.045299742 seconds. Throughput is 2649.0217 records/second. Loss is 1.2850685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00935278713056491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:25 INFO  DistriOptimizer$:406 - [Epoch 1 41760/60000][Iteration 348][Wall Clock 20.174285097s] Trained 120 records in 0.046766714 seconds. Throughput is 2565.9275 records/second. Loss is 1.4648592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009351037965214139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 41880/60000][Iteration 349][Wall Clock 20.220635682s] Trained 120 records in 0.046350585 seconds. Throughput is 2588.964 records/second. Loss is 1.3587744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009349289454001495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42000/60000][Iteration 350][Wall Clock 20.267955236s] Trained 120 records in 0.047319554 seconds. Throughput is 2535.9495 records/second. Loss is 1.3082669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009347541596560104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42120/60000][Iteration 351][Wall Clock 20.319518536s] Trained 120 records in 0.0515633 seconds. Throughput is 2327.2366 records/second. Loss is 1.3804305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009345794392523364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42240/60000][Iteration 352][Wall Clock 20.370265495s] Trained 120 records in 0.050746959 seconds. Throughput is 2364.6738 records/second. Loss is 1.3721185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009344047841524948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42360/60000][Iteration 353][Wall Clock 20.417130625s] Trained 120 records in 0.04686513 seconds. Throughput is 2560.539 records/second. Loss is 1.2487636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009342301943198805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42480/60000][Iteration 354][Wall Clock 20.461950829s] Trained 120 records in 0.044820204 seconds. Throughput is 2677.364 records/second. Loss is 1.3493602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009340556697179153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42600/60000][Iteration 355][Wall Clock 20.506519738s] Trained 120 records in 0.044568909 seconds. Throughput is 2692.46 records/second. Loss is 1.2976189. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009338812103100487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42720/60000][Iteration 356][Wall Clock 20.551626242s] Trained 120 records in 0.045106504 seconds. Throughput is 2660.37 records/second. Loss is 1.3520219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009337068160597572. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42840/60000][Iteration 357][Wall Clock 20.597764167s] Trained 120 records in 0.046137925 seconds. Throughput is 2600.8972 records/second. Loss is 1.3842585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009335324869305453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 42960/60000][Iteration 358][Wall Clock 20.652500677s] Trained 120 records in 0.05473651 seconds. Throughput is 2192.321 records/second. Loss is 1.3479409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009333582228859437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43080/60000][Iteration 359][Wall Clock 20.702467864s] Trained 120 records in 0.049967187 seconds. Throughput is 2401.576 records/second. Loss is 1.307959. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00933184023889511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43200/60000][Iteration 360][Wall Clock 20.751758646s] Trained 120 records in 0.049290782 seconds. Throughput is 2434.5322 records/second. Loss is 1.3535199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009330098899048329. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43320/60000][Iteration 361][Wall Clock 20.797465979s] Trained 120 records in 0.045707333 seconds. Throughput is 2625.3992 records/second. Loss is 1.2269281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009328358208955223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43440/60000][Iteration 362][Wall Clock 20.847706956s] Trained 120 records in 0.050240977 seconds. Throughput is 2388.4885 records/second. Loss is 1.2429395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009326618168252192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43560/60000][Iteration 363][Wall Clock 20.89269927s] Trained 120 records in 0.044992314 seconds. Throughput is 2667.1223 records/second. Loss is 1.2085587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009324878776575904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43680/60000][Iteration 364][Wall Clock 20.938089245s] Trained 120 records in 0.045389975 seconds. Throughput is 2643.7556 records/second. Loss is 1.3486464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009323140033563304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43800/60000][Iteration 365][Wall Clock 20.983866998s] Trained 120 records in 0.045777753 seconds. Throughput is 2621.3606 records/second. Loss is 1.2628938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009321401938851604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 43920/60000][Iteration 366][Wall Clock 21.029741651s] Trained 120 records in 0.045874653 seconds. Throughput is 2615.8237 records/second. Loss is 1.2619811. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009319664492078286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 44040/60000][Iteration 367][Wall Clock 21.07796634s] Trained 120 records in 0.048224689 seconds. Throughput is 2488.352 records/second. Loss is 1.2364211. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009317927692881103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:26 INFO  DistriOptimizer$:406 - [Epoch 1 44160/60000][Iteration 368][Wall Clock 21.148871005s] Trained 120 records in 0.070904665 seconds. Throughput is 1692.4133 records/second. Loss is 1.3084872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009316191540898081. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 44280/60000][Iteration 369][Wall Clock 21.205408559s] Trained 120 records in 0.056537554 seconds. Throughput is 2122.4832 records/second. Loss is 1.2698349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009314456035767513. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 44400/60000][Iteration 370][Wall Clock 21.254727668s] Trained 120 records in 0.049319109 seconds. Throughput is 2433.1338 records/second. Loss is 1.1875796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009312721177127956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 44520/60000][Iteration 371][Wall Clock 21.301631639s] Trained 120 records in 0.046903971 seconds. Throughput is 2558.4187 records/second. Loss is 1.2491031. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009310986964618248. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 44640/60000][Iteration 372][Wall Clock 21.349216479s] Trained 120 records in 0.04758484 seconds. Throughput is 2521.8115 records/second. Loss is 1.3445369. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00930925339787749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 44760/60000][Iteration 373][Wall Clock 21.400983242s] Trained 120 records in 0.051766763 seconds. Throughput is 2318.0896 records/second. Loss is 1.3048047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009307520476545048. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 44880/60000][Iteration 374][Wall Clock 21.453912677s] Trained 120 records in 0.052929435 seconds. Throughput is 2267.1694 records/second. Loss is 1.3001695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009305788200260562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45000/60000][Iteration 375][Wall Clock 21.501862383s] Trained 120 records in 0.047949706 seconds. Throughput is 2502.6223 records/second. Loss is 1.2411482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009304056568663939. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45120/60000][Iteration 376][Wall Clock 21.549291059s] Trained 120 records in 0.047428676 seconds. Throughput is 2530.115 records/second. Loss is 1.3459233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009302325581395349. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45240/60000][Iteration 377][Wall Clock 21.613884002s] Trained 120 records in 0.064592943 seconds. Throughput is 1857.7881 records/second. Loss is 1.2174745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009300595238095238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45360/60000][Iteration 378][Wall Clock 21.679362403s] Trained 120 records in 0.065478401 seconds. Throughput is 1832.6654 records/second. Loss is 1.2126992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009298865538404316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45480/60000][Iteration 379][Wall Clock 21.733849153s] Trained 120 records in 0.05448675 seconds. Throughput is 2202.37 records/second. Loss is 1.304828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009297136481963555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45600/60000][Iteration 380][Wall Clock 21.789347698s] Trained 120 records in 0.055498545 seconds. Throughput is 2162.219 records/second. Loss is 1.2498797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009295408068414203. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45720/60000][Iteration 381][Wall Clock 21.839954493s] Trained 120 records in 0.050606795 seconds. Throughput is 2371.2231 records/second. Loss is 1.1708504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00929368029739777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45840/60000][Iteration 382][Wall Clock 21.890901832s] Trained 120 records in 0.050947339 seconds. Throughput is 2355.3733 records/second. Loss is 1.1350852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00929195316855603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 45960/60000][Iteration 383][Wall Clock 21.946580022s] Trained 120 records in 0.05567819 seconds. Throughput is 2155.2424 records/second. Loss is 1.2254874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00929022668153103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 46080/60000][Iteration 384][Wall Clock 21.994346474s] Trained 120 records in 0.047766452 seconds. Throughput is 2512.2234 records/second. Loss is 1.2347717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009288500835965075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 46200/60000][Iteration 385][Wall Clock 22.049780385s] Trained 120 records in 0.055433911 seconds. Throughput is 2164.74 records/second. Loss is 1.2186435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009286775631500743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 46320/60000][Iteration 386][Wall Clock 22.097467586s] Trained 120 records in 0.047687201 seconds. Throughput is 2516.3984 records/second. Loss is 1.212922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009285051067780874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:27 INFO  DistriOptimizer$:406 - [Epoch 1 46440/60000][Iteration 387][Wall Clock 22.146675812s] Trained 120 records in 0.049208226 seconds. Throughput is 2438.6167 records/second. Loss is 1.2157543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00928332714444857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 46560/60000][Iteration 388][Wall Clock 22.195449201s] Trained 120 records in 0.048773389 seconds. Throughput is 2460.358 records/second. Loss is 1.1816026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009281603861147207. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 46680/60000][Iteration 389][Wall Clock 22.241669008s] Trained 120 records in 0.046219807 seconds. Throughput is 2596.2896 records/second. Loss is 1.2513119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009279881217520417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 46800/60000][Iteration 390][Wall Clock 22.28636031s] Trained 120 records in 0.044691302 seconds. Throughput is 2685.0862 records/second. Loss is 1.2572733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009278159213212098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 46920/60000][Iteration 391][Wall Clock 22.331166981s] Trained 120 records in 0.044806671 seconds. Throughput is 2678.1726 records/second. Loss is 1.2033355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00927643784786642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47040/60000][Iteration 392][Wall Clock 22.375934275s] Trained 120 records in 0.044767294 seconds. Throughput is 2680.5283 records/second. Loss is 1.249169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009274717121127806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47160/60000][Iteration 393][Wall Clock 22.420891442s] Trained 120 records in 0.044957167 seconds. Throughput is 2669.2073 records/second. Loss is 1.1510156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009272997032640949. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47280/60000][Iteration 394][Wall Clock 22.479749781s] Trained 120 records in 0.058858339 seconds. Throughput is 2038.7936 records/second. Loss is 1.1521156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009271277582050807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47400/60000][Iteration 395][Wall Clock 22.529056376s] Trained 120 records in 0.049306595 seconds. Throughput is 2433.7515 records/second. Loss is 1.1759689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009269558769002597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47520/60000][Iteration 396][Wall Clock 22.575168929s] Trained 120 records in 0.046112553 seconds. Throughput is 2602.3284 records/second. Loss is 1.2478936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009267840593141799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47640/60000][Iteration 397][Wall Clock 22.620559817s] Trained 120 records in 0.045390888 seconds. Throughput is 2643.7024 records/second. Loss is 1.1462852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009266123054114159. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47760/60000][Iteration 398][Wall Clock 22.668228461s] Trained 120 records in 0.047668644 seconds. Throughput is 2517.3782 records/second. Loss is 1.1712279. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009264406151565686. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 47880/60000][Iteration 399][Wall Clock 22.717319196s] Trained 120 records in 0.049090735 seconds. Throughput is 2444.4531 records/second. Loss is 1.1713657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009262689885142644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48000/60000][Iteration 400][Wall Clock 22.763788053s] Trained 120 records in 0.046468857 seconds. Throughput is 2582.3748 records/second. Loss is 1.1620173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009260974254491572. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48120/60000][Iteration 401][Wall Clock 22.808957204s] Trained 120 records in 0.045169151 seconds. Throughput is 2656.6804 records/second. Loss is 1.1730435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009259259259259259. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48240/60000][Iteration 402][Wall Clock 22.861551786s] Trained 120 records in 0.052594582 seconds. Throughput is 2281.6038 records/second. Loss is 1.0938852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00925754489909276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48360/60000][Iteration 403][Wall Clock 22.911788573s] Trained 120 records in 0.050236787 seconds. Throughput is 2388.6877 records/second. Loss is 1.2520686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009255831173639394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48480/60000][Iteration 404][Wall Clock 22.957066073s] Trained 120 records in 0.0452775 seconds. Throughput is 2650.323 records/second. Loss is 1.1417068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009254118082546734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48600/60000][Iteration 405][Wall Clock 23.001897238s] Trained 120 records in 0.044831165 seconds. Throughput is 2676.7095 records/second. Loss is 1.2704912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009252405625462621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48720/60000][Iteration 406][Wall Clock 23.051597894s] Trained 120 records in 0.049700656 seconds. Throughput is 2414.455 records/second. Loss is 1.1253152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009250693802035153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48840/60000][Iteration 407][Wall Clock 23.096329824s] Trained 120 records in 0.04473193 seconds. Throughput is 2682.6475 records/second. Loss is 1.1399509. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00924898261191269. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:28 INFO  DistriOptimizer$:406 - [Epoch 1 48960/60000][Iteration 408][Wall Clock 23.140620378s] Trained 120 records in 0.044290554 seconds. Throughput is 2709.3813 records/second. Loss is 1.1120222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009247272054743851. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49080/60000][Iteration 409][Wall Clock 23.18594279s] Trained 120 records in 0.045322412 seconds. Throughput is 2647.6968 records/second. Loss is 1.2597786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009245562130177515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49200/60000][Iteration 410][Wall Clock 23.231587061s] Trained 120 records in 0.045644271 seconds. Throughput is 2629.0264 records/second. Loss is 1.2940298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009243852837862821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49320/60000][Iteration 411][Wall Clock 23.277008644s] Trained 120 records in 0.045421583 seconds. Throughput is 2641.916 records/second. Loss is 1.1626691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009242144177449167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49440/60000][Iteration 412][Wall Clock 23.321593602s] Trained 120 records in 0.044584958 seconds. Throughput is 2691.4905 records/second. Loss is 1.1722394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009240436148586212. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49560/60000][Iteration 413][Wall Clock 23.366323675s] Trained 120 records in 0.044730073 seconds. Throughput is 2682.7588 records/second. Loss is 1.1532875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009238728750923873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49680/60000][Iteration 414][Wall Clock 23.414316645s] Trained 120 records in 0.04799297 seconds. Throughput is 2500.3662 records/second. Loss is 1.1773487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009237021984112323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49800/60000][Iteration 415][Wall Clock 23.461555594s] Trained 120 records in 0.047238949 seconds. Throughput is 2540.2766 records/second. Loss is 1.201259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009235315847801994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 49920/60000][Iteration 416][Wall Clock 23.508942789s] Trained 120 records in 0.047387195 seconds. Throughput is 2532.3298 records/second. Loss is 1.0174899. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009233610341643583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50040/60000][Iteration 417][Wall Clock 23.557480636s] Trained 120 records in 0.048537847 seconds. Throughput is 2472.2976 records/second. Loss is 1.0947818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009231905465288036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50160/60000][Iteration 418][Wall Clock 23.606210762s] Trained 120 records in 0.048730126 seconds. Throughput is 2462.5422 records/second. Loss is 1.0980167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009230201218386561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50280/60000][Iteration 419][Wall Clock 23.663487901s] Trained 120 records in 0.057277139 seconds. Throughput is 2095.0767 records/second. Loss is 1.2266009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009228497600590623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50400/60000][Iteration 420][Wall Clock 23.715967395s] Trained 120 records in 0.052479494 seconds. Throughput is 2286.6074 records/second. Loss is 1.1405455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009226794611551946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50520/60000][Iteration 421][Wall Clock 23.763947612s] Trained 120 records in 0.047980217 seconds. Throughput is 2501.0308 records/second. Loss is 1.1538196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00922509225092251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50640/60000][Iteration 422][Wall Clock 23.811223867s] Trained 120 records in 0.047276255 seconds. Throughput is 2538.2722 records/second. Loss is 1.115286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009223390518354546. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50760/60000][Iteration 423][Wall Clock 23.857498264s] Trained 120 records in 0.046274397 seconds. Throughput is 2593.2266 records/second. Loss is 1.1552538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009221689413500553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 50880/60000][Iteration 424][Wall Clock 23.90426224s] Trained 120 records in 0.046763976 seconds. Throughput is 2566.078 records/second. Loss is 1.1574461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009219988936013277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 51000/60000][Iteration 425][Wall Clock 23.949928507s] Trained 120 records in 0.045666267 seconds. Throughput is 2627.7603 records/second. Loss is 1.0521231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009218289085545723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 51120/60000][Iteration 426][Wall Clock 23.995646159s] Trained 120 records in 0.045717652 seconds. Throughput is 2624.8066 records/second. Loss is 1.0990748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009216589861751152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 51240/60000][Iteration 427][Wall Clock 24.040645812s] Trained 120 records in 0.044999653 seconds. Throughput is 2666.6873 records/second. Loss is 1.169581. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009214891264283083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 51360/60000][Iteration 428][Wall Clock 24.091925089s] Trained 120 records in 0.051279277 seconds. Throughput is 2340.1267 records/second. Loss is 1.1332338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009213193292795284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:29 INFO  DistriOptimizer$:406 - [Epoch 1 51480/60000][Iteration 429][Wall Clock 24.138880144s] Trained 120 records in 0.046955055 seconds. Throughput is 2555.6353 records/second. Loss is 1.1254456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009211495946941784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 51600/60000][Iteration 430][Wall Clock 24.183469291s] Trained 120 records in 0.044589147 seconds. Throughput is 2691.2378 records/second. Loss is 1.1397375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009209799226376865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 51720/60000][Iteration 431][Wall Clock 24.22785192s] Trained 120 records in 0.044382629 seconds. Throughput is 2703.7605 records/second. Loss is 1.2377687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009208103130755063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 51840/60000][Iteration 432][Wall Clock 24.272052892s] Trained 120 records in 0.044200972 seconds. Throughput is 2714.8726 records/second. Loss is 1.0759728. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009206407659731172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 51960/60000][Iteration 433][Wall Clock 24.316522433s] Trained 120 records in 0.044469541 seconds. Throughput is 2698.476 records/second. Loss is 1.1551291. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009204712812960236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52080/60000][Iteration 434][Wall Clock 24.361038289s] Trained 120 records in 0.044515856 seconds. Throughput is 2695.6687 records/second. Loss is 1.1689123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009203018590097553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52200/60000][Iteration 435][Wall Clock 24.407652297s] Trained 120 records in 0.046614008 seconds. Throughput is 2574.3335 records/second. Loss is 1.109497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009201324990798676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52320/60000][Iteration 436][Wall Clock 24.451541152s] Trained 120 records in 0.043888855 seconds. Throughput is 2734.1792 records/second. Loss is 1.1476072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009199632014719412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52440/60000][Iteration 437][Wall Clock 24.496747093s] Trained 120 records in 0.045205941 seconds. Throughput is 2654.5186 records/second. Loss is 1.0865071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009197939661515822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52560/60000][Iteration 438][Wall Clock 24.542600117s] Trained 120 records in 0.045853024 seconds. Throughput is 2617.0576 records/second. Loss is 1.0999318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009196247930844217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52680/60000][Iteration 439][Wall Clock 24.587972276s] Trained 120 records in 0.045372159 seconds. Throughput is 2644.7937 records/second. Loss is 1.1481546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009194556822361163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52800/60000][Iteration 440][Wall Clock 24.633296736s] Trained 120 records in 0.04532446 seconds. Throughput is 2647.5771 records/second. Loss is 1.0610722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009192866335723478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 52920/60000][Iteration 441][Wall Clock 24.678274187s] Trained 120 records in 0.044977451 seconds. Throughput is 2668.0034 records/second. Loss is 1.0791432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009191176470588236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53040/60000][Iteration 442][Wall Clock 24.723588633s] Trained 120 records in 0.045314446 seconds. Throughput is 2648.162 records/second. Loss is 1.0508784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009189487226612754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53160/60000][Iteration 443][Wall Clock 24.770379615s] Trained 120 records in 0.046790982 seconds. Throughput is 2564.5967 records/second. Loss is 1.1360503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009187798603454611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53280/60000][Iteration 444][Wall Clock 24.817069634s] Trained 120 records in 0.046690019 seconds. Throughput is 2570.1423 records/second. Loss is 1.0314964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009186110600771633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53400/60000][Iteration 445][Wall Clock 24.872666093s] Trained 120 records in 0.055596459 seconds. Throughput is 2158.411 records/second. Loss is 0.94466805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009184423218221896. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53520/60000][Iteration 446][Wall Clock 24.929876213s] Trained 120 records in 0.05721012 seconds. Throughput is 2097.531 records/second. Loss is 1.0557991. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009182736455463728. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53640/60000][Iteration 447][Wall Clock 24.980937843s] Trained 120 records in 0.05106163 seconds. Throughput is 2350.1013 records/second. Loss is 1.0726988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00918105031215571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53760/60000][Iteration 448][Wall Clock 25.02750547s] Trained 120 records in 0.046567627 seconds. Throughput is 2576.8975 records/second. Loss is 1.0028331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009179364787956674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 53880/60000][Iteration 449][Wall Clock 25.076578714s] Trained 120 records in 0.049073244 seconds. Throughput is 2445.3242 records/second. Loss is 1.0294203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009177679882525698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 54000/60000][Iteration 450][Wall Clock 25.127498373s] Trained 120 records in 0.050919659 seconds. Throughput is 2356.6536 records/second. Loss is 1.0474385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009175995595522114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:30 INFO  DistriOptimizer$:406 - [Epoch 1 54120/60000][Iteration 451][Wall Clock 25.171546556s] Trained 120 records in 0.044048183 seconds. Throughput is 2724.2896 records/second. Loss is 1.0660609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009174311926605503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 54240/60000][Iteration 452][Wall Clock 25.215578501s] Trained 120 records in 0.044031945 seconds. Throughput is 2725.2942 records/second. Loss is 1.0846494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0091726288754357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 54360/60000][Iteration 453][Wall Clock 25.263773074s] Trained 120 records in 0.048194573 seconds. Throughput is 2489.907 records/second. Loss is 0.9731847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009170946441672781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 54480/60000][Iteration 454][Wall Clock 25.319329169s] Trained 120 records in 0.055556095 seconds. Throughput is 2159.979 records/second. Loss is 1.1220921. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009169264624977077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 54600/60000][Iteration 455][Wall Clock 25.363794561s] Trained 120 records in 0.044465392 seconds. Throughput is 2698.728 records/second. Loss is 1.0611683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009167583425009168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 54720/60000][Iteration 456][Wall Clock 25.408224742s] Trained 120 records in 0.044430181 seconds. Throughput is 2700.8667 records/second. Loss is 1.0534106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00916590284142988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 54840/60000][Iteration 457][Wall Clock 25.460660528s] Trained 120 records in 0.052435786 seconds. Throughput is 2288.5134 records/second. Loss is 1.1015979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009164222873900294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 54960/60000][Iteration 458][Wall Clock 25.505409724s] Trained 120 records in 0.044749196 seconds. Throughput is 2681.6123 records/second. Loss is 0.9895154. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00916254352208173. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55080/60000][Iteration 459][Wall Clock 25.549402159s] Trained 120 records in 0.043992435 seconds. Throughput is 2727.7417 records/second. Loss is 1.0484606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009160864785635764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55200/60000][Iteration 460][Wall Clock 25.594222364s] Trained 120 records in 0.044820205 seconds. Throughput is 2677.364 records/second. Loss is 0.98492134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009159186664224217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55320/60000][Iteration 461][Wall Clock 25.638750337s] Trained 120 records in 0.044527973 seconds. Throughput is 2694.935 records/second. Loss is 0.97415465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009157509157509156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55440/60000][Iteration 462][Wall Clock 25.684069712s] Trained 120 records in 0.045319375 seconds. Throughput is 2647.874 records/second. Loss is 1.068899. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009155832265152902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55560/60000][Iteration 463][Wall Clock 25.729351832s] Trained 120 records in 0.04528212 seconds. Throughput is 2650.0525 records/second. Loss is 1.051188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009154155986818015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55680/60000][Iteration 464][Wall Clock 25.773689466s] Trained 120 records in 0.044337634 seconds. Throughput is 2706.5044 records/second. Loss is 1.0672939. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009152480322167308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55800/60000][Iteration 465][Wall Clock 25.817481217s] Trained 120 records in 0.043791751 seconds. Throughput is 2740.242 records/second. Loss is 1.0420426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009150805270863836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 55920/60000][Iteration 466][Wall Clock 25.862290188s] Trained 120 records in 0.044808971 seconds. Throughput is 2678.0352 records/second. Loss is 0.93769807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009149130832570906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 56040/60000][Iteration 467][Wall Clock 25.906415578s] Trained 120 records in 0.04412539 seconds. Throughput is 2719.5227 records/second. Loss is 1.0374795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009147457006952069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 56160/60000][Iteration 468][Wall Clock 25.954271755s] Trained 120 records in 0.047856177 seconds. Throughput is 2507.5132 records/second. Loss is 1.0507748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009145783793671118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 56280/60000][Iteration 469][Wall Clock 26.002646622s] Trained 120 records in 0.048374867 seconds. Throughput is 2480.627 records/second. Loss is 1.014539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0091441111923921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 56400/60000][Iteration 470][Wall Clock 26.051015571s] Trained 120 records in 0.048368949 seconds. Throughput is 2480.9304 records/second. Loss is 1.0169092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0091424392027793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 56520/60000][Iteration 471][Wall Clock 26.108444077s] Trained 120 records in 0.057428506 seconds. Throughput is 2089.5547 records/second. Loss is 0.96483225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009140767824497258. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:31 INFO  DistriOptimizer$:406 - [Epoch 1 56640/60000][Iteration 472][Wall Clock 26.162020905s] Trained 120 records in 0.053576828 seconds. Throughput is 2239.7744 records/second. Loss is 1.0067476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009139097057210747. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 56760/60000][Iteration 473][Wall Clock 26.212535937s] Trained 120 records in 0.050515032 seconds. Throughput is 2375.5305 records/second. Loss is 1.0405806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009137426900584795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 56880/60000][Iteration 474][Wall Clock 26.269766765s] Trained 120 records in 0.057230828 seconds. Throughput is 2096.7722 records/second. Loss is 1.0812819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00913575735428467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57000/60000][Iteration 475][Wall Clock 26.318975691s] Trained 120 records in 0.049208926 seconds. Throughput is 2438.582 records/second. Loss is 0.97383654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009134088417975887. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57120/60000][Iteration 476][Wall Clock 26.365993959s] Trained 120 records in 0.047018268 seconds. Throughput is 2552.1995 records/second. Loss is 1.0650028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009132420091324202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57240/60000][Iteration 477][Wall Clock 26.413346208s] Trained 120 records in 0.047352249 seconds. Throughput is 2534.1985 records/second. Loss is 1.0613313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009130752373995618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57360/60000][Iteration 478][Wall Clock 26.460421421s] Trained 120 records in 0.047075213 seconds. Throughput is 2549.1123 records/second. Loss is 1.0108173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009129085265656383. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57480/60000][Iteration 479][Wall Clock 26.513537111s] Trained 120 records in 0.05311569 seconds. Throughput is 2259.2195 records/second. Loss is 1.0300754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009127418765972983. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57600/60000][Iteration 480][Wall Clock 26.560502543s] Trained 120 records in 0.046965432 seconds. Throughput is 2555.0708 records/second. Loss is 0.9873889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009125752874612154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57720/60000][Iteration 481][Wall Clock 26.605679989s] Trained 120 records in 0.045177446 seconds. Throughput is 2656.1926 records/second. Loss is 1.047381. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009124087591240875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57840/60000][Iteration 482][Wall Clock 26.651731707s] Trained 120 records in 0.046051718 seconds. Throughput is 2605.7659 records/second. Loss is 0.9600423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009122422915526363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 57960/60000][Iteration 483][Wall Clock 26.696918741s] Trained 120 records in 0.045187034 seconds. Throughput is 2655.6292 records/second. Loss is 1.000417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009120758847136081. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58080/60000][Iteration 484][Wall Clock 26.742177153s] Trained 120 records in 0.045258412 seconds. Throughput is 2651.441 records/second. Loss is 1.0538881. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009119095385737734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58200/60000][Iteration 485][Wall Clock 26.786766627s] Trained 120 records in 0.044589474 seconds. Throughput is 2691.218 records/second. Loss is 0.9889825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00911743253099927. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58320/60000][Iteration 486][Wall Clock 26.830640911s] Trained 120 records in 0.043874284 seconds. Throughput is 2735.0874 records/second. Loss is 0.9850382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00911577028258888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58440/60000][Iteration 487][Wall Clock 26.875691549s] Trained 120 records in 0.045050638 seconds. Throughput is 2663.6692 records/second. Loss is 0.88504344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009114108640174992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58560/60000][Iteration 488][Wall Clock 26.921134139s] Trained 120 records in 0.04544259 seconds. Throughput is 2640.6946 records/second. Loss is 0.98850554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00911244760342628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58680/60000][Iteration 489][Wall Clock 26.966505769s] Trained 120 records in 0.04537163 seconds. Throughput is 2644.8245 records/second. Loss is 0.9199036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009110787172011662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58800/60000][Iteration 490][Wall Clock 27.015004089s] Trained 120 records in 0.04849832 seconds. Throughput is 2474.3125 records/second. Loss is 1.0017381. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009109127345600293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 58920/60000][Iteration 491][Wall Clock 27.062645681s] Trained 120 records in 0.047641592 seconds. Throughput is 2518.8076 records/second. Loss is 0.97285646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009107468123861566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 59040/60000][Iteration 492][Wall Clock 27.109609934s] Trained 120 records in 0.046964253 seconds. Throughput is 2555.1348 records/second. Loss is 0.93696266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009105809506465124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:32 INFO  DistriOptimizer$:406 - [Epoch 1 59160/60000][Iteration 493][Wall Clock 27.156624976s] Trained 120 records in 0.047015042 seconds. Throughput is 2552.3748 records/second. Loss is 0.99867547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009104151493080845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:406 - [Epoch 1 59280/60000][Iteration 494][Wall Clock 27.201685589s] Trained 120 records in 0.045060613 seconds. Throughput is 2663.0796 records/second. Loss is 0.8237689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009102494083378846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:406 - [Epoch 1 59400/60000][Iteration 495][Wall Clock 27.245881704s] Trained 120 records in 0.044196115 seconds. Throughput is 2715.171 records/second. Loss is 0.9404332. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009100837277029487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:406 - [Epoch 1 59520/60000][Iteration 496][Wall Clock 27.290372487s] Trained 120 records in 0.044490783 seconds. Throughput is 2697.1877 records/second. Loss is 1.0273918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009099181073703368. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:406 - [Epoch 1 59640/60000][Iteration 497][Wall Clock 27.346135774s] Trained 120 records in 0.055763287 seconds. Throughput is 2151.9536 records/second. Loss is 0.9969667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009097525473071326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:406 - [Epoch 1 59760/60000][Iteration 498][Wall Clock 27.394446468s] Trained 120 records in 0.048310694 seconds. Throughput is 2483.922 records/second. Loss is 0.92799747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00909587047480444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:406 - [Epoch 1 59880/60000][Iteration 499][Wall Clock 27.44486767s] Trained 120 records in 0.050421202 seconds. Throughput is 2379.9512 records/second. Loss is 0.9535897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009094216078574028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:406 - [Epoch 1 60000/60000][Iteration 500][Wall Clock 27.490760947s] Trained 120 records in 0.045893277 seconds. Throughput is 2614.762 records/second. Loss is 0.9587822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009092562284051645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:33 INFO  DistriOptimizer$:451 - [Epoch 1 60000/60000][Iteration 500][Wall Clock 27.490760947s] Epoch finished. Wall clock time is 27644.369982 ms
2019-10-23 15:53:33 INFO  DistriOptimizer$:111 - [Epoch 1 60000/60000][Iteration 500][Wall Clock 27.490760947s] Validate model...
2019-10-23 15:53:34 INFO  DistriOptimizer$:177 - [Epoch 1 60000/60000][Iteration 500][Wall Clock 27.490760947s] validate model throughput is 13942.274 records/second
2019-10-23 15:53:34 INFO  DistriOptimizer$:180 - [Epoch 1 60000/60000][Iteration 500][Wall Clock 27.490760947s] Top1Accuracy is Accuracy(correct: 7815, count: 10000, accuracy: 0.7815)
2019-10-23 15:53:34 INFO  DistriOptimizer$:220 - [Wall Clock 27.644369982s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:53:34 INFO  DistriOptimizer$:225 - [Wall Clock 27.644369982s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 120/60000][Iteration 501][Wall Clock 27.717116596s] Trained 120 records in 0.072746614 seconds. Throughput is 1649.5614 records/second. Loss is 0.955993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00909090909090909. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 240/60000][Iteration 502][Wall Clock 27.768696071s] Trained 120 records in 0.051579475 seconds. Throughput is 2326.5068 records/second. Loss is 0.9082791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009089256498818397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 360/60000][Iteration 503][Wall Clock 27.827303418s] Trained 120 records in 0.058607347 seconds. Throughput is 2047.5249 records/second. Loss is 1.0409418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009087604507451835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 480/60000][Iteration 504][Wall Clock 27.877893836s] Trained 120 records in 0.050590418 seconds. Throughput is 2371.9907 records/second. Loss is 0.95369554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009085953116481919. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 600/60000][Iteration 505][Wall Clock 27.924436731s] Trained 120 records in 0.046542895 seconds. Throughput is 2578.2668 records/second. Loss is 0.9405028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009084302325581396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 720/60000][Iteration 506][Wall Clock 27.971549418s] Trained 120 records in 0.047112687 seconds. Throughput is 2547.0845 records/second. Loss is 0.94980496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009082652134423252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 840/60000][Iteration 507][Wall Clock 28.017642895s] Trained 120 records in 0.046093477 seconds. Throughput is 2603.405 records/second. Loss is 1.0299573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009081002542680712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 960/60000][Iteration 508][Wall Clock 28.063745697s] Trained 120 records in 0.046102802 seconds. Throughput is 2602.8787 records/second. Loss is 0.9608089. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009079353550027239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1080/60000][Iteration 509][Wall Clock 28.109351506s] Trained 120 records in 0.045605809 seconds. Throughput is 2631.244 records/second. Loss is 1.1207073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00907770515613653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1200/60000][Iteration 510][Wall Clock 28.15520048s] Trained 120 records in 0.045848974 seconds. Throughput is 2617.2888 records/second. Loss is 0.95433617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00907605736068252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1320/60000][Iteration 511][Wall Clock 28.200805562s] Trained 120 records in 0.045605082 seconds. Throughput is 2631.2856 records/second. Loss is 1.0680928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009074410163339382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1440/60000][Iteration 512][Wall Clock 28.247120584s] Trained 120 records in 0.046315022 seconds. Throughput is 2590.9521 records/second. Loss is 0.8640192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009072763563781528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1560/60000][Iteration 513][Wall Clock 28.293472942s] Trained 120 records in 0.046352358 seconds. Throughput is 2588.8652 records/second. Loss is 0.9657192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009071117561683599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1680/60000][Iteration 514][Wall Clock 28.337731693s] Trained 120 records in 0.044258751 seconds. Throughput is 2711.3281 records/second. Loss is 1.1409912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009069472156720479. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1800/60000][Iteration 515][Wall Clock 28.382943405s] Trained 120 records in 0.045211712 seconds. Throughput is 2654.1794 records/second. Loss is 0.91256624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009067827348567283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 1920/60000][Iteration 516][Wall Clock 28.428526393s] Trained 120 records in 0.045582988 seconds. Throughput is 2632.561 records/second. Loss is 0.9355477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009066183136899365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 2040/60000][Iteration 517][Wall Clock 28.474387875s] Trained 120 records in 0.045861482 seconds. Throughput is 2616.5747 records/second. Loss is 0.93087804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009064539521392313. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:34 INFO  DistriOptimizer$:406 - [Epoch 2 2160/60000][Iteration 518][Wall Clock 28.519256119s] Trained 120 records in 0.044868244 seconds. Throughput is 2674.4973 records/second. Loss is 0.8309742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009062896501721951. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 2280/60000][Iteration 519][Wall Clock 28.56339612s] Trained 120 records in 0.044140001 seconds. Throughput is 2718.6226 records/second. Loss is 1.078016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009061254077564336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 2400/60000][Iteration 520][Wall Clock 28.607634442s] Trained 120 records in 0.044238322 seconds. Throughput is 2712.5803 records/second. Loss is 0.906924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00905961224859576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 2520/60000][Iteration 521][Wall Clock 28.662359416s] Trained 120 records in 0.054724974 seconds. Throughput is 2192.7832 records/second. Loss is 0.8095257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009057971014492752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 2640/60000][Iteration 522][Wall Clock 28.715246235s] Trained 120 records in 0.052886819 seconds. Throughput is 2268.9963 records/second. Loss is 0.8782492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009056330374932076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 2760/60000][Iteration 523][Wall Clock 28.769412946s] Trained 120 records in 0.054166711 seconds. Throughput is 2215.3828 records/second. Loss is 0.94071513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009054690329590729. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 2880/60000][Iteration 524][Wall Clock 28.815337424s] Trained 120 records in 0.045924478 seconds. Throughput is 2612.9856 records/second. Loss is 0.9930071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009053050878145934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3000/60000][Iteration 525][Wall Clock 28.861185228s] Trained 120 records in 0.045847804 seconds. Throughput is 2617.3555 records/second. Loss is 0.97321814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009051412020275163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3120/60000][Iteration 526][Wall Clock 28.910724854s] Trained 120 records in 0.049539626 seconds. Throughput is 2422.3032 records/second. Loss is 0.966566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00904977375565611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3240/60000][Iteration 527][Wall Clock 28.956547421s] Trained 120 records in 0.045822567 seconds. Throughput is 2618.7969 records/second. Loss is 0.8694044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009048136083966703. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3360/60000][Iteration 528][Wall Clock 29.00227228s] Trained 120 records in 0.045724859 seconds. Throughput is 2624.393 records/second. Loss is 0.836879. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009046499004885111. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3480/60000][Iteration 529][Wall Clock 29.059858052s] Trained 120 records in 0.057585772 seconds. Throughput is 2083.8481 records/second. Loss is 0.8799871. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009044862518089726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3600/60000][Iteration 530][Wall Clock 29.111751381s] Trained 120 records in 0.051893329 seconds. Throughput is 2312.436 records/second. Loss is 0.97222245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00904322662325918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3720/60000][Iteration 531][Wall Clock 29.158273225s] Trained 120 records in 0.046521844 seconds. Throughput is 2579.4336 records/second. Loss is 0.8380918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009041591320072331. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3840/60000][Iteration 532][Wall Clock 29.203212266s] Trained 120 records in 0.044939041 seconds. Throughput is 2670.284 records/second. Loss is 1.0223035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00903995660820828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 3960/60000][Iteration 533][Wall Clock 29.249093356s] Trained 120 records in 0.04588109 seconds. Throughput is 2615.4568 records/second. Loss is 0.9068734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009038322487346349. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 4080/60000][Iteration 534][Wall Clock 29.298019781s] Trained 120 records in 0.048926425 seconds. Throughput is 2452.6624 records/second. Loss is 0.86970335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009036688957166094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 4200/60000][Iteration 535][Wall Clock 29.344823814s] Trained 120 records in 0.046804033 seconds. Throughput is 2563.8816 records/second. Loss is 0.97779256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009035056017347307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 4320/60000][Iteration 536][Wall Clock 29.391269759s] Trained 120 records in 0.046445945 seconds. Throughput is 2583.6487 records/second. Loss is 0.94823164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00903342366757001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 4440/60000][Iteration 537][Wall Clock 29.443919712s] Trained 120 records in 0.052649953 seconds. Throughput is 2279.2043 records/second. Loss is 0.9741584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009031791907514452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:35 INFO  DistriOptimizer$:406 - [Epoch 2 4560/60000][Iteration 538][Wall Clock 29.494919598s] Trained 120 records in 0.050999886 seconds. Throughput is 2352.9463 records/second. Loss is 0.83818394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009030160736861116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 4680/60000][Iteration 539][Wall Clock 29.541308653s] Trained 120 records in 0.046389055 seconds. Throughput is 2586.8171 records/second. Loss is 0.94097733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00902853015529072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 4800/60000][Iteration 540][Wall Clock 29.594253418s] Trained 120 records in 0.052944765 seconds. Throughput is 2266.513 records/second. Loss is 0.8868586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009026900162484202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 4920/60000][Iteration 541][Wall Clock 29.639956596s] Trained 120 records in 0.045703178 seconds. Throughput is 2625.6382 records/second. Loss is 0.9232765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009025270758122744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5040/60000][Iteration 542][Wall Clock 29.686695579s] Trained 120 records in 0.046738983 seconds. Throughput is 2567.45 records/second. Loss is 0.9863943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009023641941887746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5160/60000][Iteration 543][Wall Clock 29.732511704s] Trained 120 records in 0.045816125 seconds. Throughput is 2619.1653 records/second. Loss is 0.8979875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009022013713460845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5280/60000][Iteration 544][Wall Clock 29.776890851s] Trained 120 records in 0.044379147 seconds. Throughput is 2703.9727 records/second. Loss is 0.9073219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009020386072523904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5400/60000][Iteration 545][Wall Clock 29.821860314s] Trained 120 records in 0.044969463 seconds. Throughput is 2668.4775 records/second. Loss is 0.949926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009018759018759018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5520/60000][Iteration 546][Wall Clock 29.875296011s] Trained 120 records in 0.053435697 seconds. Throughput is 2245.6897 records/second. Loss is 0.8355501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009017132551848512. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5640/60000][Iteration 547][Wall Clock 29.936045906s] Trained 120 records in 0.060749895 seconds. Throughput is 1975.312 records/second. Loss is 0.8773404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009015506671474938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5760/60000][Iteration 548][Wall Clock 29.994633782s] Trained 120 records in 0.058587876 seconds. Throughput is 2048.2053 records/second. Loss is 0.8352804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009013881377321075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 5880/60000][Iteration 549][Wall Clock 30.039693279s] Trained 120 records in 0.045059497 seconds. Throughput is 2663.1455 records/second. Loss is 0.87610364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009012256669069936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6000/60000][Iteration 550][Wall Clock 30.083863669s] Trained 120 records in 0.04417039 seconds. Throughput is 2716.752 records/second. Loss is 0.96799225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00901063254640476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6120/60000][Iteration 551][Wall Clock 30.129567964s] Trained 120 records in 0.045704295 seconds. Throughput is 2625.574 records/second. Loss is 0.7827984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009009009009009009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6240/60000][Iteration 552][Wall Clock 30.175347952s] Trained 120 records in 0.045779988 seconds. Throughput is 2621.2327 records/second. Loss is 0.88366085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009007386056566384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6360/60000][Iteration 553][Wall Clock 30.219468382s] Trained 120 records in 0.04412043 seconds. Throughput is 2719.8284 records/second. Loss is 0.8526115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009005763688760807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6480/60000][Iteration 554][Wall Clock 30.262858366s] Trained 120 records in 0.043389984 seconds. Throughput is 2765.6152 records/second. Loss is 0.7904961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009004141905276427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6600/60000][Iteration 555][Wall Clock 30.3156946s] Trained 120 records in 0.052836234 seconds. Throughput is 2271.1687 records/second. Loss is 0.9265481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009002520705797623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6720/60000][Iteration 556][Wall Clock 30.369309547s] Trained 120 records in 0.053614947 seconds. Throughput is 2238.182 records/second. Loss is 0.8369522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.009000900090009001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6840/60000][Iteration 557][Wall Clock 30.416256117s] Trained 120 records in 0.04694657 seconds. Throughput is 2556.0972 records/second. Loss is 0.831338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008999280057595392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 6960/60000][Iteration 558][Wall Clock 30.462991558s] Trained 120 records in 0.046735441 seconds. Throughput is 2567.6445 records/second. Loss is 0.8848106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008997660608241857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:36 INFO  DistriOptimizer$:406 - [Epoch 2 7080/60000][Iteration 559][Wall Clock 30.509713679s] Trained 120 records in 0.046722121 seconds. Throughput is 2568.3765 records/second. Loss is 0.8199077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008996041741633681. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 7200/60000][Iteration 560][Wall Clock 30.556564771s] Trained 120 records in 0.046851092 seconds. Throughput is 2561.3064 records/second. Loss is 0.83947694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008994423457456376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 7320/60000][Iteration 561][Wall Clock 30.603111405s] Trained 120 records in 0.046546634 seconds. Throughput is 2578.0596 records/second. Loss is 0.899362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008992805755395683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 7440/60000][Iteration 562][Wall Clock 30.651555674s] Trained 120 records in 0.048444269 seconds. Throughput is 2477.0732 records/second. Loss is 0.9059165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008991188635137565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 7560/60000][Iteration 563][Wall Clock 30.696493128s] Trained 120 records in 0.044937454 seconds. Throughput is 2670.3782 records/second. Loss is 0.81170046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008989572096368213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 7680/60000][Iteration 564][Wall Clock 30.741037229s] Trained 120 records in 0.044544101 seconds. Throughput is 2693.9595 records/second. Loss is 0.94654423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008987956138774043. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 7800/60000][Iteration 565][Wall Clock 30.786214017s] Trained 120 records in 0.045176788 seconds. Throughput is 2656.2312 records/second. Loss is 0.83481425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008986340762041696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 7920/60000][Iteration 566][Wall Clock 30.830627705s] Trained 120 records in 0.044413688 seconds. Throughput is 2701.8696 records/second. Loss is 0.9364036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008984725965858042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8040/60000][Iteration 567][Wall Clock 30.875345323s] Trained 120 records in 0.044717618 seconds. Throughput is 2683.506 records/second. Loss is 0.8898925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008983111749910169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8160/60000][Iteration 568][Wall Clock 30.922720965s] Trained 120 records in 0.047375642 seconds. Throughput is 2532.9473 records/second. Loss is 0.8392361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008981498113885397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8280/60000][Iteration 569][Wall Clock 30.968626083s] Trained 120 records in 0.045905118 seconds. Throughput is 2614.0876 records/second. Loss is 0.8832186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008979885057471266. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8400/60000][Iteration 570][Wall Clock 31.017451286s] Trained 120 records in 0.048825203 seconds. Throughput is 2457.747 records/second. Loss is 0.81317115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00897827258035554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8520/60000][Iteration 571][Wall Clock 31.062988994s] Trained 120 records in 0.045537708 seconds. Throughput is 2635.1787 records/second. Loss is 0.93714374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00897666068222621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8640/60000][Iteration 572][Wall Clock 31.125912585s] Trained 120 records in 0.062923591 seconds. Throughput is 1907.075 records/second. Loss is 0.82838804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008975049362771494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8760/60000][Iteration 573][Wall Clock 31.180364113s] Trained 120 records in 0.054451528 seconds. Throughput is 2203.795 records/second. Loss is 0.8981436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008973438621679828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 8880/60000][Iteration 574][Wall Clock 31.224772974s] Trained 120 records in 0.044408861 seconds. Throughput is 2702.1633 records/second. Loss is 0.8246616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00897182845863987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 9000/60000][Iteration 575][Wall Clock 31.267933663s] Trained 120 records in 0.043160689 seconds. Throughput is 2780.3079 records/second. Loss is 0.9240191. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00897021887334051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 9120/60000][Iteration 576][Wall Clock 31.311244687s] Trained 120 records in 0.043311024 seconds. Throughput is 2770.6572 records/second. Loss is 0.8676979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008968609865470852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 9240/60000][Iteration 577][Wall Clock 31.355151317s] Trained 120 records in 0.04390663 seconds. Throughput is 2733.0725 records/second. Loss is 0.8238844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00896700143472023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 9360/60000][Iteration 578][Wall Clock 31.39907772s] Trained 120 records in 0.043926403 seconds. Throughput is 2731.8423 records/second. Loss is 0.7686719. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008965393580778197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 9480/60000][Iteration 579][Wall Clock 31.443854149s] Trained 120 records in 0.044776429 seconds. Throughput is 2679.9814 records/second. Loss is 0.79115576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008963786303334529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:37 INFO  DistriOptimizer$:406 - [Epoch 2 9600/60000][Iteration 580][Wall Clock 31.488121108s] Trained 120 records in 0.044266959 seconds. Throughput is 2710.8254 records/second. Loss is 0.8494345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008962179602079227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 9720/60000][Iteration 581][Wall Clock 31.548390268s] Trained 120 records in 0.06026916 seconds. Throughput is 1991.0681 records/second. Loss is 0.76995754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008960573476702509. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 9840/60000][Iteration 582][Wall Clock 31.595878014s] Trained 120 records in 0.047487746 seconds. Throughput is 2526.9675 records/second. Loss is 0.9471723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008958967926894821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 9960/60000][Iteration 583][Wall Clock 31.642481543s] Trained 120 records in 0.046603529 seconds. Throughput is 2574.912 records/second. Loss is 0.93283826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008957362952346828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10080/60000][Iteration 584][Wall Clock 31.687737882s] Trained 120 records in 0.045256339 seconds. Throughput is 2651.5623 records/second. Loss is 0.8649342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008955758552749419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10200/60000][Iteration 585][Wall Clock 31.73230738s] Trained 120 records in 0.044569498 seconds. Throughput is 2692.4243 records/second. Loss is 0.75849277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008954154727793696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10320/60000][Iteration 586][Wall Clock 31.776003811s] Trained 120 records in 0.043696431 seconds. Throughput is 2746.2197 records/second. Loss is 0.8011359. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008952551477170993. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10440/60000][Iteration 587][Wall Clock 31.820113647s] Trained 120 records in 0.044109836 seconds. Throughput is 2720.4817 records/second. Loss is 0.934316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008950948800572862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10560/60000][Iteration 588][Wall Clock 31.864765104s] Trained 120 records in 0.044651457 seconds. Throughput is 2687.4824 records/second. Loss is 0.86045736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008949346697691068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10680/60000][Iteration 589][Wall Clock 31.909173834s] Trained 120 records in 0.04440873 seconds. Throughput is 2702.1714 records/second. Loss is 1.016507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00894774516821761. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10800/60000][Iteration 590][Wall Clock 31.953895798s] Trained 120 records in 0.044721964 seconds. Throughput is 2683.2454 records/second. Loss is 0.9122372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008946144211844696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 10920/60000][Iteration 591][Wall Clock 32.00045027s] Trained 120 records in 0.046554472 seconds. Throughput is 2577.6255 records/second. Loss is 0.8337438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008944543828264758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11040/60000][Iteration 592][Wall Clock 32.045417873s] Trained 120 records in 0.044967603 seconds. Throughput is 2668.588 records/second. Loss is 0.91620004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008942944017170452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11160/60000][Iteration 593][Wall Clock 32.090876766s] Trained 120 records in 0.045458893 seconds. Throughput is 2639.7476 records/second. Loss is 0.7820726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008941344778254649. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11280/60000][Iteration 594][Wall Clock 32.134548538s] Trained 120 records in 0.043671772 seconds. Throughput is 2747.7703 records/second. Loss is 0.79140073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008939746111210442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11400/60000][Iteration 595][Wall Clock 32.178361428s] Trained 120 records in 0.04381289 seconds. Throughput is 2738.92 records/second. Loss is 0.87714165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00893814801573114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11520/60000][Iteration 596][Wall Clock 32.223123993s] Trained 120 records in 0.044762565 seconds. Throughput is 2680.8115 records/second. Loss is 0.746787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008936550491510277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11640/60000][Iteration 597][Wall Clock 32.279697728s] Trained 120 records in 0.056573735 seconds. Throughput is 2121.1257 records/second. Loss is 0.7993123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008934953538241601. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11760/60000][Iteration 598][Wall Clock 32.329496349s] Trained 120 records in 0.049798621 seconds. Throughput is 2409.705 records/second. Loss is 0.8459135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008933357155619083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 11880/60000][Iteration 599][Wall Clock 32.374131715s] Trained 120 records in 0.044635366 seconds. Throughput is 2688.4512 records/second. Loss is 0.82928395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008931761343336907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 12000/60000][Iteration 600][Wall Clock 32.418146786s] Trained 120 records in 0.044015071 seconds. Throughput is 2726.3389 records/second. Loss is 0.77634704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00893016610108948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:38 INFO  DistriOptimizer$:406 - [Epoch 2 12120/60000][Iteration 601][Wall Clock 32.461717877s] Trained 120 records in 0.043571091 seconds. Throughput is 2754.1196 records/second. Loss is 0.85540193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008928571428571428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 12240/60000][Iteration 602][Wall Clock 32.505397525s] Trained 120 records in 0.043679648 seconds. Throughput is 2747.275 records/second. Loss is 0.8488163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008926977325477594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 12360/60000][Iteration 603][Wall Clock 32.549555825s] Trained 120 records in 0.0441583 seconds. Throughput is 2717.496 records/second. Loss is 0.8576857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008925383791503034. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 12480/60000][Iteration 604][Wall Clock 32.593526299s] Trained 120 records in 0.043970474 seconds. Throughput is 2729.1042 records/second. Loss is 0.77428806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00892379082634303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 12600/60000][Iteration 605][Wall Clock 32.638952902s] Trained 120 records in 0.045426603 seconds. Throughput is 2641.6238 records/second. Loss is 0.7635252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008922198429693077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 12720/60000][Iteration 606][Wall Clock 32.697154232s] Trained 120 records in 0.05820133 seconds. Throughput is 2061.8086 records/second. Loss is 0.79211843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008920606601248885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 12840/60000][Iteration 607][Wall Clock 32.745474419s] Trained 120 records in 0.048320187 seconds. Throughput is 2483.434 records/second. Loss is 0.77753764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008919015340706386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 12960/60000][Iteration 608][Wall Clock 32.79092367s] Trained 120 records in 0.045449251 seconds. Throughput is 2640.3076 records/second. Loss is 0.7295061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008917424647761726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13080/60000][Iteration 609][Wall Clock 32.835016231s] Trained 120 records in 0.044092561 seconds. Throughput is 2721.5474 records/second. Loss is 0.8450688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00891583452211127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13200/60000][Iteration 610][Wall Clock 32.880351075s] Trained 120 records in 0.045334844 seconds. Throughput is 2646.9705 records/second. Loss is 0.84235126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008914244963451596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13320/60000][Iteration 611][Wall Clock 32.925089968s] Trained 120 records in 0.044738893 seconds. Throughput is 2682.23 records/second. Loss is 0.73734856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0089126559714795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13440/60000][Iteration 612][Wall Clock 32.969322158s] Trained 120 records in 0.04423219 seconds. Throughput is 2712.9563 records/second. Loss is 0.8530891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008911067545891998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13560/60000][Iteration 613][Wall Clock 33.014773433s] Trained 120 records in 0.045451275 seconds. Throughput is 2640.19 records/second. Loss is 0.7784449. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008909479686386316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13680/60000][Iteration 614][Wall Clock 33.059277112s] Trained 120 records in 0.044503679 seconds. Throughput is 2696.4065 records/second. Loss is 0.8081535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008907892392659897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13800/60000][Iteration 615][Wall Clock 33.103949608s] Trained 120 records in 0.044672496 seconds. Throughput is 2686.2166 records/second. Loss is 0.84252733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008906305664410403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 13920/60000][Iteration 616][Wall Clock 33.147545482s] Trained 120 records in 0.043595874 seconds. Throughput is 2752.5542 records/second. Loss is 0.90286666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008904719501335707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 14040/60000][Iteration 617][Wall Clock 33.191373456s] Trained 120 records in 0.043827974 seconds. Throughput is 2737.9773 records/second. Loss is 0.82800746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008903133903133903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 14160/60000][Iteration 618][Wall Clock 33.234697746s] Trained 120 records in 0.04332429 seconds. Throughput is 2769.8086 records/second. Loss is 0.7587004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008901548869503294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 14280/60000][Iteration 619][Wall Clock 33.280081922s] Trained 120 records in 0.045384176 seconds. Throughput is 2644.0935 records/second. Loss is 0.6956899. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0088999644001424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 14400/60000][Iteration 620][Wall Clock 33.324149007s] Trained 120 records in 0.044067085 seconds. Throughput is 2723.1208 records/second. Loss is 0.8739338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008898380494749957. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 14520/60000][Iteration 621][Wall Clock 33.368499009s] Trained 120 records in 0.044350002 seconds. Throughput is 2705.7495 records/second. Loss is 0.8388925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00889679715302491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 14640/60000][Iteration 622][Wall Clock 33.423555404s] Trained 120 records in 0.055056395 seconds. Throughput is 2179.5835 records/second. Loss is 0.9105517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008895214374666428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:39 INFO  DistriOptimizer$:406 - [Epoch 2 14760/60000][Iteration 623][Wall Clock 33.474841289s] Trained 120 records in 0.051285885 seconds. Throughput is 2339.825 records/second. Loss is 0.8590214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008893632159373888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 14880/60000][Iteration 624][Wall Clock 33.519629439s] Trained 120 records in 0.04478815 seconds. Throughput is 2679.2803 records/second. Loss is 0.8228442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008892050506846879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15000/60000][Iteration 625][Wall Clock 33.563297295s] Trained 120 records in 0.043667856 seconds. Throughput is 2748.0166 records/second. Loss is 0.8258072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008890469416785207. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15120/60000][Iteration 626][Wall Clock 33.607727171s] Trained 120 records in 0.044429876 seconds. Throughput is 2700.8853 records/second. Loss is 0.7390266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008888888888888889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15240/60000][Iteration 627][Wall Clock 33.652702599s] Trained 120 records in 0.044975428 seconds. Throughput is 2668.1235 records/second. Loss is 0.7860196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00888730892285816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15360/60000][Iteration 628][Wall Clock 33.697473771s] Trained 120 records in 0.044771172 seconds. Throughput is 2680.2961 records/second. Loss is 0.7229351. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00888572951839346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15480/60000][Iteration 629][Wall Clock 33.742565063s] Trained 120 records in 0.045091292 seconds. Throughput is 2661.2676 records/second. Loss is 0.7711942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008884150675195452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15600/60000][Iteration 630][Wall Clock 33.787009258s] Trained 120 records in 0.044444195 seconds. Throughput is 2700.0151 records/second. Loss is 0.73036695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008882572392965004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15720/60000][Iteration 631][Wall Clock 33.831338807s] Trained 120 records in 0.044329549 seconds. Throughput is 2706.9978 records/second. Loss is 0.7752312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008880994671403198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15840/60000][Iteration 632][Wall Clock 33.875235528s] Trained 120 records in 0.043896721 seconds. Throughput is 2733.6895 records/second. Loss is 0.8263374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00887941751021133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 15960/60000][Iteration 633][Wall Clock 33.932696561s] Trained 120 records in 0.057461033 seconds. Throughput is 2088.3718 records/second. Loss is 0.7371962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008877840909090908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16080/60000][Iteration 634][Wall Clock 33.97895373s] Trained 120 records in 0.046257169 seconds. Throughput is 2594.1926 records/second. Loss is 0.8813309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008876264867743653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16200/60000][Iteration 635][Wall Clock 34.025896281s] Trained 120 records in 0.046942551 seconds. Throughput is 2556.3162 records/second. Loss is 0.87805814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008874689385871494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16320/60000][Iteration 636][Wall Clock 34.072805715s] Trained 120 records in 0.046909434 seconds. Throughput is 2558.1208 records/second. Loss is 0.8765177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008873114463176575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16440/60000][Iteration 637][Wall Clock 34.118083473s] Trained 120 records in 0.045277758 seconds. Throughput is 2650.3079 records/second. Loss is 0.6911911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008871540099361249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16560/60000][Iteration 638][Wall Clock 34.165012262s] Trained 120 records in 0.046928789 seconds. Throughput is 2557.0657 records/second. Loss is 0.8254963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008869966294128083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16680/60000][Iteration 639][Wall Clock 34.210505432s] Trained 120 records in 0.04549317 seconds. Throughput is 2637.7585 records/second. Loss is 0.7494012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008868393047179852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16800/60000][Iteration 640][Wall Clock 34.257130515s] Trained 120 records in 0.046625083 seconds. Throughput is 2573.722 records/second. Loss is 0.84919035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008866820358219544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 16920/60000][Iteration 641][Wall Clock 34.313130575s] Trained 120 records in 0.05600006 seconds. Throughput is 2142.8547 records/second. Loss is 0.87637144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008865248226950354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 17040/60000][Iteration 642][Wall Clock 34.367628586s] Trained 120 records in 0.054498011 seconds. Throughput is 2201.9153 records/second. Loss is 0.7885522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008863676653075695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 17160/60000][Iteration 643][Wall Clock 34.413089577s] Trained 120 records in 0.045460991 seconds. Throughput is 2639.6257 records/second. Loss is 0.8985922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008862105636299184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:40 INFO  DistriOptimizer$:406 - [Epoch 2 17280/60000][Iteration 644][Wall Clock 34.45698064s] Trained 120 records in 0.043891063 seconds. Throughput is 2734.0417 records/second. Loss is 0.75887525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00886053517632465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 17400/60000][Iteration 645][Wall Clock 34.500559285s] Trained 120 records in 0.043578645 seconds. Throughput is 2753.6423 records/second. Loss is 0.6922638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00885896527285613. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 17520/60000][Iteration 646][Wall Clock 34.544977259s] Trained 120 records in 0.044417974 seconds. Throughput is 2701.6091 records/second. Loss is 0.63672787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008857395925597875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 17640/60000][Iteration 647][Wall Clock 34.595060536s] Trained 120 records in 0.050083277 seconds. Throughput is 2396.0095 records/second. Loss is 0.77424985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00885582713425434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 17760/60000][Iteration 648][Wall Clock 34.646651488s] Trained 120 records in 0.051590952 seconds. Throughput is 2325.9893 records/second. Loss is 0.79331285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008854258898530193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 17880/60000][Iteration 649][Wall Clock 34.691097069s] Trained 120 records in 0.044445581 seconds. Throughput is 2699.931 records/second. Loss is 0.7218136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008852691218130312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18000/60000][Iteration 650][Wall Clock 34.734468477s] Trained 120 records in 0.043371408 seconds. Throughput is 2766.7996 records/second. Loss is 0.7010384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008851124092759781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18120/60000][Iteration 651][Wall Clock 34.7775458s] Trained 120 records in 0.043077323 seconds. Throughput is 2785.6885 records/second. Loss is 0.7667429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008849557522123895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18240/60000][Iteration 652][Wall Clock 34.828095189s] Trained 120 records in 0.050549389 seconds. Throughput is 2373.916 records/second. Loss is 0.8695477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008847991505928153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18360/60000][Iteration 653][Wall Clock 34.871397795s] Trained 120 records in 0.043302606 seconds. Throughput is 2771.1958 records/second. Loss is 0.7558806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008846426043878274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18480/60000][Iteration 654][Wall Clock 34.916483632s] Trained 120 records in 0.045085837 seconds. Throughput is 2661.5898 records/second. Loss is 0.6905154. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00884486113568017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18600/60000][Iteration 655][Wall Clock 34.960378094s] Trained 120 records in 0.043894462 seconds. Throughput is 2733.83 records/second. Loss is 0.7321965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008843296781039971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18720/60000][Iteration 656][Wall Clock 35.006129424s] Trained 120 records in 0.04575133 seconds. Throughput is 2622.8745 records/second. Loss is 0.8776454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008841732979664015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18840/60000][Iteration 657][Wall Clock 35.052679308s] Trained 120 records in 0.046549884 seconds. Throughput is 2577.8796 records/second. Loss is 0.8095874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00884016973125884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 18960/60000][Iteration 658][Wall Clock 35.098146984s] Trained 120 records in 0.045467676 seconds. Throughput is 2639.2378 records/second. Loss is 0.7432434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008838607035531201. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 19080/60000][Iteration 659][Wall Clock 35.154416499s] Trained 120 records in 0.056269515 seconds. Throughput is 2132.5935 records/second. Loss is 0.6867635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008837044892188053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 19200/60000][Iteration 660][Wall Clock 35.207176699s] Trained 120 records in 0.0527602 seconds. Throughput is 2274.442 records/second. Loss is 0.71263045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008835483300936562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 19320/60000][Iteration 661][Wall Clock 35.253430836s] Trained 120 records in 0.046254137 seconds. Throughput is 2594.3625 records/second. Loss is 0.68447036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008833922261484098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 19440/60000][Iteration 662][Wall Clock 35.301533657s] Trained 120 records in 0.048102821 seconds. Throughput is 2494.656 records/second. Loss is 0.8516427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008832361773538244. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 19560/60000][Iteration 663][Wall Clock 35.351409721s] Trained 120 records in 0.049876064 seconds. Throughput is 2405.9636 records/second. Loss is 0.7157186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008830801836806781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 19680/60000][Iteration 664][Wall Clock 35.397371147s] Trained 120 records in 0.045961426 seconds. Throughput is 2610.885 records/second. Loss is 0.8042767. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008829242450997704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:41 INFO  DistriOptimizer$:406 - [Epoch 2 19800/60000][Iteration 665][Wall Clock 35.44496116s] Trained 120 records in 0.047590013 seconds. Throughput is 2521.5374 records/second. Loss is 0.88222367. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00882768361581921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 19920/60000][Iteration 666][Wall Clock 35.494360364s] Trained 120 records in 0.049399204 seconds. Throughput is 2429.189 records/second. Loss is 0.80918896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008826125330979701. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20040/60000][Iteration 667][Wall Clock 35.54235676s] Trained 120 records in 0.047996396 seconds. Throughput is 2500.1877 records/second. Loss is 0.7387709. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008824567596187787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20160/60000][Iteration 668][Wall Clock 35.589958753s] Trained 120 records in 0.047601993 seconds. Throughput is 2520.9028 records/second. Loss is 0.69485146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008823010411152285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20280/60000][Iteration 669][Wall Clock 35.637751255s] Trained 120 records in 0.047792502 seconds. Throughput is 2510.854 records/second. Loss is 0.8191889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008821453775582216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20400/60000][Iteration 670][Wall Clock 35.689134422s] Trained 120 records in 0.051383167 seconds. Throughput is 2335.3953 records/second. Loss is 0.6950311. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008819897689186807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20520/60000][Iteration 671][Wall Clock 35.734679461s] Trained 120 records in 0.045545039 seconds. Throughput is 2634.7546 records/second. Loss is 0.74240863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008818342151675486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20640/60000][Iteration 672][Wall Clock 35.792973033s] Trained 120 records in 0.058293572 seconds. Throughput is 2058.546 records/second. Loss is 0.8084505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00881678716275789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20760/60000][Iteration 673][Wall Clock 35.846353929s] Trained 120 records in 0.053380896 seconds. Throughput is 2247.9954 records/second. Loss is 0.8057367. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008815232722143865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 20880/60000][Iteration 674][Wall Clock 35.894351758s] Trained 120 records in 0.047997829 seconds. Throughput is 2500.113 records/second. Loss is 0.70541346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008813678829543451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21000/60000][Iteration 675][Wall Clock 35.939271638s] Trained 120 records in 0.04491988 seconds. Throughput is 2671.423 records/second. Loss is 0.830809. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008812125484666901. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21120/60000][Iteration 676][Wall Clock 35.985090428s] Trained 120 records in 0.04581879 seconds. Throughput is 2619.0127 records/second. Loss is 0.7929041. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00881057268722467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21240/60000][Iteration 677][Wall Clock 36.03130534s] Trained 120 records in 0.046214912 seconds. Throughput is 2596.5645 records/second. Loss is 0.76989. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008809020436927413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21360/60000][Iteration 678][Wall Clock 36.088301003s] Trained 120 records in 0.056995663 seconds. Throughput is 2105.4233 records/second. Loss is 0.78726363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008807468733485996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21480/60000][Iteration 679][Wall Clock 36.13539818s] Trained 120 records in 0.047097177 seconds. Throughput is 2547.9233 records/second. Loss is 0.75358194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008805917576611484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21600/60000][Iteration 680][Wall Clock 36.18109058s] Trained 120 records in 0.0456924 seconds. Throughput is 2626.2573 records/second. Loss is 0.7316887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008804366966015144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21720/60000][Iteration 681][Wall Clock 36.225583564s] Trained 120 records in 0.044492984 seconds. Throughput is 2697.0544 records/second. Loss is 0.6915416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00880281690140845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21840/60000][Iteration 682][Wall Clock 36.270656343s] Trained 120 records in 0.045072779 seconds. Throughput is 2662.3608 records/second. Loss is 0.8200137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00880126738250308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 21960/60000][Iteration 683][Wall Clock 36.317919798s] Trained 120 records in 0.047263455 seconds. Throughput is 2538.9595 records/second. Loss is 0.8156341. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008799718409010912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 22080/60000][Iteration 684][Wall Clock 36.364401796s] Trained 120 records in 0.046481998 seconds. Throughput is 2581.6448 records/second. Loss is 0.65951467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008798169980644026. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 22200/60000][Iteration 685][Wall Clock 36.4179283s] Trained 120 records in 0.053526504 seconds. Throughput is 2241.88 records/second. Loss is 0.78478044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008796622097114707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:42 INFO  DistriOptimizer$:406 - [Epoch 2 22320/60000][Iteration 686][Wall Clock 36.47206135s] Trained 120 records in 0.05413305 seconds. Throughput is 2216.7603 records/second. Loss is 0.7851476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008795074758135445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 22440/60000][Iteration 687][Wall Clock 36.517868079s] Trained 120 records in 0.045806729 seconds. Throughput is 2619.7024 records/second. Loss is 0.89173245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008793527963418923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 22560/60000][Iteration 688][Wall Clock 36.561540764s] Trained 120 records in 0.043672685 seconds. Throughput is 2747.713 records/second. Loss is 0.72477525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008791981712678039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 22680/60000][Iteration 689][Wall Clock 36.605222261s] Trained 120 records in 0.043681497 seconds. Throughput is 2747.1584 records/second. Loss is 0.7399563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00879043600562588. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 22800/60000][Iteration 690][Wall Clock 36.649039297s] Trained 120 records in 0.043817036 seconds. Throughput is 2738.661 records/second. Loss is 0.677127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008788890841975743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 22920/60000][Iteration 691][Wall Clock 36.691967116s] Trained 120 records in 0.042927819 seconds. Throughput is 2795.39 records/second. Loss is 0.71757567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008787346221441126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23040/60000][Iteration 692][Wall Clock 36.73594404s] Trained 120 records in 0.043976924 seconds. Throughput is 2728.7036 records/second. Loss is 0.79634327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008785802143735722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23160/60000][Iteration 693][Wall Clock 36.78085522s] Trained 120 records in 0.04491118 seconds. Throughput is 2671.9404 records/second. Loss is 0.68081546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008784258608573436. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23280/60000][Iteration 694][Wall Clock 36.823655505s] Trained 120 records in 0.042800285 seconds. Throughput is 2803.7197 records/second. Loss is 0.78715974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008782715615668365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23400/60000][Iteration 695][Wall Clock 36.867452395s] Trained 120 records in 0.04379689 seconds. Throughput is 2739.9207 records/second. Loss is 0.7118463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008781173164734809. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23520/60000][Iteration 696][Wall Clock 36.912425963s] Trained 120 records in 0.044973568 seconds. Throughput is 2668.234 records/second. Loss is 0.76587147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00877963125548727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23640/60000][Iteration 697][Wall Clock 36.964401802s] Trained 120 records in 0.051975839 seconds. Throughput is 2308.7651 records/second. Loss is 0.7534612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00877808988764045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23760/60000][Iteration 698][Wall Clock 37.018081964s] Trained 120 records in 0.053680162 seconds. Throughput is 2235.4626 records/second. Loss is 0.66888964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008776549060909251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 23880/60000][Iteration 699][Wall Clock 37.062906484s] Trained 120 records in 0.04482452 seconds. Throughput is 2677.1062 records/second. Loss is 0.72661847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008775008775008775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24000/60000][Iteration 700][Wall Clock 37.107516801s] Trained 120 records in 0.044610317 seconds. Throughput is 2689.9607 records/second. Loss is 0.70600146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008773469029654327. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24120/60000][Iteration 701][Wall Clock 37.15097983s] Trained 120 records in 0.043463029 seconds. Throughput is 2760.9673 records/second. Loss is 0.7008456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008771929824561403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24240/60000][Iteration 702][Wall Clock 37.193766448s] Trained 120 records in 0.042786618 seconds. Throughput is 2804.6152 records/second. Loss is 0.76085496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00877039115944571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24360/60000][Iteration 703][Wall Clock 37.237407496s] Trained 120 records in 0.043641048 seconds. Throughput is 2749.7048 records/second. Loss is 0.86573994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008768853034023149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24480/60000][Iteration 704][Wall Clock 37.281938929s] Trained 120 records in 0.044531433 seconds. Throughput is 2694.7256 records/second. Loss is 0.5693053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00876731544800982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24600/60000][Iteration 705][Wall Clock 37.325401776s] Trained 120 records in 0.043462847 seconds. Throughput is 2760.9788 records/second. Loss is 0.6897996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00876577840112202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24720/60000][Iteration 706][Wall Clock 37.368871172s] Trained 120 records in 0.043469396 seconds. Throughput is 2760.563 records/second. Loss is 0.86880755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008764241893076249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24840/60000][Iteration 707][Wall Clock 37.412732167s] Trained 120 records in 0.043860995 seconds. Throughput is 2735.916 records/second. Loss is 0.802241. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008762705923589204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:43 INFO  DistriOptimizer$:406 - [Epoch 2 24960/60000][Iteration 708][Wall Clock 37.456631277s] Trained 120 records in 0.04389911 seconds. Throughput is 2733.5405 records/second. Loss is 0.7047685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008761170492377781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25080/60000][Iteration 709][Wall Clock 37.500774537s] Trained 120 records in 0.04414326 seconds. Throughput is 2718.4219 records/second. Loss is 0.7583688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008759635599159075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25200/60000][Iteration 710][Wall Clock 37.543990554s] Trained 120 records in 0.043216017 seconds. Throughput is 2776.7483 records/second. Loss is 0.75348055. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008758101243650377. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25320/60000][Iteration 711][Wall Clock 37.587879135s] Trained 120 records in 0.043888581 seconds. Throughput is 2734.1965 records/second. Loss is 0.60687137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008756567425569177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25440/60000][Iteration 712][Wall Clock 37.642369006s] Trained 120 records in 0.054489871 seconds. Throughput is 2202.2441 records/second. Loss is 0.78082335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008755034144633165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25560/60000][Iteration 713][Wall Clock 37.689817122s] Trained 120 records in 0.047448116 seconds. Throughput is 2529.0781 records/second. Loss is 0.5988853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008753501400560224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25680/60000][Iteration 714][Wall Clock 37.733423299s] Trained 120 records in 0.043606177 seconds. Throughput is 2751.9038 records/second. Loss is 0.7110331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00875196919306844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25800/60000][Iteration 715][Wall Clock 37.777292265s] Trained 120 records in 0.043868966 seconds. Throughput is 2735.419 records/second. Loss is 0.67757744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008750437521876094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 25920/60000][Iteration 716][Wall Clock 37.821667354s] Trained 120 records in 0.044375089 seconds. Throughput is 2704.22 records/second. Loss is 0.6539701. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008748906386701663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26040/60000][Iteration 717][Wall Clock 37.865401036s] Trained 120 records in 0.043733682 seconds. Throughput is 2743.8806 records/second. Loss is 0.74789613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008747375787263822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26160/60000][Iteration 718][Wall Clock 37.909305724s] Trained 120 records in 0.043904688 seconds. Throughput is 2733.1934 records/second. Loss is 0.6813645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008745845723281442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26280/60000][Iteration 719][Wall Clock 37.953491955s] Trained 120 records in 0.044186231 seconds. Throughput is 2715.778 records/second. Loss is 0.6872591. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008744316194473592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26400/60000][Iteration 720][Wall Clock 38.001857377s] Trained 120 records in 0.048365422 seconds. Throughput is 2481.1113 records/second. Loss is 0.62148356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00874278720055954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26520/60000][Iteration 721][Wall Clock 38.047605248s] Trained 120 records in 0.045747871 seconds. Throughput is 2623.0728 records/second. Loss is 0.7504765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00874125874125874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26640/60000][Iteration 722][Wall Clock 38.096173777s] Trained 120 records in 0.048568529 seconds. Throughput is 2470.7358 records/second. Loss is 0.6636174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008739730816290857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26760/60000][Iteration 723][Wall Clock 38.152543184s] Trained 120 records in 0.056369407 seconds. Throughput is 2128.8145 records/second. Loss is 0.64860535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008738203425375742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 26880/60000][Iteration 724][Wall Clock 38.198683235s] Trained 120 records in 0.046140051 seconds. Throughput is 2600.7773 records/second. Loss is 0.75649947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008736676568233443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 27000/60000][Iteration 725][Wall Clock 38.243418628s] Trained 120 records in 0.044735393 seconds. Throughput is 2682.4397 records/second. Loss is 0.7199789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008735150244584206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 27120/60000][Iteration 726][Wall Clock 38.288670381s] Trained 120 records in 0.045251753 seconds. Throughput is 2651.831 records/second. Loss is 0.7228082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008733624454148471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 27240/60000][Iteration 727][Wall Clock 38.332381844s] Trained 120 records in 0.043711463 seconds. Throughput is 2745.2751 records/second. Loss is 0.65198046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008732099196646874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 27360/60000][Iteration 728][Wall Clock 38.376343522s] Trained 120 records in 0.043961678 seconds. Throughput is 2729.6501 records/second. Loss is 0.66905123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008730574471800244. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 27480/60000][Iteration 729][Wall Clock 38.42064174s] Trained 120 records in 0.044298218 seconds. Throughput is 2708.9126 records/second. Loss is 0.74563724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00872905027932961. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:44 INFO  DistriOptimizer$:406 - [Epoch 2 27600/60000][Iteration 730][Wall Clock 38.467524482s] Trained 120 records in 0.046882742 seconds. Throughput is 2559.5774 records/second. Loss is 0.7103287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008727526618956188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 27720/60000][Iteration 731][Wall Clock 38.511852179s] Trained 120 records in 0.044327697 seconds. Throughput is 2707.111 records/second. Loss is 0.86072546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008726003490401398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 27840/60000][Iteration 732][Wall Clock 38.556748518s] Trained 120 records in 0.044896339 seconds. Throughput is 2672.8237 records/second. Loss is 0.7362031. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008724480893386845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 27960/60000][Iteration 733][Wall Clock 38.600610254s] Trained 120 records in 0.043861736 seconds. Throughput is 2735.8699 records/second. Loss is 0.58148825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008722958827634334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28080/60000][Iteration 734][Wall Clock 38.643847877s] Trained 120 records in 0.043237623 seconds. Throughput is 2775.3608 records/second. Loss is 0.6806548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008721437292865864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28200/60000][Iteration 735][Wall Clock 38.688609799s] Trained 120 records in 0.044761922 seconds. Throughput is 2680.85 records/second. Loss is 0.7149278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008719916288803628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28320/60000][Iteration 736][Wall Clock 38.732104884s] Trained 120 records in 0.043495085 seconds. Throughput is 2758.9324 records/second. Loss is 0.70025384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008718395815170008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28440/60000][Iteration 737][Wall Clock 38.775308716s] Trained 120 records in 0.043203832 seconds. Throughput is 2777.5315 records/second. Loss is 0.7440638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008716875871687587. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28560/60000][Iteration 738][Wall Clock 38.825376367s] Trained 120 records in 0.050067651 seconds. Throughput is 2396.757 records/second. Loss is 0.7643215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008715356458079136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28680/60000][Iteration 739][Wall Clock 38.877202309s] Trained 120 records in 0.051825942 seconds. Throughput is 2315.4429 records/second. Loss is 0.7312636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00871383757406762. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28800/60000][Iteration 740][Wall Clock 38.924283088s] Trained 120 records in 0.047080779 seconds. Throughput is 2548.811 records/second. Loss is 0.6460525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008712319219376199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 28920/60000][Iteration 741][Wall Clock 38.970734335s] Trained 120 records in 0.046451247 seconds. Throughput is 2583.3535 records/second. Loss is 0.7644635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008710801393728223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29040/60000][Iteration 742][Wall Clock 39.024031768s] Trained 120 records in 0.053297433 seconds. Throughput is 2251.5156 records/second. Loss is 0.68861884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008709284096847238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29160/60000][Iteration 743][Wall Clock 39.076346025s] Trained 120 records in 0.052314257 seconds. Throughput is 2293.8298 records/second. Loss is 0.6540409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008707767328456984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29280/60000][Iteration 744][Wall Clock 39.122171088s] Trained 120 records in 0.045825063 seconds. Throughput is 2618.6543 records/second. Loss is 0.7583945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008706251088281386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29400/60000][Iteration 745][Wall Clock 39.168089093s] Trained 120 records in 0.045918005 seconds. Throughput is 2613.3538 records/second. Loss is 0.7055112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008704735376044569. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29520/60000][Iteration 746][Wall Clock 39.212223007s] Trained 120 records in 0.044133914 seconds. Throughput is 2718.9976 records/second. Loss is 0.6707953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008703220191470844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29640/60000][Iteration 747][Wall Clock 39.259451358s] Trained 120 records in 0.047228351 seconds. Throughput is 2540.8467 records/second. Loss is 0.70229053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00870170553428472. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29760/60000][Iteration 748][Wall Clock 39.310202284s] Trained 120 records in 0.050750926 seconds. Throughput is 2364.4888 records/second. Loss is 0.7429863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008700191404210893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 29880/60000][Iteration 749][Wall Clock 39.358750745s] Trained 120 records in 0.048548461 seconds. Throughput is 2471.757 records/second. Loss is 0.804351. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008698677800974252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 30000/60000][Iteration 750][Wall Clock 39.403383226s] Trained 120 records in 0.044632481 seconds. Throughput is 2688.625 records/second. Loss is 0.72027427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008697164724299879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:45 INFO  DistriOptimizer$:406 - [Epoch 2 30120/60000][Iteration 751][Wall Clock 39.446941662s] Trained 120 records in 0.043558436 seconds. Throughput is 2754.9197 records/second. Loss is 0.64684886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008695652173913044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 30240/60000][Iteration 752][Wall Clock 39.490677599s] Trained 120 records in 0.043735937 seconds. Throughput is 2743.739 records/second. Loss is 0.70205843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008694140149539212. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 30360/60000][Iteration 753][Wall Clock 39.53356022s] Trained 120 records in 0.042882621 seconds. Throughput is 2798.3364 records/second. Loss is 0.6066665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008692628650904033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 30480/60000][Iteration 754][Wall Clock 39.576321225s] Trained 120 records in 0.042761005 seconds. Throughput is 2806.2952 records/second. Loss is 0.69596165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008691117677733355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 30600/60000][Iteration 755][Wall Clock 39.618330054s] Trained 120 records in 0.042008829 seconds. Throughput is 2856.5425 records/second. Loss is 0.8697207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008689607229753215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 30720/60000][Iteration 756][Wall Clock 39.661277191s] Trained 120 records in 0.042947137 seconds. Throughput is 2794.1328 records/second. Loss is 0.7612721. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008688097306689836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 30840/60000][Iteration 757][Wall Clock 39.703798357s] Trained 120 records in 0.042521166 seconds. Throughput is 2822.1238 records/second. Loss is 0.73894995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008686587908269632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 30960/60000][Iteration 758][Wall Clock 39.746333845s] Trained 120 records in 0.042535488 seconds. Throughput is 2821.1738 records/second. Loss is 0.752026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008685079034219213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31080/60000][Iteration 759][Wall Clock 39.790209858s] Trained 120 records in 0.043876013 seconds. Throughput is 2734.9795 records/second. Loss is 0.67708373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00868357068426537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31200/60000][Iteration 760][Wall Clock 39.834093109s] Trained 120 records in 0.043883251 seconds. Throughput is 2734.5286 records/second. Loss is 0.61326754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008682062858135093. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31320/60000][Iteration 761][Wall Clock 39.877543361s] Trained 120 records in 0.043450252 seconds. Throughput is 2761.7793 records/second. Loss is 0.659456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008680555555555556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31440/60000][Iteration 762][Wall Clock 39.921079693s] Trained 120 records in 0.043536332 seconds. Throughput is 2756.3186 records/second. Loss is 0.6388814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008679048776254122. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31560/60000][Iteration 763][Wall Clock 39.965663905s] Trained 120 records in 0.044584212 seconds. Throughput is 2691.536 records/second. Loss is 0.6952041. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008677542519958347. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31680/60000][Iteration 764][Wall Clock 40.009241685s] Trained 120 records in 0.04357778 seconds. Throughput is 2753.697 records/second. Loss is 0.56145424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008676036786395974. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31800/60000][Iteration 765][Wall Clock 40.066104953s] Trained 120 records in 0.056863268 seconds. Throughput is 2110.3254 records/second. Loss is 0.7555984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008674531575294934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 31920/60000][Iteration 766][Wall Clock 40.112927483s] Trained 120 records in 0.04682253 seconds. Throughput is 2562.869 records/second. Loss is 0.6946618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008673026886383347. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 32040/60000][Iteration 767][Wall Clock 40.157027494s] Trained 120 records in 0.044100011 seconds. Throughput is 2721.0876 records/second. Loss is 0.6349083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008671522719389525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 32160/60000][Iteration 768][Wall Clock 40.201078555s] Trained 120 records in 0.044051061 seconds. Throughput is 2724.1113 records/second. Loss is 0.8123748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008670019074041963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 32280/60000][Iteration 769][Wall Clock 40.244908105s] Trained 120 records in 0.04382955 seconds. Throughput is 2737.879 records/second. Loss is 0.6115887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00866851595006935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 32400/60000][Iteration 770][Wall Clock 40.292757333s] Trained 120 records in 0.047849228 seconds. Throughput is 2507.8774 records/second. Loss is 0.64192325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008667013347200556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 32520/60000][Iteration 771][Wall Clock 40.338374177s] Trained 120 records in 0.045616844 seconds. Throughput is 2630.6074 records/second. Loss is 0.6027278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008665511265164646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 32640/60000][Iteration 772][Wall Clock 40.38746022s] Trained 120 records in 0.049086043 seconds. Throughput is 2444.6868 records/second. Loss is 0.7609231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00866400970369087. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:46 INFO  DistriOptimizer$:406 - [Epoch 2 32760/60000][Iteration 773][Wall Clock 40.438410528s] Trained 120 records in 0.050950308 seconds. Throughput is 2355.236 records/second. Loss is 0.6452252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008662508662508662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 32880/60000][Iteration 774][Wall Clock 40.484830683s] Trained 120 records in 0.046420155 seconds. Throughput is 2585.084 records/second. Loss is 0.71767384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008661008141347652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33000/60000][Iteration 775][Wall Clock 40.528686951s] Trained 120 records in 0.043856268 seconds. Throughput is 2736.211 records/second. Loss is 0.6300428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008659508139937652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33120/60000][Iteration 776][Wall Clock 40.572272128s] Trained 120 records in 0.043585177 seconds. Throughput is 2753.2295 records/second. Loss is 0.87594676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008658008658008658. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33240/60000][Iteration 777][Wall Clock 40.615266499s] Trained 120 records in 0.042994371 seconds. Throughput is 2791.063 records/second. Loss is 0.7176356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00865650969529086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33360/60000][Iteration 778][Wall Clock 40.659610505s] Trained 120 records in 0.044344006 seconds. Throughput is 2706.1155 records/second. Loss is 0.66190237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008655011251514627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33480/60000][Iteration 779][Wall Clock 40.703283143s] Trained 120 records in 0.043672638 seconds. Throughput is 2747.716 records/second. Loss is 0.6439388. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008653513326410523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33600/60000][Iteration 780][Wall Clock 40.747127958s] Trained 120 records in 0.043844815 seconds. Throughput is 2736.9255 records/second. Loss is 0.7050291. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008652015919709292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33720/60000][Iteration 781][Wall Clock 40.791025176s] Trained 120 records in 0.043897218 seconds. Throughput is 2733.6584 records/second. Loss is 0.62734586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00865051903114187. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33840/60000][Iteration 782][Wall Clock 40.835317896s] Trained 120 records in 0.04429272 seconds. Throughput is 2709.249 records/second. Loss is 0.8252516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008649022660439369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 33960/60000][Iteration 783][Wall Clock 40.880463456s] Trained 120 records in 0.04514556 seconds. Throughput is 2658.0686 records/second. Loss is 0.76335794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008647526807333102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34080/60000][Iteration 784][Wall Clock 40.925128666s] Trained 120 records in 0.04466521 seconds. Throughput is 2686.6548 records/second. Loss is 0.7125084. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008646031471554556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34200/60000][Iteration 785][Wall Clock 40.969908173s] Trained 120 records in 0.044779507 seconds. Throughput is 2679.7974 records/second. Loss is 0.71152914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008644536652835409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34320/60000][Iteration 786][Wall Clock 41.014222072s] Trained 120 records in 0.044313899 seconds. Throughput is 2707.9539 records/second. Loss is 0.79936564. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00864304235090752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34440/60000][Iteration 787][Wall Clock 41.058328535s] Trained 120 records in 0.044106463 seconds. Throughput is 2720.6897 records/second. Loss is 0.6557568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008641548565502939. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34560/60000][Iteration 788][Wall Clock 41.101503807s] Trained 120 records in 0.043175272 seconds. Throughput is 2779.3687 records/second. Loss is 0.71129864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008640055296353897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34680/60000][Iteration 789][Wall Clock 41.144179972s] Trained 120 records in 0.042676165 seconds. Throughput is 2811.874 records/second. Loss is 0.690266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008638562543192813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34800/60000][Iteration 790][Wall Clock 41.187112553s] Trained 120 records in 0.042932581 seconds. Throughput is 2795.08 records/second. Loss is 0.7307419. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00863707030575229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 34920/60000][Iteration 791][Wall Clock 41.23808255s] Trained 120 records in 0.050969997 seconds. Throughput is 2354.3262 records/second. Loss is 0.6037912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008635578583765112. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 35040/60000][Iteration 792][Wall Clock 41.289914638s] Trained 120 records in 0.051832088 seconds. Throughput is 2315.1682 records/second. Loss is 0.6027281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008634087376964255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 35160/60000][Iteration 793][Wall Clock 41.337162002s] Trained 120 records in 0.047247364 seconds. Throughput is 2539.8242 records/second. Loss is 0.59993845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008632596685082872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 35280/60000][Iteration 794][Wall Clock 41.381387168s] Trained 120 records in 0.044225166 seconds. Throughput is 2713.3872 records/second. Loss is 0.55634004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008631106507854307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:47 INFO  DistriOptimizer$:406 - [Epoch 2 35400/60000][Iteration 795][Wall Clock 41.436062504s] Trained 120 records in 0.054675336 seconds. Throughput is 2194.774 records/second. Loss is 0.7992582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00862961684501208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 35520/60000][Iteration 796][Wall Clock 41.484879549s] Trained 120 records in 0.048817045 seconds. Throughput is 2458.1577 records/second. Loss is 0.74511397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008628127696289905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 35640/60000][Iteration 797][Wall Clock 41.530011566s] Trained 120 records in 0.045132017 seconds. Throughput is 2658.8662 records/second. Loss is 0.8032753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00862663906142167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 35760/60000][Iteration 798][Wall Clock 41.575036964s] Trained 120 records in 0.045025398 seconds. Throughput is 2665.1626 records/second. Loss is 0.6095307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008625150940141452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 35880/60000][Iteration 799][Wall Clock 41.619367845s] Trained 120 records in 0.044330881 seconds. Throughput is 2706.9167 records/second. Loss is 0.6298091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008623663332183512. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36000/60000][Iteration 800][Wall Clock 41.673796744s] Trained 120 records in 0.054428899 seconds. Throughput is 2204.7112 records/second. Loss is 0.71798795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00862217623728229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36120/60000][Iteration 801][Wall Clock 41.717653099s] Trained 120 records in 0.043856355 seconds. Throughput is 2736.2053 records/second. Loss is 0.6879499. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008620689655172415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36240/60000][Iteration 802][Wall Clock 41.761057149s] Trained 120 records in 0.04340405 seconds. Throughput is 2764.719 records/second. Loss is 0.64502746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008619203585588691. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36360/60000][Iteration 803][Wall Clock 41.804928826s] Trained 120 records in 0.043871677 seconds. Throughput is 2735.2498 records/second. Loss is 0.5205715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008617718028266115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36480/60000][Iteration 804][Wall Clock 41.849119398s] Trained 120 records in 0.044190572 seconds. Throughput is 2715.5115 records/second. Loss is 0.7190295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008616232982939858. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36600/60000][Iteration 805][Wall Clock 41.892687783s] Trained 120 records in 0.043568385 seconds. Throughput is 2754.2908 records/second. Loss is 0.7008571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008614748449345278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36720/60000][Iteration 806][Wall Clock 41.936617077s] Trained 120 records in 0.043929294 seconds. Throughput is 2731.6624 records/second. Loss is 0.7340735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008613264427217916. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36840/60000][Iteration 807][Wall Clock 41.980769025s] Trained 120 records in 0.044151948 seconds. Throughput is 2717.887 records/second. Loss is 0.83848035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00861178091629349. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 36960/60000][Iteration 808][Wall Clock 42.024732497s] Trained 120 records in 0.043963472 seconds. Throughput is 2729.5386 records/second. Loss is 0.58039844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008610297916307904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37080/60000][Iteration 809][Wall Clock 42.067962607s] Trained 120 records in 0.04323011 seconds. Throughput is 2775.843 records/second. Loss is 0.7066804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008608815426997245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37200/60000][Iteration 810][Wall Clock 42.110853962s] Trained 120 records in 0.042891355 seconds. Throughput is 2797.7666 records/second. Loss is 0.71166205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00860733344809778. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37320/60000][Iteration 811][Wall Clock 42.15420997s] Trained 120 records in 0.043356008 seconds. Throughput is 2767.7825 records/second. Loss is 0.6723393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008605851979345956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37440/60000][Iteration 812][Wall Clock 42.197363716s] Trained 120 records in 0.043153746 seconds. Throughput is 2780.7551 records/second. Loss is 0.6822735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008604371020478403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37560/60000][Iteration 813][Wall Clock 42.239950743s] Trained 120 records in 0.042587027 seconds. Throughput is 2817.7595 records/second. Loss is 0.69213796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008602890571231933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37680/60000][Iteration 814][Wall Clock 42.290812305s] Trained 120 records in 0.050861562 seconds. Throughput is 2359.3455 records/second. Loss is 0.7339855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00860141063134354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37800/60000][Iteration 815][Wall Clock 42.334110776s] Trained 120 records in 0.043298471 seconds. Throughput is 2771.4604 records/second. Loss is 0.7078707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008599931200550396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 37920/60000][Iteration 816][Wall Clock 42.377184396s] Trained 120 records in 0.04307362 seconds. Throughput is 2785.928 records/second. Loss is 0.6333292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008598452278589854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:48 INFO  DistriOptimizer$:406 - [Epoch 2 38040/60000][Iteration 817][Wall Clock 42.421201615s] Trained 120 records in 0.044017219 seconds. Throughput is 2726.2058 records/second. Loss is 0.57269174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00859697386519945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 38160/60000][Iteration 818][Wall Clock 42.476005661s] Trained 120 records in 0.054804046 seconds. Throughput is 2189.6194 records/second. Loss is 0.6604334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008595495960116899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 38280/60000][Iteration 819][Wall Clock 42.524544288s] Trained 120 records in 0.048538627 seconds. Throughput is 2472.2578 records/second. Loss is 0.5948063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008594018563080097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 38400/60000][Iteration 820][Wall Clock 42.574179495s] Trained 120 records in 0.049635207 seconds. Throughput is 2417.639 records/second. Loss is 0.76798064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008592541673827118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 38520/60000][Iteration 821][Wall Clock 42.618841529s] Trained 120 records in 0.044662034 seconds. Throughput is 2686.846 records/second. Loss is 0.7211114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00859106529209622. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 38640/60000][Iteration 822][Wall Clock 42.664652795s] Trained 120 records in 0.045811266 seconds. Throughput is 2619.443 records/second. Loss is 0.5951957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008589589417625837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 38760/60000][Iteration 823][Wall Clock 42.709372332s] Trained 120 records in 0.044719537 seconds. Throughput is 2683.391 records/second. Loss is 0.49401218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008588114050154586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 38880/60000][Iteration 824][Wall Clock 42.752139003s] Trained 120 records in 0.042766671 seconds. Throughput is 2805.9233 records/second. Loss is 0.5920724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00858663918942126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39000/60000][Iteration 825][Wall Clock 42.795424014s] Trained 120 records in 0.043285011 seconds. Throughput is 2772.3223 records/second. Loss is 0.7948889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008585164835164834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39120/60000][Iteration 826][Wall Clock 42.848615698s] Trained 120 records in 0.053191684 seconds. Throughput is 2255.9917 records/second. Loss is 0.7027785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008583690987124463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39240/60000][Iteration 827][Wall Clock 42.896362378s] Trained 120 records in 0.04774668 seconds. Throughput is 2513.2637 records/second. Loss is 0.6910072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008582217645039478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39360/60000][Iteration 828][Wall Clock 42.940727408s] Trained 120 records in 0.04436503 seconds. Throughput is 2704.833 records/second. Loss is 0.6846915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008580744808649392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39480/60000][Iteration 829][Wall Clock 42.984872695s] Trained 120 records in 0.044145287 seconds. Throughput is 2718.297 records/second. Loss is 0.5030607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008579272477693892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39600/60000][Iteration 830][Wall Clock 43.028825834s] Trained 120 records in 0.043953139 seconds. Throughput is 2730.1804 records/second. Loss is 0.7584097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00857780065191285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39720/60000][Iteration 831][Wall Clock 43.073024318s] Trained 120 records in 0.044198484 seconds. Throughput is 2715.0254 records/second. Loss is 0.5573795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008576329331046312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39840/60000][Iteration 832][Wall Clock 43.115902873s] Trained 120 records in 0.042878555 seconds. Throughput is 2798.6018 records/second. Loss is 0.74360543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008574858514834506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 39960/60000][Iteration 833][Wall Clock 43.159319656s] Trained 120 records in 0.043416783 seconds. Throughput is 2763.9082 records/second. Loss is 0.66168404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008573388203017831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 40080/60000][Iteration 834][Wall Clock 43.202385947s] Trained 120 records in 0.043066291 seconds. Throughput is 2786.402 records/second. Loss is 0.7079383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008571918395336876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 40200/60000][Iteration 835][Wall Clock 43.245184841s] Trained 120 records in 0.042798894 seconds. Throughput is 2803.8108 records/second. Loss is 0.71880215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008570449091532395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 40320/60000][Iteration 836][Wall Clock 43.288775295s] Trained 120 records in 0.043590454 seconds. Throughput is 2752.8965 records/second. Loss is 0.6240699. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00856898029134533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 40440/60000][Iteration 837][Wall Clock 43.332711001s] Trained 120 records in 0.043935706 seconds. Throughput is 2731.2637 records/second. Loss is 0.61119646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008567511994516792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 40560/60000][Iteration 838][Wall Clock 43.376495545s] Trained 120 records in 0.043784544 seconds. Throughput is 2740.693 records/second. Loss is 0.61759675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008566044200788075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:49 INFO  DistriOptimizer$:406 - [Epoch 2 40680/60000][Iteration 839][Wall Clock 43.419525923s] Trained 120 records in 0.043030378 seconds. Throughput is 2788.7275 records/second. Loss is 0.6048943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00856457690990065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 40800/60000][Iteration 840][Wall Clock 43.463433396s] Trained 120 records in 0.043907473 seconds. Throughput is 2733.0198 records/second. Loss is 0.5464324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008563110121596164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 40920/60000][Iteration 841][Wall Clock 43.506636238s] Trained 120 records in 0.043202842 seconds. Throughput is 2777.595 records/second. Loss is 0.5203694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00856164383561644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41040/60000][Iteration 842][Wall Clock 43.550147511s] Trained 120 records in 0.043511273 seconds. Throughput is 2757.906 records/second. Loss is 0.5532717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008560178051703475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41160/60000][Iteration 843][Wall Clock 43.593470488s] Trained 120 records in 0.043322977 seconds. Throughput is 2769.8928 records/second. Loss is 0.61509645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008558712769599451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41280/60000][Iteration 844][Wall Clock 43.644248644s] Trained 120 records in 0.050778156 seconds. Throughput is 2363.221 records/second. Loss is 0.6369329. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008557247989046722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41400/60000][Iteration 845][Wall Clock 43.697660448s] Trained 120 records in 0.053411804 seconds. Throughput is 2246.6943 records/second. Loss is 0.52817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008555783709787816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41520/60000][Iteration 846][Wall Clock 43.74842893s] Trained 120 records in 0.050768482 seconds. Throughput is 2363.6711 records/second. Loss is 0.58864444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00855431993156544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41640/60000][Iteration 847][Wall Clock 43.796038029s] Trained 120 records in 0.047609099 seconds. Throughput is 2520.5266 records/second. Loss is 0.6453338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008552856654122478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41760/60000][Iteration 848][Wall Clock 43.845577201s] Trained 120 records in 0.049539172 seconds. Throughput is 2422.3254 records/second. Loss is 0.58667856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008551393877201984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 41880/60000][Iteration 849][Wall Clock 43.899123128s] Trained 120 records in 0.053545927 seconds. Throughput is 2241.067 records/second. Loss is 0.72748494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008549931600547196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42000/60000][Iteration 850][Wall Clock 43.944430267s] Trained 120 records in 0.045307139 seconds. Throughput is 2648.589 records/second. Loss is 0.4902731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008548469823901523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42120/60000][Iteration 851][Wall Clock 43.989229785s] Trained 120 records in 0.044799518 seconds. Throughput is 2678.6003 records/second. Loss is 0.6620193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008547008547008548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42240/60000][Iteration 852][Wall Clock 44.033465299s] Trained 120 records in 0.044235514 seconds. Throughput is 2712.7524 records/second. Loss is 0.64289016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008545547769612033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42360/60000][Iteration 853][Wall Clock 44.088724387s] Trained 120 records in 0.055259088 seconds. Throughput is 2171.5886 records/second. Loss is 0.59839857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008544087491455913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42480/60000][Iteration 854][Wall Clock 44.132311412s] Trained 120 records in 0.043587025 seconds. Throughput is 2753.1128 records/second. Loss is 0.7143917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008542627712284298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42600/60000][Iteration 855][Wall Clock 44.175843468s] Trained 120 records in 0.043532056 seconds. Throughput is 2756.5894 records/second. Loss is 0.67411494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008541168431841476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42720/60000][Iteration 856][Wall Clock 44.219385591s] Trained 120 records in 0.043542123 seconds. Throughput is 2755.952 records/second. Loss is 0.56696475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008539709649871904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42840/60000][Iteration 857][Wall Clock 44.263398776s] Trained 120 records in 0.044013185 seconds. Throughput is 2726.4558 records/second. Loss is 0.5709442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00853825136612022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 42960/60000][Iteration 858][Wall Clock 44.307722893s] Trained 120 records in 0.044324117 seconds. Throughput is 2707.3296 records/second. Loss is 0.6622283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008536793580331228. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 43080/60000][Iteration 859][Wall Clock 44.351840013s] Trained 120 records in 0.04411712 seconds. Throughput is 2720.0325 records/second. Loss is 0.7648197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008535336292249915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 43200/60000][Iteration 860][Wall Clock 44.395309918s] Trained 120 records in 0.043469905 seconds. Throughput is 2760.5305 records/second. Loss is 0.69964004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008533879501621438. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:50 INFO  DistriOptimizer$:406 - [Epoch 2 43320/60000][Iteration 861][Wall Clock 44.438373626s] Trained 120 records in 0.043063708 seconds. Throughput is 2786.569 records/second. Loss is 0.6330551. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008532423208191127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 43440/60000][Iteration 862][Wall Clock 44.481976112s] Trained 120 records in 0.043602486 seconds. Throughput is 2752.1367 records/second. Loss is 0.63409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008530967411704487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 43560/60000][Iteration 863][Wall Clock 44.524883351s] Trained 120 records in 0.042907239 seconds. Throughput is 2796.731 records/second. Loss is 0.6173255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008529512111907198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 43680/60000][Iteration 864][Wall Clock 44.568194428s] Trained 120 records in 0.043311077 seconds. Throughput is 2770.6538 records/second. Loss is 0.7251503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008528057308545113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 43800/60000][Iteration 865][Wall Clock 44.612300691s] Trained 120 records in 0.044106263 seconds. Throughput is 2720.702 records/second. Loss is 0.8571486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008526603001364257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 43920/60000][Iteration 866][Wall Clock 44.655718412s] Trained 120 records in 0.043417721 seconds. Throughput is 2763.8484 records/second. Loss is 0.5526955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008525149190110827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44040/60000][Iteration 867][Wall Clock 44.699382737s] Trained 120 records in 0.043664325 seconds. Throughput is 2748.239 records/second. Loss is 0.58782005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008523695874531197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44160/60000][Iteration 868][Wall Clock 44.742912813s] Trained 120 records in 0.043530076 seconds. Throughput is 2756.7146 records/second. Loss is 0.60932094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00852224305437191. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44280/60000][Iteration 869][Wall Clock 44.786254206s] Trained 120 records in 0.043341393 seconds. Throughput is 2768.7158 records/second. Loss is 0.61314225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008520790729379687. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44400/60000][Iteration 870][Wall Clock 44.829710083s] Trained 120 records in 0.043455877 seconds. Throughput is 2761.4216 records/second. Loss is 0.6786557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008519338899301414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44520/60000][Iteration 871][Wall Clock 44.891303724s] Trained 120 records in 0.061593641 seconds. Throughput is 1948.253 records/second. Loss is 0.6637824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008517887563884158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44640/60000][Iteration 872][Wall Clock 44.940405343s] Trained 120 records in 0.049101619 seconds. Throughput is 2443.9114 records/second. Loss is 0.648394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008516436722875149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44760/60000][Iteration 873][Wall Clock 44.986394708s] Trained 120 records in 0.045989365 seconds. Throughput is 2609.2988 records/second. Loss is 0.54565454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0085149863760218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 44880/60000][Iteration 874][Wall Clock 45.030344335s] Trained 120 records in 0.043949627 seconds. Throughput is 2730.3987 records/second. Loss is 0.64914644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008513536523071684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45000/60000][Iteration 875][Wall Clock 45.073932912s] Trained 120 records in 0.043588577 seconds. Throughput is 2753.0146 records/second. Loss is 0.6333115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008512087163772556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45120/60000][Iteration 876][Wall Clock 45.118927735s] Trained 120 records in 0.044994823 seconds. Throughput is 2666.9734 records/second. Loss is 0.7343835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00851063829787234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45240/60000][Iteration 877][Wall Clock 45.163176792s] Trained 120 records in 0.044249057 seconds. Throughput is 2711.922 records/second. Loss is 0.6727848. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00850918992511913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45360/60000][Iteration 878][Wall Clock 45.207464944s] Trained 120 records in 0.044288152 seconds. Throughput is 2709.5283 records/second. Loss is 0.6393934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008507742045261188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45480/60000][Iteration 879][Wall Clock 45.26245614s] Trained 120 records in 0.054991196 seconds. Throughput is 2182.1675 records/second. Loss is 0.55986965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008506294658046955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45600/60000][Iteration 880][Wall Clock 45.306377782s] Trained 120 records in 0.043921642 seconds. Throughput is 2732.1382 records/second. Loss is 0.6048347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008504847763225038. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45720/60000][Iteration 881][Wall Clock 45.353068338s] Trained 120 records in 0.046690556 seconds. Throughput is 2570.1128 records/second. Loss is 0.5342897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008503401360544218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:51 INFO  DistriOptimizer$:406 - [Epoch 2 45840/60000][Iteration 882][Wall Clock 45.397852204s] Trained 120 records in 0.044783866 seconds. Throughput is 2679.5366 records/second. Loss is 0.66252124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008501955449753445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 45960/60000][Iteration 883][Wall Clock 45.44395683s] Trained 120 records in 0.046104626 seconds. Throughput is 2602.776 records/second. Loss is 0.6461094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008500510030601835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46080/60000][Iteration 884][Wall Clock 45.497517339s] Trained 120 records in 0.053560509 seconds. Throughput is 2240.4565 records/second. Loss is 0.5998054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008499065102838687. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46200/60000][Iteration 885][Wall Clock 45.544201092s] Trained 120 records in 0.046683753 seconds. Throughput is 2570.4873 records/second. Loss is 0.72228307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00849762066621346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46320/60000][Iteration 886][Wall Clock 45.593291812s] Trained 120 records in 0.04909072 seconds. Throughput is 2444.4539 records/second. Loss is 0.6292816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008496176720475786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46440/60000][Iteration 887][Wall Clock 45.641947811s] Trained 120 records in 0.048655999 seconds. Throughput is 2466.2942 records/second. Loss is 0.6239071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008494733265375467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46560/60000][Iteration 888][Wall Clock 45.691804571s] Trained 120 records in 0.04985676 seconds. Throughput is 2406.8953 records/second. Loss is 0.6663986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008493290300662476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46680/60000][Iteration 889][Wall Clock 45.74353401s] Trained 120 records in 0.051729439 seconds. Throughput is 2319.7622 records/second. Loss is 0.7054287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008491847826086956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46800/60000][Iteration 890][Wall Clock 45.787543704s] Trained 120 records in 0.044009694 seconds. Throughput is 2726.672 records/second. Loss is 0.6760375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008490405841399219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 46920/60000][Iteration 891][Wall Clock 45.839682486s] Trained 120 records in 0.052138782 seconds. Throughput is 2301.5498 records/second. Loss is 0.6003409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008488964346349746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47040/60000][Iteration 892][Wall Clock 45.889435845s] Trained 120 records in 0.049753359 seconds. Throughput is 2411.8975 records/second. Loss is 0.729687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008487523340689187. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47160/60000][Iteration 893][Wall Clock 45.936223571s] Trained 120 records in 0.046787726 seconds. Throughput is 2564.7751 records/second. Loss is 0.64071083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008486082824168364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47280/60000][Iteration 894][Wall Clock 45.982036687s] Trained 120 records in 0.045813116 seconds. Throughput is 2619.3372 records/second. Loss is 0.7067449. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008484642796538265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47400/60000][Iteration 895][Wall Clock 46.026658333s] Trained 120 records in 0.044621646 seconds. Throughput is 2689.2778 records/second. Loss is 0.57146204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00848320325755005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47520/60000][Iteration 896][Wall Clock 46.07894738s] Trained 120 records in 0.052289047 seconds. Throughput is 2294.9358 records/second. Loss is 0.54813707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008481764206955046. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47640/60000][Iteration 897][Wall Clock 46.140388068s] Trained 120 records in 0.061440688 seconds. Throughput is 1953.1031 records/second. Loss is 0.5254366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008480325644504749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47760/60000][Iteration 898][Wall Clock 46.191424754s] Trained 120 records in 0.051036686 seconds. Throughput is 2351.2498 records/second. Loss is 0.52820957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008478887569950822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 47880/60000][Iteration 899][Wall Clock 46.235858633s] Trained 120 records in 0.044433879 seconds. Throughput is 2700.6418 records/second. Loss is 0.66058904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0084774499830451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 48000/60000][Iteration 900][Wall Clock 46.279871174s] Trained 120 records in 0.044012541 seconds. Throughput is 2726.4956 records/second. Loss is 0.59818035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008476012883539583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 48120/60000][Iteration 901][Wall Clock 46.32396704s] Trained 120 records in 0.044095866 seconds. Throughput is 2721.3435 records/second. Loss is 0.58979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00847457627118644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 48240/60000][Iteration 902][Wall Clock 46.36858957s] Trained 120 records in 0.04462253 seconds. Throughput is 2689.2246 records/second. Loss is 0.5446884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00847314014573801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:52 INFO  DistriOptimizer$:406 - [Epoch 2 48360/60000][Iteration 903][Wall Clock 46.415037996s] Trained 120 records in 0.046448426 seconds. Throughput is 2583.5107 records/second. Loss is 0.74351186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008471704506946797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 48480/60000][Iteration 904][Wall Clock 46.460664255s] Trained 120 records in 0.045626259 seconds. Throughput is 2630.0645 records/second. Loss is 0.6019978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008470269354565475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 48600/60000][Iteration 905][Wall Clock 46.511178072s] Trained 120 records in 0.050513817 seconds. Throughput is 2375.5876 records/second. Loss is 0.58573365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008468834688346883. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 48720/60000][Iteration 906][Wall Clock 46.55835483s] Trained 120 records in 0.047176758 seconds. Throughput is 2543.6252 records/second. Loss is 0.57412606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00846740050804403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 48840/60000][Iteration 907][Wall Clock 46.601901639s] Trained 120 records in 0.043546809 seconds. Throughput is 2755.6553 records/second. Loss is 0.5356424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008465966813410091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 48960/60000][Iteration 908][Wall Clock 46.646165255s] Trained 120 records in 0.044263616 seconds. Throughput is 2711.0303 records/second. Loss is 0.7534075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008464533604198408. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49080/60000][Iteration 909][Wall Clock 46.6916849s] Trained 120 records in 0.045519645 seconds. Throughput is 2636.2244 records/second. Loss is 0.6044784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008463100880162493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49200/60000][Iteration 910][Wall Clock 46.740825417s] Trained 120 records in 0.049140517 seconds. Throughput is 2441.9768 records/second. Loss is 0.5221438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008461668641056016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49320/60000][Iteration 911][Wall Clock 46.78860292s] Trained 120 records in 0.047777503 seconds. Throughput is 2511.6423 records/second. Loss is 0.6542776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008460236886632826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49440/60000][Iteration 912][Wall Clock 46.836739973s] Trained 120 records in 0.048137053 seconds. Throughput is 2492.882 records/second. Loss is 0.59861773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00845880561664693. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49560/60000][Iteration 913][Wall Clock 46.884284082s] Trained 120 records in 0.047544109 seconds. Throughput is 2523.972 records/second. Loss is 0.55826795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008457374830852505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49680/60000][Iteration 914][Wall Clock 46.929481179s] Trained 120 records in 0.045197097 seconds. Throughput is 2655.0378 records/second. Loss is 0.65011305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00845594452900389. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49800/60000][Iteration 915][Wall Clock 46.975243925s] Trained 120 records in 0.045762746 seconds. Throughput is 2622.2202 records/second. Loss is 0.61962426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008454514710855596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 49920/60000][Iteration 916][Wall Clock 47.020654442s] Trained 120 records in 0.045410517 seconds. Throughput is 2642.5596 records/second. Loss is 0.5078365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008453085376162298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50040/60000][Iteration 917][Wall Clock 47.066788327s] Trained 120 records in 0.046133885 seconds. Throughput is 2601.125 records/second. Loss is 0.55736727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008451656524678837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50160/60000][Iteration 918][Wall Clock 47.113138021s] Trained 120 records in 0.046349694 seconds. Throughput is 2589.014 records/second. Loss is 0.5297469. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008450228156160217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50280/60000][Iteration 919][Wall Clock 47.158304572s] Trained 120 records in 0.045166551 seconds. Throughput is 2656.8333 records/second. Loss is 0.6335677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00844880027036161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50400/60000][Iteration 920][Wall Clock 47.202178706s] Trained 120 records in 0.043874134 seconds. Throughput is 2735.0967 records/second. Loss is 0.5687036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00844737286703835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50520/60000][Iteration 921][Wall Clock 47.247080026s] Trained 120 records in 0.04490132 seconds. Throughput is 2672.5273 records/second. Loss is 0.59376884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008445945945945946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50640/60000][Iteration 922][Wall Clock 47.311074633s] Trained 120 records in 0.063994607 seconds. Throughput is 1875.158 records/second. Loss is 0.5711073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008444519506840062. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50760/60000][Iteration 923][Wall Clock 47.366707249s] Trained 120 records in 0.055632616 seconds. Throughput is 2157.008 records/second. Loss is 0.49264336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008443093549476527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:53 INFO  DistriOptimizer$:406 - [Epoch 2 50880/60000][Iteration 924][Wall Clock 47.41081531s] Trained 120 records in 0.044108061 seconds. Throughput is 2720.5913 records/second. Loss is 0.5838015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008441668073611346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51000/60000][Iteration 925][Wall Clock 47.457325779s] Trained 120 records in 0.046510469 seconds. Throughput is 2580.0642 records/second. Loss is 0.64957625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008440243079000674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51120/60000][Iteration 926][Wall Clock 47.501892463s] Trained 120 records in 0.044566684 seconds. Throughput is 2692.5942 records/second. Loss is 0.6232803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008438818565400843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51240/60000][Iteration 927][Wall Clock 47.552898761s] Trained 120 records in 0.051006298 seconds. Throughput is 2352.6506 records/second. Loss is 0.6780195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008437394532568343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51360/60000][Iteration 928][Wall Clock 47.599822757s] Trained 120 records in 0.046923996 seconds. Throughput is 2557.327 records/second. Loss is 0.7021972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008435970980259827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51480/60000][Iteration 929][Wall Clock 47.646003163s] Trained 120 records in 0.046180406 seconds. Throughput is 2598.5046 records/second. Loss is 0.55889136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008434547908232119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51600/60000][Iteration 930][Wall Clock 47.690234798s] Trained 120 records in 0.044231635 seconds. Throughput is 2712.9905 records/second. Loss is 0.57902753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0084331253162422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51720/60000][Iteration 931][Wall Clock 47.74253036s] Trained 120 records in 0.052295562 seconds. Throughput is 2294.65 records/second. Loss is 0.5535895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008431703204047219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51840/60000][Iteration 932][Wall Clock 47.793930075s] Trained 120 records in 0.051399715 seconds. Throughput is 2334.6433 records/second. Loss is 0.6166486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008430281571404486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 51960/60000][Iteration 933][Wall Clock 47.837013518s] Trained 120 records in 0.043083443 seconds. Throughput is 2785.2927 records/second. Loss is 0.6363855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008428860418071478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52080/60000][Iteration 934][Wall Clock 47.883214656s] Trained 120 records in 0.046201138 seconds. Throughput is 2597.3386 records/second. Loss is 0.61434686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008427439743805831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52200/60000][Iteration 935][Wall Clock 47.927463374s] Trained 120 records in 0.044248718 seconds. Throughput is 2711.9429 records/second. Loss is 0.5163082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008426019548365351. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52320/60000][Iteration 936][Wall Clock 47.971559436s] Trained 120 records in 0.044096062 seconds. Throughput is 2721.3313 records/second. Loss is 0.55227107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008424599831508003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52440/60000][Iteration 937][Wall Clock 48.016102759s] Trained 120 records in 0.044543323 seconds. Throughput is 2694.0066 records/second. Loss is 0.535023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008423180592991913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52560/60000][Iteration 938][Wall Clock 48.061011754s] Trained 120 records in 0.044908995 seconds. Throughput is 2672.0703 records/second. Loss is 0.5490213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008421761832575375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52680/60000][Iteration 939][Wall Clock 48.106128952s] Trained 120 records in 0.045117198 seconds. Throughput is 2659.7395 records/second. Loss is 0.64647174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008420343550016841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52800/60000][Iteration 940][Wall Clock 48.1488649s] Trained 120 records in 0.042735948 seconds. Throughput is 2807.9404 records/second. Loss is 0.6498011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00841892574507493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 52920/60000][Iteration 941][Wall Clock 48.191370674s] Trained 120 records in 0.042505774 seconds. Throughput is 2823.1458 records/second. Loss is 0.6180206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008417508417508417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 53040/60000][Iteration 942][Wall Clock 48.234160244s] Trained 120 records in 0.04278957 seconds. Throughput is 2804.4216 records/second. Loss is 0.5531319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008416091567076251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 53160/60000][Iteration 943][Wall Clock 48.276858764s] Trained 120 records in 0.04269852 seconds. Throughput is 2810.4019 records/second. Loss is 0.78068864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008414675193537528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 53280/60000][Iteration 944][Wall Clock 48.319384576s] Trained 120 records in 0.042525812 seconds. Throughput is 2821.8154 records/second. Loss is 0.5477487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008413259296651522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 53400/60000][Iteration 945][Wall Clock 48.361745051s] Trained 120 records in 0.042360475 seconds. Throughput is 2832.8296 records/second. Loss is 0.5047077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008411843876177657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:54 INFO  DistriOptimizer$:406 - [Epoch 2 53520/60000][Iteration 946][Wall Clock 48.404226874s] Trained 120 records in 0.042481823 seconds. Throughput is 2824.7373 records/second. Loss is 0.5824793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008410428931875526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 53640/60000][Iteration 947][Wall Clock 48.455129542s] Trained 120 records in 0.050902668 seconds. Throughput is 2357.4402 records/second. Loss is 0.6350829. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008409014463504878. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 53760/60000][Iteration 948][Wall Clock 48.505706536s] Trained 120 records in 0.050576994 seconds. Throughput is 2372.6204 records/second. Loss is 0.5870799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008407600470825626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 53880/60000][Iteration 949][Wall Clock 48.549414232s] Trained 120 records in 0.043707696 seconds. Throughput is 2745.512 records/second. Loss is 0.59115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008406186953597848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54000/60000][Iteration 950][Wall Clock 48.592202634s] Trained 120 records in 0.042788402 seconds. Throughput is 2804.4983 records/second. Loss is 0.68303525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00840477391158178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54120/60000][Iteration 951][Wall Clock 48.634695069s] Trained 120 records in 0.042492435 seconds. Throughput is 2824.0322 records/second. Loss is 0.633139. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008403361344537816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54240/60000][Iteration 952][Wall Clock 48.677589915s] Trained 120 records in 0.042894846 seconds. Throughput is 2797.5388 records/second. Loss is 0.5722442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008401949252226518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54360/60000][Iteration 953][Wall Clock 48.719904767s] Trained 120 records in 0.042314852 seconds. Throughput is 2835.8835 records/second. Loss is 0.56077254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008400537634408603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54480/60000][Iteration 954][Wall Clock 48.762513019s] Trained 120 records in 0.042608252 seconds. Throughput is 2816.3557 records/second. Loss is 0.5133253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008399126490844951. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54600/60000][Iteration 955][Wall Clock 48.805698862s] Trained 120 records in 0.043185843 seconds. Throughput is 2778.6885 records/second. Loss is 0.48507437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008397715821296607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54720/60000][Iteration 956][Wall Clock 48.848147192s] Trained 120 records in 0.04244833 seconds. Throughput is 2826.9663 records/second. Loss is 0.6243319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008396305625524769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54840/60000][Iteration 957][Wall Clock 48.891841917s] Trained 120 records in 0.043694725 seconds. Throughput is 2746.3271 records/second. Loss is 0.68072104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0083948959032908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 54960/60000][Iteration 958][Wall Clock 48.944177189s] Trained 120 records in 0.052335272 seconds. Throughput is 2292.9087 records/second. Loss is 0.5730662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008393486654356219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55080/60000][Iteration 959][Wall Clock 48.992580829s] Trained 120 records in 0.04840364 seconds. Throughput is 2479.1523 records/second. Loss is 0.5733678. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008392077878482713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55200/60000][Iteration 960][Wall Clock 49.039466156s] Trained 120 records in 0.046885327 seconds. Throughput is 2559.4363 records/second. Loss is 0.72083336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00839066957543212. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55320/60000][Iteration 961][Wall Clock 49.084994513s] Trained 120 records in 0.045528357 seconds. Throughput is 2635.72 records/second. Loss is 0.58000964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008389261744966443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55440/60000][Iteration 962][Wall Clock 49.128827423s] Trained 120 records in 0.04383291 seconds. Throughput is 2737.6692 records/second. Loss is 0.5744038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008387854386847846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55560/60000][Iteration 963][Wall Clock 49.172552752s] Trained 120 records in 0.043725329 seconds. Throughput is 2744.4045 records/second. Loss is 0.567944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008386447500838645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55680/60000][Iteration 964][Wall Clock 49.216762893s] Trained 120 records in 0.044210141 seconds. Throughput is 2714.3096 records/second. Loss is 0.49897707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008385041086701324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55800/60000][Iteration 965][Wall Clock 49.260294499s] Trained 120 records in 0.043531606 seconds. Throughput is 2756.6177 records/second. Loss is 0.48741215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008383635144198523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 55920/60000][Iteration 966][Wall Clock 49.304023243s] Trained 120 records in 0.043728744 seconds. Throughput is 2744.1904 records/second. Loss is 0.6242225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008382229673093043. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 56040/60000][Iteration 967][Wall Clock 49.347796372s] Trained 120 records in 0.043773129 seconds. Throughput is 2741.4077 records/second. Loss is 0.6926934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008380824673147838. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:55 INFO  DistriOptimizer$:406 - [Epoch 2 56160/60000][Iteration 968][Wall Clock 49.391078109s] Trained 120 records in 0.043281737 seconds. Throughput is 2772.532 records/second. Loss is 0.51012164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008379420144126027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 56280/60000][Iteration 969][Wall Clock 49.434437139s] Trained 120 records in 0.04335903 seconds. Throughput is 2767.5896 records/second. Loss is 0.5456354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008378016085790885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 56400/60000][Iteration 970][Wall Clock 49.477328914s] Trained 120 records in 0.042891775 seconds. Throughput is 2797.7393 records/second. Loss is 0.5925117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008376612497905847. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 56520/60000][Iteration 971][Wall Clock 49.520371781s] Trained 120 records in 0.043042867 seconds. Throughput is 2787.9182 records/second. Loss is 0.59047115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008375209380234507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 56640/60000][Iteration 972][Wall Clock 49.574184731s] Trained 120 records in 0.05381295 seconds. Throughput is 2229.9465 records/second. Loss is 0.61975724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008373806732540614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 56760/60000][Iteration 973][Wall Clock 49.623284271s] Trained 120 records in 0.04909954 seconds. Throughput is 2444.015 records/second. Loss is 0.70191187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008372404554588079. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 56880/60000][Iteration 974][Wall Clock 49.67069886s] Trained 120 records in 0.047414589 seconds. Throughput is 2530.8665 records/second. Loss is 0.73288083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008371002846140967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57000/60000][Iteration 975][Wall Clock 49.713454406s] Trained 120 records in 0.042755546 seconds. Throughput is 2806.6536 records/second. Loss is 0.6749123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008369601606963508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57120/60000][Iteration 976][Wall Clock 49.756716301s] Trained 120 records in 0.043261895 seconds. Throughput is 2773.8035 records/second. Loss is 0.5871198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008368200836820083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57240/60000][Iteration 977][Wall Clock 49.799376332s] Trained 120 records in 0.042660031 seconds. Throughput is 2812.9375 records/second. Loss is 0.46477637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008366800535475234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57360/60000][Iteration 978][Wall Clock 49.842512233s] Trained 120 records in 0.043135901 seconds. Throughput is 2781.9055 records/second. Loss is 0.54850084. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008365400702693659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57480/60000][Iteration 979][Wall Clock 49.887110111s] Trained 120 records in 0.044597878 seconds. Throughput is 2690.711 records/second. Loss is 0.60971534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008364001338240215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57600/60000][Iteration 980][Wall Clock 49.930399747s] Trained 120 records in 0.043289636 seconds. Throughput is 2772.0261 records/second. Loss is 0.49245644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008362602441879913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57720/60000][Iteration 981][Wall Clock 49.973351143s] Trained 120 records in 0.042951396 seconds. Throughput is 2793.8555 records/second. Loss is 0.5111077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008361204013377928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57840/60000][Iteration 982][Wall Clock 50.017220352s] Trained 120 records in 0.043869209 seconds. Throughput is 2735.4038 records/second. Loss is 0.5562168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008359806052499582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 57960/60000][Iteration 983][Wall Clock 50.060535203s] Trained 120 records in 0.043314851 seconds. Throughput is 2770.4124 records/second. Loss is 0.6776453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008358408559010364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 58080/60000][Iteration 984][Wall Clock 50.103832281s] Trained 120 records in 0.043297078 seconds. Throughput is 2771.5496 records/second. Loss is 0.6035236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008357011532675915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 58200/60000][Iteration 985][Wall Clock 50.16135773s] Trained 120 records in 0.057525449 seconds. Throughput is 2086.0332 records/second. Loss is 0.50350875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008355614973262033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 58320/60000][Iteration 986][Wall Clock 50.206273188s] Trained 120 records in 0.044915458 seconds. Throughput is 2671.686 records/second. Loss is 0.4892127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00835421888053467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 58440/60000][Iteration 987][Wall Clock 50.249276214s] Trained 120 records in 0.043003026 seconds. Throughput is 2790.5012 records/second. Loss is 0.6207663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00835282325425994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 58560/60000][Iteration 988][Wall Clock 50.293093632s] Trained 120 records in 0.043817418 seconds. Throughput is 2738.637 records/second. Loss is 0.49573502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008351428094204109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 58680/60000][Iteration 989][Wall Clock 50.336497054s] Trained 120 records in 0.043403422 seconds. Throughput is 2764.759 records/second. Loss is 0.5334987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008350033400133601. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:56 INFO  DistriOptimizer$:406 - [Epoch 2 58800/60000][Iteration 990][Wall Clock 50.380117563s] Trained 120 records in 0.043620509 seconds. Throughput is 2750.9995 records/second. Loss is 0.5105942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008348639171814994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 58920/60000][Iteration 991][Wall Clock 50.423987498s] Trained 120 records in 0.043869935 seconds. Throughput is 2735.3584 records/second. Loss is 0.5740476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008347245409015026. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59040/60000][Iteration 992][Wall Clock 50.467096878s] Trained 120 records in 0.04310938 seconds. Throughput is 2783.617 records/second. Loss is 0.47721586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008345852111500586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59160/60000][Iteration 993][Wall Clock 50.509745291s] Trained 120 records in 0.042648413 seconds. Throughput is 2813.7039 records/second. Loss is 0.6451843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00834445927903872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59280/60000][Iteration 994][Wall Clock 50.552867821s] Trained 120 records in 0.04312253 seconds. Throughput is 2782.768 records/second. Loss is 0.5983152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00834306691139663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59400/60000][Iteration 995][Wall Clock 50.595318966s] Trained 120 records in 0.042451145 seconds. Throughput is 2826.779 records/second. Loss is 0.4314167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008341675008341674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59520/60000][Iteration 996][Wall Clock 50.63854001s] Trained 120 records in 0.043221044 seconds. Throughput is 2776.4253 records/second. Loss is 0.53670716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008340283569641367. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59640/60000][Iteration 997][Wall Clock 50.688764661s] Trained 120 records in 0.050224651 seconds. Throughput is 2389.265 records/second. Loss is 0.6024263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008338892595063376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59760/60000][Iteration 998][Wall Clock 50.73862466s] Trained 120 records in 0.049859999 seconds. Throughput is 2406.7388 records/second. Loss is 0.45733392. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00833750208437552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 59880/60000][Iteration 999][Wall Clock 50.782063891s] Trained 120 records in 0.043439231 seconds. Throughput is 2762.4797 records/second. Loss is 0.56575763. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008336112037345782. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:406 - [Epoch 2 60000/60000][Iteration 1000][Wall Clock 50.824783509s] Trained 120 records in 0.042719618 seconds. Throughput is 2809.014 records/second. Loss is 0.6489915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008334722453742291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:57 INFO  DistriOptimizer$:451 - [Epoch 2 60000/60000][Iteration 1000][Wall Clock 50.824783509s] Epoch finished. Wall clock time is 51722.796549 ms
2019-10-23 15:53:57 INFO  DistriOptimizer$:111 - [Epoch 2 60000/60000][Iteration 1000][Wall Clock 50.824783509s] Validate model...
2019-10-23 15:53:58 INFO  DistriOptimizer$:177 - [Epoch 2 60000/60000][Iteration 1000][Wall Clock 50.824783509s] validate model throughput is 14935.953 records/second
2019-10-23 15:53:58 INFO  DistriOptimizer$:180 - [Epoch 2 60000/60000][Iteration 1000][Wall Clock 50.824783509s] Top1Accuracy is Accuracy(correct: 8643, count: 10000, accuracy: 0.8643)
2019-10-23 15:53:58 INFO  DistriOptimizer$:220 - [Wall Clock 51.722796549s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:53:58 INFO  DistriOptimizer$:225 - [Wall Clock 51.722796549s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 120/60000][Iteration 1001][Wall Clock 51.772950207s] Trained 120 records in 0.050153658 seconds. Throughput is 2392.647 records/second. Loss is 0.5217335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008333333333333333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 240/60000][Iteration 1002][Wall Clock 51.816710836s] Trained 120 records in 0.043760629 seconds. Throughput is 2742.191 records/second. Loss is 0.5986634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008331944675887352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 360/60000][Iteration 1003][Wall Clock 51.860282705s] Trained 120 records in 0.043571869 seconds. Throughput is 2754.0703 records/second. Loss is 0.5467566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008330556481172941. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 480/60000][Iteration 1004][Wall Clock 51.902840736s] Trained 120 records in 0.042558031 seconds. Throughput is 2819.6794 records/second. Loss is 0.5910326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008329168748958853. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 600/60000][Iteration 1005][Wall Clock 51.946698095s] Trained 120 records in 0.043857359 seconds. Throughput is 2736.1428 records/second. Loss is 0.4722972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008327781479013991. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 720/60000][Iteration 1006][Wall Clock 51.989649242s] Trained 120 records in 0.042951147 seconds. Throughput is 2793.8718 records/second. Loss is 0.67656195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00832639467110741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 840/60000][Iteration 1007][Wall Clock 52.035985122s] Trained 120 records in 0.04633588 seconds. Throughput is 2589.7856 records/second. Loss is 0.600444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008325008325008324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 960/60000][Iteration 1008][Wall Clock 52.079429236s] Trained 120 records in 0.043444114 seconds. Throughput is 2762.1692 records/second. Loss is 0.4848314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0083236224404861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1080/60000][Iteration 1009][Wall Clock 52.122619057s] Trained 120 records in 0.043189821 seconds. Throughput is 2778.4326 records/second. Loss is 0.49557334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008322237017310254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1200/60000][Iteration 1010][Wall Clock 52.177958446s] Trained 120 records in 0.055339389 seconds. Throughput is 2168.4375 records/second. Loss is 0.4547781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008320852055250457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1320/60000][Iteration 1011][Wall Clock 52.226522409s] Trained 120 records in 0.048563963 seconds. Throughput is 2470.968 records/second. Loss is 0.4875835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00831946755407654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1440/60000][Iteration 1012][Wall Clock 52.270733208s] Trained 120 records in 0.044210799 seconds. Throughput is 2714.269 records/second. Loss is 0.5871401. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008318083513558477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1560/60000][Iteration 1013][Wall Clock 52.31335108s] Trained 120 records in 0.042617872 seconds. Throughput is 2815.7202 records/second. Loss is 0.62566316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008316699933466402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1680/60000][Iteration 1014][Wall Clock 52.355863847s] Trained 120 records in 0.042512767 seconds. Throughput is 2822.6814 records/second. Loss is 0.63520366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008315316813570598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1800/60000][Iteration 1015][Wall Clock 52.398693775s] Trained 120 records in 0.042829928 seconds. Throughput is 2801.7793 records/second. Loss is 0.54639506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008313934153641503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 1920/60000][Iteration 1016][Wall Clock 52.441761186s] Trained 120 records in 0.043067411 seconds. Throughput is 2786.3296 records/second. Loss is 0.3996137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00831255195344971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 2040/60000][Iteration 1017][Wall Clock 52.484797839s] Trained 120 records in 0.043036653 seconds. Throughput is 2788.3208 records/second. Loss is 0.5606436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008311170212765957. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 2160/60000][Iteration 1018][Wall Clock 52.52818505s] Trained 120 records in 0.043387211 seconds. Throughput is 2765.792 records/second. Loss is 0.50524884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008309788931361143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:58 INFO  DistriOptimizer$:406 - [Epoch 3 2280/60000][Iteration 1019][Wall Clock 52.571104111s] Trained 120 records in 0.042919061 seconds. Throughput is 2795.9604 records/second. Loss is 0.59795415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008308408109006314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 2400/60000][Iteration 1020][Wall Clock 52.616965351s] Trained 120 records in 0.04586124 seconds. Throughput is 2616.5886 records/second. Loss is 0.5331228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00830702774547267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 2520/60000][Iteration 1021][Wall Clock 52.672738192s] Trained 120 records in 0.055772841 seconds. Throughput is 2151.585 records/second. Loss is 0.56227964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008305647840531562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 2640/60000][Iteration 1022][Wall Clock 52.724337588s] Trained 120 records in 0.051599396 seconds. Throughput is 2325.6086 records/second. Loss is 0.55637616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008304268393954492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 2760/60000][Iteration 1023][Wall Clock 52.767122809s] Trained 120 records in 0.042785221 seconds. Throughput is 2804.7068 records/second. Loss is 0.4250046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008302889405513119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 2880/60000][Iteration 1024][Wall Clock 52.810040888s] Trained 120 records in 0.042918079 seconds. Throughput is 2796.0244 records/second. Loss is 0.65263444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008301510874979245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3000/60000][Iteration 1025][Wall Clock 52.852818121s] Trained 120 records in 0.042777233 seconds. Throughput is 2805.2305 records/second. Loss is 0.5638901. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008300132802124834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3120/60000][Iteration 1026][Wall Clock 52.895816229s] Trained 120 records in 0.042998108 seconds. Throughput is 2790.8203 records/second. Loss is 0.51392776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008298755186721992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3240/60000][Iteration 1027][Wall Clock 52.939370236s] Trained 120 records in 0.043554007 seconds. Throughput is 2755.2 records/second. Loss is 0.59105414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00829737802854298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3360/60000][Iteration 1028][Wall Clock 52.982350431s] Trained 120 records in 0.042980195 seconds. Throughput is 2791.9836 records/second. Loss is 0.55251014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008296001327360213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3480/60000][Iteration 1029][Wall Clock 53.025495876s] Trained 120 records in 0.043145445 seconds. Throughput is 2781.2903 records/second. Loss is 0.50242937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00829462508294625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3600/60000][Iteration 1030][Wall Clock 53.068826086s] Trained 120 records in 0.04333021 seconds. Throughput is 2769.4304 records/second. Loss is 0.45187336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00829324929507381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3720/60000][Iteration 1031][Wall Clock 53.112126473s] Trained 120 records in 0.043300387 seconds. Throughput is 2771.338 records/second. Loss is 0.63871914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008291873963515755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3840/60000][Iteration 1032][Wall Clock 53.156212804s] Trained 120 records in 0.044086331 seconds. Throughput is 2721.9321 records/second. Loss is 0.758281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0082904990880451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 3960/60000][Iteration 1033][Wall Clock 53.199980158s] Trained 120 records in 0.043767354 seconds. Throughput is 2741.7695 records/second. Loss is 0.5438251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008289124668435014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4080/60000][Iteration 1034][Wall Clock 53.243170479s] Trained 120 records in 0.043190321 seconds. Throughput is 2778.4001 records/second. Loss is 0.6079885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00828775070445881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4200/60000][Iteration 1035][Wall Clock 53.286055272s] Trained 120 records in 0.042884793 seconds. Throughput is 2798.1946 records/second. Loss is 0.58508074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008286377195889956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4320/60000][Iteration 1036][Wall Clock 53.32950277s] Trained 120 records in 0.043447498 seconds. Throughput is 2761.954 records/second. Loss is 0.60808307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008285004142502071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4440/60000][Iteration 1037][Wall Clock 53.379320406s] Trained 120 records in 0.049817636 seconds. Throughput is 2408.7854 records/second. Loss is 0.5092813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00828363154406892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4560/60000][Iteration 1038][Wall Clock 53.429977436s] Trained 120 records in 0.05065703 seconds. Throughput is 2368.8716 records/second. Loss is 0.48770007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008282259400364419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4680/60000][Iteration 1039][Wall Clock 53.475312552s] Trained 120 records in 0.045335116 seconds. Throughput is 2646.9546 records/second. Loss is 0.55914223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008280887711162636. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4800/60000][Iteration 1040][Wall Clock 53.518523641s] Trained 120 records in 0.043211089 seconds. Throughput is 2777.065 records/second. Loss is 0.5183057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008279516476237788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:53:59 INFO  DistriOptimizer$:406 - [Epoch 3 4920/60000][Iteration 1041][Wall Clock 53.561582243s] Trained 120 records in 0.043058602 seconds. Throughput is 2786.8997 records/second. Loss is 0.5266691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008278145695364239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5040/60000][Iteration 1042][Wall Clock 53.605029017s] Trained 120 records in 0.043446774 seconds. Throughput is 2762.0002 records/second. Loss is 0.5042751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008276775368316504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5160/60000][Iteration 1043][Wall Clock 53.647630849s] Trained 120 records in 0.042601832 seconds. Throughput is 2816.7803 records/second. Loss is 0.5382828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00827540549486925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5280/60000][Iteration 1044][Wall Clock 53.690312406s] Trained 120 records in 0.042681557 seconds. Throughput is 2811.5188 records/second. Loss is 0.57271695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008274036074797285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5400/60000][Iteration 1045][Wall Clock 53.744107475s] Trained 120 records in 0.053795069 seconds. Throughput is 2230.6877 records/second. Loss is 0.6472281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00827266710787558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5520/60000][Iteration 1046][Wall Clock 53.789525859s] Trained 120 records in 0.045418384 seconds. Throughput is 2642.1018 records/second. Loss is 0.5931632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008271298593879239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5640/60000][Iteration 1047][Wall Clock 53.843591393s] Trained 120 records in 0.054065534 seconds. Throughput is 2219.5286 records/second. Loss is 0.45363393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008269930532583526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5760/60000][Iteration 1048][Wall Clock 53.88644166s] Trained 120 records in 0.042850267 seconds. Throughput is 2800.4492 records/second. Loss is 0.5969387. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00826856292376385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 5880/60000][Iteration 1049][Wall Clock 53.930406679s] Trained 120 records in 0.043965019 seconds. Throughput is 2729.4426 records/second. Loss is 0.5109035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008267195767195767. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6000/60000][Iteration 1050][Wall Clock 53.975764022s] Trained 120 records in 0.045357343 seconds. Throughput is 2645.6577 records/second. Loss is 0.57043606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008265829062654984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6120/60000][Iteration 1051][Wall Clock 54.020705169s] Trained 120 records in 0.044941147 seconds. Throughput is 2670.159 records/second. Loss is 0.48871467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008264462809917356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6240/60000][Iteration 1052][Wall Clock 54.066163157s] Trained 120 records in 0.045457988 seconds. Throughput is 2639.8 records/second. Loss is 0.6229263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008263097008758883. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6360/60000][Iteration 1053][Wall Clock 54.111374049s] Trained 120 records in 0.045210892 seconds. Throughput is 2654.2278 records/second. Loss is 0.5268225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008261731658955718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6480/60000][Iteration 1054][Wall Clock 54.157868458s] Trained 120 records in 0.046494409 seconds. Throughput is 2580.9556 records/second. Loss is 0.5173899. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008260366760284157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6600/60000][Iteration 1055][Wall Clock 54.20377231s] Trained 120 records in 0.045903852 seconds. Throughput is 2614.16 records/second. Loss is 0.5114642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008259002312520646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6720/60000][Iteration 1056][Wall Clock 54.247889461s] Trained 120 records in 0.044117151 seconds. Throughput is 2720.0305 records/second. Loss is 0.6104657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008257638315441783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6840/60000][Iteration 1057][Wall Clock 54.291128496s] Trained 120 records in 0.043239035 seconds. Throughput is 2775.27 records/second. Loss is 0.52848244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008256274768824306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 6960/60000][Iteration 1058][Wall Clock 54.333760873s] Trained 120 records in 0.042632377 seconds. Throughput is 2814.762 records/second. Loss is 0.5786094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008254911672445105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 7080/60000][Iteration 1059][Wall Clock 54.380999644s] Trained 120 records in 0.047238771 seconds. Throughput is 2540.2861 records/second. Loss is 0.66898125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008253549026081214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 7200/60000][Iteration 1060][Wall Clock 54.423579673s] Trained 120 records in 0.042580029 seconds. Throughput is 2818.2224 records/second. Loss is 0.4094793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00825218682950982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 7320/60000][Iteration 1061][Wall Clock 54.466480328s] Trained 120 records in 0.042900655 seconds. Throughput is 2797.1602 records/second. Loss is 0.5468743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008250825082508252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 7440/60000][Iteration 1062][Wall Clock 54.509633581s] Trained 120 records in 0.043153253 seconds. Throughput is 2780.7869 records/second. Loss is 0.4771633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008249463784853986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:00 INFO  DistriOptimizer$:406 - [Epoch 3 7560/60000][Iteration 1063][Wall Clock 54.55313323s] Trained 120 records in 0.043499649 seconds. Throughput is 2758.643 records/second. Loss is 0.5562723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008248102936324647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 7680/60000][Iteration 1064][Wall Clock 54.605617929s] Trained 120 records in 0.052484699 seconds. Throughput is 2286.3806 records/second. Loss is 0.5999336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008246742536698003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 7800/60000][Iteration 1065][Wall Clock 54.655484532s] Trained 120 records in 0.049866603 seconds. Throughput is 2406.4202 records/second. Loss is 0.5539944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008245382585751979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 7920/60000][Iteration 1066][Wall Clock 54.700776727s] Trained 120 records in 0.045292195 seconds. Throughput is 2649.4631 records/second. Loss is 0.64985085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008244023083264633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8040/60000][Iteration 1067][Wall Clock 54.744007592s] Trained 120 records in 0.043230865 seconds. Throughput is 2775.7944 records/second. Loss is 0.5416709. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008242664029014177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8160/60000][Iteration 1068][Wall Clock 54.788586507s] Trained 120 records in 0.044578915 seconds. Throughput is 2691.8557 records/second. Loss is 0.55040985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008241305422778969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8280/60000][Iteration 1069][Wall Clock 54.831559456s] Trained 120 records in 0.042972949 seconds. Throughput is 2792.4543 records/second. Loss is 0.5254047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008239947264337508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8400/60000][Iteration 1070][Wall Clock 54.876020384s] Trained 120 records in 0.044460928 seconds. Throughput is 2698.999 records/second. Loss is 0.5250927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008238589553468446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8520/60000][Iteration 1071][Wall Clock 54.920373081s] Trained 120 records in 0.044352697 seconds. Throughput is 2705.5852 records/second. Loss is 0.519624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008237232289950576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8640/60000][Iteration 1072][Wall Clock 54.970581022s] Trained 120 records in 0.050207941 seconds. Throughput is 2390.06 records/second. Loss is 0.6066379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00823587547356284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8760/60000][Iteration 1073][Wall Clock 55.019492588s] Trained 120 records in 0.048911566 seconds. Throughput is 2453.4075 records/second. Loss is 0.49735975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008234519104084322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 8880/60000][Iteration 1074][Wall Clock 55.063084358s] Trained 120 records in 0.04359177 seconds. Throughput is 2752.8132 records/second. Loss is 0.4507944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008233163181294254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9000/60000][Iteration 1075][Wall Clock 55.107311366s] Trained 120 records in 0.044227008 seconds. Throughput is 2713.2742 records/second. Loss is 0.60349274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008231807704972012. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9120/60000][Iteration 1076][Wall Clock 55.151440282s] Trained 120 records in 0.044128916 seconds. Throughput is 2719.3054 records/second. Loss is 0.56069446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008230452674897118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9240/60000][Iteration 1077][Wall Clock 55.195152215s] Trained 120 records in 0.043711933 seconds. Throughput is 2745.2456 records/second. Loss is 0.53442895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008229098090849242. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9360/60000][Iteration 1078][Wall Clock 55.239037648s] Trained 120 records in 0.043885433 seconds. Throughput is 2734.3926 records/second. Loss is 0.52779305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008227743952608195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9480/60000][Iteration 1079][Wall Clock 55.282953257s] Trained 120 records in 0.043915609 seconds. Throughput is 2732.5134 records/second. Loss is 0.6164667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008226390259953932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9600/60000][Iteration 1080][Wall Clock 55.327365793s] Trained 120 records in 0.044412536 seconds. Throughput is 2701.94 records/second. Loss is 0.5389863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008225037012666558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9720/60000][Iteration 1081][Wall Clock 55.370228909s] Trained 120 records in 0.042863116 seconds. Throughput is 2799.6099 records/second. Loss is 0.4610099. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008223684210526315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9840/60000][Iteration 1082][Wall Clock 55.412449328s] Trained 120 records in 0.042220419 seconds. Throughput is 2842.2268 records/second. Loss is 0.5150209. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0082223318533136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 9960/60000][Iteration 1083][Wall Clock 55.455612072s] Trained 120 records in 0.043162744 seconds. Throughput is 2780.1753 records/second. Loss is 0.6353655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008220979940808944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 10080/60000][Iteration 1084][Wall Clock 55.498679191s] Trained 120 records in 0.043067119 seconds. Throughput is 2786.3484 records/second. Loss is 0.54741925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008219628472793028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:01 INFO  DistriOptimizer$:406 - [Epoch 3 10200/60000][Iteration 1085][Wall Clock 55.541742921s] Trained 120 records in 0.04306373 seconds. Throughput is 2786.5676 records/second. Loss is 0.5281335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00821827744904668. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 10320/60000][Iteration 1086][Wall Clock 55.584979963s] Trained 120 records in 0.043237042 seconds. Throughput is 2775.398 records/second. Loss is 0.55170286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008216926869350863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 10440/60000][Iteration 1087][Wall Clock 55.62956869s] Trained 120 records in 0.044588727 seconds. Throughput is 2691.2632 records/second. Loss is 0.6083874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00821557673348669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 10560/60000][Iteration 1088][Wall Clock 55.674667241s] Trained 120 records in 0.045098551 seconds. Throughput is 2660.8394 records/second. Loss is 0.5531839. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008214227041235419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 10680/60000][Iteration 1089][Wall Clock 55.717676893s] Trained 120 records in 0.043009652 seconds. Throughput is 2790.0713 records/second. Loss is 0.43195766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00821287779237845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 10800/60000][Iteration 1090][Wall Clock 55.760497184s] Trained 120 records in 0.042820291 seconds. Throughput is 2802.41 records/second. Loss is 0.5600698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008211528986697324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 10920/60000][Iteration 1091][Wall Clock 55.817037646s] Trained 120 records in 0.056540462 seconds. Throughput is 2122.3738 records/second. Loss is 0.69528013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008210180623973728. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11040/60000][Iteration 1092][Wall Clock 55.86533331s] Trained 120 records in 0.048295664 seconds. Throughput is 2484.695 records/second. Loss is 0.47063833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008208832703989493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11160/60000][Iteration 1093][Wall Clock 55.907520624s] Trained 120 records in 0.042187314 seconds. Throughput is 2844.457 records/second. Loss is 0.53541005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008207485226526593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11280/60000][Iteration 1094][Wall Clock 55.950068192s] Trained 120 records in 0.042547568 seconds. Throughput is 2820.3726 records/second. Loss is 0.56673634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008206138191367143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11400/60000][Iteration 1095][Wall Clock 55.993664828s] Trained 120 records in 0.043596636 seconds. Throughput is 2752.5059 records/second. Loss is 0.6619587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008204791598293402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11520/60000][Iteration 1096][Wall Clock 56.038381487s] Trained 120 records in 0.044716659 seconds. Throughput is 2683.5635 records/second. Loss is 0.5233935. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008203445447087777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11640/60000][Iteration 1097][Wall Clock 56.084365241s] Trained 120 records in 0.045983754 seconds. Throughput is 2609.6172 records/second. Loss is 0.5499151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008202099737532808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11760/60000][Iteration 1098][Wall Clock 56.128439785s] Trained 120 records in 0.044074544 seconds. Throughput is 2722.6602 records/second. Loss is 0.5663178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008200754469411186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 11880/60000][Iteration 1099][Wall Clock 56.179515427s] Trained 120 records in 0.051075642 seconds. Throughput is 2349.4565 records/second. Loss is 0.48679626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008199409642505739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12000/60000][Iteration 1100][Wall Clock 56.224889957s] Trained 120 records in 0.04537453 seconds. Throughput is 2644.6555 records/second. Loss is 0.5694899. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008198065256599442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12120/60000][Iteration 1101][Wall Clock 56.2681009s] Trained 120 records in 0.043210943 seconds. Throughput is 2777.0745 records/second. Loss is 0.5754339. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00819672131147541. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12240/60000][Iteration 1102][Wall Clock 56.312220666s] Trained 120 records in 0.044119766 seconds. Throughput is 2719.8691 records/second. Loss is 0.4922931. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0081953778069169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12360/60000][Iteration 1103][Wall Clock 56.357281485s] Trained 120 records in 0.045060819 seconds. Throughput is 2663.0676 records/second. Loss is 0.5127424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00819403474270731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12480/60000][Iteration 1104][Wall Clock 56.403855765s] Trained 120 records in 0.04657428 seconds. Throughput is 2576.5293 records/second. Loss is 0.6128568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008192692118630182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12600/60000][Iteration 1105][Wall Clock 56.448900778s] Trained 120 records in 0.045045013 seconds. Throughput is 2664.0017 records/second. Loss is 0.48240313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0081913499344692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12720/60000][Iteration 1106][Wall Clock 56.492684558s] Trained 120 records in 0.04378378 seconds. Throughput is 2740.741 records/second. Loss is 0.42891914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00819000819000819. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:02 INFO  DistriOptimizer$:406 - [Epoch 3 12840/60000][Iteration 1107][Wall Clock 56.536594409s] Trained 120 records in 0.043909851 seconds. Throughput is 2732.8718 records/second. Loss is 0.47887713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008188666885031117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 12960/60000][Iteration 1108][Wall Clock 56.581180009s] Trained 120 records in 0.0445856 seconds. Throughput is 2691.452 records/second. Loss is 0.518289. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008187326019322089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13080/60000][Iteration 1109][Wall Clock 56.624915331s] Trained 120 records in 0.043735322 seconds. Throughput is 2743.7776 records/second. Loss is 0.4976543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008185985592665358. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13200/60000][Iteration 1110][Wall Clock 56.66789115s] Trained 120 records in 0.042975819 seconds. Throughput is 2792.2678 records/second. Loss is 0.47768772. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00818464560484531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13320/60000][Iteration 1111][Wall Clock 56.711385344s] Trained 120 records in 0.043494194 seconds. Throughput is 2758.9888 records/second. Loss is 0.57804114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008183306055646482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13440/60000][Iteration 1112][Wall Clock 56.758394868s] Trained 120 records in 0.047009524 seconds. Throughput is 2552.6743 records/second. Loss is 0.6221769. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008181966944853543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13560/60000][Iteration 1113][Wall Clock 56.803207637s] Trained 120 records in 0.044812769 seconds. Throughput is 2677.808 records/second. Loss is 0.58859897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008180628272251309. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13680/60000][Iteration 1114][Wall Clock 56.84637428s] Trained 120 records in 0.043166643 seconds. Throughput is 2779.9243 records/second. Loss is 0.47024605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008179290037624735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13800/60000][Iteration 1115][Wall Clock 56.889280158s] Trained 120 records in 0.042905878 seconds. Throughput is 2796.8196 records/second. Loss is 0.46821672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008177952240758915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 13920/60000][Iteration 1116][Wall Clock 56.932443611s] Trained 120 records in 0.043163453 seconds. Throughput is 2780.13 records/second. Loss is 0.45035142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008176614881439084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14040/60000][Iteration 1117][Wall Clock 56.984332946s] Trained 120 records in 0.051889335 seconds. Throughput is 2312.614 records/second. Loss is 0.5376126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008175277959450621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14160/60000][Iteration 1118][Wall Clock 57.03563541s] Trained 120 records in 0.051302464 seconds. Throughput is 2339.069 records/second. Loss is 0.5064345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008173941474579042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14280/60000][Iteration 1119][Wall Clock 57.080889396s] Trained 120 records in 0.045253986 seconds. Throughput is 2651.7002 records/second. Loss is 0.64825636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008172605426610004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14400/60000][Iteration 1120][Wall Clock 57.126402874s] Trained 120 records in 0.045513478 seconds. Throughput is 2636.5818 records/second. Loss is 0.63109213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008171269815329302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14520/60000][Iteration 1121][Wall Clock 57.17066574s] Trained 120 records in 0.044262866 seconds. Throughput is 2711.0762 records/second. Loss is 0.5130489. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008169934640522876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14640/60000][Iteration 1122][Wall Clock 57.213274636s] Trained 120 records in 0.042608896 seconds. Throughput is 2816.3135 records/second. Loss is 0.50047946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008168599901976801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14760/60000][Iteration 1123][Wall Clock 57.256967214s] Trained 120 records in 0.043692578 seconds. Throughput is 2746.462 records/second. Loss is 0.4403403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008167265599477296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 14880/60000][Iteration 1124][Wall Clock 57.300245345s] Trained 120 records in 0.043278131 seconds. Throughput is 2772.763 records/second. Loss is 0.4918062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008165931732810713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 15000/60000][Iteration 1125][Wall Clock 57.349368731s] Trained 120 records in 0.049123386 seconds. Throughput is 2442.8284 records/second. Loss is 0.47995397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008164598301763552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 15120/60000][Iteration 1126][Wall Clock 57.394379976s] Trained 120 records in 0.045011245 seconds. Throughput is 2666.0005 records/second. Loss is 0.5774294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008163265306122448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 15240/60000][Iteration 1127][Wall Clock 57.436688629s] Trained 120 records in 0.042308653 seconds. Throughput is 2836.299 records/second. Loss is 0.48217562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008161932745674175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 15360/60000][Iteration 1128][Wall Clock 57.479241047s] Trained 120 records in 0.042552418 seconds. Throughput is 2820.0513 records/second. Loss is 0.40876025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008160600620205648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 15480/60000][Iteration 1129][Wall Clock 57.522163949s] Trained 120 records in 0.042922902 seconds. Throughput is 2795.7102 records/second. Loss is 0.48415342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008159268929503917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:03 INFO  DistriOptimizer$:406 - [Epoch 3 15600/60000][Iteration 1130][Wall Clock 57.564916319s] Trained 120 records in 0.04275237 seconds. Throughput is 2806.8618 records/second. Loss is 0.5578915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008157937673356175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 15720/60000][Iteration 1131][Wall Clock 57.607854021s] Trained 120 records in 0.042937702 seconds. Throughput is 2794.7466 records/second. Loss is 0.4568136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008156606851549756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 15840/60000][Iteration 1132][Wall Clock 57.649958921s] Trained 120 records in 0.0421049 seconds. Throughput is 2850.0247 records/second. Loss is 0.5309789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008155276463872126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 15960/60000][Iteration 1133][Wall Clock 57.692368235s] Trained 120 records in 0.042409314 seconds. Throughput is 2829.567 records/second. Loss is 0.52015287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008153946510110895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16080/60000][Iteration 1134][Wall Clock 57.734327687s] Trained 120 records in 0.041959452 seconds. Throughput is 2859.9038 records/second. Loss is 0.50648665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008152616990053808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16200/60000][Iteration 1135][Wall Clock 57.777103099s] Trained 120 records in 0.042775412 seconds. Throughput is 2805.35 records/second. Loss is 0.5670821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008151287903488753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16320/60000][Iteration 1136][Wall Clock 57.820114385s] Trained 120 records in 0.043011286 seconds. Throughput is 2789.9653 records/second. Loss is 0.4786966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008149959250203748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16440/60000][Iteration 1137][Wall Clock 57.863017244s] Trained 120 records in 0.042902859 seconds. Throughput is 2797.0164 records/second. Loss is 0.53172195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008148631029986962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16560/60000][Iteration 1138][Wall Clock 57.905450158s] Trained 120 records in 0.042432914 seconds. Throughput is 2827.9934 records/second. Loss is 0.5500258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008147303242626691. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16680/60000][Iteration 1139][Wall Clock 57.947748931s] Trained 120 records in 0.042298773 seconds. Throughput is 2836.962 records/second. Loss is 0.5953634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008145975887911373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16800/60000][Iteration 1140][Wall Clock 57.990044636s] Trained 120 records in 0.042295705 seconds. Throughput is 2837.1675 records/second. Loss is 0.5961867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008144648965629582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 16920/60000][Iteration 1141][Wall Clock 58.032264722s] Trained 120 records in 0.042220086 seconds. Throughput is 2842.249 records/second. Loss is 0.500674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008143322475570033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17040/60000][Iteration 1142][Wall Clock 58.076009982s] Trained 120 records in 0.04374526 seconds. Throughput is 2743.1543 records/second. Loss is 0.5807707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008141996417521577. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17160/60000][Iteration 1143][Wall Clock 58.119862524s] Trained 120 records in 0.043852542 seconds. Throughput is 2736.4434 records/second. Loss is 0.54731905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008140670791273202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17280/60000][Iteration 1144][Wall Clock 58.177297862s] Trained 120 records in 0.057435338 seconds. Throughput is 2089.3062 records/second. Loss is 0.63410497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008139345596614033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17400/60000][Iteration 1145][Wall Clock 58.224308616s] Trained 120 records in 0.047010754 seconds. Throughput is 2552.6074 records/second. Loss is 0.61167884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008138020833333332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17520/60000][Iteration 1146][Wall Clock 58.267925443s] Trained 120 records in 0.043616827 seconds. Throughput is 2751.2317 records/second. Loss is 0.54060453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008136696501220505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17640/60000][Iteration 1147][Wall Clock 58.310860854s] Trained 120 records in 0.042935411 seconds. Throughput is 2794.8958 records/second. Loss is 0.56814456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008135372600065083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17760/60000][Iteration 1148][Wall Clock 58.353418943s] Trained 120 records in 0.042558089 seconds. Throughput is 2819.6755 records/second. Loss is 0.52784497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008134049129656743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 17880/60000][Iteration 1149][Wall Clock 58.395505997s] Trained 120 records in 0.042087054 seconds. Throughput is 2851.233 records/second. Loss is 0.50754786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008132726089785295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 18000/60000][Iteration 1150][Wall Clock 58.437767791s] Trained 120 records in 0.042261794 seconds. Throughput is 2839.444 records/second. Loss is 0.58255756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00813140348024069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 18120/60000][Iteration 1151][Wall Clock 58.479774966s] Trained 120 records in 0.042007175 seconds. Throughput is 2856.6548 records/second. Loss is 0.62954545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008130081300813009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:04 INFO  DistriOptimizer$:406 - [Epoch 3 18240/60000][Iteration 1152][Wall Clock 58.530458412s] Trained 120 records in 0.050683446 seconds. Throughput is 2367.637 records/second. Loss is 0.7078187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008128759551292473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 18360/60000][Iteration 1153][Wall Clock 58.573213454s] Trained 120 records in 0.042755042 seconds. Throughput is 2806.6865 records/second. Loss is 0.48349476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008127438231469442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 18480/60000][Iteration 1154][Wall Clock 58.618508535s] Trained 120 records in 0.045295081 seconds. Throughput is 2649.2942 records/second. Loss is 0.43427226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008126117341134406. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 18600/60000][Iteration 1155][Wall Clock 58.66407478s] Trained 120 records in 0.045566245 seconds. Throughput is 2633.5283 records/second. Loss is 0.5101076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008124796880077998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 18720/60000][Iteration 1156][Wall Clock 58.70934387s] Trained 120 records in 0.04526909 seconds. Throughput is 2650.8154 records/second. Loss is 0.5428343. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008123476848090982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 18840/60000][Iteration 1157][Wall Clock 58.754993121s] Trained 120 records in 0.045649251 seconds. Throughput is 2628.7397 records/second. Loss is 0.61984915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008122157244964262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 18960/60000][Iteration 1158][Wall Clock 58.798349444s] Trained 120 records in 0.043356323 seconds. Throughput is 2767.7625 records/second. Loss is 0.5875238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008120838070488873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19080/60000][Iteration 1159][Wall Clock 58.84148023s] Trained 120 records in 0.043130786 seconds. Throughput is 2782.2354 records/second. Loss is 0.49119753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008119519324455992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19200/60000][Iteration 1160][Wall Clock 58.884274674s] Trained 120 records in 0.042794444 seconds. Throughput is 2804.1023 records/second. Loss is 0.66685975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008118201006656925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19320/60000][Iteration 1161][Wall Clock 58.927010409s] Trained 120 records in 0.042735735 seconds. Throughput is 2807.9543 records/second. Loss is 0.47839192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008116883116883118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19440/60000][Iteration 1162][Wall Clock 58.970052803s] Trained 120 records in 0.043042394 seconds. Throughput is 2787.949 records/second. Loss is 0.5659153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008115565654926148. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19560/60000][Iteration 1163][Wall Clock 59.013227614s] Trained 120 records in 0.043174811 seconds. Throughput is 2779.3984 records/second. Loss is 0.44706503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008114248620577734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19680/60000][Iteration 1164][Wall Clock 59.056583626s] Trained 120 records in 0.043356012 seconds. Throughput is 2767.7822 records/second. Loss is 0.47470713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008112932013629727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19800/60000][Iteration 1165][Wall Clock 59.09983858s] Trained 120 records in 0.043254954 seconds. Throughput is 2774.2488 records/second. Loss is 0.5059429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008111615833874108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 19920/60000][Iteration 1166][Wall Clock 59.145924469s] Trained 120 records in 0.046085889 seconds. Throughput is 2603.8337 records/second. Loss is 0.5784457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008110300081103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20040/60000][Iteration 1167][Wall Clock 59.19001139s] Trained 120 records in 0.044086921 seconds. Throughput is 2721.8955 records/second. Loss is 0.5206546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00810898475510866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20160/60000][Iteration 1168][Wall Clock 59.233166693s] Trained 120 records in 0.043155303 seconds. Throughput is 2780.6548 records/second. Loss is 0.4728332. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008107669855683477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20280/60000][Iteration 1169][Wall Clock 59.275917659s] Trained 120 records in 0.042750966 seconds. Throughput is 2806.954 records/second. Loss is 0.51457584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008106355382619975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20400/60000][Iteration 1170][Wall Clock 59.332572814s] Trained 120 records in 0.056655155 seconds. Throughput is 2118.0774 records/second. Loss is 0.504809. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008105041335710812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20520/60000][Iteration 1171][Wall Clock 59.383349351s] Trained 120 records in 0.050776537 seconds. Throughput is 2363.2961 records/second. Loss is 0.41796964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008103727714748784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20640/60000][Iteration 1172][Wall Clock 59.426304073s] Trained 120 records in 0.042954722 seconds. Throughput is 2793.6394 records/second. Loss is 0.54087865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00810241451952682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20760/60000][Iteration 1173][Wall Clock 59.469408916s] Trained 120 records in 0.043104843 seconds. Throughput is 2783.91 records/second. Loss is 0.46354562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00810110174983798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 20880/60000][Iteration 1174][Wall Clock 59.512002498s] Trained 120 records in 0.042593582 seconds. Throughput is 2817.3257 records/second. Loss is 0.44481117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008099789405475458. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:05 INFO  DistriOptimizer$:406 - [Epoch 3 21000/60000][Iteration 1175][Wall Clock 59.554990413s] Trained 120 records in 0.042987915 seconds. Throughput is 2791.4822 records/second. Loss is 0.51986855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008098477486232589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21120/60000][Iteration 1176][Wall Clock 59.598244535s] Trained 120 records in 0.043254122 seconds. Throughput is 2774.302 records/second. Loss is 0.5538491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008097165991902834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21240/60000][Iteration 1177][Wall Clock 59.641992065s] Trained 120 records in 0.04374753 seconds. Throughput is 2743.012 records/second. Loss is 0.5045174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008095854922279792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21360/60000][Iteration 1178][Wall Clock 59.692700031s] Trained 120 records in 0.050707966 seconds. Throughput is 2366.4922 records/second. Loss is 0.5226712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008094544277157195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21480/60000][Iteration 1179][Wall Clock 59.735692195s] Trained 120 records in 0.042992164 seconds. Throughput is 2791.2063 records/second. Loss is 0.6088246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00809323405632891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21600/60000][Iteration 1180][Wall Clock 59.779060618s] Trained 120 records in 0.043368423 seconds. Throughput is 2766.9902 records/second. Loss is 0.53020024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00809192425958893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21720/60000][Iteration 1181][Wall Clock 59.822049591s] Trained 120 records in 0.042988973 seconds. Throughput is 2791.4133 records/second. Loss is 0.5607275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008090614886731393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21840/60000][Iteration 1182][Wall Clock 59.865256952s] Trained 120 records in 0.043207361 seconds. Throughput is 2777.3044 records/second. Loss is 0.51645935. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008089305937550558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 21960/60000][Iteration 1183][Wall Clock 59.908898941s] Trained 120 records in 0.043641989 seconds. Throughput is 2749.6455 records/second. Loss is 0.43980864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008087997411840828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22080/60000][Iteration 1184][Wall Clock 59.951771063s] Trained 120 records in 0.042872122 seconds. Throughput is 2799.0217 records/second. Loss is 0.53696626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008086689309396733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22200/60000][Iteration 1185][Wall Clock 59.994753857s] Trained 120 records in 0.042982794 seconds. Throughput is 2791.8147 records/second. Loss is 0.5434453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008085381630012937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22320/60000][Iteration 1186][Wall Clock 60.037973601s] Trained 120 records in 0.043219744 seconds. Throughput is 2776.5088 records/second. Loss is 0.5877422. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008084074373484235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22440/60000][Iteration 1187][Wall Clock 60.081386511s] Trained 120 records in 0.04341291 seconds. Throughput is 2764.1548 records/second. Loss is 0.52896565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008082767539605561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22560/60000][Iteration 1188][Wall Clock 60.124540799s] Trained 120 records in 0.043154288 seconds. Throughput is 2780.7202 records/second. Loss is 0.5426405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008081461128171973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22680/60000][Iteration 1189][Wall Clock 60.168027502s] Trained 120 records in 0.043486703 seconds. Throughput is 2759.464 records/second. Loss is 0.6161526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00808015513897867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22800/60000][Iteration 1190][Wall Clock 60.210051612s] Trained 120 records in 0.04202411 seconds. Throughput is 2855.5037 records/second. Loss is 0.4952688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008078849571820973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 22920/60000][Iteration 1191][Wall Clock 60.252239039s] Trained 120 records in 0.042187427 seconds. Throughput is 2844.4495 records/second. Loss is 0.56058365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008077544426494346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 23040/60000][Iteration 1192][Wall Clock 60.294970334s] Trained 120 records in 0.042731295 seconds. Throughput is 2808.246 records/second. Loss is 0.47784555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008076239702794379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 23160/60000][Iteration 1193][Wall Clock 60.338319597s] Trained 120 records in 0.043349263 seconds. Throughput is 2768.2131 records/second. Loss is 0.4846834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008074935400516797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 23280/60000][Iteration 1194][Wall Clock 60.381401155s] Trained 120 records in 0.043081558 seconds. Throughput is 2785.4146 records/second. Loss is 0.40071175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008073631519457452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 23400/60000][Iteration 1195][Wall Clock 60.436032756s] Trained 120 records in 0.054631601 seconds. Throughput is 2196.5308 records/second. Loss is 0.5369163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008072328059412335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 23520/60000][Iteration 1196][Wall Clock 60.490091226s] Trained 120 records in 0.05405847 seconds. Throughput is 2219.8186 records/second. Loss is 0.47947773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008071025020177562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:06 INFO  DistriOptimizer$:406 - [Epoch 3 23640/60000][Iteration 1197][Wall Clock 60.537861975s] Trained 120 records in 0.047770749 seconds. Throughput is 2511.9973 records/second. Loss is 0.52369887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008069722401549387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 23760/60000][Iteration 1198][Wall Clock 60.582100254s] Trained 120 records in 0.044238279 seconds. Throughput is 2712.5828 records/second. Loss is 0.5151258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008068420203324189. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 23880/60000][Iteration 1199][Wall Clock 60.625557543s] Trained 120 records in 0.043457289 seconds. Throughput is 2761.332 records/second. Loss is 0.44195187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008067118425298484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24000/60000][Iteration 1200][Wall Clock 60.668913626s] Trained 120 records in 0.043356083 seconds. Throughput is 2767.7776 records/second. Loss is 0.44979864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008065817067268914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24120/60000][Iteration 1201][Wall Clock 60.711401309s] Trained 120 records in 0.042487683 seconds. Throughput is 2824.348 records/second. Loss is 0.48485786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008064516129032258. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24240/60000][Iteration 1202][Wall Clock 60.754041588s] Trained 120 records in 0.042640279 seconds. Throughput is 2814.2405 records/second. Loss is 0.47088262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008063215610385421. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24360/60000][Iteration 1203][Wall Clock 60.796381693s] Trained 120 records in 0.042340105 seconds. Throughput is 2834.1924 records/second. Loss is 0.41196248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008061915511125443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24480/60000][Iteration 1204][Wall Clock 60.844699981s] Trained 120 records in 0.048318288 seconds. Throughput is 2483.5317 records/second. Loss is 0.45234543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008060615831049493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24600/60000][Iteration 1205][Wall Clock 60.891659604s] Trained 120 records in 0.046959623 seconds. Throughput is 2555.3867 records/second. Loss is 0.5014396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008059316569954867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24720/60000][Iteration 1206][Wall Clock 60.934795815s] Trained 120 records in 0.043136211 seconds. Throughput is 2781.8855 records/second. Loss is 0.46021658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008058017727639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24840/60000][Iteration 1207][Wall Clock 60.977218883s] Trained 120 records in 0.042423068 seconds. Throughput is 2828.6497 records/second. Loss is 0.4766606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008056719303899451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 24960/60000][Iteration 1208][Wall Clock 61.019825861s] Trained 120 records in 0.042606978 seconds. Throughput is 2816.44 records/second. Loss is 0.49210203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008055421298533913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25080/60000][Iteration 1209][Wall Clock 61.06362709s] Trained 120 records in 0.043801229 seconds. Throughput is 2739.6492 records/second. Loss is 0.56834906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008054123711340205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25200/60000][Iteration 1210][Wall Clock 61.106343164s] Trained 120 records in 0.042716074 seconds. Throughput is 2809.2468 records/second. Loss is 0.4850608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008052826542116283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25320/60000][Iteration 1211][Wall Clock 61.148908191s] Trained 120 records in 0.042565027 seconds. Throughput is 2819.216 records/second. Loss is 0.6046399. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008051529790660227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25440/60000][Iteration 1212][Wall Clock 61.191199962s] Trained 120 records in 0.042291771 seconds. Throughput is 2837.4314 records/second. Loss is 0.49966294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008050233456770247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25560/60000][Iteration 1213][Wall Clock 61.23371853s] Trained 120 records in 0.042518568 seconds. Throughput is 2822.2964 records/second. Loss is 0.4848868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008048937540244688. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25680/60000][Iteration 1214][Wall Clock 61.276188395s] Trained 120 records in 0.042469865 seconds. Throughput is 2825.5327 records/second. Loss is 0.4279124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008047642040882022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25800/60000][Iteration 1215][Wall Clock 61.318605731s] Trained 120 records in 0.042417336 seconds. Throughput is 2829.032 records/second. Loss is 0.5634387. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008046346958480851. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 25920/60000][Iteration 1216][Wall Clock 61.361267919s] Trained 120 records in 0.042662188 seconds. Throughput is 2812.7952 records/second. Loss is 0.46684274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008045052292839902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 26040/60000][Iteration 1217][Wall Clock 61.404619471s] Trained 120 records in 0.043351552 seconds. Throughput is 2768.067 records/second. Loss is 0.69351256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008043758043758044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 26160/60000][Iteration 1218][Wall Clock 61.447541395s] Trained 120 records in 0.042921924 seconds. Throughput is 2795.7742 records/second. Loss is 0.48071352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00804246421103426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 26280/60000][Iteration 1219][Wall Clock 61.493596104s] Trained 120 records in 0.046054709 seconds. Throughput is 2605.5967 records/second. Loss is 0.48536193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008041170794467674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:07 INFO  DistriOptimizer$:406 - [Epoch 3 26400/60000][Iteration 1220][Wall Clock 61.547481796s] Trained 120 records in 0.053885692 seconds. Throughput is 2226.9363 records/second. Loss is 0.47190502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008039877793857533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 26520/60000][Iteration 1221][Wall Clock 61.601456452s] Trained 120 records in 0.053974656 seconds. Throughput is 2223.2656 records/second. Loss is 0.40327924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008038585209003215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 26640/60000][Iteration 1222][Wall Clock 61.644479313s] Trained 120 records in 0.043022861 seconds. Throughput is 2789.2148 records/second. Loss is 0.4178572. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008037293039704229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 26760/60000][Iteration 1223][Wall Clock 61.686874084s] Trained 120 records in 0.042394771 seconds. Throughput is 2830.5376 records/second. Loss is 0.54200673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008036001285760206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 26880/60000][Iteration 1224][Wall Clock 61.729191957s] Trained 120 records in 0.042317873 seconds. Throughput is 2835.6812 records/second. Loss is 0.43478933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008034709946970914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27000/60000][Iteration 1225][Wall Clock 61.771668407s] Trained 120 records in 0.04247645 seconds. Throughput is 2825.095 records/second. Loss is 0.5361033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008033419023136246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27120/60000][Iteration 1226][Wall Clock 61.814518873s] Trained 120 records in 0.042850466 seconds. Throughput is 2800.4363 records/second. Loss is 0.5525946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008032128514056224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27240/60000][Iteration 1227][Wall Clock 61.857670248s] Trained 120 records in 0.043151375 seconds. Throughput is 2780.908 records/second. Loss is 0.49206492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008030838419530999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27360/60000][Iteration 1228][Wall Clock 61.900375202s] Trained 120 records in 0.042704954 seconds. Throughput is 2809.9783 records/second. Loss is 0.5457465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008029548739360848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27480/60000][Iteration 1229][Wall Clock 61.94306942s] Trained 120 records in 0.042694218 seconds. Throughput is 2810.685 records/second. Loss is 0.50919735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008028259473346178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27600/60000][Iteration 1230][Wall Clock 61.985898368s] Trained 120 records in 0.042828948 seconds. Throughput is 2801.8433 records/second. Loss is 0.53704554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008026970621287526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27720/60000][Iteration 1231][Wall Clock 62.037500872s] Trained 120 records in 0.051602504 seconds. Throughput is 2325.4685 records/second. Loss is 0.55704844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008025682182985555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27840/60000][Iteration 1232][Wall Clock 62.085360011s] Trained 120 records in 0.047859139 seconds. Throughput is 2507.3582 records/second. Loss is 0.42792103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008024394158241053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 27960/60000][Iteration 1233][Wall Clock 62.128852187s] Trained 120 records in 0.043492176 seconds. Throughput is 2759.117 records/second. Loss is 0.47326902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008023106546854942. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28080/60000][Iteration 1234][Wall Clock 62.172199831s] Trained 120 records in 0.043347644 seconds. Throughput is 2768.3164 records/second. Loss is 0.58417314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00802181934862827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28200/60000][Iteration 1235][Wall Clock 62.214774213s] Trained 120 records in 0.042574382 seconds. Throughput is 2818.5964 records/second. Loss is 0.46029955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008020532563362208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28320/60000][Iteration 1236][Wall Clock 62.257482734s] Trained 120 records in 0.042708521 seconds. Throughput is 2809.744 records/second. Loss is 0.46150073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00801924619085806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28440/60000][Iteration 1237][Wall Clock 62.299790703s] Trained 120 records in 0.042307969 seconds. Throughput is 2836.345 records/second. Loss is 0.4693674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008017960230917255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28560/60000][Iteration 1238][Wall Clock 62.342314346s] Trained 120 records in 0.042523643 seconds. Throughput is 2821.9597 records/second. Loss is 0.47208646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00801667468334135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28680/60000][Iteration 1239][Wall Clock 62.385031064s] Trained 120 records in 0.042716718 seconds. Throughput is 2809.2046 records/second. Loss is 0.44357383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008015389547932029. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28800/60000][Iteration 1240][Wall Clock 62.427738589s] Trained 120 records in 0.042707525 seconds. Throughput is 2809.8093 records/second. Loss is 0.45072544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008014104824491105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 28920/60000][Iteration 1241][Wall Clock 62.469825916s] Trained 120 records in 0.042087327 seconds. Throughput is 2851.2146 records/second. Loss is 0.46490353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008012820512820514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:08 INFO  DistriOptimizer$:406 - [Epoch 3 29040/60000][Iteration 1242][Wall Clock 62.511746173s] Trained 120 records in 0.041920257 seconds. Throughput is 2862.578 records/second. Loss is 0.37268648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00801153661272232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 29160/60000][Iteration 1243][Wall Clock 62.554367413s] Trained 120 records in 0.04262124 seconds. Throughput is 2815.4976 records/second. Loss is 0.55010664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00801025312399872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 29280/60000][Iteration 1244][Wall Clock 62.597068091s] Trained 120 records in 0.042700678 seconds. Throughput is 2810.2598 records/second. Loss is 0.47421443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008008970046452027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 29400/60000][Iteration 1245][Wall Clock 62.647977003s] Trained 120 records in 0.050908912 seconds. Throughput is 2357.1511 records/second. Loss is 0.44222224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008007687379884689. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 29520/60000][Iteration 1246][Wall Clock 62.701104184s] Trained 120 records in 0.053127181 seconds. Throughput is 2258.7307 records/second. Loss is 0.5100276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008006405124099279. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 29640/60000][Iteration 1247][Wall Clock 62.745345659s] Trained 120 records in 0.044241475 seconds. Throughput is 2712.387 records/second. Loss is 0.55622077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008005123278898494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 29760/60000][Iteration 1248][Wall Clock 62.789049166s] Trained 120 records in 0.043703507 seconds. Throughput is 2745.7751 records/second. Loss is 0.36037108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00800384184408516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 29880/60000][Iteration 1249][Wall Clock 62.831704901s] Trained 120 records in 0.042655735 seconds. Throughput is 2813.2207 records/second. Loss is 0.39738747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008002560819462228. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30000/60000][Iteration 1250][Wall Clock 62.873958031s] Trained 120 records in 0.04225313 seconds. Throughput is 2840.0264 records/second. Loss is 0.49370876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008001280204832774. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30120/60000][Iteration 1251][Wall Clock 62.915797875s] Trained 120 records in 0.041839844 seconds. Throughput is 2868.0793 records/second. Loss is 0.479549. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30240/60000][Iteration 1252][Wall Clock 62.958057729s] Trained 120 records in 0.042259854 seconds. Throughput is 2839.5745 records/second. Loss is 0.4705714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007998720204767237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30360/60000][Iteration 1253][Wall Clock 63.000893041s] Trained 120 records in 0.042835312 seconds. Throughput is 2801.427 records/second. Loss is 0.48274094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00799744081893794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30480/60000][Iteration 1254][Wall Clock 63.043856946s] Trained 120 records in 0.042963905 seconds. Throughput is 2793.0422 records/second. Loss is 0.38247153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00799616184231569. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30600/60000][Iteration 1255][Wall Clock 63.0866187s] Trained 120 records in 0.042761754 seconds. Throughput is 2806.2458 records/second. Loss is 0.5567116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00799488327470419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30720/60000][Iteration 1256][Wall Clock 63.129367792s] Trained 120 records in 0.042749092 seconds. Throughput is 2807.0771 records/second. Loss is 0.39181635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007993605115907274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30840/60000][Iteration 1257][Wall Clock 63.181459637s] Trained 120 records in 0.052091845 seconds. Throughput is 2303.6235 records/second. Loss is 0.5046593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007992327365728899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 30960/60000][Iteration 1258][Wall Clock 63.232396047s] Trained 120 records in 0.05093641 seconds. Throughput is 2355.8787 records/second. Loss is 0.70489967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00799105002397315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 31080/60000][Iteration 1259][Wall Clock 63.275354048s] Trained 120 records in 0.042958001 seconds. Throughput is 2793.426 records/second. Loss is 0.43718842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00798977309044423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 31200/60000][Iteration 1260][Wall Clock 63.318099617s] Trained 120 records in 0.042745569 seconds. Throughput is 2807.3086 records/second. Loss is 0.4986774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007988496564946478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 31320/60000][Iteration 1261][Wall Clock 63.361095427s] Trained 120 records in 0.04299581 seconds. Throughput is 2790.9695 records/second. Loss is 0.48794195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007987220447284345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 31440/60000][Iteration 1262][Wall Clock 63.404316655s] Trained 120 records in 0.043221228 seconds. Throughput is 2776.4136 records/second. Loss is 0.48732826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007985944737262418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 31560/60000][Iteration 1263][Wall Clock 63.446807467s] Trained 120 records in 0.042490812 seconds. Throughput is 2824.1401 records/second. Loss is 0.43993324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007984669434685404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 31680/60000][Iteration 1264][Wall Clock 63.489026772s] Trained 120 records in 0.042219305 seconds. Throughput is 2842.3018 records/second. Loss is 0.532655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007983394539358136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:09 INFO  DistriOptimizer$:406 - [Epoch 3 31800/60000][Iteration 1265][Wall Clock 63.531559334s] Trained 120 records in 0.042532562 seconds. Throughput is 2821.3677 records/second. Loss is 0.4966005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007982120051085567. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 31920/60000][Iteration 1266][Wall Clock 63.575252977s] Trained 120 records in 0.043693643 seconds. Throughput is 2746.395 records/second. Loss is 0.5007966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007980845969672785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32040/60000][Iteration 1267][Wall Clock 63.61816161s] Trained 120 records in 0.042908633 seconds. Throughput is 2796.6401 records/second. Loss is 0.51108706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007979572294924991. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32160/60000][Iteration 1268][Wall Clock 63.661085847s] Trained 120 records in 0.042924237 seconds. Throughput is 2795.6233 records/second. Loss is 0.48483554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007978299026647519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32280/60000][Iteration 1269][Wall Clock 63.703537543s] Trained 120 records in 0.042451696 seconds. Throughput is 2826.7422 records/second. Loss is 0.53683394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00797702616464582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32400/60000][Iteration 1270][Wall Clock 63.753404735s] Trained 120 records in 0.049867192 seconds. Throughput is 2406.3918 records/second. Loss is 0.49354327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007975753708725474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32520/60000][Iteration 1271][Wall Clock 63.819535398s] Trained 120 records in 0.066130663 seconds. Throughput is 1814.5895 records/second. Loss is 0.50053483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007974481658692184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32640/60000][Iteration 1272][Wall Clock 63.863866007s] Trained 120 records in 0.044330609 seconds. Throughput is 2706.9333 records/second. Loss is 0.47770214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007973210014351778. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32760/60000][Iteration 1273][Wall Clock 63.906456379s] Trained 120 records in 0.042590372 seconds. Throughput is 2817.538 records/second. Loss is 0.4739074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007971938775510204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 32880/60000][Iteration 1274][Wall Clock 63.950629162s] Trained 120 records in 0.044172783 seconds. Throughput is 2716.605 records/second. Loss is 0.58373547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007970667941973538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33000/60000][Iteration 1275][Wall Clock 63.995707809s] Trained 120 records in 0.045078647 seconds. Throughput is 2662.0142 records/second. Loss is 0.3657659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007969397513547976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33120/60000][Iteration 1276][Wall Clock 64.03953084s] Trained 120 records in 0.043823031 seconds. Throughput is 2738.2861 records/second. Loss is 0.43474457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007968127490039842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33240/60000][Iteration 1277][Wall Clock 64.082914572s] Trained 120 records in 0.043383732 seconds. Throughput is 2766.0137 records/second. Loss is 0.45118052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007966857871255577. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33360/60000][Iteration 1278][Wall Clock 64.125810011s] Trained 120 records in 0.042895439 seconds. Throughput is 2797.5002 records/second. Loss is 0.48409793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007965588657001752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33480/60000][Iteration 1279][Wall Clock 64.168581188s] Trained 120 records in 0.042771177 seconds. Throughput is 2805.628 records/second. Loss is 0.38642886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00796431984708506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33600/60000][Iteration 1280][Wall Clock 64.211867627s] Trained 120 records in 0.043286439 seconds. Throughput is 2772.2307 records/second. Loss is 0.4759234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00796305144131231. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33720/60000][Iteration 1281][Wall Clock 64.255134787s] Trained 120 records in 0.04326716 seconds. Throughput is 2773.466 records/second. Loss is 0.6006411. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007961783439490446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33840/60000][Iteration 1282][Wall Clock 64.299332175s] Trained 120 records in 0.044197388 seconds. Throughput is 2715.0925 records/second. Loss is 0.43310255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007960515841426525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 33960/60000][Iteration 1283][Wall Clock 64.345307546s] Trained 120 records in 0.045975371 seconds. Throughput is 2610.093 records/second. Loss is 0.41808394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00795924864692773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 34080/60000][Iteration 1284][Wall Clock 64.399780206s] Trained 120 records in 0.05447266 seconds. Throughput is 2202.94 records/second. Loss is 0.46744493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00795798185580137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 34200/60000][Iteration 1285][Wall Clock 64.449604477s] Trained 120 records in 0.049824271 seconds. Throughput is 2408.4648 records/second. Loss is 0.38895586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007956715467854869. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 34320/60000][Iteration 1286][Wall Clock 64.493216066s] Trained 120 records in 0.043611589 seconds. Throughput is 2751.5623 records/second. Loss is 0.5773022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007955449482895782. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:10 INFO  DistriOptimizer$:406 - [Epoch 3 34440/60000][Iteration 1287][Wall Clock 64.536190184s] Trained 120 records in 0.042974118 seconds. Throughput is 2792.3784 records/second. Loss is 0.47757548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007954183900731784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 34560/60000][Iteration 1288][Wall Clock 64.579486166s] Trained 120 records in 0.043295982 seconds. Throughput is 2771.6196 records/second. Loss is 0.46478286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00795291872117067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 34680/60000][Iteration 1289][Wall Clock 64.622447074s] Trained 120 records in 0.042960908 seconds. Throughput is 2793.237 records/second. Loss is 0.52679265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007951653944020356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 34800/60000][Iteration 1290][Wall Clock 64.673813611s] Trained 120 records in 0.051366537 seconds. Throughput is 2336.1511 records/second. Loss is 0.47165975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007950389569088886. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 34920/60000][Iteration 1291][Wall Clock 64.726408689s] Trained 120 records in 0.052595078 seconds. Throughput is 2281.5823 records/second. Loss is 0.44073576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00794912559618442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35040/60000][Iteration 1292][Wall Clock 64.769960654s] Trained 120 records in 0.043551965 seconds. Throughput is 2755.329 records/second. Loss is 0.4881597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007947862025115245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35160/60000][Iteration 1293][Wall Clock 64.812324558s] Trained 120 records in 0.042363904 seconds. Throughput is 2832.6 records/second. Loss is 0.41063303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007946598855689765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35280/60000][Iteration 1294][Wall Clock 64.8544109s] Trained 120 records in 0.042086342 seconds. Throughput is 2851.2815 records/second. Loss is 0.5023239. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00794533608771651. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35400/60000][Iteration 1295][Wall Clock 64.897572869s] Trained 120 records in 0.043161969 seconds. Throughput is 2780.2253 records/second. Loss is 0.48928207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00794407372100413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35520/60000][Iteration 1296][Wall Clock 64.948117577s] Trained 120 records in 0.050544708 seconds. Throughput is 2374.1357 records/second. Loss is 0.47064257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0079428117553614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35640/60000][Iteration 1297][Wall Clock 64.999589015s] Trained 120 records in 0.051471438 seconds. Throughput is 2331.3901 records/second. Loss is 0.48812732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007941550190597205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35760/60000][Iteration 1298][Wall Clock 65.043499733s] Trained 120 records in 0.043910718 seconds. Throughput is 2732.8179 records/second. Loss is 0.51776063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007940289026520565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 35880/60000][Iteration 1299][Wall Clock 65.087019188s] Trained 120 records in 0.043519455 seconds. Throughput is 2757.3875 records/second. Loss is 0.488296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007939028262940616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36000/60000][Iteration 1300][Wall Clock 65.129874812s] Trained 120 records in 0.042855624 seconds. Throughput is 2800.099 records/second. Loss is 0.62885296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007937767899666614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36120/60000][Iteration 1301][Wall Clock 65.172619033s] Trained 120 records in 0.042744221 seconds. Throughput is 2807.3972 records/second. Loss is 0.38513044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007936507936507936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36240/60000][Iteration 1302][Wall Clock 65.216268093s] Trained 120 records in 0.04364906 seconds. Throughput is 2749.2002 records/second. Loss is 0.46870473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007935248373274084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36360/60000][Iteration 1303][Wall Clock 65.259021735s] Trained 120 records in 0.042753642 seconds. Throughput is 2806.7786 records/second. Loss is 0.5217897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007933989209774676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36480/60000][Iteration 1304][Wall Clock 65.302334989s] Trained 120 records in 0.043313254 seconds. Throughput is 2770.5146 records/second. Loss is 0.4733881. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007932730445819451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36600/60000][Iteration 1305][Wall Clock 65.345757874s] Trained 120 records in 0.043422885 seconds. Throughput is 2763.5198 records/second. Loss is 0.4212908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007931472081218274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36720/60000][Iteration 1306][Wall Clock 65.388844076s] Trained 120 records in 0.043086202 seconds. Throughput is 2785.1145 records/second. Loss is 0.42641386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007930214115781126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36840/60000][Iteration 1307][Wall Clock 65.431867516s] Trained 120 records in 0.04302344 seconds. Throughput is 2789.1772 records/second. Loss is 0.4581587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00792895654931811. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 36960/60000][Iteration 1308][Wall Clock 65.474517842s] Trained 120 records in 0.042650326 seconds. Throughput is 2813.5774 records/second. Loss is 0.45138445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007927699381639447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:11 INFO  DistriOptimizer$:406 - [Epoch 3 37080/60000][Iteration 1309][Wall Clock 65.517405627s] Trained 120 records in 0.042887785 seconds. Throughput is 2797.9995 records/second. Loss is 0.6101512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007926442612555484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 37200/60000][Iteration 1310][Wall Clock 65.560057874s] Trained 120 records in 0.042652247 seconds. Throughput is 2813.451 records/second. Loss is 0.40945107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007925186241876684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 37320/60000][Iteration 1311][Wall Clock 65.61359467s] Trained 120 records in 0.053536796 seconds. Throughput is 2241.449 records/second. Loss is 0.4609602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00792393026941363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 37440/60000][Iteration 1312][Wall Clock 65.662853173s] Trained 120 records in 0.049258503 seconds. Throughput is 2436.1277 records/second. Loss is 0.3797824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007922674694977025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 37560/60000][Iteration 1313][Wall Clock 65.706609451s] Trained 120 records in 0.043756278 seconds. Throughput is 2742.4636 records/second. Loss is 0.43503106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007921419518377694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 37680/60000][Iteration 1314][Wall Clock 65.751804624s] Trained 120 records in 0.045195173 seconds. Throughput is 2655.151 records/second. Loss is 0.4671771. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007920164739426581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 37800/60000][Iteration 1315][Wall Clock 65.795418615s] Trained 120 records in 0.043613991 seconds. Throughput is 2751.4106 records/second. Loss is 0.40587616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007918910357934749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 37920/60000][Iteration 1316][Wall Clock 65.839575507s] Trained 120 records in 0.044156892 seconds. Throughput is 2717.5828 records/second. Loss is 0.48717076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007917656373713382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38040/60000][Iteration 1317][Wall Clock 65.882324391s] Trained 120 records in 0.042748884 seconds. Throughput is 2807.0908 records/second. Loss is 0.4659637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007916402786573781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38160/60000][Iteration 1318][Wall Clock 65.927340399s] Trained 120 records in 0.045016008 seconds. Throughput is 2665.7183 records/second. Loss is 0.5271639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007915149596327371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38280/60000][Iteration 1319][Wall Clock 65.971548204s] Trained 120 records in 0.044207805 seconds. Throughput is 2714.453 records/second. Loss is 0.4524384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007913896802785692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38400/60000][Iteration 1320][Wall Clock 66.016555795s] Trained 120 records in 0.045007591 seconds. Throughput is 2666.217 records/second. Loss is 0.4408776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007912644405760404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38520/60000][Iteration 1321][Wall Clock 66.071665456s] Trained 120 records in 0.055109661 seconds. Throughput is 2177.4766 records/second. Loss is 0.3668391. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007911392405063292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38640/60000][Iteration 1322][Wall Clock 66.11838742s] Trained 120 records in 0.046721964 seconds. Throughput is 2568.385 records/second. Loss is 0.4485218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00791014080050625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38760/60000][Iteration 1323][Wall Clock 66.161744936s] Trained 120 records in 0.043357516 seconds. Throughput is 2767.686 records/second. Loss is 0.5752196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007908889591901298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 38880/60000][Iteration 1324][Wall Clock 66.204470222s] Trained 120 records in 0.042725286 seconds. Throughput is 2808.641 records/second. Loss is 0.37852412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007907638779060573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 39000/60000][Iteration 1325][Wall Clock 66.248836618s] Trained 120 records in 0.044366396 seconds. Throughput is 2704.7498 records/second. Loss is 0.43183598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007906388361796331. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 39120/60000][Iteration 1326][Wall Clock 66.292566847s] Trained 120 records in 0.043730229 seconds. Throughput is 2744.0972 records/second. Loss is 0.52508837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007905138339920948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 39240/60000][Iteration 1327][Wall Clock 66.336638831s] Trained 120 records in 0.044071984 seconds. Throughput is 2722.818 records/second. Loss is 0.646704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007903888713246918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 39360/60000][Iteration 1328][Wall Clock 66.380560225s] Trained 120 records in 0.043921394 seconds. Throughput is 2732.1538 records/second. Loss is 0.38795954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00790263948158685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 39480/60000][Iteration 1329][Wall Clock 66.424441434s] Trained 120 records in 0.043881209 seconds. Throughput is 2734.6558 records/second. Loss is 0.4796364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007901390644753476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 39600/60000][Iteration 1330][Wall Clock 66.467486558s] Trained 120 records in 0.043045124 seconds. Throughput is 2787.7722 records/second. Loss is 0.47176164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007900142202559647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:12 INFO  DistriOptimizer$:406 - [Epoch 3 39720/60000][Iteration 1331][Wall Clock 66.510166742s] Trained 120 records in 0.042680184 seconds. Throughput is 2811.6091 records/second. Loss is 0.54674727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007898894154818325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 39840/60000][Iteration 1332][Wall Clock 66.554514258s] Trained 120 records in 0.044347516 seconds. Throughput is 2705.9011 records/second. Loss is 0.5739774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0078976465013426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 39960/60000][Iteration 1333][Wall Clock 66.599182979s] Trained 120 records in 0.044668721 seconds. Throughput is 2686.4436 records/second. Loss is 0.39053008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007896399241945674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40080/60000][Iteration 1334][Wall Clock 66.642927229s] Trained 120 records in 0.04374425 seconds. Throughput is 2743.2175 records/second. Loss is 0.42531577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007895152376440865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40200/60000][Iteration 1335][Wall Clock 66.687340031s] Trained 120 records in 0.044412802 seconds. Throughput is 2701.9236 records/second. Loss is 0.5512319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007893905904641616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40320/60000][Iteration 1336][Wall Clock 66.731939484s] Trained 120 records in 0.044599453 seconds. Throughput is 2690.616 records/second. Loss is 0.41427103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007892659826361484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40440/60000][Iteration 1337][Wall Clock 66.776766854s] Trained 120 records in 0.04482737 seconds. Throughput is 2676.9358 records/second. Loss is 0.40175524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007891414141414142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40560/60000][Iteration 1338][Wall Clock 66.839268892s] Trained 120 records in 0.062502038 seconds. Throughput is 1919.9373 records/second. Loss is 0.4659562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007890168849613381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40680/60000][Iteration 1339][Wall Clock 66.901823168s] Trained 120 records in 0.062554276 seconds. Throughput is 1918.334 records/second. Loss is 0.44828078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007888923950773114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40800/60000][Iteration 1340][Wall Clock 66.946810837s] Trained 120 records in 0.044987669 seconds. Throughput is 2667.3977 records/second. Loss is 0.5071328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007887679444707366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 40920/60000][Iteration 1341][Wall Clock 66.993758342s] Trained 120 records in 0.046947505 seconds. Throughput is 2556.0464 records/second. Loss is 0.42795542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007886435331230283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41040/60000][Iteration 1342][Wall Clock 67.037887012s] Trained 120 records in 0.04412867 seconds. Throughput is 2719.3206 records/second. Loss is 0.5079923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007885191610156127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41160/60000][Iteration 1343][Wall Clock 67.080973171s] Trained 120 records in 0.043086159 seconds. Throughput is 2785.1172 records/second. Loss is 0.37944907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007883948281299276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41280/60000][Iteration 1344][Wall Clock 67.124529644s] Trained 120 records in 0.043556473 seconds. Throughput is 2755.044 records/second. Loss is 0.44078827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007882705344474224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41400/60000][Iteration 1345][Wall Clock 67.168462529s] Trained 120 records in 0.043932885 seconds. Throughput is 2731.4392 records/second. Loss is 0.57240576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007881462799495585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41520/60000][Iteration 1346][Wall Clock 67.217504375s] Trained 120 records in 0.049041846 seconds. Throughput is 2446.89 records/second. Loss is 0.6458234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007880220646178092. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41640/60000][Iteration 1347][Wall Clock 67.269236944s] Trained 120 records in 0.051732569 seconds. Throughput is 2319.6218 records/second. Loss is 0.5551251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00787897888433659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41760/60000][Iteration 1348][Wall Clock 67.313010675s] Trained 120 records in 0.043773731 seconds. Throughput is 2741.3704 records/second. Loss is 0.39880112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00787773751378604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 41880/60000][Iteration 1349][Wall Clock 67.356194482s] Trained 120 records in 0.043183807 seconds. Throughput is 2778.8193 records/second. Loss is 0.48835197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007876496534341524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 42000/60000][Iteration 1350][Wall Clock 67.399511601s] Trained 120 records in 0.043317119 seconds. Throughput is 2770.2673 records/second. Loss is 0.53626883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007875255945818239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 42120/60000][Iteration 1351][Wall Clock 67.442507873s] Trained 120 records in 0.042996272 seconds. Throughput is 2790.9397 records/second. Loss is 0.5398934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007874015748031496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 42240/60000][Iteration 1352][Wall Clock 67.484970694s] Trained 120 records in 0.042462821 seconds. Throughput is 2826.0015 records/second. Loss is 0.55136245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007872775940796726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:13 INFO  DistriOptimizer$:406 - [Epoch 3 42360/60000][Iteration 1353][Wall Clock 67.526917444s] Trained 120 records in 0.04194675 seconds. Throughput is 2860.7698 records/second. Loss is 0.44073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007871536523929471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 42480/60000][Iteration 1354][Wall Clock 67.569532471s] Trained 120 records in 0.042615027 seconds. Throughput is 2815.9082 records/second. Loss is 0.48411617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007870297497245396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 42600/60000][Iteration 1355][Wall Clock 67.611875613s] Trained 120 records in 0.042343142 seconds. Throughput is 2833.989 records/second. Loss is 0.41796702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007869058860560278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 42720/60000][Iteration 1356][Wall Clock 67.653853764s] Trained 120 records in 0.041978151 seconds. Throughput is 2858.63 records/second. Loss is 0.50034267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007867820613690008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 42840/60000][Iteration 1357][Wall Clock 67.696766485s] Trained 120 records in 0.042912721 seconds. Throughput is 2796.3735 records/second. Loss is 0.42921555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007866582756450599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 42960/60000][Iteration 1358][Wall Clock 67.740114025s] Trained 120 records in 0.04334754 seconds. Throughput is 2768.323 records/second. Loss is 0.45137733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007865345288658171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43080/60000][Iteration 1359][Wall Clock 67.782979275s] Trained 120 records in 0.04286525 seconds. Throughput is 2799.4705 records/second. Loss is 0.33434594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007864108210128971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43200/60000][Iteration 1360][Wall Clock 67.825437805s] Trained 120 records in 0.04245853 seconds. Throughput is 2826.287 records/second. Loss is 0.66900814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007862871520679353. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43320/60000][Iteration 1361][Wall Clock 67.868610883s] Trained 120 records in 0.043173078 seconds. Throughput is 2779.51 records/second. Loss is 0.42364123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007861635220125786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43440/60000][Iteration 1362][Wall Clock 67.910752519s] Trained 120 records in 0.042141636 seconds. Throughput is 2847.5403 records/second. Loss is 0.47500196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007860399308284862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43560/60000][Iteration 1363][Wall Clock 67.953288872s] Trained 120 records in 0.042536353 seconds. Throughput is 2821.1165 records/second. Loss is 0.41101414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00785916378497328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43680/60000][Iteration 1364][Wall Clock 68.003787618s] Trained 120 records in 0.050498746 seconds. Throughput is 2376.2966 records/second. Loss is 0.4649144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007857928650007858. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43800/60000][Iteration 1365][Wall Clock 68.05525011s] Trained 120 records in 0.051462492 seconds. Throughput is 2331.7952 records/second. Loss is 0.5796533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00785669390320553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 43920/60000][Iteration 1366][Wall Clock 68.101819172s] Trained 120 records in 0.046569062 seconds. Throughput is 2576.818 records/second. Loss is 0.48178548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007855459544383346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44040/60000][Iteration 1367][Wall Clock 68.14812354s] Trained 120 records in 0.046304368 seconds. Throughput is 2591.548 records/second. Loss is 0.43555364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007854225573358466. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44160/60000][Iteration 1368][Wall Clock 68.194713008s] Trained 120 records in 0.046589468 seconds. Throughput is 2575.6895 records/second. Loss is 0.39080152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00785299198994817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44280/60000][Iteration 1369][Wall Clock 68.239820405s] Trained 120 records in 0.045107397 seconds. Throughput is 2660.3174 records/second. Loss is 0.4092109. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007851758793969849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44400/60000][Iteration 1370][Wall Clock 68.290735623s] Trained 120 records in 0.050915218 seconds. Throughput is 2356.8591 records/second. Loss is 0.45115823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00785052598524101. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44520/60000][Iteration 1371][Wall Clock 68.335491354s] Trained 120 records in 0.044755731 seconds. Throughput is 2681.221 records/second. Loss is 0.5436093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007849293563579277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44640/60000][Iteration 1372][Wall Clock 68.378543319s] Trained 120 records in 0.043051965 seconds. Throughput is 2787.329 records/second. Loss is 0.58292985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007848061528802385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44760/60000][Iteration 1373][Wall Clock 68.433539496s] Trained 120 records in 0.054996177 seconds. Throughput is 2181.9697 records/second. Loss is 0.4305635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007846829880728186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 44880/60000][Iteration 1374][Wall Clock 68.476537805s] Trained 120 records in 0.042998309 seconds. Throughput is 2790.8074 records/second. Loss is 0.43014207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007845598619174643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:14 INFO  DistriOptimizer$:406 - [Epoch 3 45000/60000][Iteration 1375][Wall Clock 68.518994066s] Trained 120 records in 0.042456261 seconds. Throughput is 2826.4382 records/second. Loss is 0.4950317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007844367743959838. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45120/60000][Iteration 1376][Wall Clock 68.561992441s] Trained 120 records in 0.042998375 seconds. Throughput is 2790.8032 records/second. Loss is 0.3663368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00784313725490196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45240/60000][Iteration 1377][Wall Clock 68.605607593s] Trained 120 records in 0.043615152 seconds. Throughput is 2751.3374 records/second. Loss is 0.42200905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007841907151819323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45360/60000][Iteration 1378][Wall Clock 68.650872455s] Trained 120 records in 0.045264862 seconds. Throughput is 2651.063 records/second. Loss is 0.4891797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007840677434530343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45480/60000][Iteration 1379][Wall Clock 68.695501529s] Trained 120 records in 0.044629074 seconds. Throughput is 2688.83 records/second. Loss is 0.3356748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00783944810285356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45600/60000][Iteration 1380][Wall Clock 68.73833358s] Trained 120 records in 0.042832051 seconds. Throughput is 2801.6404 records/second. Loss is 0.5609871. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007838219156607618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45720/60000][Iteration 1381][Wall Clock 68.784921949s] Trained 120 records in 0.046588369 seconds. Throughput is 2575.7502 records/second. Loss is 0.40453386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007836990595611285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45840/60000][Iteration 1382][Wall Clock 68.829196544s] Trained 120 records in 0.044274595 seconds. Throughput is 2710.358 records/second. Loss is 0.44655553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007835762419683435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 45960/60000][Iteration 1383][Wall Clock 68.870839449s] Trained 120 records in 0.041642905 seconds. Throughput is 2881.6433 records/second. Loss is 0.42164937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007834534628643058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46080/60000][Iteration 1384][Wall Clock 68.913317663s] Trained 120 records in 0.042478214 seconds. Throughput is 2824.9775 records/second. Loss is 0.52440095. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007833307222309259. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46200/60000][Iteration 1385][Wall Clock 68.955533801s] Trained 120 records in 0.042216138 seconds. Throughput is 2842.515 records/second. Loss is 0.42875347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007832080200501254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46320/60000][Iteration 1386][Wall Clock 68.998173041s] Trained 120 records in 0.04263924 seconds. Throughput is 2814.309 records/second. Loss is 0.47267163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00783085356303837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46440/60000][Iteration 1387][Wall Clock 69.04066985s] Trained 120 records in 0.042496809 seconds. Throughput is 2823.7415 records/second. Loss is 0.51027876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007829627309740055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46560/60000][Iteration 1388][Wall Clock 69.082844948s] Trained 120 records in 0.042175098 seconds. Throughput is 2845.2808 records/second. Loss is 0.45410278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007828401440425865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46680/60000][Iteration 1389][Wall Clock 69.124940608s] Trained 120 records in 0.04209566 seconds. Throughput is 2850.6501 records/second. Loss is 0.5048937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007827175954915467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46800/60000][Iteration 1390][Wall Clock 69.167029091s] Trained 120 records in 0.042088483 seconds. Throughput is 2851.1362 records/second. Loss is 0.509232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007825950853028642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 46920/60000][Iteration 1391][Wall Clock 69.217965373s] Trained 120 records in 0.050936282 seconds. Throughput is 2355.8845 records/second. Loss is 0.4093294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00782472613458529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 47040/60000][Iteration 1392][Wall Clock 69.266685392s] Trained 120 records in 0.048720019 seconds. Throughput is 2463.0532 records/second. Loss is 0.34460756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007823501799405413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 47160/60000][Iteration 1393][Wall Clock 69.312791914s] Trained 120 records in 0.046106522 seconds. Throughput is 2602.6687 records/second. Loss is 0.43102863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007822277847309137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 47280/60000][Iteration 1394][Wall Clock 69.356179883s] Trained 120 records in 0.043387969 seconds. Throughput is 2765.7437 records/second. Loss is 0.47025892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00782105427811669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 47400/60000][Iteration 1395][Wall Clock 69.399615322s] Trained 120 records in 0.043435439 seconds. Throughput is 2762.721 records/second. Loss is 0.5567257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00781983109164842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 47520/60000][Iteration 1396][Wall Clock 69.445736213s] Trained 120 records in 0.046120891 seconds. Throughput is 2601.858 records/second. Loss is 0.47817212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007818608287724786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:15 INFO  DistriOptimizer$:406 - [Epoch 3 47640/60000][Iteration 1397][Wall Clock 69.48803279s] Trained 120 records in 0.042296577 seconds. Throughput is 2837.109 records/second. Loss is 0.6197319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007817385866166355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 47760/60000][Iteration 1398][Wall Clock 69.529194363s] Trained 120 records in 0.041161573 seconds. Throughput is 2915.3403 records/second. Loss is 0.51908654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00781616382679381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 47880/60000][Iteration 1399][Wall Clock 69.577465384s] Trained 120 records in 0.048271021 seconds. Throughput is 2485.9634 records/second. Loss is 0.49490306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007814942169427946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48000/60000][Iteration 1400][Wall Clock 69.622324525s] Trained 120 records in 0.044859141 seconds. Throughput is 2675.04 records/second. Loss is 0.45334476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00781372089388967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48120/60000][Iteration 1401][Wall Clock 69.664672108s] Trained 120 records in 0.042347583 seconds. Throughput is 2833.6917 records/second. Loss is 0.46476096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0078125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48240/60000][Iteration 1402][Wall Clock 69.707427376s] Trained 120 records in 0.042755268 seconds. Throughput is 2806.6716 records/second. Loss is 0.44509703. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007811279487580066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48360/60000][Iteration 1403][Wall Clock 69.750737587s] Trained 120 records in 0.043310211 seconds. Throughput is 2770.7092 records/second. Loss is 0.45463437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007810059356451109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48480/60000][Iteration 1404][Wall Clock 69.794095252s] Trained 120 records in 0.043357665 seconds. Throughput is 2767.6765 records/second. Loss is 0.46768153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007808839606434484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48600/60000][Iteration 1405][Wall Clock 69.836684931s] Trained 120 records in 0.042589679 seconds. Throughput is 2817.584 records/second. Loss is 0.37813684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007807620237351656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48720/60000][Iteration 1406][Wall Clock 69.879180583s] Trained 120 records in 0.042495652 seconds. Throughput is 2823.818 records/second. Loss is 0.49365824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007806401249024199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48840/60000][Iteration 1407][Wall Clock 69.921653771s] Trained 120 records in 0.042473188 seconds. Throughput is 2825.3118 records/second. Loss is 0.58167535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007805182641273806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 48960/60000][Iteration 1408][Wall Clock 69.963986818s] Trained 120 records in 0.042333047 seconds. Throughput is 2834.6648 records/second. Loss is 0.42885718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007803964413922272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49080/60000][Iteration 1409][Wall Clock 70.006527427s] Trained 120 records in 0.042540609 seconds. Throughput is 2820.834 records/second. Loss is 0.39004624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007802746566791511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49200/60000][Iteration 1410][Wall Clock 70.048797829s] Trained 120 records in 0.042270402 seconds. Throughput is 2838.8657 records/second. Loss is 0.34734556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007801529099703542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49320/60000][Iteration 1411][Wall Clock 70.090488957s] Trained 120 records in 0.041691128 seconds. Throughput is 2878.3103 records/second. Loss is 0.3767353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0078003120124804995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49440/60000][Iteration 1412][Wall Clock 70.131863569s] Trained 120 records in 0.041374612 seconds. Throughput is 2900.3293 records/second. Loss is 0.44826108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007799095304944627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49560/60000][Iteration 1413][Wall Clock 70.173441705s] Trained 120 records in 0.041578136 seconds. Throughput is 2886.1323 records/second. Loss is 0.41371217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007797878976918278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49680/60000][Iteration 1414][Wall Clock 70.21568987s] Trained 120 records in 0.042248165 seconds. Throughput is 2840.36 records/second. Loss is 0.49661407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00779666302822392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49800/60000][Iteration 1415][Wall Clock 70.257038098s] Trained 120 records in 0.041348228 seconds. Throughput is 2902.1802 records/second. Loss is 0.45183522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007795447458684129. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 49920/60000][Iteration 1416][Wall Clock 70.298880184s] Trained 120 records in 0.041842086 seconds. Throughput is 2867.926 records/second. Loss is 0.42428648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007794232268121591. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 50040/60000][Iteration 1417][Wall Clock 70.340755719s] Trained 120 records in 0.041875535 seconds. Throughput is 2865.635 records/second. Loss is 0.47369033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077930174563591035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 50160/60000][Iteration 1418][Wall Clock 70.400258655s] Trained 120 records in 0.059502936 seconds. Throughput is 2016.7072 records/second. Loss is 0.5306867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007791803023219573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 50280/60000][Iteration 1419][Wall Clock 70.457338956s] Trained 120 records in 0.057080301 seconds. Throughput is 2102.3015 records/second. Loss is 0.49379876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00779058896852602. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:16 INFO  DistriOptimizer$:406 - [Epoch 3 50400/60000][Iteration 1420][Wall Clock 70.503444172s] Trained 120 records in 0.046105216 seconds. Throughput is 2602.7424 records/second. Loss is 0.44302207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007789375292101573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 50520/60000][Iteration 1421][Wall Clock 70.549036215s] Trained 120 records in 0.045592043 seconds. Throughput is 2632.038 records/second. Loss is 0.4570802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00778816199376947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 50640/60000][Iteration 1422][Wall Clock 70.591718488s] Trained 120 records in 0.042682273 seconds. Throughput is 2811.4717 records/second. Loss is 0.52634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00778694907335306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 50760/60000][Iteration 1423][Wall Clock 70.634384006s] Trained 120 records in 0.042665518 seconds. Throughput is 2812.5757 records/second. Loss is 0.5994751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077857365306758025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 50880/60000][Iteration 1424][Wall Clock 70.676450314s] Trained 120 records in 0.042066308 seconds. Throughput is 2852.6392 records/second. Loss is 0.5044921. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077845243655612646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51000/60000][Iteration 1425][Wall Clock 70.719572825s] Trained 120 records in 0.043122511 seconds. Throughput is 2782.7693 records/second. Loss is 0.40099114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077833125778331265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51120/60000][Iteration 1426][Wall Clock 70.76901001s] Trained 120 records in 0.049437185 seconds. Throughput is 2427.3228 records/second. Loss is 0.5729806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007782101167315174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51240/60000][Iteration 1427][Wall Clock 70.817465462s] Trained 120 records in 0.048455452 seconds. Throughput is 2476.5015 records/second. Loss is 0.43994245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00778089013383131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51360/60000][Iteration 1428][Wall Clock 70.860719631s] Trained 120 records in 0.043254169 seconds. Throughput is 2774.299 records/second. Loss is 0.43118662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007779679477205538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51480/60000][Iteration 1429][Wall Clock 70.903030222s] Trained 120 records in 0.042310591 seconds. Throughput is 2836.1692 records/second. Loss is 0.4635758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007778469197261978. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51600/60000][Iteration 1430][Wall Clock 70.945422229s] Trained 120 records in 0.042392007 seconds. Throughput is 2830.7222 records/second. Loss is 0.4417501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007777259293824856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51720/60000][Iteration 1431][Wall Clock 70.989110564s] Trained 120 records in 0.043688335 seconds. Throughput is 2746.7288 records/second. Loss is 0.36786002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077760497667185065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51840/60000][Iteration 1432][Wall Clock 71.032062309s] Trained 120 records in 0.042951745 seconds. Throughput is 2793.833 records/second. Loss is 0.5647308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007774840615767377. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 51960/60000][Iteration 1433][Wall Clock 71.074849003s] Trained 120 records in 0.042786694 seconds. Throughput is 2804.61 records/second. Loss is 0.472739. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00777363184079602. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52080/60000][Iteration 1434][Wall Clock 71.117087009s] Trained 120 records in 0.042238006 seconds. Throughput is 2841.0432 records/second. Loss is 0.42066056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077724234416291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52200/60000][Iteration 1435][Wall Clock 71.159188965s] Trained 120 records in 0.042101956 seconds. Throughput is 2850.2239 records/second. Loss is 0.46679863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00777121541809139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52320/60000][Iteration 1436][Wall Clock 71.201119452s] Trained 120 records in 0.041930487 seconds. Throughput is 2861.8796 records/second. Loss is 0.47418797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007770007770007771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52440/60000][Iteration 1437][Wall Clock 71.242489915s] Trained 120 records in 0.041370463 seconds. Throughput is 2900.62 records/second. Loss is 0.34179968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007768800497203233. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52560/60000][Iteration 1438][Wall Clock 71.284701261s] Trained 120 records in 0.042211346 seconds. Throughput is 2842.8376 records/second. Loss is 0.36620057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007767593599502875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52680/60000][Iteration 1439][Wall Clock 71.327170419s] Trained 120 records in 0.042469158 seconds. Throughput is 2825.5798 records/second. Loss is 0.3734064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007766387076731904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52800/60000][Iteration 1440][Wall Clock 71.370090373s] Trained 120 records in 0.042919954 seconds. Throughput is 2795.9023 records/second. Loss is 0.35772103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007765180928715639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 52920/60000][Iteration 1441][Wall Clock 71.413075581s] Trained 120 records in 0.042985208 seconds. Throughput is 2791.658 records/second. Loss is 0.49163157. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007763975155279503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 53040/60000][Iteration 1442][Wall Clock 71.455227172s] Trained 120 records in 0.042151591 seconds. Throughput is 2846.8674 records/second. Loss is 0.40959594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00776276975624903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:17 INFO  DistriOptimizer$:406 - [Epoch 3 53160/60000][Iteration 1443][Wall Clock 71.4966146s] Trained 120 records in 0.041387428 seconds. Throughput is 2899.4312 records/second. Loss is 0.4509278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00776156473144986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 53280/60000][Iteration 1444][Wall Clock 71.548793178s] Trained 120 records in 0.052178578 seconds. Throughput is 2299.7944 records/second. Loss is 0.45362598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007760360080707745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 53400/60000][Iteration 1445][Wall Clock 71.599266921s] Trained 120 records in 0.050473743 seconds. Throughput is 2377.4739 records/second. Loss is 0.50302136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007759155803848542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 53520/60000][Iteration 1446][Wall Clock 71.65550401s] Trained 120 records in 0.056237089 seconds. Throughput is 2133.823 records/second. Loss is 0.38817582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007757951900698215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 53640/60000][Iteration 1447][Wall Clock 71.699546358s] Trained 120 records in 0.044042348 seconds. Throughput is 2724.6504 records/second. Loss is 0.394213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077567483710828415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 53760/60000][Iteration 1448][Wall Clock 71.741681701s] Trained 120 records in 0.042135343 seconds. Throughput is 2847.9653 records/second. Loss is 0.38070092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007755545214828602. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 53880/60000][Iteration 1449][Wall Clock 71.783624984s] Trained 120 records in 0.041943283 seconds. Throughput is 2861.0063 records/second. Loss is 0.5410324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007754342431761786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54000/60000][Iteration 1450][Wall Clock 71.824980568s] Trained 120 records in 0.041355584 seconds. Throughput is 2901.6638 records/second. Loss is 0.59064686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007753140021708792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54120/60000][Iteration 1451][Wall Clock 71.866711409s] Trained 120 records in 0.041730841 seconds. Throughput is 2875.5713 records/second. Loss is 0.48665163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007751937984496124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54240/60000][Iteration 1452][Wall Clock 71.915932819s] Trained 120 records in 0.04922141 seconds. Throughput is 2437.9634 records/second. Loss is 0.43107286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007750736319950395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54360/60000][Iteration 1453][Wall Clock 71.962085992s] Trained 120 records in 0.046153173 seconds. Throughput is 2600.0378 records/second. Loss is 0.5167616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007749535027898326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54480/60000][Iteration 1454][Wall Clock 72.005235218s] Trained 120 records in 0.043149226 seconds. Throughput is 2781.0464 records/second. Loss is 0.4235279. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007748334108166745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54600/60000][Iteration 1455][Wall Clock 72.048258855s] Trained 120 records in 0.043023637 seconds. Throughput is 2789.1643 records/second. Loss is 0.35312095. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077471335605825845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54720/60000][Iteration 1456][Wall Clock 72.091603516s] Trained 120 records in 0.043344661 seconds. Throughput is 2768.507 records/second. Loss is 0.39131457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077459333849728895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54840/60000][Iteration 1457][Wall Clock 72.134927437s] Trained 120 records in 0.043323921 seconds. Throughput is 2769.8325 records/second. Loss is 0.48735204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007744733581164808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 54960/60000][Iteration 1458][Wall Clock 72.177525446s] Trained 120 records in 0.042598009 seconds. Throughput is 2817.033 records/second. Loss is 0.48717982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007743534148985598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 55080/60000][Iteration 1459][Wall Clock 72.220068038s] Trained 120 records in 0.042542592 seconds. Throughput is 2820.7026 records/second. Loss is 0.4424481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00774233508826262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 55200/60000][Iteration 1460][Wall Clock 72.26397543s] Trained 120 records in 0.043907392 seconds. Throughput is 2733.025 records/second. Loss is 0.37351573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007741136398823347. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 55320/60000][Iteration 1461][Wall Clock 72.306650271s] Trained 120 records in 0.042674841 seconds. Throughput is 2811.9614 records/second. Loss is 0.4495982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007739938080495356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 55440/60000][Iteration 1462][Wall Clock 72.348994544s] Trained 120 records in 0.042344273 seconds. Throughput is 2833.9133 records/second. Loss is 0.37728179. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007738740133106331. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 55560/60000][Iteration 1463][Wall Clock 72.39201754s] Trained 120 records in 0.043022996 seconds. Throughput is 2789.2058 records/second. Loss is 0.3854542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007737542556484061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 55680/60000][Iteration 1464][Wall Clock 72.435579441s] Trained 120 records in 0.043561901 seconds. Throughput is 2754.7007 records/second. Loss is 0.528385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007736345350456445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:18 INFO  DistriOptimizer$:406 - [Epoch 3 55800/60000][Iteration 1465][Wall Clock 72.478226761s] Trained 120 records in 0.04264732 seconds. Throughput is 2813.776 records/second. Loss is 0.5474272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007735148514851486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 55920/60000][Iteration 1466][Wall Clock 72.52088016s] Trained 120 records in 0.042653399 seconds. Throughput is 2813.3748 records/second. Loss is 0.4129899. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007733952049497292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56040/60000][Iteration 1467][Wall Clock 72.563811059s] Trained 120 records in 0.042930899 seconds. Throughput is 2795.1897 records/second. Loss is 0.54043585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007732755954222084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56160/60000][Iteration 1468][Wall Clock 72.610828596s] Trained 120 records in 0.047017537 seconds. Throughput is 2552.2393 records/second. Loss is 0.6832942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007731560228854182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56280/60000][Iteration 1469][Wall Clock 72.65398489s] Trained 120 records in 0.043156294 seconds. Throughput is 2780.591 records/second. Loss is 0.40535828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077303648732220155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56400/60000][Iteration 1470][Wall Clock 72.706223019s] Trained 120 records in 0.052238129 seconds. Throughput is 2297.1726 records/second. Loss is 0.41091695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007729169887154119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56520/60000][Iteration 1471][Wall Clock 72.756325924s] Trained 120 records in 0.050102905 seconds. Throughput is 2395.0708 records/second. Loss is 0.44952777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077279752704791345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56640/60000][Iteration 1472][Wall Clock 72.798747516s] Trained 120 records in 0.042421592 seconds. Throughput is 2828.7483 records/second. Loss is 0.47568038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007726781023025807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56760/60000][Iteration 1473][Wall Clock 72.84095011s] Trained 120 records in 0.042202594 seconds. Throughput is 2843.427 records/second. Loss is 0.4533795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077255871446229914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 56880/60000][Iteration 1474][Wall Clock 72.88310412s] Trained 120 records in 0.04215401 seconds. Throughput is 2846.7043 records/second. Loss is 0.39486694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007724393635099645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57000/60000][Iteration 1475][Wall Clock 72.925326467s] Trained 120 records in 0.042222347 seconds. Throughput is 2842.097 records/second. Loss is 0.41247237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007723200494284832. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57120/60000][Iteration 1476][Wall Clock 72.967575447s] Trained 120 records in 0.04224898 seconds. Throughput is 2840.3054 records/second. Loss is 0.49645168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007722007722007722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57240/60000][Iteration 1477][Wall Clock 73.010007867s] Trained 120 records in 0.04243242 seconds. Throughput is 2828.0264 records/second. Loss is 0.47069913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077208153180975915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57360/60000][Iteration 1478][Wall Clock 73.051533224s] Trained 120 records in 0.041525357 seconds. Throughput is 2889.8005 records/second. Loss is 0.43591443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00771962328238382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57480/60000][Iteration 1479][Wall Clock 73.107485403s] Trained 120 records in 0.055952179 seconds. Throughput is 2144.6885 records/second. Loss is 0.380328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007718431614695894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57600/60000][Iteration 1480][Wall Clock 73.149475515s] Trained 120 records in 0.041990112 seconds. Throughput is 2857.8157 records/second. Loss is 0.35302833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007717240314863405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57720/60000][Iteration 1481][Wall Clock 73.190656464s] Trained 120 records in 0.041180949 seconds. Throughput is 2913.9688 records/second. Loss is 0.43759686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007716049382716049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57840/60000][Iteration 1482][Wall Clock 73.232475178s] Trained 120 records in 0.041818714 seconds. Throughput is 2869.5286 records/second. Loss is 0.41995376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007714858818083629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 57960/60000][Iteration 1483][Wall Clock 73.27417875s] Trained 120 records in 0.041703572 seconds. Throughput is 2877.4514 records/second. Loss is 0.44085017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007713668620796051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 58080/60000][Iteration 1484][Wall Clock 73.316316021s] Trained 120 records in 0.042137271 seconds. Throughput is 2847.835 records/second. Loss is 0.49635226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007712478790683326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 58200/60000][Iteration 1485][Wall Clock 73.35923352s] Trained 120 records in 0.042917499 seconds. Throughput is 2796.0625 records/second. Loss is 0.44643122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007711289327575571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 58320/60000][Iteration 1486][Wall Clock 73.403445575s] Trained 120 records in 0.044212055 seconds. Throughput is 2714.192 records/second. Loss is 0.40316695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007710100231303006. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 58440/60000][Iteration 1487][Wall Clock 73.447460238s] Trained 120 records in 0.044014663 seconds. Throughput is 2726.3643 records/second. Loss is 0.5345745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00770891150169596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:19 INFO  DistriOptimizer$:406 - [Epoch 3 58560/60000][Iteration 1488][Wall Clock 73.492221877s] Trained 120 records in 0.044761639 seconds. Throughput is 2680.867 records/second. Loss is 0.3910877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007707723138584861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 58680/60000][Iteration 1489][Wall Clock 73.540242983s] Trained 120 records in 0.048021106 seconds. Throughput is 2498.9014 records/second. Loss is 0.43616912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0077065351418002465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 58800/60000][Iteration 1490][Wall Clock 73.588359029s] Trained 120 records in 0.048116046 seconds. Throughput is 2493.9705 records/second. Loss is 0.5850264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007705347511172754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 58920/60000][Iteration 1491][Wall Clock 73.63491958s] Trained 120 records in 0.046560551 seconds. Throughput is 2577.289 records/second. Loss is 0.40905887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007704160246533128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59040/60000][Iteration 1492][Wall Clock 73.681484997s] Trained 120 records in 0.046565417 seconds. Throughput is 2577.0198 records/second. Loss is 0.3170203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007702973347712217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59160/60000][Iteration 1493][Wall Clock 73.724532258s] Trained 120 records in 0.043047261 seconds. Throughput is 2787.6338 records/second. Loss is 0.3346707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007701786814540973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59280/60000][Iteration 1494][Wall Clock 73.767728458s] Trained 120 records in 0.0431962 seconds. Throughput is 2778.022 records/second. Loss is 0.45584032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007700600646850454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59400/60000][Iteration 1495][Wall Clock 73.815979957s] Trained 120 records in 0.048251499 seconds. Throughput is 2486.9695 records/second. Loss is 0.430517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076994148444718205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59520/60000][Iteration 1496][Wall Clock 73.869946058s] Trained 120 records in 0.053966101 seconds. Throughput is 2223.6182 records/second. Loss is 0.43114048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007698229407236336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59640/60000][Iteration 1497][Wall Clock 73.916646695s] Trained 120 records in 0.046700637 seconds. Throughput is 2569.558 records/second. Loss is 0.6162741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076970443349753705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59760/60000][Iteration 1498][Wall Clock 73.960597185s] Trained 120 records in 0.04395049 seconds. Throughput is 2730.345 records/second. Loss is 0.44044906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007695859627520395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 59880/60000][Iteration 1499][Wall Clock 74.003849856s] Trained 120 records in 0.043252671 seconds. Throughput is 2774.3953 records/second. Loss is 0.48120028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007694675284702985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:406 - [Epoch 3 60000/60000][Iteration 1500][Wall Clock 74.046504657s] Trained 120 records in 0.042654801 seconds. Throughput is 2813.2825 records/second. Loss is 0.4438057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007693491306354824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:20 INFO  DistriOptimizer$:451 - [Epoch 3 60000/60000][Iteration 1500][Wall Clock 74.046504657s] Epoch finished. Wall clock time is 74863.683565 ms
2019-10-23 15:54:20 INFO  DistriOptimizer$:111 - [Epoch 3 60000/60000][Iteration 1500][Wall Clock 74.046504657s] Validate model...
2019-10-23 15:54:21 INFO  DistriOptimizer$:177 - [Epoch 3 60000/60000][Iteration 1500][Wall Clock 74.046504657s] validate model throughput is 14600.238 records/second
2019-10-23 15:54:21 INFO  DistriOptimizer$:180 - [Epoch 3 60000/60000][Iteration 1500][Wall Clock 74.046504657s] Top1Accuracy is Accuracy(correct: 8925, count: 10000, accuracy: 0.8925)
2019-10-23 15:54:21 INFO  DistriOptimizer$:220 - [Wall Clock 74.863683565s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:54:21 INFO  DistriOptimizer$:225 - [Wall Clock 74.863683565s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 120/60000][Iteration 1501][Wall Clock 74.913236135s] Trained 120 records in 0.04955257 seconds. Throughput is 2421.6704 records/second. Loss is 0.4088408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007692307692307692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 240/60000][Iteration 1502][Wall Clock 74.956492869s] Trained 120 records in 0.043256734 seconds. Throughput is 2774.1345 records/second. Loss is 0.5243216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007691124442393478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 360/60000][Iteration 1503][Wall Clock 74.999703104s] Trained 120 records in 0.043210235 seconds. Throughput is 2777.1199 records/second. Loss is 0.36429825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007689941556444172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 480/60000][Iteration 1504][Wall Clock 75.051987001s] Trained 120 records in 0.052283897 seconds. Throughput is 2295.1616 records/second. Loss is 0.42581925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007688759034291865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 600/60000][Iteration 1505][Wall Clock 75.10079961s] Trained 120 records in 0.048812609 seconds. Throughput is 2458.381 records/second. Loss is 0.46194023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076875768757687585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 720/60000][Iteration 1506][Wall Clock 75.143685472s] Trained 120 records in 0.042885862 seconds. Throughput is 2798.125 records/second. Loss is 0.4306976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007686395080707149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 840/60000][Iteration 1507][Wall Clock 75.186525315s] Trained 120 records in 0.042839843 seconds. Throughput is 2801.1306 records/second. Loss is 0.42756337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00768521364893944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 960/60000][Iteration 1508][Wall Clock 75.229258128s] Trained 120 records in 0.042732813 seconds. Throughput is 2808.1465 records/second. Loss is 0.50375265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00768403258029814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1080/60000][Iteration 1509][Wall Clock 75.272240339s] Trained 120 records in 0.042982211 seconds. Throughput is 2791.8528 records/second. Loss is 0.5427296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007682851874615857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1200/60000][Iteration 1510][Wall Clock 75.315603324s] Trained 120 records in 0.043362985 seconds. Throughput is 2767.3372 records/second. Loss is 0.5513078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007681671531725303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1320/60000][Iteration 1511][Wall Clock 75.357881669s] Trained 120 records in 0.042278345 seconds. Throughput is 2838.3325 records/second. Loss is 0.34825617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007680491551459293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1440/60000][Iteration 1512][Wall Clock 75.400283394s] Trained 120 records in 0.042401725 seconds. Throughput is 2830.0737 records/second. Loss is 0.51260835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007679311933650745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1560/60000][Iteration 1513][Wall Clock 75.443127841s] Trained 120 records in 0.042844447 seconds. Throughput is 2800.8296 records/second. Loss is 0.48608378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007678132678132678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1680/60000][Iteration 1514][Wall Clock 75.487554438s] Trained 120 records in 0.044426597 seconds. Throughput is 2701.0847 records/second. Loss is 0.57158744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076769537847382165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1800/60000][Iteration 1515][Wall Clock 75.532113222s] Trained 120 records in 0.044558784 seconds. Throughput is 2693.0715 records/second. Loss is 0.42361456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007675775253300584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:21 INFO  DistriOptimizer$:406 - [Epoch 4 1920/60000][Iteration 1516][Wall Clock 75.576611517s] Trained 120 records in 0.044498295 seconds. Throughput is 2696.7327 records/second. Loss is 0.4361606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007674597083653109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2040/60000][Iteration 1517][Wall Clock 75.620716413s] Trained 120 records in 0.044104896 seconds. Throughput is 2720.7864 records/second. Loss is 0.43498212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007673419275629221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2160/60000][Iteration 1518][Wall Clock 75.670694652s] Trained 120 records in 0.049978239 seconds. Throughput is 2401.0452 records/second. Loss is 0.34545645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007672241829062453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2280/60000][Iteration 1519][Wall Clock 75.723553722s] Trained 120 records in 0.05285907 seconds. Throughput is 2270.1875 records/second. Loss is 0.45309904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007671064743786437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2400/60000][Iteration 1520][Wall Clock 75.768565312s] Trained 120 records in 0.04501159 seconds. Throughput is 2665.98 records/second. Loss is 0.47131842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007669888019634913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2520/60000][Iteration 1521][Wall Clock 75.813199431s] Trained 120 records in 0.044634119 seconds. Throughput is 2688.5264 records/second. Loss is 0.39610645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007668711656441718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2640/60000][Iteration 1522][Wall Clock 75.856435977s] Trained 120 records in 0.043236546 seconds. Throughput is 2775.43 records/second. Loss is 0.46951827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007667535654040792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2760/60000][Iteration 1523][Wall Clock 75.900961584s] Trained 120 records in 0.044525607 seconds. Throughput is 2695.0784 records/second. Loss is 0.43289712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076663600122661765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 2880/60000][Iteration 1524][Wall Clock 75.945387367s] Trained 120 records in 0.044425783 seconds. Throughput is 2701.1343 records/second. Loss is 0.47481707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007665184730952016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3000/60000][Iteration 1525][Wall Clock 75.989486765s] Trained 120 records in 0.044099398 seconds. Throughput is 2721.1255 records/second. Loss is 0.5293779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007664009809932557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3120/60000][Iteration 1526][Wall Clock 76.033133063s] Trained 120 records in 0.043646298 seconds. Throughput is 2749.374 records/second. Loss is 0.33822376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007662835249042146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3240/60000][Iteration 1527][Wall Clock 76.076696119s] Trained 120 records in 0.043563056 seconds. Throughput is 2754.6277 records/second. Loss is 0.44806764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007661661048115231. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3360/60000][Iteration 1528][Wall Clock 76.120315263s] Trained 120 records in 0.043619144 seconds. Throughput is 2751.0857 records/second. Loss is 0.40921694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076604872069863635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3480/60000][Iteration 1529][Wall Clock 76.163307677s] Trained 120 records in 0.042992414 seconds. Throughput is 2791.1902 records/second. Loss is 0.3768016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007659313725490196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3600/60000][Iteration 1530][Wall Clock 76.211763749s] Trained 120 records in 0.048456072 seconds. Throughput is 2476.4697 records/second. Loss is 0.54662913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076581406034614795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3720/60000][Iteration 1531][Wall Clock 76.259105824s] Trained 120 records in 0.047342075 seconds. Throughput is 2534.7432 records/second. Loss is 0.48234743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007656967840735069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3840/60000][Iteration 1532][Wall Clock 76.302008279s] Trained 120 records in 0.042902455 seconds. Throughput is 2797.0427 records/second. Loss is 0.3387393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007655795437145919. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 3960/60000][Iteration 1533][Wall Clock 76.345478727s] Trained 120 records in 0.043470448 seconds. Throughput is 2760.4958 records/second. Loss is 0.451865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076546233925290875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 4080/60000][Iteration 1534][Wall Clock 76.388825304s] Trained 120 records in 0.043346577 seconds. Throughput is 2768.3848 records/second. Loss is 0.38167885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007653451706719731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 4200/60000][Iteration 1535][Wall Clock 76.432472035s] Trained 120 records in 0.043646731 seconds. Throughput is 2749.347 records/second. Loss is 0.39344093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007652280379553107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 4320/60000][Iteration 1536][Wall Clock 76.476639875s] Trained 120 records in 0.04416784 seconds. Throughput is 2716.909 records/second. Loss is 0.55179006. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076511094108645756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 4440/60000][Iteration 1537][Wall Clock 76.5201023s] Trained 120 records in 0.043462425 seconds. Throughput is 2761.0056 records/second. Loss is 0.41638413. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007649938800489597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:22 INFO  DistriOptimizer$:406 - [Epoch 4 4560/60000][Iteration 1538][Wall Clock 76.56305501s] Trained 120 records in 0.04295271 seconds. Throughput is 2793.7703 records/second. Loss is 0.49761. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007648768548263731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 4680/60000][Iteration 1539][Wall Clock 76.605958017s] Trained 120 records in 0.042903007 seconds. Throughput is 2797.0068 records/second. Loss is 0.45599923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007647598654022637. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 4800/60000][Iteration 1540][Wall Clock 76.649870016s] Trained 120 records in 0.043911999 seconds. Throughput is 2732.7383 records/second. Loss is 0.41847727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00764642911760208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 4920/60000][Iteration 1541][Wall Clock 76.696175709s] Trained 120 records in 0.046305693 seconds. Throughput is 2591.4739 records/second. Loss is 0.3636096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00764525993883792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5040/60000][Iteration 1542][Wall Clock 76.738710133s] Trained 120 records in 0.042534424 seconds. Throughput is 2821.2441 records/second. Loss is 0.35532522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007644091117566121. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5160/60000][Iteration 1543][Wall Clock 76.783433539s] Trained 120 records in 0.044723406 seconds. Throughput is 2683.1587 records/second. Loss is 0.36235306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007642922653622745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5280/60000][Iteration 1544][Wall Clock 76.839481507s] Trained 120 records in 0.056047968 seconds. Throughput is 2141.0232 records/second. Loss is 0.46948445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007641754546843955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5400/60000][Iteration 1545][Wall Clock 76.884762789s] Trained 120 records in 0.045281282 seconds. Throughput is 2650.1016 records/second. Loss is 0.45917872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007640586797066015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5520/60000][Iteration 1546][Wall Clock 76.927309141s] Trained 120 records in 0.042546352 seconds. Throughput is 2820.4534 records/second. Loss is 0.3943494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007639419404125287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5640/60000][Iteration 1547][Wall Clock 76.969780009s] Trained 120 records in 0.042470868 seconds. Throughput is 2825.466 records/second. Loss is 0.47621793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007638252367858233. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5760/60000][Iteration 1548][Wall Clock 77.012740914s] Trained 120 records in 0.042960905 seconds. Throughput is 2793.2373 records/second. Loss is 0.37096593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00763708568810142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 5880/60000][Iteration 1549][Wall Clock 77.056643302s] Trained 120 records in 0.043902388 seconds. Throughput is 2733.3364 records/second. Loss is 0.42607135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076359193646915085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6000/60000][Iteration 1550][Wall Clock 77.099895923s] Trained 120 records in 0.043252621 seconds. Throughput is 2774.3984 records/second. Loss is 0.45297638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007634753397465261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6120/60000][Iteration 1551][Wall Clock 77.142788126s] Trained 120 records in 0.042892203 seconds. Throughput is 2797.7112 records/second. Loss is 0.36746892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007633587786259542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6240/60000][Iteration 1552][Wall Clock 77.185238832s] Trained 120 records in 0.042450706 seconds. Throughput is 2826.808 records/second. Loss is 0.45346504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007632422530911311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6360/60000][Iteration 1553][Wall Clock 77.227124017s] Trained 120 records in 0.041885185 seconds. Throughput is 2864.9749 records/second. Loss is 0.46398562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007631257631257631. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6480/60000][Iteration 1554][Wall Clock 77.269565035s] Trained 120 records in 0.042441018 seconds. Throughput is 2827.4534 records/second. Loss is 0.4207427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007630093087135663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6600/60000][Iteration 1555][Wall Clock 77.31179382s] Trained 120 records in 0.042228785 seconds. Throughput is 2841.6636 records/second. Loss is 0.35452706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007628928898382668. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6720/60000][Iteration 1556][Wall Clock 77.354024327s] Trained 120 records in 0.042230507 seconds. Throughput is 2841.5479 records/second. Loss is 0.4406147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007627765064836004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6840/60000][Iteration 1557][Wall Clock 77.403390323s] Trained 120 records in 0.049365996 seconds. Throughput is 2430.823 records/second. Loss is 0.38155395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007626601586333131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 6960/60000][Iteration 1558][Wall Clock 77.459141774s] Trained 120 records in 0.055751451 seconds. Throughput is 2152.4104 records/second. Loss is 0.45038635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007625438462711607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 7080/60000][Iteration 1559][Wall Clock 77.502371789s] Trained 120 records in 0.043230015 seconds. Throughput is 2775.849 records/second. Loss is 0.498372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007624275693809089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:23 INFO  DistriOptimizer$:406 - [Epoch 4 7200/60000][Iteration 1560][Wall Clock 77.54535497s] Trained 120 records in 0.042983181 seconds. Throughput is 2791.7896 records/second. Loss is 0.3672628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007623113279463333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 7320/60000][Iteration 1561][Wall Clock 77.588221022s] Trained 120 records in 0.042866052 seconds. Throughput is 2799.4182 records/second. Loss is 0.41191468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007621951219512195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 7440/60000][Iteration 1562][Wall Clock 77.630809878s] Trained 120 records in 0.042588856 seconds. Throughput is 2817.6384 records/second. Loss is 0.42900732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007620789513793629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 7560/60000][Iteration 1563][Wall Clock 77.673352178s] Trained 120 records in 0.0425423 seconds. Throughput is 2820.722 records/second. Loss is 0.4132594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007619628162145687. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 7680/60000][Iteration 1564][Wall Clock 77.715597381s] Trained 120 records in 0.042245203 seconds. Throughput is 2840.5593 records/second. Loss is 0.42489967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007618467164406522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 7800/60000][Iteration 1565][Wall Clock 77.759571353s] Trained 120 records in 0.043973972 seconds. Throughput is 2728.887 records/second. Loss is 0.38484606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007617306520414382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 7920/60000][Iteration 1566][Wall Clock 77.801925325s] Trained 120 records in 0.042353972 seconds. Throughput is 2833.2644 records/second. Loss is 0.32558167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007616146230007617. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8040/60000][Iteration 1567][Wall Clock 77.843338468s] Trained 120 records in 0.041413143 seconds. Throughput is 2897.6309 records/second. Loss is 0.42585438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007614986293024672. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8160/60000][Iteration 1568][Wall Clock 77.886428222s] Trained 120 records in 0.043089754 seconds. Throughput is 2784.8848 records/second. Loss is 0.3453169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007613826709304096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8280/60000][Iteration 1569][Wall Clock 77.935771029s] Trained 120 records in 0.049342807 seconds. Throughput is 2431.9653 records/second. Loss is 0.3482911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00761266747868453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8400/60000][Iteration 1570][Wall Clock 77.982586542s] Trained 120 records in 0.046815513 seconds. Throughput is 2563.253 records/second. Loss is 0.5104458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076115086010047186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8520/60000][Iteration 1571][Wall Clock 78.02632002s] Trained 120 records in 0.043733478 seconds. Throughput is 2743.8933 records/second. Loss is 0.35502377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076103500761035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8640/60000][Iteration 1572][Wall Clock 78.069740214s] Trained 120 records in 0.043420194 seconds. Throughput is 2763.691 records/second. Loss is 0.38409585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076091919038198145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8760/60000][Iteration 1573][Wall Clock 78.113415265s] Trained 120 records in 0.043675051 seconds. Throughput is 2747.5642 records/second. Loss is 0.47213945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007608034083992696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 8880/60000][Iteration 1574][Wall Clock 78.157073067s] Trained 120 records in 0.043657802 seconds. Throughput is 2748.6497 records/second. Loss is 0.4033427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007606876616461282. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9000/60000][Iteration 1575][Wall Clock 78.200953993s] Trained 120 records in 0.043880926 seconds. Throughput is 2734.6736 records/second. Loss is 0.39457834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007605719501064801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9120/60000][Iteration 1576][Wall Clock 78.243330242s] Trained 120 records in 0.042376249 seconds. Throughput is 2831.775 records/second. Loss is 0.36807668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007604562737642586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9240/60000][Iteration 1577][Wall Clock 78.285598746s] Trained 120 records in 0.042268504 seconds. Throughput is 2838.9934 records/second. Loss is 0.48057765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0076034063260340635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9360/60000][Iteration 1578][Wall Clock 78.327806759s] Trained 120 records in 0.042208013 seconds. Throughput is 2843.062 records/second. Loss is 0.3267282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00760225026607876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9480/60000][Iteration 1579][Wall Clock 78.369386073s] Trained 120 records in 0.041579314 seconds. Throughput is 2886.0505 records/second. Loss is 0.49573267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007601094557616298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9600/60000][Iteration 1580][Wall Clock 78.4112074s] Trained 120 records in 0.041821327 seconds. Throughput is 2869.3494 records/second. Loss is 0.5681663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007599939200486396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9720/60000][Iteration 1581][Wall Clock 78.453775315s] Trained 120 records in 0.042567915 seconds. Throughput is 2819.0244 records/second. Loss is 0.4292827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007598784194528876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9840/60000][Iteration 1582][Wall Clock 78.496835373s] Trained 120 records in 0.043060058 seconds. Throughput is 2786.8054 records/second. Loss is 0.37261313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00759762953958365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:24 INFO  DistriOptimizer$:406 - [Epoch 4 9960/60000][Iteration 1583][Wall Clock 78.539007288s] Trained 120 records in 0.042171915 seconds. Throughput is 2845.4956 records/second. Loss is 0.3909233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007596475235490732. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10080/60000][Iteration 1584][Wall Clock 78.589596843s] Trained 120 records in 0.050589555 seconds. Throughput is 2372.0312 records/second. Loss is 0.43950087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007595321282090233. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10200/60000][Iteration 1585][Wall Clock 78.64028502s] Trained 120 records in 0.050688177 seconds. Throughput is 2367.416 records/second. Loss is 0.38351133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007594167679222358. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10320/60000][Iteration 1586][Wall Clock 78.683535306s] Trained 120 records in 0.043250286 seconds. Throughput is 2774.548 records/second. Loss is 0.49480486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007593014426727412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10440/60000][Iteration 1587][Wall Clock 78.729136184s] Trained 120 records in 0.045600878 seconds. Throughput is 2631.5283 records/second. Loss is 0.39546144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007591861524445793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10560/60000][Iteration 1588][Wall Clock 78.771240728s] Trained 120 records in 0.042104544 seconds. Throughput is 2850.0488 records/second. Loss is 0.4113641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007590708972218005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10680/60000][Iteration 1589][Wall Clock 78.813770051s] Trained 120 records in 0.042529323 seconds. Throughput is 2821.5828 records/second. Loss is 0.5101536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007589556769884639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10800/60000][Iteration 1590][Wall Clock 78.855329363s] Trained 120 records in 0.041559312 seconds. Throughput is 2887.4395 records/second. Loss is 0.46472552. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007588404917286386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 10920/60000][Iteration 1591][Wall Clock 78.896587963s] Trained 120 records in 0.0412586 seconds. Throughput is 2908.4846 records/second. Loss is 0.50663686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007587253414264036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11040/60000][Iteration 1592][Wall Clock 78.939152659s] Trained 120 records in 0.042564696 seconds. Throughput is 2819.2378 records/second. Loss is 0.48470592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007586102260658474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11160/60000][Iteration 1593][Wall Clock 78.983088169s] Trained 120 records in 0.04393551 seconds. Throughput is 2731.276 records/second. Loss is 0.52457243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00758495145631068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11280/60000][Iteration 1594][Wall Clock 79.036483592s] Trained 120 records in 0.053395423 seconds. Throughput is 2247.3835 records/second. Loss is 0.50461537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075838010010617326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11400/60000][Iteration 1595][Wall Clock 79.081495032s] Trained 120 records in 0.04501144 seconds. Throughput is 2665.989 records/second. Loss is 0.3723944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075826508947528055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11520/60000][Iteration 1596][Wall Clock 79.124953601s] Trained 120 records in 0.043458569 seconds. Throughput is 2761.2505 records/second. Loss is 0.3985833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007581501137225171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11640/60000][Iteration 1597][Wall Clock 79.16768152s] Trained 120 records in 0.042727919 seconds. Throughput is 2808.4683 records/second. Loss is 0.42630538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007580351728320195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11760/60000][Iteration 1598][Wall Clock 79.209926751s] Trained 120 records in 0.042245231 seconds. Throughput is 2840.5574 records/second. Loss is 0.42228162. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00757920266787934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 11880/60000][Iteration 1599][Wall Clock 79.252042825s] Trained 120 records in 0.042116074 seconds. Throughput is 2849.2683 records/second. Loss is 0.39452487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007578053955744166. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 12000/60000][Iteration 1600][Wall Clock 79.295008931s] Trained 120 records in 0.042966106 seconds. Throughput is 2792.8992 records/second. Loss is 0.5041376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007576905591756326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 12120/60000][Iteration 1601][Wall Clock 79.33696266s] Trained 120 records in 0.041953729 seconds. Throughput is 2860.2942 records/second. Loss is 0.3201543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007575757575757576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 12240/60000][Iteration 1602][Wall Clock 79.378138351s] Trained 120 records in 0.041175691 seconds. Throughput is 2914.341 records/second. Loss is 0.49942568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007574609907589759. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 12360/60000][Iteration 1603][Wall Clock 79.419865346s] Trained 120 records in 0.041726995 seconds. Throughput is 2875.8362 records/second. Loss is 0.43416175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00757346258709482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 12480/60000][Iteration 1604][Wall Clock 79.462468065s] Trained 120 records in 0.042602719 seconds. Throughput is 2816.7217 records/second. Loss is 0.386164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007572315614114797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 12600/60000][Iteration 1605][Wall Clock 79.504692356s] Trained 120 records in 0.042224291 seconds. Throughput is 2841.966 records/second. Loss is 0.38812965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007571168988491824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:25 INFO  DistriOptimizer$:406 - [Epoch 4 12720/60000][Iteration 1606][Wall Clock 79.546112798s] Trained 120 records in 0.041420442 seconds. Throughput is 2897.1204 records/second. Loss is 0.4061045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007570022710068131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 12840/60000][Iteration 1607][Wall Clock 79.587754346s] Trained 120 records in 0.041641548 seconds. Throughput is 2881.7373 records/second. Loss is 0.38506106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007568876778686042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 12960/60000][Iteration 1608][Wall Clock 79.629406897s] Trained 120 records in 0.041652551 seconds. Throughput is 2880.9758 records/second. Loss is 0.50181425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007567731194187982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13080/60000][Iteration 1609][Wall Clock 79.670442213s] Trained 120 records in 0.041035316 seconds. Throughput is 2924.3103 records/second. Loss is 0.44607747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007566585956416464. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13200/60000][Iteration 1610][Wall Clock 79.711907896s] Trained 120 records in 0.041465683 seconds. Throughput is 2893.9592 records/second. Loss is 0.3729852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075654410652141015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13320/60000][Iteration 1611][Wall Clock 79.766884749s] Trained 120 records in 0.054976853 seconds. Throughput is 2182.7368 records/second. Loss is 0.42047966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007564296520423601. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13440/60000][Iteration 1612][Wall Clock 79.812482892s] Trained 120 records in 0.045598143 seconds. Throughput is 2631.6863 records/second. Loss is 0.36877233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007563152321887763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13560/60000][Iteration 1613][Wall Clock 79.854920357s] Trained 120 records in 0.042437465 seconds. Throughput is 2827.6902 records/second. Loss is 0.42783174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007562008469449486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13680/60000][Iteration 1614][Wall Clock 79.896924675s] Trained 120 records in 0.042004318 seconds. Throughput is 2856.849 records/second. Loss is 0.33196166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007560864962951762. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13800/60000][Iteration 1615][Wall Clock 79.939402555s] Trained 120 records in 0.04247788 seconds. Throughput is 2824.9998 records/second. Loss is 0.4281647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007559721802237678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 13920/60000][Iteration 1616][Wall Clock 79.982080238s] Trained 120 records in 0.042677683 seconds. Throughput is 2811.7742 records/second. Loss is 0.3451137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007558578987150416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14040/60000][Iteration 1617][Wall Clock 80.024042372s] Trained 120 records in 0.041962134 seconds. Throughput is 2859.721 records/second. Loss is 0.4362199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007557436517533253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14160/60000][Iteration 1618][Wall Clock 80.066870241s] Trained 120 records in 0.042827869 seconds. Throughput is 2801.9138 records/second. Loss is 0.36798763. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007556294393229561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14280/60000][Iteration 1619][Wall Clock 80.110078546s] Trained 120 records in 0.043208305 seconds. Throughput is 2777.244 records/second. Loss is 0.53205156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007555152614082805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14400/60000][Iteration 1620][Wall Clock 80.164471648s] Trained 120 records in 0.054393102 seconds. Throughput is 2206.162 records/second. Loss is 0.45998946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007554011179936546. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14520/60000][Iteration 1621][Wall Clock 80.20700735s] Trained 120 records in 0.042535702 seconds. Throughput is 2821.1594 records/second. Loss is 0.32978362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007552870090634441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14640/60000][Iteration 1622][Wall Clock 80.249663974s] Trained 120 records in 0.042656624 seconds. Throughput is 2813.162 records/second. Loss is 0.4518872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007551729346020239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14760/60000][Iteration 1623][Wall Clock 80.291561918s] Trained 120 records in 0.041897944 seconds. Throughput is 2864.1023 records/second. Loss is 0.60820305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007550588945937783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 14880/60000][Iteration 1624][Wall Clock 80.333852838s] Trained 120 records in 0.04229092 seconds. Throughput is 2837.4885 records/second. Loss is 0.41568547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007549448890231013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 15000/60000][Iteration 1625][Wall Clock 80.375810182s] Trained 120 records in 0.041957344 seconds. Throughput is 2860.0476 records/second. Loss is 0.42433625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007548309178743962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 15120/60000][Iteration 1626][Wall Clock 80.417756441s] Trained 120 records in 0.041946259 seconds. Throughput is 2860.8035 records/second. Loss is 0.38066542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007547169811320755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 15240/60000][Iteration 1627][Wall Clock 80.461163045s] Trained 120 records in 0.043406604 seconds. Throughput is 2764.5562 records/second. Loss is 0.45121923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007546030787805615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 15360/60000][Iteration 1628][Wall Clock 80.504056555s] Trained 120 records in 0.04289351 seconds. Throughput is 2797.626 records/second. Loss is 0.43946064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007544892108042854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:26 INFO  DistriOptimizer$:406 - [Epoch 4 15480/60000][Iteration 1629][Wall Clock 80.546250201s] Trained 120 records in 0.042193646 seconds. Throughput is 2844.03 records/second. Loss is 0.5470828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007543753771876886. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 15600/60000][Iteration 1630][Wall Clock 80.588898577s] Trained 120 records in 0.042648376 seconds. Throughput is 2813.7063 records/second. Loss is 0.37665918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00754261577915221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 15720/60000][Iteration 1631][Wall Clock 80.631374134s] Trained 120 records in 0.042475557 seconds. Throughput is 2825.154 records/second. Loss is 0.39232785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007541478129713424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 15840/60000][Iteration 1632][Wall Clock 80.677384802s] Trained 120 records in 0.046010668 seconds. Throughput is 2608.0908 records/second. Loss is 0.39186397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007540340823405218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 15960/60000][Iteration 1633][Wall Clock 80.718860128s] Trained 120 records in 0.041475326 seconds. Throughput is 2893.2864 records/second. Loss is 0.38006836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075392038600723766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16080/60000][Iteration 1634][Wall Clock 80.760561901s] Trained 120 records in 0.041701773 seconds. Throughput is 2877.5757 records/second. Loss is 0.39435926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007538067239559777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16200/60000][Iteration 1635][Wall Clock 80.802151377s] Trained 120 records in 0.041589476 seconds. Throughput is 2885.3452 records/second. Loss is 0.3889735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007536930961712391. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16320/60000][Iteration 1636][Wall Clock 80.844754746s] Trained 120 records in 0.042603369 seconds. Throughput is 2816.6787 records/second. Loss is 0.36283794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007535795026375283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16440/60000][Iteration 1637][Wall Clock 80.894620556s] Trained 120 records in 0.04986581 seconds. Throughput is 2406.4585 records/second. Loss is 0.42131367. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007534659433393611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16560/60000][Iteration 1638][Wall Clock 80.954052266s] Trained 120 records in 0.05943171 seconds. Throughput is 2019.1241 records/second. Loss is 0.47110274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007533524182612627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16680/60000][Iteration 1639][Wall Clock 81.001126822s] Trained 120 records in 0.047074556 seconds. Throughput is 2549.1477 records/second. Loss is 0.2939679. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075323892738776745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16800/60000][Iteration 1640][Wall Clock 81.043669296s] Trained 120 records in 0.042542474 seconds. Throughput is 2820.7104 records/second. Loss is 0.39509296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007531254707034192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 16920/60000][Iteration 1641][Wall Clock 81.086036166s] Trained 120 records in 0.04236687 seconds. Throughput is 2832.4019 records/second. Loss is 0.4060186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007530120481927711. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17040/60000][Iteration 1642][Wall Clock 81.128510621s] Trained 120 records in 0.042474455 seconds. Throughput is 2825.2275 records/second. Loss is 0.5157007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007528986598403855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17160/60000][Iteration 1643][Wall Clock 81.17291565s] Trained 120 records in 0.044405029 seconds. Throughput is 2702.3967 records/second. Loss is 0.41095352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007527853056308341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17280/60000][Iteration 1644][Wall Clock 81.219210995s] Trained 120 records in 0.046295345 seconds. Throughput is 2592.0532 records/second. Loss is 0.4811503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007526719855486979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17400/60000][Iteration 1645][Wall Clock 81.263190109s] Trained 120 records in 0.043979114 seconds. Throughput is 2728.5679 records/second. Loss is 0.3017921. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007525586995785672. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17520/60000][Iteration 1646][Wall Clock 81.314362074s] Trained 120 records in 0.051171965 seconds. Throughput is 2345.034 records/second. Loss is 0.39702612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007524454477050415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17640/60000][Iteration 1647][Wall Clock 81.356496645s] Trained 120 records in 0.042134571 seconds. Throughput is 2848.0176 records/second. Loss is 0.42712066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007523322299127295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17760/60000][Iteration 1648][Wall Clock 81.398775044s] Trained 120 records in 0.042278399 seconds. Throughput is 2838.3289 records/second. Loss is 0.41732684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007522190461862493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 17880/60000][Iteration 1649][Wall Clock 81.441501923s] Trained 120 records in 0.042726879 seconds. Throughput is 2808.5366 records/second. Loss is 0.50058395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007521058965102286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 18000/60000][Iteration 1650][Wall Clock 81.48510944s] Trained 120 records in 0.043607517 seconds. Throughput is 2751.819 records/second. Loss is 0.4541032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007519927808693036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:27 INFO  DistriOptimizer$:406 - [Epoch 4 18120/60000][Iteration 1651][Wall Clock 81.527564116s] Trained 120 records in 0.042454676 seconds. Throughput is 2826.544 records/second. Loss is 0.36896512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007518796992481203. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 18240/60000][Iteration 1652][Wall Clock 81.570588363s] Trained 120 records in 0.043024247 seconds. Throughput is 2789.125 records/second. Loss is 0.39181885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007517666516313336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 18360/60000][Iteration 1653][Wall Clock 81.613846066s] Trained 120 records in 0.043257703 seconds. Throughput is 2774.0725 records/second. Loss is 0.3491658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00751653638003608. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 18480/60000][Iteration 1654][Wall Clock 81.655702084s] Trained 120 records in 0.041856018 seconds. Throughput is 2866.9714 records/second. Loss is 0.3751772. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007515406583496168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 18600/60000][Iteration 1655][Wall Clock 81.698089582s] Trained 120 records in 0.042387498 seconds. Throughput is 2831.0234 records/second. Loss is 0.38870746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007514277126540427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 18720/60000][Iteration 1656][Wall Clock 81.740764148s] Trained 120 records in 0.042674566 seconds. Throughput is 2811.9792 records/second. Loss is 0.38483584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007513148009015778. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 18840/60000][Iteration 1657][Wall Clock 81.783908421s] Trained 120 records in 0.043144273 seconds. Throughput is 2781.3655 records/second. Loss is 0.4943544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007512019230769231. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 18960/60000][Iteration 1658][Wall Clock 81.825842644s] Trained 120 records in 0.041934223 seconds. Throughput is 2861.6245 records/second. Loss is 0.37145475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00751089079164789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19080/60000][Iteration 1659][Wall Clock 81.868007314s] Trained 120 records in 0.04216467 seconds. Throughput is 2845.9846 records/second. Loss is 0.5565154. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00750976269149895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19200/60000][Iteration 1660][Wall Clock 81.909670571s] Trained 120 records in 0.041663257 seconds. Throughput is 2880.2358 records/second. Loss is 0.43037978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007508634930169695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19320/60000][Iteration 1661][Wall Clock 81.952445138s] Trained 120 records in 0.042774567 seconds. Throughput is 2805.4055 records/second. Loss is 0.3580228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075075075075075074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19440/60000][Iteration 1662][Wall Clock 81.995648938s] Trained 120 records in 0.0432038 seconds. Throughput is 2777.5334 records/second. Loss is 0.41024482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007506380423359856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19560/60000][Iteration 1663][Wall Clock 82.039502476s] Trained 120 records in 0.043853538 seconds. Throughput is 2736.3813 records/second. Loss is 0.30477828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007505253677574302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19680/60000][Iteration 1664][Wall Clock 82.092777825s] Trained 120 records in 0.053275349 seconds. Throughput is 2252.4487 records/second. Loss is 0.36018655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075041272699984994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19800/60000][Iteration 1665][Wall Clock 82.152438992s] Trained 120 records in 0.059661167 seconds. Throughput is 2011.3585 records/second. Loss is 0.36372793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007503001200480192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 19920/60000][Iteration 1666][Wall Clock 82.199100707s] Trained 120 records in 0.046661715 seconds. Throughput is 2571.7014 records/second. Loss is 0.44526407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075018754688672175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 20040/60000][Iteration 1667][Wall Clock 82.243064593s] Trained 120 records in 0.043963886 seconds. Throughput is 2729.513 records/second. Loss is 0.43332294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0075007500750075016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 20160/60000][Iteration 1668][Wall Clock 82.286833032s] Trained 120 records in 0.043768439 seconds. Throughput is 2741.7017 records/second. Loss is 0.47230878. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074996250187490615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 20280/60000][Iteration 1669][Wall Clock 82.333136558s] Trained 120 records in 0.046303526 seconds. Throughput is 2591.5952 records/second. Loss is 0.5277273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007498500299940011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 20400/60000][Iteration 1670][Wall Clock 82.375258999s] Trained 120 records in 0.042122441 seconds. Throughput is 2848.8376 records/second. Loss is 0.46531117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00749737591842855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 20520/60000][Iteration 1671][Wall Clock 82.417810544s] Trained 120 records in 0.042551545 seconds. Throughput is 2820.1091 records/second. Loss is 0.4253125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074962518740629685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 20640/60000][Iteration 1672][Wall Clock 82.467452976s] Trained 120 records in 0.049642432 seconds. Throughput is 2417.2869 records/second. Loss is 0.46071872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00749512816669165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:28 INFO  DistriOptimizer$:406 - [Epoch 4 20760/60000][Iteration 1673][Wall Clock 82.511819628s] Trained 120 records in 0.044366652 seconds. Throughput is 2704.7344 records/second. Loss is 0.42061707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00749400479616307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 20880/60000][Iteration 1674][Wall Clock 82.553955791s] Trained 120 records in 0.042136163 seconds. Throughput is 2847.91 records/second. Loss is 0.45731354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007492881762325791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21000/60000][Iteration 1675][Wall Clock 82.596182428s] Trained 120 records in 0.042226637 seconds. Throughput is 2841.808 records/second. Loss is 0.34193447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007491759065028469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21120/60000][Iteration 1676][Wall Clock 82.642047516s] Trained 120 records in 0.045865088 seconds. Throughput is 2616.3691 records/second. Loss is 0.557252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00749063670411985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21240/60000][Iteration 1677][Wall Clock 82.684472267s] Trained 120 records in 0.042424751 seconds. Throughput is 2828.5376 records/second. Loss is 0.39496365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074895146794487725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21360/60000][Iteration 1678][Wall Clock 82.726443337s] Trained 120 records in 0.04197107 seconds. Throughput is 2859.1123 records/second. Loss is 0.39615786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074883929908641615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21480/60000][Iteration 1679][Wall Clock 82.768734709s] Trained 120 records in 0.042291372 seconds. Throughput is 2837.458 records/second. Loss is 0.5758079. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007487271638215035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21600/60000][Iteration 1680][Wall Clock 82.810286839s] Trained 120 records in 0.04155213 seconds. Throughput is 2887.9385 records/second. Loss is 0.4425176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007486150621350501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21720/60000][Iteration 1681][Wall Clock 82.851403312s] Trained 120 records in 0.041116473 seconds. Throughput is 2918.5383 records/second. Loss is 0.4667985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074850299401197605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21840/60000][Iteration 1682][Wall Clock 82.893079413s] Trained 120 records in 0.041676101 seconds. Throughput is 2879.3481 records/second. Loss is 0.39821842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074839095943721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 21960/60000][Iteration 1683][Wall Clock 82.935384317s] Trained 120 records in 0.042304904 seconds. Throughput is 2836.5505 records/second. Loss is 0.46098518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074827895839568994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22080/60000][Iteration 1684][Wall Clock 82.978556071s] Trained 120 records in 0.043171754 seconds. Throughput is 2779.5952 records/second. Loss is 0.40749723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007481669908723627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22200/60000][Iteration 1685][Wall Clock 83.020719896s] Trained 120 records in 0.042163825 seconds. Throughput is 2846.0415 records/second. Loss is 0.41265213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007480550568521843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22320/60000][Iteration 1686][Wall Clock 83.063418883s] Trained 120 records in 0.042698987 seconds. Throughput is 2810.371 records/second. Loss is 0.32955372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007479431563201197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22440/60000][Iteration 1687][Wall Clock 83.106498077s] Trained 120 records in 0.043079194 seconds. Throughput is 2785.5674 records/second. Loss is 0.6654476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074783128926114275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22560/60000][Iteration 1688][Wall Clock 83.150157865s] Trained 120 records in 0.043659788 seconds. Throughput is 2748.5247 records/second. Loss is 0.36678216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007477194556602362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22680/60000][Iteration 1689][Wall Clock 83.192352272s] Trained 120 records in 0.042194407 seconds. Throughput is 2843.9788 records/second. Loss is 0.5223339. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074760765550239226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22800/60000][Iteration 1690][Wall Clock 83.234709499s] Trained 120 records in 0.042357227 seconds. Throughput is 2833.0466 records/second. Loss is 0.45589933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007474958887726117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 22920/60000][Iteration 1691][Wall Clock 83.291616432s] Trained 120 records in 0.056906933 seconds. Throughput is 2108.706 records/second. Loss is 0.43766937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007473841554559043. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 23040/60000][Iteration 1692][Wall Clock 83.339552325s] Trained 120 records in 0.047935893 seconds. Throughput is 2503.3435 records/second. Loss is 0.33255723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007472724555372889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 23160/60000][Iteration 1693][Wall Clock 83.382910575s] Trained 120 records in 0.04335825 seconds. Throughput is 2767.6394 records/second. Loss is 0.38641027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007471607890017932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 23280/60000][Iteration 1694][Wall Clock 83.426201592s] Trained 120 records in 0.043291017 seconds. Throughput is 2771.9377 records/second. Loss is 0.4104404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007470491558344539. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 23400/60000][Iteration 1695][Wall Clock 83.469302653s] Trained 120 records in 0.043101061 seconds. Throughput is 2784.1543 records/second. Loss is 0.45450962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007469375560203167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:29 INFO  DistriOptimizer$:406 - [Epoch 4 23520/60000][Iteration 1696][Wall Clock 83.510990368s] Trained 120 records in 0.041687715 seconds. Throughput is 2878.546 records/second. Loss is 0.41340637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074682598954443615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 23640/60000][Iteration 1697][Wall Clock 83.553018848s] Trained 120 records in 0.04202848 seconds. Throughput is 2855.2068 records/second. Loss is 0.36009768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007467144563918758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 23760/60000][Iteration 1698][Wall Clock 83.595703055s] Trained 120 records in 0.042684207 seconds. Throughput is 2811.3442 records/second. Loss is 0.5342389. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00746602956547708. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 23880/60000][Iteration 1699][Wall Clock 83.646364501s] Trained 120 records in 0.050661446 seconds. Throughput is 2368.6653 records/second. Loss is 0.34156337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007464914899970141. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24000/60000][Iteration 1700][Wall Clock 83.691755598s] Trained 120 records in 0.045391097 seconds. Throughput is 2643.6902 records/second. Loss is 0.35882896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007463800567248844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24120/60000][Iteration 1701][Wall Clock 83.734327527s] Trained 120 records in 0.042571929 seconds. Throughput is 2818.7588 records/second. Loss is 0.5626134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007462686567164179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24240/60000][Iteration 1702][Wall Clock 83.776705859s] Trained 120 records in 0.042378332 seconds. Throughput is 2831.6357 records/second. Loss is 0.40415007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074615728995672285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24360/60000][Iteration 1703][Wall Clock 83.818518514s] Trained 120 records in 0.041812655 seconds. Throughput is 2869.9446 records/second. Loss is 0.31805196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007460459564309161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24480/60000][Iteration 1704][Wall Clock 83.860265077s] Trained 120 records in 0.041746563 seconds. Throughput is 2874.488 records/second. Loss is 0.40903372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007459346561241235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24600/60000][Iteration 1705][Wall Clock 83.902438938s] Trained 120 records in 0.042173861 seconds. Throughput is 2845.3643 records/second. Loss is 0.47559616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007458233890214798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24720/60000][Iteration 1706][Wall Clock 83.944761025s] Trained 120 records in 0.042322087 seconds. Throughput is 2835.399 records/second. Loss is 0.46656048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007457121551081283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24840/60000][Iteration 1707][Wall Clock 83.987618693s] Trained 120 records in 0.042857668 seconds. Throughput is 2799.9656 records/second. Loss is 0.5389359. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007456009543692217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 24960/60000][Iteration 1708][Wall Clock 84.031420575s] Trained 120 records in 0.043801882 seconds. Throughput is 2739.6084 records/second. Loss is 0.39253247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007454897867899209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25080/60000][Iteration 1709][Wall Clock 84.07386901s] Trained 120 records in 0.042448435 seconds. Throughput is 2826.9592 records/second. Loss is 0.4248085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074537865235539645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25200/60000][Iteration 1710][Wall Clock 84.116547212s] Trained 120 records in 0.042678202 seconds. Throughput is 2811.7397 records/second. Loss is 0.52520305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007452675510508272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25320/60000][Iteration 1711][Wall Clock 84.159244887s] Trained 120 records in 0.042697675 seconds. Throughput is 2810.4575 records/second. Loss is 0.49164116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007451564828614009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25440/60000][Iteration 1712][Wall Clock 84.201775598s] Trained 120 records in 0.042530711 seconds. Throughput is 2821.4905 records/second. Loss is 0.51887286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007450454477723141. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25560/60000][Iteration 1713][Wall Clock 84.243383442s] Trained 120 records in 0.041607844 seconds. Throughput is 2884.0715 records/second. Loss is 0.5419749. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007449344457687724. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25680/60000][Iteration 1714][Wall Clock 84.285403906s] Trained 120 records in 0.042020464 seconds. Throughput is 2855.7515 records/second. Loss is 0.39416283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007448234768359899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25800/60000][Iteration 1715][Wall Clock 84.32827117s] Trained 120 records in 0.042867264 seconds. Throughput is 2799.3389 records/second. Loss is 0.37718633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074471254095918975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 25920/60000][Iteration 1716][Wall Clock 84.370260758s] Trained 120 records in 0.041989588 seconds. Throughput is 2857.8513 records/second. Loss is 0.33144978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007446016381236039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 26040/60000][Iteration 1717][Wall Clock 84.421917597s] Trained 120 records in 0.051656839 seconds. Throughput is 2323.0225 records/second. Loss is 0.37938982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00744490768314473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 26160/60000][Iteration 1718][Wall Clock 84.474068585s] Trained 120 records in 0.052150988 seconds. Throughput is 2301.011 records/second. Loss is 0.41204888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007443799315170464. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:30 INFO  DistriOptimizer$:406 - [Epoch 4 26280/60000][Iteration 1719][Wall Clock 84.521204498s] Trained 120 records in 0.047135913 seconds. Throughput is 2545.8296 records/second. Loss is 0.3536743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007442691277165824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 26400/60000][Iteration 1720][Wall Clock 84.567941518s] Trained 120 records in 0.04673702 seconds. Throughput is 2567.5579 records/second. Loss is 0.38406006. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007441583568983481. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 26520/60000][Iteration 1721][Wall Clock 84.610021962s] Trained 120 records in 0.042080444 seconds. Throughput is 2851.681 records/second. Loss is 0.41987327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00744047619047619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 26640/60000][Iteration 1722][Wall Clock 84.651415851s] Trained 120 records in 0.041393889 seconds. Throughput is 2898.9788 records/second. Loss is 0.41175583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007439369141496801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 26760/60000][Iteration 1723][Wall Clock 84.692193561s] Trained 120 records in 0.04077771 seconds. Throughput is 2942.7842 records/second. Loss is 0.36594227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007438262421898245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 26880/60000][Iteration 1724][Wall Clock 84.733444628s] Trained 120 records in 0.041251067 seconds. Throughput is 2909.0156 records/second. Loss is 0.49114534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007437156031533542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27000/60000][Iteration 1725][Wall Clock 84.783966775s] Trained 120 records in 0.050522147 seconds. Throughput is 2375.1958 records/second. Loss is 0.3187317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074360499702558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27120/60000][Iteration 1726][Wall Clock 84.827327824s] Trained 120 records in 0.043361049 seconds. Throughput is 2767.4607 records/second. Loss is 0.47066087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007434944237918216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27240/60000][Iteration 1727][Wall Clock 84.868044866s] Trained 120 records in 0.040717042 seconds. Throughput is 2947.169 records/second. Loss is 0.4379194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074338388343740715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27360/60000][Iteration 1728][Wall Clock 84.90998999s] Trained 120 records in 0.041945124 seconds. Throughput is 2860.8809 records/second. Loss is 0.37540922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074327337594767345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27480/60000][Iteration 1729][Wall Clock 84.95182891s] Trained 120 records in 0.04183892 seconds. Throughput is 2868.1428 records/second. Loss is 0.44599044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007431629013079666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27600/60000][Iteration 1730][Wall Clock 84.993651029s] Trained 120 records in 0.041822119 seconds. Throughput is 2869.295 records/second. Loss is 0.512492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007430524595036409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27720/60000][Iteration 1731][Wall Clock 85.036629186s] Trained 120 records in 0.042978157 seconds. Throughput is 2792.116 records/second. Loss is 0.46438405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007429420505200594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27840/60000][Iteration 1732][Wall Clock 85.080014783s] Trained 120 records in 0.043385597 seconds. Throughput is 2765.8948 records/second. Loss is 0.35449424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00742831674342594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 27960/60000][Iteration 1733][Wall Clock 85.122584315s] Trained 120 records in 0.042569532 seconds. Throughput is 2818.9175 records/second. Loss is 0.39248163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074272133095662505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28080/60000][Iteration 1734][Wall Clock 85.164569165s] Trained 120 records in 0.04198485 seconds. Throughput is 2858.1738 records/second. Loss is 0.35962301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007426110203475419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28200/60000][Iteration 1735][Wall Clock 85.206486727s] Trained 120 records in 0.041917562 seconds. Throughput is 2862.762 records/second. Loss is 0.51461816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007425007425007425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28320/60000][Iteration 1736][Wall Clock 85.248258594s] Trained 120 records in 0.041771867 seconds. Throughput is 2872.7468 records/second. Loss is 0.5108066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007423904974016333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28440/60000][Iteration 1737][Wall Clock 85.290073841s] Trained 120 records in 0.041815247 seconds. Throughput is 2869.7666 records/second. Loss is 0.45530477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007422802850356295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28560/60000][Iteration 1738][Wall Clock 85.33169833s] Trained 120 records in 0.041624489 seconds. Throughput is 2882.9182 records/second. Loss is 0.39626998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00742170105388155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28680/60000][Iteration 1739][Wall Clock 85.372921761s] Trained 120 records in 0.041223431 seconds. Throughput is 2910.966 records/second. Loss is 0.40199825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074205995844464235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28800/60000][Iteration 1740][Wall Clock 85.415257769s] Trained 120 records in 0.042336008 seconds. Throughput is 2834.4666 records/second. Loss is 0.42965686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007419498441905328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 28920/60000][Iteration 1741][Wall Clock 85.458608979s] Trained 120 records in 0.04335121 seconds. Throughput is 2768.0889 records/second. Loss is 0.3813421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007418397626112759. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:31 INFO  DistriOptimizer$:406 - [Epoch 4 29040/60000][Iteration 1742][Wall Clock 85.500901248s] Trained 120 records in 0.042292269 seconds. Throughput is 2837.398 records/second. Loss is 0.4195738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007417297136923305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 29160/60000][Iteration 1743][Wall Clock 85.556984846s] Trained 120 records in 0.056083598 seconds. Throughput is 2139.663 records/second. Loss is 0.4004418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007416196974191634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 29280/60000][Iteration 1744][Wall Clock 85.60686907s] Trained 120 records in 0.049884224 seconds. Throughput is 2405.5703 records/second. Loss is 0.40789852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007415097137772505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 29400/60000][Iteration 1745][Wall Clock 85.649849278s] Trained 120 records in 0.042980208 seconds. Throughput is 2791.9827 records/second. Loss is 0.41405255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00741399762752076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 29520/60000][Iteration 1746][Wall Clock 85.692704966s] Trained 120 records in 0.042855688 seconds. Throughput is 2800.095 records/second. Loss is 0.4781029. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074128984432913275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 29640/60000][Iteration 1747][Wall Clock 85.734380028s] Trained 120 records in 0.041675062 seconds. Throughput is 2879.42 records/second. Loss is 0.36678216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007411799584939224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 29760/60000][Iteration 1748][Wall Clock 85.775992697s] Trained 120 records in 0.041612669 seconds. Throughput is 2883.737 records/second. Loss is 0.47526026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0074107010523195484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 29880/60000][Iteration 1749][Wall Clock 85.818291085s] Trained 120 records in 0.042298388 seconds. Throughput is 2836.9875 records/second. Loss is 0.41404074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007409602845287492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30000/60000][Iteration 1750][Wall Clock 85.860914818s] Trained 120 records in 0.042623733 seconds. Throughput is 2815.333 records/second. Loss is 0.3820019. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007408504963698325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30120/60000][Iteration 1751][Wall Clock 85.909737216s] Trained 120 records in 0.048822398 seconds. Throughput is 2457.8882 records/second. Loss is 0.39125937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007407407407407407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30240/60000][Iteration 1752][Wall Clock 85.959237738s] Trained 120 records in 0.049500522 seconds. Throughput is 2424.2168 records/second. Loss is 0.37348536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007406310176270182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30360/60000][Iteration 1753][Wall Clock 86.002069353s] Trained 120 records in 0.042831615 seconds. Throughput is 2801.669 records/second. Loss is 0.40168267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00740521327014218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30480/60000][Iteration 1754][Wall Clock 86.044638228s] Trained 120 records in 0.042568875 seconds. Throughput is 2818.9612 records/second. Loss is 0.43154898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007404116688879017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30600/60000][Iteration 1755][Wall Clock 86.08719737s] Trained 120 records in 0.042559142 seconds. Throughput is 2819.6057 records/second. Loss is 0.50855535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007403020432336393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30720/60000][Iteration 1756][Wall Clock 86.129631622s] Trained 120 records in 0.042434252 seconds. Throughput is 2827.904 records/second. Loss is 0.35631672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007401924500370097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30840/60000][Iteration 1757][Wall Clock 86.171535975s] Trained 120 records in 0.041904353 seconds. Throughput is 2863.6643 records/second. Loss is 0.41913322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007400828892835998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 30960/60000][Iteration 1758][Wall Clock 86.213881615s] Trained 120 records in 0.04234564 seconds. Throughput is 2833.8218 records/second. Loss is 0.36203766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007399733609590055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 31080/60000][Iteration 1759][Wall Clock 86.256710967s] Trained 120 records in 0.042829352 seconds. Throughput is 2801.8167 records/second. Loss is 0.39790636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007398638650488311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 31200/60000][Iteration 1760][Wall Clock 86.299190417s] Trained 120 records in 0.04247945 seconds. Throughput is 2824.8953 records/second. Loss is 0.4184903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007397544015386892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 31320/60000][Iteration 1761][Wall Clock 86.342560342s] Trained 120 records in 0.043369925 seconds. Throughput is 2766.8943 records/second. Loss is 0.4268052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073964497041420114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 31440/60000][Iteration 1762][Wall Clock 86.386241118s] Trained 120 records in 0.043680776 seconds. Throughput is 2747.2039 records/second. Loss is 0.4657027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007395355716609969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 31560/60000][Iteration 1763][Wall Clock 86.433389102s] Trained 120 records in 0.047147984 seconds. Throughput is 2545.1777 records/second. Loss is 0.36585897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007394262052647146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 31680/60000][Iteration 1764][Wall Clock 86.475480537s] Trained 120 records in 0.042091435 seconds. Throughput is 2850.9363 records/second. Loss is 0.34573525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00739316871211001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:32 INFO  DistriOptimizer$:406 - [Epoch 4 31800/60000][Iteration 1765][Wall Clock 86.518281996s] Trained 120 records in 0.042801459 seconds. Throughput is 2803.6428 records/second. Loss is 0.53164685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007392075694855116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 31920/60000][Iteration 1766][Wall Clock 86.560220566s] Trained 120 records in 0.04193857 seconds. Throughput is 2861.328 records/second. Loss is 0.44570857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007390983000739098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32040/60000][Iteration 1767][Wall Clock 86.601995139s] Trained 120 records in 0.041774573 seconds. Throughput is 2872.5605 records/second. Loss is 0.4391475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007389890629618682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32160/60000][Iteration 1768][Wall Clock 86.649729915s] Trained 120 records in 0.047734776 seconds. Throughput is 2513.8906 records/second. Loss is 0.415094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007388798581350673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32280/60000][Iteration 1769][Wall Clock 86.701038337s] Trained 120 records in 0.051308422 seconds. Throughput is 2338.7974 records/second. Loss is 0.5527248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073877068557919616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32400/60000][Iteration 1770][Wall Clock 86.743646651s] Trained 120 records in 0.042608314 seconds. Throughput is 2816.3518 records/second. Loss is 0.3563611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007386615452799527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32520/60000][Iteration 1771][Wall Clock 86.785689462s] Trained 120 records in 0.042042811 seconds. Throughput is 2854.2336 records/second. Loss is 0.36364543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007385524372230428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32640/60000][Iteration 1772][Wall Clock 86.82711885s] Trained 120 records in 0.041429388 seconds. Throughput is 2896.4946 records/second. Loss is 0.49863595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007384433613941811. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32760/60000][Iteration 1773][Wall Clock 86.868522537s] Trained 120 records in 0.041403687 seconds. Throughput is 2898.2925 records/second. Loss is 0.51705486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007383343177790903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 32880/60000][Iteration 1774][Wall Clock 86.91062393s] Trained 120 records in 0.042101393 seconds. Throughput is 2850.262 records/second. Loss is 0.42813116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007382253063635022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33000/60000][Iteration 1775][Wall Clock 86.952597047s] Trained 120 records in 0.041973117 seconds. Throughput is 2858.9727 records/second. Loss is 0.3346928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007381163271331562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33120/60000][Iteration 1776][Wall Clock 86.994521146s] Trained 120 records in 0.041924099 seconds. Throughput is 2862.3154 records/second. Loss is 0.34463125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007380073800738008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33240/60000][Iteration 1777][Wall Clock 87.037775915s] Trained 120 records in 0.043254769 seconds. Throughput is 2774.2605 records/second. Loss is 0.3713686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007378984651711925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33360/60000][Iteration 1778][Wall Clock 87.087985583s] Trained 120 records in 0.050209668 seconds. Throughput is 2389.978 records/second. Loss is 0.31129876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007377895824110964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33480/60000][Iteration 1779][Wall Clock 87.133796593s] Trained 120 records in 0.04581101 seconds. Throughput is 2619.4578 records/second. Loss is 0.3861834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00737680731779286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33600/60000][Iteration 1780][Wall Clock 87.175475423s] Trained 120 records in 0.04167883 seconds. Throughput is 2879.1594 records/second. Loss is 0.41323033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007375719132615431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33720/60000][Iteration 1781][Wall Clock 87.217512549s] Trained 120 records in 0.042037126 seconds. Throughput is 2854.6196 records/second. Loss is 0.42890787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007374631268436578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33840/60000][Iteration 1782][Wall Clock 87.259736575s] Trained 120 records in 0.042224026 seconds. Throughput is 2841.984 records/second. Loss is 0.34019232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073735437251142896. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 33960/60000][Iteration 1783][Wall Clock 87.302659669s] Trained 120 records in 0.042923094 seconds. Throughput is 2795.698 records/second. Loss is 0.36447588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007372456502506635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 34080/60000][Iteration 1784][Wall Clock 87.347662283s] Trained 120 records in 0.045002614 seconds. Throughput is 2666.5117 records/second. Loss is 0.55471414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007371369600471768. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 34200/60000][Iteration 1785][Wall Clock 87.390102212s] Trained 120 records in 0.042439929 seconds. Throughput is 2827.526 records/second. Loss is 0.27911994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007370283018867925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 34320/60000][Iteration 1786][Wall Clock 87.434344028s] Trained 120 records in 0.044241816 seconds. Throughput is 2712.366 records/second. Loss is 0.4142711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007369196757553427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 34440/60000][Iteration 1787][Wall Clock 87.478437032s] Trained 120 records in 0.044093004 seconds. Throughput is 2721.52 records/second. Loss is 0.33961314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073681108163866785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:33 INFO  DistriOptimizer$:406 - [Epoch 4 34560/60000][Iteration 1788][Wall Clock 87.521328119s] Trained 120 records in 0.042891087 seconds. Throughput is 2797.7842 records/second. Loss is 0.39800552. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007367025195226168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 34680/60000][Iteration 1789][Wall Clock 87.570904653s] Trained 120 records in 0.049576534 seconds. Throughput is 2420.5 records/second. Loss is 0.38133425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073659398939304645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 34800/60000][Iteration 1790][Wall Clock 87.61335852s] Trained 120 records in 0.042453867 seconds. Throughput is 2826.5977 records/second. Loss is 0.4273271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007364854912358226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 34920/60000][Iteration 1791][Wall Clock 87.655667222s] Trained 120 records in 0.042308702 seconds. Throughput is 2836.296 records/second. Loss is 0.47586852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007363770250368188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35040/60000][Iteration 1792][Wall Clock 87.702636111s] Trained 120 records in 0.046968889 seconds. Throughput is 2554.8826 records/second. Loss is 0.4606666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007362685907819172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35160/60000][Iteration 1793][Wall Clock 87.759500232s] Trained 120 records in 0.056864121 seconds. Throughput is 2110.2937 records/second. Loss is 0.36054403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007361601884570083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35280/60000][Iteration 1794][Wall Clock 87.811965331s] Trained 120 records in 0.052465099 seconds. Throughput is 2287.2349 records/second. Loss is 0.3386934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007360518180479906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35400/60000][Iteration 1795][Wall Clock 87.856616401s] Trained 120 records in 0.04465107 seconds. Throughput is 2687.5056 records/second. Loss is 0.4073423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073594347954077126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35520/60000][Iteration 1796][Wall Clock 87.899880147s] Trained 120 records in 0.043263746 seconds. Throughput is 2773.685 records/second. Loss is 0.31029597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007358351729212656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35640/60000][Iteration 1797][Wall Clock 87.945422061s] Trained 120 records in 0.045541914 seconds. Throughput is 2634.9355 records/second. Loss is 0.43678534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007357268981753973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35760/60000][Iteration 1798][Wall Clock 87.990780345s] Trained 120 records in 0.045358284 seconds. Throughput is 2645.6025 records/second. Loss is 0.44042483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007356186552890982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 35880/60000][Iteration 1799][Wall Clock 88.039483137s] Trained 120 records in 0.048702792 seconds. Throughput is 2463.9246 records/second. Loss is 0.36735517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073551044424830835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36000/60000][Iteration 1800][Wall Clock 88.082976301s] Trained 120 records in 0.043493164 seconds. Throughput is 2759.0544 records/second. Loss is 0.31921265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007354022650389764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36120/60000][Iteration 1801][Wall Clock 88.132096851s] Trained 120 records in 0.04912055 seconds. Throughput is 2442.9695 records/second. Loss is 0.41357976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007352941176470588. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36240/60000][Iteration 1802][Wall Clock 88.17579978s] Trained 120 records in 0.043702929 seconds. Throughput is 2745.8113 records/second. Loss is 0.43899828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007351860020585208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36360/60000][Iteration 1803][Wall Clock 88.218586971s] Trained 120 records in 0.042787191 seconds. Throughput is 2804.5776 records/second. Loss is 0.29294273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073507791825933545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36480/60000][Iteration 1804][Wall Clock 88.269511047s] Trained 120 records in 0.050924076 seconds. Throughput is 2356.4492 records/second. Loss is 0.53529257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007349698662354844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36600/60000][Iteration 1805][Wall Clock 88.323412898s] Trained 120 records in 0.053901851 seconds. Throughput is 2226.2686 records/second. Loss is 0.35179612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007348618459729571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36720/60000][Iteration 1806][Wall Clock 88.366664556s] Trained 120 records in 0.043251658 seconds. Throughput is 2774.46 records/second. Loss is 0.4770097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073475385745775165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36840/60000][Iteration 1807][Wall Clock 88.410910512s] Trained 120 records in 0.044245956 seconds. Throughput is 2712.1123 records/second. Loss is 0.4087078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073464590067587425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 36960/60000][Iteration 1808][Wall Clock 88.454893084s] Trained 120 records in 0.043982572 seconds. Throughput is 2728.3533 records/second. Loss is 0.35589707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007345379756133393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:34 INFO  DistriOptimizer$:406 - [Epoch 4 37080/60000][Iteration 1809][Wall Clock 88.498590832s] Trained 120 records in 0.043697748 seconds. Throughput is 2746.137 records/second. Loss is 0.425786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007344300822561691. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 37200/60000][Iteration 1810][Wall Clock 88.542154786s] Trained 120 records in 0.043563954 seconds. Throughput is 2754.5708 records/second. Loss is 0.41097033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00734322220590395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 37320/60000][Iteration 1811][Wall Clock 88.584527743s] Trained 120 records in 0.042372957 seconds. Throughput is 2831.9949 records/second. Loss is 0.42539483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007342143906020558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 37440/60000][Iteration 1812][Wall Clock 88.626259212s] Trained 120 records in 0.041731469 seconds. Throughput is 2875.5278 records/second. Loss is 0.3853994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007341065922771986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 37560/60000][Iteration 1813][Wall Clock 88.668911734s] Trained 120 records in 0.042652522 seconds. Throughput is 2813.4329 records/second. Loss is 0.31290677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00733998825601879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 37680/60000][Iteration 1814][Wall Clock 88.710973054s] Trained 120 records in 0.04206132 seconds. Throughput is 2852.9773 records/second. Loss is 0.41486424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007338910905621606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 37800/60000][Iteration 1815][Wall Clock 88.753616647s] Trained 120 records in 0.042643593 seconds. Throughput is 2814.022 records/second. Loss is 0.37029117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00733783387144115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 37920/60000][Iteration 1816][Wall Clock 88.796192684s] Trained 120 records in 0.042576037 seconds. Throughput is 2818.4868 records/second. Loss is 0.43271443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007336757153338225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38040/60000][Iteration 1817][Wall Clock 88.838330026s] Trained 120 records in 0.042137342 seconds. Throughput is 2847.8303 records/second. Loss is 0.29995707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007335680751173709. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38160/60000][Iteration 1818][Wall Clock 88.888064376s] Trained 120 records in 0.04973435 seconds. Throughput is 2412.8193 records/second. Loss is 0.3565126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007334604664808567. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38280/60000][Iteration 1819][Wall Clock 88.938488577s] Trained 120 records in 0.050424201 seconds. Throughput is 2379.8098 records/second. Loss is 0.3848937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007333528894103844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38400/60000][Iteration 1820][Wall Clock 88.983363063s] Trained 120 records in 0.044874486 seconds. Throughput is 2674.1252 records/second. Loss is 0.34587353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007332453438920664. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38520/60000][Iteration 1821][Wall Clock 89.02666752s] Trained 120 records in 0.043304457 seconds. Throughput is 2771.0774 records/second. Loss is 0.35842058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007331378299120235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38640/60000][Iteration 1822][Wall Clock 89.068848755s] Trained 120 records in 0.042181235 seconds. Throughput is 2844.867 records/second. Loss is 0.39320186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007330303474563846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38760/60000][Iteration 1823][Wall Clock 89.11129415s] Trained 120 records in 0.042445395 seconds. Throughput is 2827.1619 records/second. Loss is 0.4236963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00732922896511287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 38880/60000][Iteration 1824][Wall Clock 89.153761207s] Trained 120 records in 0.042467057 seconds. Throughput is 2825.7197 records/second. Loss is 0.35127357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007328154770628756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39000/60000][Iteration 1825][Wall Clock 89.196170775s] Trained 120 records in 0.042409568 seconds. Throughput is 2829.55 records/second. Loss is 0.4018637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007327080890973036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39120/60000][Iteration 1826][Wall Clock 89.238060405s] Trained 120 records in 0.04188963 seconds. Throughput is 2864.671 records/second. Loss is 0.4169537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007326007326007326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39240/60000][Iteration 1827][Wall Clock 89.281216112s] Trained 120 records in 0.043155707 seconds. Throughput is 2780.6287 records/second. Loss is 0.37195444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00732493407559332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39360/60000][Iteration 1828][Wall Clock 89.323936298s] Trained 120 records in 0.042720186 seconds. Throughput is 2808.9763 records/second. Loss is 0.30804306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007323861139592794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39480/60000][Iteration 1829][Wall Clock 89.365524687s] Trained 120 records in 0.041588389 seconds. Throughput is 2885.421 records/second. Loss is 0.3727421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007322788517867603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39600/60000][Iteration 1830][Wall Clock 89.40812873s] Trained 120 records in 0.042604043 seconds. Throughput is 2816.634 records/second. Loss is 0.38130903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007321716210279689. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39720/60000][Iteration 1831][Wall Clock 89.460576797s] Trained 120 records in 0.052448067 seconds. Throughput is 2287.9775 records/second. Loss is 0.4746494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007320644216691068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:35 INFO  DistriOptimizer$:406 - [Epoch 4 39840/60000][Iteration 1832][Wall Clock 89.504571568s] Trained 120 records in 0.043994771 seconds. Throughput is 2727.597 records/second. Loss is 0.37509003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007319572536963841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 39960/60000][Iteration 1833][Wall Clock 89.546456724s] Trained 120 records in 0.041885156 seconds. Throughput is 2864.9768 records/second. Loss is 0.29137918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007318501170960187. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40080/60000][Iteration 1834][Wall Clock 89.588206213s] Trained 120 records in 0.041749489 seconds. Throughput is 2874.2866 records/second. Loss is 0.36202186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073174301185423675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40200/60000][Iteration 1835][Wall Clock 89.629973057s] Trained 120 records in 0.041766844 seconds. Throughput is 2873.0923 records/second. Loss is 0.3426814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073163593795727245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40320/60000][Iteration 1836][Wall Clock 89.672769442s] Trained 120 records in 0.042796385 seconds. Throughput is 2803.975 records/second. Loss is 0.42761773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0073152889539136795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40440/60000][Iteration 1837][Wall Clock 89.714671792s] Trained 120 records in 0.04190235 seconds. Throughput is 2863.8013 records/second. Loss is 0.42024577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007314218841427736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40560/60000][Iteration 1838][Wall Clock 89.756213629s] Trained 120 records in 0.041541837 seconds. Throughput is 2888.654 records/second. Loss is 0.32249185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007313149041977476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40680/60000][Iteration 1839][Wall Clock 89.797744104s] Trained 120 records in 0.041530475 seconds. Throughput is 2889.4443 records/second. Loss is 0.49832883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007312079555425563. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40800/60000][Iteration 1840][Wall Clock 89.838767956s] Trained 120 records in 0.041023852 seconds. Throughput is 2925.1277 records/second. Loss is 0.4941392. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007311010381634743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 40920/60000][Iteration 1841][Wall Clock 89.881127345s] Trained 120 records in 0.042359389 seconds. Throughput is 2832.902 records/second. Loss is 0.3882721. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007309941520467837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41040/60000][Iteration 1842][Wall Clock 89.923980966s] Trained 120 records in 0.042853621 seconds. Throughput is 2800.2302 records/second. Loss is 0.3802188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00730887297178775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41160/60000][Iteration 1843][Wall Clock 89.969199371s] Trained 120 records in 0.045218405 seconds. Throughput is 2653.7866 records/second. Loss is 0.3817146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007307804735457469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41280/60000][Iteration 1844][Wall Clock 90.027420787s] Trained 120 records in 0.058221416 seconds. Throughput is 2061.0972 records/second. Loss is 0.45784107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007306736811340055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41400/60000][Iteration 1845][Wall Clock 90.073628725s] Trained 120 records in 0.046207938 seconds. Throughput is 2596.9563 records/second. Loss is 0.36610255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007305669199298656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41520/60000][Iteration 1846][Wall Clock 90.115923361s] Trained 120 records in 0.042294636 seconds. Throughput is 2837.2393 records/second. Loss is 0.42216852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007304601899196494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41640/60000][Iteration 1847][Wall Clock 90.161222708s] Trained 120 records in 0.045299347 seconds. Throughput is 2649.0447 records/second. Loss is 0.42112684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007303534910896874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41760/60000][Iteration 1848][Wall Clock 90.203627623s] Trained 120 records in 0.042404915 seconds. Throughput is 2829.8606 records/second. Loss is 0.33703366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007302468234263181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 41880/60000][Iteration 1849][Wall Clock 90.245282675s] Trained 120 records in 0.041655052 seconds. Throughput is 2880.803 records/second. Loss is 0.37296122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007301401869158878. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 42000/60000][Iteration 1850][Wall Clock 90.286792944s] Trained 120 records in 0.041510269 seconds. Throughput is 2890.8508 records/second. Loss is 0.36186168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00730033581544751. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 42120/60000][Iteration 1851][Wall Clock 90.328317346s] Trained 120 records in 0.041524402 seconds. Throughput is 2889.867 records/second. Loss is 0.4210314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072992700729927005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 42240/60000][Iteration 1852][Wall Clock 90.370871881s] Trained 120 records in 0.042554535 seconds. Throughput is 2819.911 records/second. Loss is 0.40935054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007298204641658152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 42360/60000][Iteration 1853][Wall Clock 90.413285051s] Trained 120 records in 0.04241317 seconds. Throughput is 2829.3098 records/second. Loss is 0.36270627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072971395213076475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 42480/60000][Iteration 1854][Wall Clock 90.455276024s] Trained 120 records in 0.041990973 seconds. Throughput is 2857.757 records/second. Loss is 0.26269266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072960747118050485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:36 INFO  DistriOptimizer$:406 - [Epoch 4 42600/60000][Iteration 1855][Wall Clock 90.497582767s] Trained 120 records in 0.042306743 seconds. Throughput is 2836.4272 records/second. Loss is 0.3332159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007295010213014298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 42720/60000][Iteration 1856][Wall Clock 90.541109385s] Trained 120 records in 0.043526618 seconds. Throughput is 2756.9336 records/second. Loss is 0.4482375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007293946024799417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 42840/60000][Iteration 1857][Wall Clock 90.591819468s] Trained 120 records in 0.050710083 seconds. Throughput is 2366.3933 records/second. Loss is 0.33367437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007292882147024504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 42960/60000][Iteration 1858][Wall Clock 90.641433866s] Trained 120 records in 0.049614398 seconds. Throughput is 2418.6526 records/second. Loss is 0.34169522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007291818579553741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43080/60000][Iteration 1859][Wall Clock 90.684194769s] Trained 120 records in 0.042760903 seconds. Throughput is 2806.302 records/second. Loss is 0.4486449. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007290755322251386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43200/60000][Iteration 1860][Wall Clock 90.726037039s] Trained 120 records in 0.04184227 seconds. Throughput is 2867.913 records/second. Loss is 0.45446667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007289692374981776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43320/60000][Iteration 1861][Wall Clock 90.76802998s] Trained 120 records in 0.041992941 seconds. Throughput is 2857.6233 records/second. Loss is 0.47965127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00728862973760933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43440/60000][Iteration 1862][Wall Clock 90.809563898s] Trained 120 records in 0.041533918 seconds. Throughput is 2889.205 records/second. Loss is 0.3349866. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007287567409998542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43560/60000][Iteration 1863][Wall Clock 90.85158913s] Trained 120 records in 0.042025232 seconds. Throughput is 2855.4275 records/second. Loss is 0.43294552. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00728650539201399. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43680/60000][Iteration 1864][Wall Clock 90.894005722s] Trained 120 records in 0.042416592 seconds. Throughput is 2829.0815 records/second. Loss is 0.42489126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007285443683520326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43800/60000][Iteration 1865][Wall Clock 90.936852291s] Trained 120 records in 0.042846569 seconds. Throughput is 2800.6912 records/second. Loss is 0.3670421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007284382284382284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 43920/60000][Iteration 1866][Wall Clock 90.979784648s] Trained 120 records in 0.042932357 seconds. Throughput is 2795.0945 records/second. Loss is 0.41016114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007283321194464676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44040/60000][Iteration 1867][Wall Clock 91.023202347s] Trained 120 records in 0.043417699 seconds. Throughput is 2763.8499 records/second. Loss is 0.41696385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007282260413632392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44160/60000][Iteration 1868][Wall Clock 91.067386064s] Trained 120 records in 0.044183717 seconds. Throughput is 2715.9326 records/second. Loss is 0.43406603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007281199941750401. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44280/60000][Iteration 1869][Wall Clock 91.120661723s] Trained 120 records in 0.053275659 seconds. Throughput is 2252.4358 records/second. Loss is 0.36697617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00728013977868375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44400/60000][Iteration 1870][Wall Clock 91.169722367s] Trained 120 records in 0.049060644 seconds. Throughput is 2445.9524 records/second. Loss is 0.41961637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007279079924297568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44520/60000][Iteration 1871][Wall Clock 91.216975361s] Trained 120 records in 0.047252994 seconds. Throughput is 2539.5217 records/second. Loss is 0.3154062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00727802037845706. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44640/60000][Iteration 1872][Wall Clock 91.260857029s] Trained 120 records in 0.043881668 seconds. Throughput is 2734.627 records/second. Loss is 0.36525658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007276961141027507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44760/60000][Iteration 1873][Wall Clock 91.305087622s] Trained 120 records in 0.044230593 seconds. Throughput is 2713.0544 records/second. Loss is 0.36146176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007275902211874272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 44880/60000][Iteration 1874][Wall Clock 91.348117394s] Trained 120 records in 0.043029772 seconds. Throughput is 2788.7668 records/second. Loss is 0.37780845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007274843590862797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 45000/60000][Iteration 1875][Wall Clock 91.390797981s] Trained 120 records in 0.042680587 seconds. Throughput is 2811.5828 records/second. Loss is 0.37866306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007273785277858598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 45120/60000][Iteration 1876][Wall Clock 91.433372555s] Trained 120 records in 0.042574574 seconds. Throughput is 2818.5837 records/second. Loss is 0.38984817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007272727272727273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:37 INFO  DistriOptimizer$:406 - [Epoch 4 45240/60000][Iteration 1877][Wall Clock 91.477324524s] Trained 120 records in 0.043951969 seconds. Throughput is 2730.2532 records/second. Loss is 0.3885688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007271669575334497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 45360/60000][Iteration 1878][Wall Clock 91.52119366s] Trained 120 records in 0.043869136 seconds. Throughput is 2735.4082 records/second. Loss is 0.5198995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007270612185546023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 45480/60000][Iteration 1879][Wall Clock 91.56655401s] Trained 120 records in 0.04536035 seconds. Throughput is 2645.4822 records/second. Loss is 0.42086238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007269555103227683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 45600/60000][Iteration 1880][Wall Clock 91.610184404s] Trained 120 records in 0.043630394 seconds. Throughput is 2750.3762 records/second. Loss is 0.31801185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007268498328245385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 45720/60000][Iteration 1881][Wall Clock 91.652454015s] Trained 120 records in 0.042269611 seconds. Throughput is 2838.919 records/second. Loss is 0.32177705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007267441860465117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 45840/60000][Iteration 1882][Wall Clock 91.695160935s] Trained 120 records in 0.04270692 seconds. Throughput is 2809.8489 records/second. Loss is 0.44805023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007266385699752942. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 45960/60000][Iteration 1883][Wall Clock 91.737159445s] Trained 120 records in 0.04199851 seconds. Throughput is 2857.2444 records/second. Loss is 0.53187346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007265329845975007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46080/60000][Iteration 1884][Wall Clock 91.787029104s] Trained 120 records in 0.049869659 seconds. Throughput is 2406.2727 records/second. Loss is 0.2825266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00726427429899753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46200/60000][Iteration 1885][Wall Clock 91.839814132s] Trained 120 records in 0.052785028 seconds. Throughput is 2273.3718 records/second. Loss is 0.38592774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00726321905868681. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46320/60000][Iteration 1886][Wall Clock 91.882391026s] Trained 120 records in 0.042576894 seconds. Throughput is 2818.4302 records/second. Loss is 0.36571997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007262164124909223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46440/60000][Iteration 1887][Wall Clock 91.928522948s] Trained 120 records in 0.046131922 seconds. Throughput is 2601.2356 records/second. Loss is 0.41453427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007261109497531223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46560/60000][Iteration 1888][Wall Clock 91.971566966s] Trained 120 records in 0.043044018 seconds. Throughput is 2787.8438 records/second. Loss is 0.3952358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072600551764193414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46680/60000][Iteration 1889][Wall Clock 92.014431014s] Trained 120 records in 0.042864048 seconds. Throughput is 2799.549 records/second. Loss is 0.40916595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007259001161440186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46800/60000][Iteration 1890][Wall Clock 92.056635772s] Trained 120 records in 0.042204758 seconds. Throughput is 2843.2815 records/second. Loss is 0.3506508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007257947452460444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 46920/60000][Iteration 1891][Wall Clock 92.099242619s] Trained 120 records in 0.042606847 seconds. Throughput is 2816.4487 records/second. Loss is 0.4376641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007256894049346879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47040/60000][Iteration 1892][Wall Clock 92.141079504s] Trained 120 records in 0.041836885 seconds. Throughput is 2868.2825 records/second. Loss is 0.2806327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072558409519663325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47160/60000][Iteration 1893][Wall Clock 92.183626823s] Trained 120 records in 0.042547319 seconds. Throughput is 2820.3892 records/second. Loss is 0.3756805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007254788160185722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47280/60000][Iteration 1894][Wall Clock 92.234734707s] Trained 120 records in 0.051107884 seconds. Throughput is 2347.9744 records/second. Loss is 0.41610345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007253735673872044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47400/60000][Iteration 1895][Wall Clock 92.285563404s] Trained 120 records in 0.050828697 seconds. Throughput is 2360.871 records/second. Loss is 0.29432788. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00725268349289237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47520/60000][Iteration 1896][Wall Clock 92.327902566s] Trained 120 records in 0.042339162 seconds. Throughput is 2834.2556 records/second. Loss is 0.44279417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007251631617113851. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47640/60000][Iteration 1897][Wall Clock 92.370553793s] Trained 120 records in 0.042651227 seconds. Throughput is 2813.518 records/second. Loss is 0.3215997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007250580046403713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47760/60000][Iteration 1898][Wall Clock 92.413347957s] Trained 120 records in 0.042794164 seconds. Throughput is 2804.1206 records/second. Loss is 0.43041196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00724952878062926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 47880/60000][Iteration 1899][Wall Clock 92.455166468s] Trained 120 records in 0.041818511 seconds. Throughput is 2869.5427 records/second. Loss is 0.39996082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072484778196578725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:38 INFO  DistriOptimizer$:406 - [Epoch 4 48000/60000][Iteration 1900][Wall Clock 92.497142553s] Trained 120 records in 0.041976085 seconds. Throughput is 2858.7705 records/second. Loss is 0.36663714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007247427163357009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48120/60000][Iteration 1901][Wall Clock 92.539305793s] Trained 120 records in 0.04216324 seconds. Throughput is 2846.081 records/second. Loss is 0.4378023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007246376811594204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48240/60000][Iteration 1902][Wall Clock 92.581058102s] Trained 120 records in 0.041752309 seconds. Throughput is 2874.0925 records/second. Loss is 0.40585706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007245326764237067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48360/60000][Iteration 1903][Wall Clock 92.623532631s] Trained 120 records in 0.042474529 seconds. Throughput is 2825.2224 records/second. Loss is 0.48447198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007244277021153289. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48480/60000][Iteration 1904][Wall Clock 92.666515972s] Trained 120 records in 0.042983341 seconds. Throughput is 2791.7793 records/second. Loss is 0.4135802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007243227582210633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48600/60000][Iteration 1905][Wall Clock 92.709544016s] Trained 120 records in 0.043028044 seconds. Throughput is 2788.8787 records/second. Loss is 0.3243451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007242178447276941. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48720/60000][Iteration 1906][Wall Clock 92.752985635s] Trained 120 records in 0.043441619 seconds. Throughput is 2762.328 records/second. Loss is 0.42567644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00724112961622013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48840/60000][Iteration 1907][Wall Clock 92.795377221s] Trained 120 records in 0.042391586 seconds. Throughput is 2830.7502 records/second. Loss is 0.47430652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007240081088908196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 48960/60000][Iteration 1908][Wall Clock 92.837947547s] Trained 120 records in 0.042570326 seconds. Throughput is 2818.865 records/second. Loss is 0.47017622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007239032865209208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49080/60000][Iteration 1909][Wall Clock 92.880078997s] Trained 120 records in 0.04213145 seconds. Throughput is 2848.2285 records/second. Loss is 0.4242627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007237984944991315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49200/60000][Iteration 1910][Wall Clock 92.923205642s] Trained 120 records in 0.043126645 seconds. Throughput is 2782.5024 records/second. Loss is 0.39968026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007236937328122738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49320/60000][Iteration 1911][Wall Clock 92.980019971s] Trained 120 records in 0.056814329 seconds. Throughput is 2112.1433 records/second. Loss is 0.37934467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00723589001447178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49440/60000][Iteration 1912][Wall Clock 93.024467441s] Trained 120 records in 0.04444747 seconds. Throughput is 2699.8162 records/second. Loss is 0.28400278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072348430039068145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49560/60000][Iteration 1913][Wall Clock 93.066605864s] Trained 120 records in 0.042138423 seconds. Throughput is 2847.7573 records/second. Loss is 0.44506356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007233796296296296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49680/60000][Iteration 1914][Wall Clock 93.109263359s] Trained 120 records in 0.042657495 seconds. Throughput is 2813.1047 records/second. Loss is 0.34016043. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072327498915087515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49800/60000][Iteration 1915][Wall Clock 93.150972379s] Trained 120 records in 0.04170902 seconds. Throughput is 2877.0754 records/second. Loss is 0.3287215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007231703789412786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 49920/60000][Iteration 1916][Wall Clock 93.192696775s] Trained 120 records in 0.041724396 seconds. Throughput is 2876.0154 records/second. Loss is 0.33934104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007230657989877079. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 50040/60000][Iteration 1917][Wall Clock 93.233947396s] Trained 120 records in 0.041250621 seconds. Throughput is 2909.047 records/second. Loss is 0.3807501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007229612492770388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 50160/60000][Iteration 1918][Wall Clock 93.276637938s] Trained 120 records in 0.042690542 seconds. Throughput is 2810.927 records/second. Loss is 0.27692512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007228567297961544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 50280/60000][Iteration 1919][Wall Clock 93.319120613s] Trained 120 records in 0.042482675 seconds. Throughput is 2824.681 records/second. Loss is 0.49206606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007227522405319457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 50400/60000][Iteration 1920][Wall Clock 93.374074758s] Trained 120 records in 0.054954145 seconds. Throughput is 2183.6387 records/second. Loss is 0.4205306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00722647781471311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 50520/60000][Iteration 1921][Wall Clock 93.41699457s] Trained 120 records in 0.042919812 seconds. Throughput is 2795.9116 records/second. Loss is 0.42266992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007225433526011561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:39 INFO  DistriOptimizer$:406 - [Epoch 4 50640/60000][Iteration 1922][Wall Clock 93.459347899s] Trained 120 records in 0.042353329 seconds. Throughput is 2833.3074 records/second. Loss is 0.42490873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007224389539083947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 50760/60000][Iteration 1923][Wall Clock 93.50112256s] Trained 120 records in 0.041774661 seconds. Throughput is 2872.5547 records/second. Loss is 0.36122957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00722334585379948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 50880/60000][Iteration 1924][Wall Clock 93.543118245s] Trained 120 records in 0.041995685 seconds. Throughput is 2857.4363 records/second. Loss is 0.35053226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007222302470027445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51000/60000][Iteration 1925][Wall Clock 93.585640296s] Trained 120 records in 0.042522051 seconds. Throughput is 2822.0652 records/second. Loss is 0.41497272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007221259387637204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51120/60000][Iteration 1926][Wall Clock 93.626926797s] Trained 120 records in 0.041286501 seconds. Throughput is 2906.519 records/second. Loss is 0.4110829. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007220216606498195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51240/60000][Iteration 1927][Wall Clock 93.668308945s] Trained 120 records in 0.041382148 seconds. Throughput is 2899.801 records/second. Loss is 0.4556152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007219174126479931. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51360/60000][Iteration 1928][Wall Clock 93.713442957s] Trained 120 records in 0.045134012 seconds. Throughput is 2658.7488 records/second. Loss is 0.34058297. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007218131947452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51480/60000][Iteration 1929][Wall Clock 93.754228355s] Trained 120 records in 0.040785398 seconds. Throughput is 2942.2295 records/second. Loss is 0.39949635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007217090069284065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51600/60000][Iteration 1930][Wall Clock 93.795595674s] Trained 120 records in 0.041367319 seconds. Throughput is 2900.8406 records/second. Loss is 0.44921592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072160484918458645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51720/60000][Iteration 1931][Wall Clock 93.836753078s] Trained 120 records in 0.041157404 seconds. Throughput is 2915.6357 records/second. Loss is 0.43385953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007215007215007214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51840/60000][Iteration 1932][Wall Clock 93.877931594s] Trained 120 records in 0.041178516 seconds. Throughput is 2914.1409 records/second. Loss is 0.48432112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007213966238638003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 51960/60000][Iteration 1933][Wall Clock 93.919697918s] Trained 120 records in 0.041766324 seconds. Throughput is 2873.1282 records/second. Loss is 0.38569573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007212925562608194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52080/60000][Iteration 1934][Wall Clock 93.961922147s] Trained 120 records in 0.042224229 seconds. Throughput is 2841.9702 records/second. Loss is 0.45699197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007211885186787826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52200/60000][Iteration 1935][Wall Clock 94.003934236s] Trained 120 records in 0.042012089 seconds. Throughput is 2856.3208 records/second. Loss is 0.38197756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007210845111047015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52320/60000][Iteration 1936][Wall Clock 94.045891482s] Trained 120 records in 0.041957246 seconds. Throughput is 2860.0544 records/second. Loss is 0.4742603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0072098053352559486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52440/60000][Iteration 1937][Wall Clock 94.087867276s] Trained 120 records in 0.041975794 seconds. Throughput is 2858.7905 records/second. Loss is 0.47307378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00720876585928489. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52560/60000][Iteration 1938][Wall Clock 94.141143108s] Trained 120 records in 0.053275832 seconds. Throughput is 2252.4285 records/second. Loss is 0.4837021. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007207726683004181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52680/60000][Iteration 1939][Wall Clock 94.187468152s] Trained 120 records in 0.046325044 seconds. Throughput is 2590.3916 records/second. Loss is 0.33542696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007206687806284232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52800/60000][Iteration 1940][Wall Clock 94.229317743s] Trained 120 records in 0.041849591 seconds. Throughput is 2867.4116 records/second. Loss is 0.5059535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007205649228995533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 52920/60000][Iteration 1941][Wall Clock 94.271316944s] Trained 120 records in 0.041999201 seconds. Throughput is 2857.197 records/second. Loss is 0.31313285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007204610951008646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 53040/60000][Iteration 1942][Wall Clock 94.313179413s] Trained 120 records in 0.041862469 seconds. Throughput is 2866.5295 records/second. Loss is 0.44727248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007203572972194208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 53160/60000][Iteration 1943][Wall Clock 94.355433715s] Trained 120 records in 0.042254302 seconds. Throughput is 2839.9475 records/second. Loss is 0.3859429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007202535292422933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 53280/60000][Iteration 1944][Wall Clock 94.398021406s] Trained 120 records in 0.042587691 seconds. Throughput is 2817.7156 records/second. Loss is 0.5361009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007201497911565605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 53400/60000][Iteration 1945][Wall Clock 94.439653836s] Trained 120 records in 0.04163243 seconds. Throughput is 2882.3684 records/second. Loss is 0.3790275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007200460829493088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:40 INFO  DistriOptimizer$:406 - [Epoch 4 53520/60000][Iteration 1946][Wall Clock 94.489965749s] Trained 120 records in 0.050311913 seconds. Throughput is 2385.121 records/second. Loss is 0.4688758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007199424046076314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 53640/60000][Iteration 1947][Wall Clock 94.535283375s] Trained 120 records in 0.045317626 seconds. Throughput is 2647.9763 records/second. Loss is 0.30745554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007198387561186294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 53760/60000][Iteration 1948][Wall Clock 94.577521339s] Trained 120 records in 0.042237964 seconds. Throughput is 2841.0461 records/second. Loss is 0.348402. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007197351374694113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 53880/60000][Iteration 1949][Wall Clock 94.619537977s] Trained 120 records in 0.042016638 seconds. Throughput is 2856.0115 records/second. Loss is 0.5326296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007196315486470927. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54000/60000][Iteration 1950][Wall Clock 94.661769527s] Trained 120 records in 0.04223155 seconds. Throughput is 2841.4775 records/second. Loss is 0.33373433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007195279896387969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54120/60000][Iteration 1951][Wall Clock 94.704767161s] Trained 120 records in 0.042997634 seconds. Throughput is 2790.8513 records/second. Loss is 0.44500515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007194244604316546. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54240/60000][Iteration 1952][Wall Clock 94.747189186s] Trained 120 records in 0.042422025 seconds. Throughput is 2828.7192 records/second. Loss is 0.4635434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007193209610128039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54360/60000][Iteration 1953][Wall Clock 94.789390437s] Trained 120 records in 0.042201251 seconds. Throughput is 2843.5176 records/second. Loss is 0.503066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007192174913693901. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54480/60000][Iteration 1954][Wall Clock 94.83121788s] Trained 120 records in 0.041827443 seconds. Throughput is 2868.9297 records/second. Loss is 0.33647034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071911405148856605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54600/60000][Iteration 1955][Wall Clock 94.873019457s] Trained 120 records in 0.041801577 seconds. Throughput is 2870.705 records/second. Loss is 0.45712787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007190106413574921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54720/60000][Iteration 1956][Wall Clock 94.915281889s] Trained 120 records in 0.042262432 seconds. Throughput is 2839.4014 records/second. Loss is 0.43275827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007189072609633357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54840/60000][Iteration 1957][Wall Clock 94.957385477s] Trained 120 records in 0.042103588 seconds. Throughput is 2850.1133 records/second. Loss is 0.30632478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00718803910293272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 54960/60000][Iteration 1958][Wall Clock 95.000159237s] Trained 120 records in 0.04277376 seconds. Throughput is 2805.4583 records/second. Loss is 0.38163334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007187005893344833. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55080/60000][Iteration 1959][Wall Clock 95.042347454s] Trained 120 records in 0.042188217 seconds. Throughput is 2844.3962 records/second. Loss is 0.30756825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007185972980741593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55200/60000][Iteration 1960][Wall Clock 95.085242907s] Trained 120 records in 0.042895453 seconds. Throughput is 2797.4995 records/second. Loss is 0.33052376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007184940364994971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55320/60000][Iteration 1961][Wall Clock 95.127257359s] Trained 120 records in 0.042014452 seconds. Throughput is 2856.16 records/second. Loss is 0.26410457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007183908045977012. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55440/60000][Iteration 1962][Wall Clock 95.168807558s] Trained 120 records in 0.041550199 seconds. Throughput is 2888.0728 records/second. Loss is 0.3768448. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007182876023559834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55560/60000][Iteration 1963][Wall Clock 95.210304793s] Trained 120 records in 0.041497235 seconds. Throughput is 2891.759 records/second. Loss is 0.5322751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007181844297615627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55680/60000][Iteration 1964][Wall Clock 95.259715278s] Trained 120 records in 0.049410485 seconds. Throughput is 2428.6343 records/second. Loss is 0.3707163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007180812868016659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55800/60000][Iteration 1965][Wall Clock 95.30928921s] Trained 120 records in 0.049573932 seconds. Throughput is 2420.627 records/second. Loss is 0.38566303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007179781734635267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 55920/60000][Iteration 1966][Wall Clock 95.354651906s] Trained 120 records in 0.045362696 seconds. Throughput is 2645.3455 records/second. Loss is 0.3960681. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007178750897343863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 56040/60000][Iteration 1967][Wall Clock 95.397468791s] Trained 120 records in 0.042816885 seconds. Throughput is 2802.6326 records/second. Loss is 0.32634956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00717772035601493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 56160/60000][Iteration 1968][Wall Clock 95.443443573s] Trained 120 records in 0.045974782 seconds. Throughput is 2610.1265 records/second. Loss is 0.3980722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007176690110521028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:41 INFO  DistriOptimizer$:406 - [Epoch 4 56280/60000][Iteration 1969][Wall Clock 95.487006824s] Trained 120 records in 0.043563251 seconds. Throughput is 2754.6155 records/second. Loss is 0.45082295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007175660160734788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 56400/60000][Iteration 1970][Wall Clock 95.529070652s] Trained 120 records in 0.042063828 seconds. Throughput is 2852.8074 records/second. Loss is 0.43932354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007174630506528913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 56520/60000][Iteration 1971][Wall Clock 95.571671769s] Trained 120 records in 0.042601117 seconds. Throughput is 2816.8276 records/second. Loss is 0.36823606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007173601147776183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 56640/60000][Iteration 1972][Wall Clock 95.613337436s] Trained 120 records in 0.041665667 seconds. Throughput is 2880.069 records/second. Loss is 0.27852386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007172572084349447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 56760/60000][Iteration 1973][Wall Clock 95.663613283s] Trained 120 records in 0.050275847 seconds. Throughput is 2386.832 records/second. Loss is 0.37868267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007171543316121629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 56880/60000][Iteration 1974][Wall Clock 95.705768526s] Trained 120 records in 0.042155243 seconds. Throughput is 2846.6208 records/second. Loss is 0.3763688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007170514842965724. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57000/60000][Iteration 1975][Wall Clock 95.747349385s] Trained 120 records in 0.041580859 seconds. Throughput is 2885.943 records/second. Loss is 0.4209925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007169486664754803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57120/60000][Iteration 1976][Wall Clock 95.788906769s] Trained 120 records in 0.041557384 seconds. Throughput is 2887.5735 records/second. Loss is 0.3860708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007168458781362007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57240/60000][Iteration 1977][Wall Clock 95.83054239s] Trained 120 records in 0.041635621 seconds. Throughput is 2882.1475 records/second. Loss is 0.42295653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007167431192660551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57360/60000][Iteration 1978][Wall Clock 95.871617918s] Trained 120 records in 0.041075528 seconds. Throughput is 2921.4475 records/second. Loss is 0.36222345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007166403898523721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57480/60000][Iteration 1979][Wall Clock 95.914920852s] Trained 120 records in 0.043302934 seconds. Throughput is 2771.1748 records/second. Loss is 0.31382772. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071653768988248785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57600/60000][Iteration 1980][Wall Clock 95.957584892s] Trained 120 records in 0.04266404 seconds. Throughput is 2812.673 records/second. Loss is 0.34702727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007164350193437456. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57720/60000][Iteration 1981][Wall Clock 96.000311257s] Trained 120 records in 0.042726365 seconds. Throughput is 2808.5703 records/second. Loss is 0.3351608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071633237822349575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57840/60000][Iteration 1982][Wall Clock 96.042601091s] Trained 120 records in 0.042289834 seconds. Throughput is 2837.5613 records/second. Loss is 0.40599504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007162297665090962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 57960/60000][Iteration 1983][Wall Clock 96.085569738s] Trained 120 records in 0.042968647 seconds. Throughput is 2792.7341 records/second. Loss is 0.43133718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007161271841879117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58080/60000][Iteration 1984][Wall Clock 96.12702602s] Trained 120 records in 0.041456282 seconds. Throughput is 2894.6155 records/second. Loss is 0.25684017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007160246312473149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58200/60000][Iteration 1985][Wall Clock 96.168897285s] Trained 120 records in 0.041871265 seconds. Throughput is 2865.9272 records/second. Loss is 0.42316613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00715922107674685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58320/60000][Iteration 1986][Wall Clock 96.211235376s] Trained 120 records in 0.042338091 seconds. Throughput is 2834.3271 records/second. Loss is 0.48519522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071581961345740875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58440/60000][Iteration 1987][Wall Clock 96.253959257s] Trained 120 records in 0.042723881 seconds. Throughput is 2808.7336 records/second. Loss is 0.40910864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071571714858288. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58560/60000][Iteration 1988][Wall Clock 96.296459522s] Trained 120 records in 0.042500265 seconds. Throughput is 2823.5117 records/second. Loss is 0.54912126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007156147130385001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58680/60000][Iteration 1989][Wall Clock 96.338891191s] Trained 120 records in 0.042431669 seconds. Throughput is 2828.0764 records/second. Loss is 0.4257957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007155123068116772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58800/60000][Iteration 1990][Wall Clock 96.381551677s] Trained 120 records in 0.042660486 seconds. Throughput is 2812.9075 records/second. Loss is 0.48166865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007154099298898268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 58920/60000][Iteration 1991][Wall Clock 96.431842356s] Trained 120 records in 0.050290679 seconds. Throughput is 2386.1282 records/second. Loss is 0.40600437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007153075822603719. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:42 INFO  DistriOptimizer$:406 - [Epoch 4 59040/60000][Iteration 1992][Wall Clock 96.482396407s] Trained 120 records in 0.050554051 seconds. Throughput is 2373.697 records/second. Loss is 0.33310977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007152052639107423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 59160/60000][Iteration 1993][Wall Clock 96.530277396s] Trained 120 records in 0.047880989 seconds. Throughput is 2506.2139 records/second. Loss is 0.35086286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007151029748283752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 59280/60000][Iteration 1994][Wall Clock 96.574495976s] Trained 120 records in 0.04421858 seconds. Throughput is 2713.7913 records/second. Loss is 0.33085012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00715000715000715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 59400/60000][Iteration 1995][Wall Clock 96.61660699s] Trained 120 records in 0.042111014 seconds. Throughput is 2849.6108 records/second. Loss is 0.38281247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007148984844152131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 59520/60000][Iteration 1996][Wall Clock 96.657837564s] Trained 120 records in 0.041230574 seconds. Throughput is 2910.4614 records/second. Loss is 0.34440053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007147962830593281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 59640/60000][Iteration 1997][Wall Clock 96.699606569s] Trained 120 records in 0.041769005 seconds. Throughput is 2872.9436 records/second. Loss is 0.3225457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007146941109205261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 59760/60000][Iteration 1998][Wall Clock 96.74141986s] Trained 120 records in 0.041813291 seconds. Throughput is 2869.901 records/second. Loss is 0.39880547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007145919679862799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 59880/60000][Iteration 1999][Wall Clock 96.789859284s] Trained 120 records in 0.048439424 seconds. Throughput is 2477.321 records/second. Loss is 0.38895732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007144898542440698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:406 - [Epoch 4 60000/60000][Iteration 2000][Wall Clock 96.835597134s] Trained 120 records in 0.04573785 seconds. Throughput is 2623.6475 records/second. Loss is 0.3515234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007143877696813831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:43 INFO  DistriOptimizer$:451 - [Epoch 4 60000/60000][Iteration 2000][Wall Clock 96.835597134s] Epoch finished. Wall clock time is 97667.885662 ms
2019-10-23 15:54:43 INFO  DistriOptimizer$:111 - [Epoch 4 60000/60000][Iteration 2000][Wall Clock 96.835597134s] Validate model...
2019-10-23 15:54:44 INFO  DistriOptimizer$:177 - [Epoch 4 60000/60000][Iteration 2000][Wall Clock 96.835597134s] validate model throughput is 14945.236 records/second
2019-10-23 15:54:44 INFO  DistriOptimizer$:180 - [Epoch 4 60000/60000][Iteration 2000][Wall Clock 96.835597134s] Top1Accuracy is Accuracy(correct: 9066, count: 10000, accuracy: 0.9066)
2019-10-23 15:54:44 INFO  DistriOptimizer$:220 - [Wall Clock 97.667885662s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:54:44 INFO  DistriOptimizer$:225 - [Wall Clock 97.667885662s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 120/60000][Iteration 2001][Wall Clock 97.716921893s] Trained 120 records in 0.049036231 seconds. Throughput is 2447.1702 records/second. Loss is 0.37808287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071428571428571435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 240/60000][Iteration 2002][Wall Clock 97.759379646s] Trained 120 records in 0.042457753 seconds. Throughput is 2826.339 records/second. Loss is 0.3429114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007141836880445652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 360/60000][Iteration 2003][Wall Clock 97.801646076s] Trained 120 records in 0.04226643 seconds. Throughput is 2839.1328 records/second. Loss is 0.47071335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007140816909454441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 480/60000][Iteration 2004][Wall Clock 97.843074098s] Trained 120 records in 0.041428022 seconds. Throughput is 2896.59 records/second. Loss is 0.31127873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007139797229758675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 600/60000][Iteration 2005][Wall Clock 97.884423449s] Trained 120 records in 0.041349351 seconds. Throughput is 2902.101 records/second. Loss is 0.30043155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007138777841233581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 720/60000][Iteration 2006][Wall Clock 97.926334601s] Trained 120 records in 0.041911152 seconds. Throughput is 2863.1997 records/second. Loss is 0.31273776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007137758743754461. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 840/60000][Iteration 2007][Wall Clock 97.967779183s] Trained 120 records in 0.041444582 seconds. Throughput is 2895.4329 records/second. Loss is 0.37168244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007136739937196689. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 960/60000][Iteration 2008][Wall Clock 98.00951669s] Trained 120 records in 0.041737507 seconds. Throughput is 2875.1118 records/second. Loss is 0.35451016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007135721421435708. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1080/60000][Iteration 2009][Wall Clock 98.051388633s] Trained 120 records in 0.041871943 seconds. Throughput is 2865.8809 records/second. Loss is 0.36416283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071347031963470324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1200/60000][Iteration 2010][Wall Clock 98.093096478s] Trained 120 records in 0.041707845 seconds. Throughput is 2877.1567 records/second. Loss is 0.39662403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007133685261806248. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1320/60000][Iteration 2011][Wall Clock 98.136264169s] Trained 120 records in 0.043167691 seconds. Throughput is 2779.8567 records/second. Loss is 0.2763258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007132667617689015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1440/60000][Iteration 2012][Wall Clock 98.180488979s] Trained 120 records in 0.04422481 seconds. Throughput is 2713.4092 records/second. Loss is 0.30025807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007131650263871059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1560/60000][Iteration 2013][Wall Clock 98.224444466s] Trained 120 records in 0.043955487 seconds. Throughput is 2730.0347 records/second. Loss is 0.4756963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00713063320022818. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1680/60000][Iteration 2014][Wall Clock 98.26726498s] Trained 120 records in 0.042820514 seconds. Throughput is 2802.3953 records/second. Loss is 0.39882293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007129616426636246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1800/60000][Iteration 2015][Wall Clock 98.309368985s] Trained 120 records in 0.042104005 seconds. Throughput is 2850.0852 records/second. Loss is 0.4749141. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071285999429712005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 1920/60000][Iteration 2016][Wall Clock 98.359187885s] Trained 120 records in 0.0498189 seconds. Throughput is 2408.7244 records/second. Loss is 0.4224445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007127583749109052. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 2040/60000][Iteration 2017][Wall Clock 98.411698842s] Trained 120 records in 0.052510957 seconds. Throughput is 2285.2373 records/second. Loss is 0.3222951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007126567844925884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 2160/60000][Iteration 2018][Wall Clock 98.459416177s] Trained 120 records in 0.047717335 seconds. Throughput is 2514.8093 records/second. Loss is 0.41529885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007125552230297848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 2280/60000][Iteration 2019][Wall Clock 98.502293911s] Trained 120 records in 0.042877734 seconds. Throughput is 2798.6553 records/second. Loss is 0.30366755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007124536905101168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 2400/60000][Iteration 2020][Wall Clock 98.544614857s] Trained 120 records in 0.042320946 seconds. Throughput is 2835.4756 records/second. Loss is 0.2967242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007123521869212139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:44 INFO  DistriOptimizer$:406 - [Epoch 5 2520/60000][Iteration 2021][Wall Clock 98.587512902s] Trained 120 records in 0.042898045 seconds. Throughput is 2797.3303 records/second. Loss is 0.30573028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071225071225071235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 2640/60000][Iteration 2022][Wall Clock 98.629741433s] Trained 120 records in 0.042228531 seconds. Throughput is 2841.6807 records/second. Loss is 0.43675005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007121492664862556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 2760/60000][Iteration 2023][Wall Clock 98.671737557s] Trained 120 records in 0.041996124 seconds. Throughput is 2857.4065 records/second. Loss is 0.35069183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007120478496154941. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 2880/60000][Iteration 2024][Wall Clock 98.713733228s] Trained 120 records in 0.041995671 seconds. Throughput is 2857.4375 records/second. Loss is 0.36244017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007119464616260857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3000/60000][Iteration 2025][Wall Clock 98.764868528s] Trained 120 records in 0.0511353 seconds. Throughput is 2346.7153 records/second. Loss is 0.35861525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071184510250569474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3120/60000][Iteration 2026][Wall Clock 98.81159197s] Trained 120 records in 0.046723442 seconds. Throughput is 2568.304 records/second. Loss is 0.4248358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071174377224199285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3240/60000][Iteration 2027][Wall Clock 98.854596094s] Trained 120 records in 0.043004124 seconds. Throughput is 2790.43 records/second. Loss is 0.379212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007116424708226587. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3360/60000][Iteration 2028][Wall Clock 98.896378294s] Trained 120 records in 0.0417822 seconds. Throughput is 2872.0364 records/second. Loss is 0.42818376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071154119823537785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3480/60000][Iteration 2029][Wall Clock 98.938493767s] Trained 120 records in 0.042115473 seconds. Throughput is 2849.309 records/second. Loss is 0.28799787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071143995446784295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3600/60000][Iteration 2030][Wall Clock 98.980485602s] Trained 120 records in 0.041991835 seconds. Throughput is 2857.6985 records/second. Loss is 0.4563783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007113387395077536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3720/60000][Iteration 2031][Wall Clock 99.02312265s] Trained 120 records in 0.042637048 seconds. Throughput is 2814.4539 records/second. Loss is 0.32030377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007112375533428164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3840/60000][Iteration 2032][Wall Clock 99.065162841s] Trained 120 records in 0.042040191 seconds. Throughput is 2854.4114 records/second. Loss is 0.3021766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007111363959607452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 3960/60000][Iteration 2033][Wall Clock 99.10800846s] Trained 120 records in 0.042845619 seconds. Throughput is 2800.7532 records/second. Loss is 0.32184282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007110352673492605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4080/60000][Iteration 2034][Wall Clock 99.150491609s] Trained 120 records in 0.042483149 seconds. Throughput is 2824.6494 records/second. Loss is 0.35314777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007109341674960899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4200/60000][Iteration 2035][Wall Clock 99.193244244s] Trained 120 records in 0.042752635 seconds. Throughput is 2806.8445 records/second. Loss is 0.36179078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071083309638896785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4320/60000][Iteration 2036][Wall Clock 99.235074644s] Trained 120 records in 0.0418304 seconds. Throughput is 2868.7273 records/second. Loss is 0.3533137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007107320540156361. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4440/60000][Iteration 2037][Wall Clock 99.277525154s] Trained 120 records in 0.04245051 seconds. Throughput is 2826.821 records/second. Loss is 0.40645456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007106310403638431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4560/60000][Iteration 2038][Wall Clock 99.319528989s] Trained 120 records in 0.042003835 seconds. Throughput is 2856.8818 records/second. Loss is 0.39352977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0071053005542134435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4680/60000][Iteration 2039][Wall Clock 99.361250287s] Trained 120 records in 0.041721298 seconds. Throughput is 2876.2288 records/second. Loss is 0.28845465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007104290991759023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4800/60000][Iteration 2040][Wall Clock 99.40321224s] Trained 120 records in 0.041961953 seconds. Throughput is 2859.7334 records/second. Loss is 0.4134983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007103281716152863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 4920/60000][Iteration 2041][Wall Clock 99.446295146s] Trained 120 records in 0.043082906 seconds. Throughput is 2785.3274 records/second. Loss is 0.37206537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007102272727272728. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 5040/60000][Iteration 2042][Wall Clock 99.504628218s] Trained 120 records in 0.058333072 seconds. Throughput is 2057.152 records/second. Loss is 0.2814261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00710126402499645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:45 INFO  DistriOptimizer$:406 - [Epoch 5 5160/60000][Iteration 2043][Wall Clock 99.552842806s] Trained 120 records in 0.048214588 seconds. Throughput is 2488.8733 records/second. Loss is 0.5108711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007100255609201931. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 5280/60000][Iteration 2044][Wall Clock 99.595219986s] Trained 120 records in 0.04237718 seconds. Throughput is 2831.7126 records/second. Loss is 0.28220704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007099247479767145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 5400/60000][Iteration 2045][Wall Clock 99.636913121s] Trained 120 records in 0.041693135 seconds. Throughput is 2878.1716 records/second. Loss is 0.3772654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007098239636570131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 5520/60000][Iteration 2046][Wall Clock 99.679149542s] Trained 120 records in 0.042236421 seconds. Throughput is 2841.15 records/second. Loss is 0.2690838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007097232079488999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 5640/60000][Iteration 2047][Wall Clock 99.721344889s] Trained 120 records in 0.042195347 seconds. Throughput is 2843.9155 records/second. Loss is 0.36569917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00709622480840193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 5760/60000][Iteration 2048][Wall Clock 99.764547549s] Trained 120 records in 0.04320266 seconds. Throughput is 2777.6067 records/second. Loss is 0.39813247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007095217823187172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 5880/60000][Iteration 2049][Wall Clock 99.807528478s] Trained 120 records in 0.042980929 seconds. Throughput is 2791.936 records/second. Loss is 0.39016488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007094211123723043. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6000/60000][Iteration 2050][Wall Clock 99.849099331s] Trained 120 records in 0.041570853 seconds. Throughput is 2886.638 records/second. Loss is 0.46994197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007093204709887928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6120/60000][Iteration 2051][Wall Clock 99.900542463s] Trained 120 records in 0.051443132 seconds. Throughput is 2332.6729 records/second. Loss is 0.47700956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070921985815602835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6240/60000][Iteration 2052][Wall Clock 99.945907583s] Trained 120 records in 0.04536512 seconds. Throughput is 2645.204 records/second. Loss is 0.3067494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070911927386186355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6360/60000][Iteration 2053][Wall Clock 99.988164042s] Trained 120 records in 0.042256459 seconds. Throughput is 2839.8025 records/second. Loss is 0.36926025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007090187180941576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6480/60000][Iteration 2054][Wall Clock 100.030345269s] Trained 120 records in 0.042181227 seconds. Throughput is 2844.8674 records/second. Loss is 0.40549287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007089181908407769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6600/60000][Iteration 2055][Wall Clock 100.072878044s] Trained 120 records in 0.042532775 seconds. Throughput is 2821.3535 records/second. Loss is 0.3783469. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007088176920895945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6720/60000][Iteration 2056][Wall Clock 100.114483226s] Trained 120 records in 0.041605182 seconds. Throughput is 2884.256 records/second. Loss is 0.43665215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007087172218284904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6840/60000][Iteration 2057][Wall Clock 100.156113796s] Trained 120 records in 0.04163057 seconds. Throughput is 2882.497 records/second. Loss is 0.32934675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007086167800453515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 6960/60000][Iteration 2058][Wall Clock 100.197576163s] Trained 120 records in 0.041462367 seconds. Throughput is 2894.191 records/second. Loss is 0.37676618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007085163667280714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7080/60000][Iteration 2059][Wall Clock 100.238959123s] Trained 120 records in 0.04138296 seconds. Throughput is 2899.7441 records/second. Loss is 0.38707536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007084159818645509. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7200/60000][Iteration 2060][Wall Clock 100.280993948s] Trained 120 records in 0.042034825 seconds. Throughput is 2854.776 records/second. Loss is 0.3725434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007083156254426973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7320/60000][Iteration 2061][Wall Clock 100.322635108s] Trained 120 records in 0.04164116 seconds. Throughput is 2881.7642 records/second. Loss is 0.40970898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007082152974504249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7440/60000][Iteration 2062][Wall Clock 100.364336121s] Trained 120 records in 0.041701013 seconds. Throughput is 2877.628 records/second. Loss is 0.486604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007081149978756551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7560/60000][Iteration 2063][Wall Clock 100.406107084s] Trained 120 records in 0.041770963 seconds. Throughput is 2872.8088 records/second. Loss is 0.25576913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007080147267063155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7680/60000][Iteration 2064][Wall Clock 100.451633926s] Trained 120 records in 0.045526842 seconds. Throughput is 2635.8076 records/second. Loss is 0.26644495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007079144839303412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7800/60000][Iteration 2065][Wall Clock 100.494678038s] Trained 120 records in 0.043044112 seconds. Throughput is 2787.8376 records/second. Loss is 0.35372692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007078142695356738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:46 INFO  DistriOptimizer$:406 - [Epoch 5 7920/60000][Iteration 2066][Wall Clock 100.537936976s] Trained 120 records in 0.043258938 seconds. Throughput is 2773.9932 records/second. Loss is 0.43788502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007077140835102618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8040/60000][Iteration 2067][Wall Clock 100.590275592s] Trained 120 records in 0.052338616 seconds. Throughput is 2292.7622 records/second. Loss is 0.35884243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007076139258420606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8160/60000][Iteration 2068][Wall Clock 100.642575039s] Trained 120 records in 0.052299447 seconds. Throughput is 2294.4792 records/second. Loss is 0.33027032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007075137965190321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8280/60000][Iteration 2069][Wall Clock 100.684631821s] Trained 120 records in 0.042056782 seconds. Throughput is 2853.2854 records/second. Loss is 0.4579211. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007074136955291454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8400/60000][Iteration 2070][Wall Clock 100.726198322s] Trained 120 records in 0.041566501 seconds. Throughput is 2886.94 records/second. Loss is 0.25163457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007073136228603763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8520/60000][Iteration 2071][Wall Clock 100.767843564s] Trained 120 records in 0.041645242 seconds. Throughput is 2881.4814 records/second. Loss is 0.4213743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007072135785007072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8640/60000][Iteration 2072][Wall Clock 100.809802258s] Trained 120 records in 0.041958694 seconds. Throughput is 2859.9556 records/second. Loss is 0.47433382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007071135624381275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8760/60000][Iteration 2073][Wall Clock 100.85120053s] Trained 120 records in 0.041398272 seconds. Throughput is 2898.6716 records/second. Loss is 0.43478495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007070135746606335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 8880/60000][Iteration 2074][Wall Clock 100.892787219s] Trained 120 records in 0.041586689 seconds. Throughput is 2885.5386 records/second. Loss is 0.26022866. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070691361515622785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9000/60000][Iteration 2075][Wall Clock 100.934183893s] Trained 120 records in 0.041396674 seconds. Throughput is 2898.7837 records/second. Loss is 0.32805398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007068136839129205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9120/60000][Iteration 2076][Wall Clock 100.976828855s] Trained 120 records in 0.042644962 seconds. Throughput is 2813.9314 records/second. Loss is 0.42679766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007067137809187279. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9240/60000][Iteration 2077][Wall Clock 101.025715088s] Trained 120 records in 0.048886233 seconds. Throughput is 2454.679 records/second. Loss is 0.40691334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070661390616167325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9360/60000][Iteration 2078][Wall Clock 101.072071365s] Trained 120 records in 0.046356277 seconds. Throughput is 2588.6462 records/second. Loss is 0.31969327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007065140596297866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9480/60000][Iteration 2079][Wall Clock 101.113995133s] Trained 120 records in 0.041923768 seconds. Throughput is 2862.3381 records/second. Loss is 0.41505304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007064142413111049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9600/60000][Iteration 2080][Wall Clock 101.155680961s] Trained 120 records in 0.041685828 seconds. Throughput is 2878.6763 records/second. Loss is 0.44848734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007063144511936715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9720/60000][Iteration 2081][Wall Clock 101.198692165s] Trained 120 records in 0.043011204 seconds. Throughput is 2789.9707 records/second. Loss is 0.23888917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007062146892655368. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9840/60000][Iteration 2082][Wall Clock 101.240511367s] Trained 120 records in 0.041819202 seconds. Throughput is 2869.495 records/second. Loss is 0.38444108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007061149555147579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 9960/60000][Iteration 2083][Wall Clock 101.282344703s] Trained 120 records in 0.041833336 seconds. Throughput is 2868.5256 records/second. Loss is 0.3859085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007060152499293986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 10080/60000][Iteration 2084][Wall Clock 101.324114164s] Trained 120 records in 0.041769461 seconds. Throughput is 2872.9124 records/second. Loss is 0.37956792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007059155724975293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 10200/60000][Iteration 2085][Wall Clock 101.365921443s] Trained 120 records in 0.041807279 seconds. Throughput is 2870.3135 records/second. Loss is 0.35155237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007058159232072275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 10320/60000][Iteration 2086][Wall Clock 101.407034036s] Trained 120 records in 0.041112593 seconds. Throughput is 2918.8137 records/second. Loss is 0.38888353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007057163020465773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 10440/60000][Iteration 2087][Wall Clock 101.448646731s] Trained 120 records in 0.041612695 seconds. Throughput is 2883.7354 records/second. Loss is 0.3772213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007056167090036692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 10560/60000][Iteration 2088][Wall Clock 101.490583617s] Trained 120 records in 0.041936886 seconds. Throughput is 2861.4429 records/second. Loss is 0.27437317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007055171440666009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 10680/60000][Iteration 2089][Wall Clock 101.532014596s] Trained 120 records in 0.041430979 seconds. Throughput is 2896.3833 records/second. Loss is 0.40277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007054176072234763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:47 INFO  DistriOptimizer$:406 - [Epoch 5 10800/60000][Iteration 2090][Wall Clock 101.573086539s] Trained 120 records in 0.041071943 seconds. Throughput is 2921.7024 records/second. Loss is 0.51944137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070531809846240655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 10920/60000][Iteration 2091][Wall Clock 101.614995036s] Trained 120 records in 0.041908497 seconds. Throughput is 2863.381 records/second. Loss is 0.38027123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007052186177715091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11040/60000][Iteration 2092][Wall Clock 101.676445366s] Trained 120 records in 0.06145033 seconds. Throughput is 1952.7968 records/second. Loss is 0.36555454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007051191651389084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11160/60000][Iteration 2093][Wall Clock 101.728570165s] Trained 120 records in 0.052124799 seconds. Throughput is 2302.1672 records/second. Loss is 0.31445754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007050197405527354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11280/60000][Iteration 2094][Wall Clock 101.77144344s] Trained 120 records in 0.042873275 seconds. Throughput is 2798.9465 records/second. Loss is 0.3882018. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007049203440011279. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11400/60000][Iteration 2095][Wall Clock 101.813522627s] Trained 120 records in 0.042079187 seconds. Throughput is 2851.766 records/second. Loss is 0.44728366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070482097547223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11520/60000][Iteration 2096][Wall Clock 101.855751449s] Trained 120 records in 0.042228822 seconds. Throughput is 2841.6611 records/second. Loss is 0.51763093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007047216349541931. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11640/60000][Iteration 2097][Wall Clock 101.898267735s] Trained 120 records in 0.042516286 seconds. Throughput is 2822.4478 records/second. Loss is 0.34187397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007046223224351747. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11760/60000][Iteration 2098][Wall Clock 101.940536952s] Trained 120 records in 0.042269217 seconds. Throughput is 2838.9453 records/second. Loss is 0.31251055. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070452303790333945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 11880/60000][Iteration 2099][Wall Clock 101.98311328s] Trained 120 records in 0.042576328 seconds. Throughput is 2818.4675 records/second. Loss is 0.26346102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007044237813468583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12000/60000][Iteration 2100][Wall Clock 102.025706476s] Trained 120 records in 0.042593196 seconds. Throughput is 2817.3513 records/second. Loss is 0.35628033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007043245527539091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12120/60000][Iteration 2101][Wall Clock 102.068072188s] Trained 120 records in 0.042365712 seconds. Throughput is 2832.4792 records/second. Loss is 0.36813983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007042253521126761. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12240/60000][Iteration 2102][Wall Clock 102.114128696s] Trained 120 records in 0.046056508 seconds. Throughput is 2605.4949 records/second. Loss is 0.40069914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007041261794113506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12360/60000][Iteration 2103][Wall Clock 102.15689096s] Trained 120 records in 0.042762264 seconds. Throughput is 2806.2124 records/second. Loss is 0.3718684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007040270346381302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12480/60000][Iteration 2104][Wall Clock 102.212427014s] Trained 120 records in 0.055536054 seconds. Throughput is 2160.7585 records/second. Loss is 0.41337654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007039279177812192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12600/60000][Iteration 2105][Wall Clock 102.258539442s] Trained 120 records in 0.046112428 seconds. Throughput is 2602.3352 records/second. Loss is 0.40782148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007038288288288288. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12720/60000][Iteration 2106][Wall Clock 102.301339028s] Trained 120 records in 0.042799586 seconds. Throughput is 2803.7656 records/second. Loss is 0.33509248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007037297677691766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12840/60000][Iteration 2107][Wall Clock 102.344282797s] Trained 120 records in 0.042943769 seconds. Throughput is 2794.3518 records/second. Loss is 0.49626398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007036307345904869. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 12960/60000][Iteration 2108][Wall Clock 102.387355398s] Trained 120 records in 0.043072601 seconds. Throughput is 2785.994 records/second. Loss is 0.29926297. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007035317292809906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 13080/60000][Iteration 2109][Wall Clock 102.430741854s] Trained 120 records in 0.043386456 seconds. Throughput is 2765.84 records/second. Loss is 0.26975006. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007034327518289252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 13200/60000][Iteration 2110][Wall Clock 102.47461651s] Trained 120 records in 0.043874656 seconds. Throughput is 2735.0642 records/second. Loss is 0.31665343. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007033338022225348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 13320/60000][Iteration 2111][Wall Clock 102.517820649s] Trained 120 records in 0.043204139 seconds. Throughput is 2777.5117 records/second. Loss is 0.47757244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007032348804500703. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:48 INFO  DistriOptimizer$:406 - [Epoch 5 13440/60000][Iteration 2112][Wall Clock 102.559991341s] Trained 120 records in 0.042170692 seconds. Throughput is 2845.5781 records/second. Loss is 0.3298382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00703135986499789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 13560/60000][Iteration 2113][Wall Clock 102.603421757s] Trained 120 records in 0.043430416 seconds. Throughput is 2763.0405 records/second. Loss is 0.35776424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00703037120359955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 13680/60000][Iteration 2114][Wall Clock 102.646660972s] Trained 120 records in 0.043239215 seconds. Throughput is 2775.2585 records/second. Loss is 0.33089325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070293828201883875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 13800/60000][Iteration 2115][Wall Clock 102.6897292s] Trained 120 records in 0.043068228 seconds. Throughput is 2786.2769 records/second. Loss is 0.34386542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007028394714647174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 13920/60000][Iteration 2116][Wall Clock 102.733090044s] Trained 120 records in 0.043360844 seconds. Throughput is 2767.4739 records/second. Loss is 0.3443726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007027406886858749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14040/60000][Iteration 2117][Wall Clock 102.784266322s] Trained 120 records in 0.051176278 seconds. Throughput is 2344.8364 records/second. Loss is 0.40392944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070264193367060145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14160/60000][Iteration 2118][Wall Clock 102.836086507s] Trained 120 records in 0.051820185 seconds. Throughput is 2315.7 records/second. Loss is 0.42160857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00702543206407194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14280/60000][Iteration 2119][Wall Clock 102.880926402s] Trained 120 records in 0.044839895 seconds. Throughput is 2676.1882 records/second. Loss is 0.3617154. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007024445068839562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14400/60000][Iteration 2120][Wall Clock 102.926084569s] Trained 120 records in 0.045158167 seconds. Throughput is 2657.3267 records/second. Loss is 0.37501243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007023458350891979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14520/60000][Iteration 2121][Wall Clock 102.970134755s] Trained 120 records in 0.044050186 seconds. Throughput is 2724.1655 records/second. Loss is 0.4042122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00702247191011236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14640/60000][Iteration 2122][Wall Clock 103.013999012s] Trained 120 records in 0.043864257 seconds. Throughput is 2735.7126 records/second. Loss is 0.32114887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007021485746383936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14760/60000][Iteration 2123][Wall Clock 103.056901296s] Trained 120 records in 0.042902284 seconds. Throughput is 2797.054 records/second. Loss is 0.32619673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007020499859590004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 14880/60000][Iteration 2124][Wall Clock 103.100211454s] Trained 120 records in 0.043310158 seconds. Throughput is 2770.7126 records/second. Loss is 0.39757356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007019514249613926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15000/60000][Iteration 2125][Wall Clock 103.142689365s] Trained 120 records in 0.042477911 seconds. Throughput is 2824.9978 records/second. Loss is 0.34274298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007018528916339135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15120/60000][Iteration 2126][Wall Clock 103.184501854s] Trained 120 records in 0.041812489 seconds. Throughput is 2869.9558 records/second. Loss is 0.39219806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007017543859649123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15240/60000][Iteration 2127][Wall Clock 103.225539309s] Trained 120 records in 0.041037455 seconds. Throughput is 2924.158 records/second. Loss is 0.3926441. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070165590794274485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15360/60000][Iteration 2128][Wall Clock 103.267355497s] Trained 120 records in 0.041816188 seconds. Throughput is 2869.7021 records/second. Loss is 0.4474486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007015574575557739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15480/60000][Iteration 2129][Wall Clock 103.309085344s] Trained 120 records in 0.041729847 seconds. Throughput is 2875.6394 records/second. Loss is 0.31964403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007014590347923681. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15600/60000][Iteration 2130][Wall Clock 103.360025337s] Trained 120 records in 0.050939993 seconds. Throughput is 2355.713 records/second. Loss is 0.2930823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070136063964090336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15720/60000][Iteration 2131][Wall Clock 103.409241945s] Trained 120 records in 0.049216608 seconds. Throughput is 2438.2012 records/second. Loss is 0.34301427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070126227208976155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15840/60000][Iteration 2132][Wall Clock 103.452039477s] Trained 120 records in 0.042797532 seconds. Throughput is 2803.9 records/second. Loss is 0.40310037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007011639321273314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 15960/60000][Iteration 2133][Wall Clock 103.494661783s] Trained 120 records in 0.042622306 seconds. Throughput is 2815.4272 records/second. Loss is 0.4264656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007010656197420078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:49 INFO  DistriOptimizer$:406 - [Epoch 5 16080/60000][Iteration 2134][Wall Clock 103.537144109s] Trained 120 records in 0.042482326 seconds. Throughput is 2824.7039 records/second. Loss is 0.34514394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007009673349221926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 16200/60000][Iteration 2135][Wall Clock 103.579239111s] Trained 120 records in 0.042095002 seconds. Throughput is 2850.6948 records/second. Loss is 0.40034306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007008690776562938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 16320/60000][Iteration 2136][Wall Clock 103.621018378s] Trained 120 records in 0.041779267 seconds. Throughput is 2872.238 records/second. Loss is 0.39627063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00700770847932726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 16440/60000][Iteration 2137][Wall Clock 103.662559034s] Trained 120 records in 0.041540656 seconds. Throughput is 2888.7363 records/second. Loss is 0.34591883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007006726457399103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 16560/60000][Iteration 2138][Wall Clock 103.705149164s] Trained 120 records in 0.04259013 seconds. Throughput is 2817.5542 records/second. Loss is 0.37380317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070057447106627434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 16680/60000][Iteration 2139][Wall Clock 103.750601353s] Trained 120 records in 0.045452189 seconds. Throughput is 2640.137 records/second. Loss is 0.24557877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070047632390025216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 16800/60000][Iteration 2140][Wall Clock 103.793106299s] Trained 120 records in 0.042504946 seconds. Throughput is 2823.2007 records/second. Loss is 0.39538914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007003782042302844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 16920/60000][Iteration 2141][Wall Clock 103.83613945s] Trained 120 records in 0.043033151 seconds. Throughput is 2788.5476 records/second. Loss is 0.35166448. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070028011204481795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17040/60000][Iteration 2142][Wall Clock 103.880079518s] Trained 120 records in 0.043940068 seconds. Throughput is 2730.9927 records/second. Loss is 0.3606334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0070018204733230645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17160/60000][Iteration 2143][Wall Clock 103.935146757s] Trained 120 records in 0.055067239 seconds. Throughput is 2179.154 records/second. Loss is 0.34320414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.007000840100812098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17280/60000][Iteration 2144][Wall Clock 103.978762406s] Trained 120 records in 0.043615649 seconds. Throughput is 2751.306 records/second. Loss is 0.25404102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069998600027999435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17400/60000][Iteration 2145][Wall Clock 104.021403732s] Trained 120 records in 0.042641326 seconds. Throughput is 2814.1714 records/second. Loss is 0.30833974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006998880179171332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17520/60000][Iteration 2146][Wall Clock 104.064525204s] Trained 120 records in 0.043121472 seconds. Throughput is 2782.8364 records/second. Loss is 0.47451928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006997900629811056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17640/60000][Iteration 2147][Wall Clock 104.106754149s] Trained 120 records in 0.042228945 seconds. Throughput is 2841.6528 records/second. Loss is 0.37680718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006996921354603974. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17760/60000][Iteration 2148][Wall Clock 104.148403104s] Trained 120 records in 0.041648955 seconds. Throughput is 2881.2249 records/second. Loss is 0.3446048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006995942353435008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 17880/60000][Iteration 2149][Wall Clock 104.190205942s] Trained 120 records in 0.041802838 seconds. Throughput is 2870.6184 records/second. Loss is 0.36916432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006994963626189144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18000/60000][Iteration 2150][Wall Clock 104.232412196s] Trained 120 records in 0.042206254 seconds. Throughput is 2843.1807 records/second. Loss is 0.4241305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006993985172751434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18120/60000][Iteration 2151][Wall Clock 104.274462487s] Trained 120 records in 0.042050291 seconds. Throughput is 2853.7258 records/second. Loss is 0.31069228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006993006993006994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18240/60000][Iteration 2152][Wall Clock 104.316823128s] Trained 120 records in 0.042360641 seconds. Throughput is 2832.8184 records/second. Loss is 0.38326842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006992029086841001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18360/60000][Iteration 2153][Wall Clock 104.358984027s] Trained 120 records in 0.042160899 seconds. Throughput is 2846.2393 records/second. Loss is 0.36891583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006991051454138702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18480/60000][Iteration 2154][Wall Clock 104.402550492s] Trained 120 records in 0.043566465 seconds. Throughput is 2754.412 records/second. Loss is 0.28059638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006990074094785404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18600/60000][Iteration 2155][Wall Clock 104.445084091s] Trained 120 records in 0.042533599 seconds. Throughput is 2821.299 records/second. Loss is 0.37932178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00698909700866648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18720/60000][Iteration 2156][Wall Clock 104.48807684s] Trained 120 records in 0.042992749 seconds. Throughput is 2791.1685 records/second. Loss is 0.34617603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069881201956673656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:50 INFO  DistriOptimizer$:406 - [Epoch 5 18840/60000][Iteration 2157][Wall Clock 104.54399776s] Trained 120 records in 0.05592092 seconds. Throughput is 2145.8875 records/second. Loss is 0.303187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006987143655673561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 18960/60000][Iteration 2158][Wall Clock 104.588314065s] Trained 120 records in 0.044316305 seconds. Throughput is 2707.807 records/second. Loss is 0.22673015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00698616738857063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19080/60000][Iteration 2159][Wall Clock 104.631517019s] Trained 120 records in 0.043202954 seconds. Throughput is 2777.5876 records/second. Loss is 0.3776766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006985191394244202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19200/60000][Iteration 2160][Wall Clock 104.674274457s] Trained 120 records in 0.042757438 seconds. Throughput is 2806.5293 records/second. Loss is 0.3536248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006984215672579969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19320/60000][Iteration 2161][Wall Clock 104.716792134s] Trained 120 records in 0.042517677 seconds. Throughput is 2822.3555 records/second. Loss is 0.34556013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006983240223463688. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19440/60000][Iteration 2162][Wall Clock 104.759341085s] Trained 120 records in 0.042548951 seconds. Throughput is 2820.281 records/second. Loss is 0.46281213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006982265046781177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19560/60000][Iteration 2163][Wall Clock 104.802815485s] Trained 120 records in 0.0434744 seconds. Throughput is 2760.245 records/second. Loss is 0.48081508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069812901424183196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19680/60000][Iteration 2164][Wall Clock 104.845370469s] Trained 120 records in 0.042554984 seconds. Throughput is 2819.881 records/second. Loss is 0.32588762. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006980315510261063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19800/60000][Iteration 2165][Wall Clock 104.887968211s] Trained 120 records in 0.042597742 seconds. Throughput is 2817.0508 records/second. Loss is 0.3611737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006979341150195421. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 19920/60000][Iteration 2166][Wall Clock 104.931857613s] Trained 120 records in 0.043889402 seconds. Throughput is 2734.1453 records/second. Loss is 0.30362496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006978367062107467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20040/60000][Iteration 2167][Wall Clock 104.977156241s] Trained 120 records in 0.045298628 seconds. Throughput is 2649.087 records/second. Loss is 0.3068546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006977393245883338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20160/60000][Iteration 2168][Wall Clock 105.03032032s] Trained 120 records in 0.053164079 seconds. Throughput is 2257.163 records/second. Loss is 0.3820252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006976419701409237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20280/60000][Iteration 2169][Wall Clock 105.07673854s] Trained 120 records in 0.04641822 seconds. Throughput is 2585.192 records/second. Loss is 0.36009896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006975446428571429. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20400/60000][Iteration 2170][Wall Clock 105.12059661s] Trained 120 records in 0.04385807 seconds. Throughput is 2736.0986 records/second. Loss is 0.35355532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006974473427256243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20520/60000][Iteration 2171][Wall Clock 105.163402171s] Trained 120 records in 0.042805561 seconds. Throughput is 2803.374 records/second. Loss is 0.3425973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006973500697350071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20640/60000][Iteration 2172][Wall Clock 105.205520691s] Trained 120 records in 0.04211852 seconds. Throughput is 2849.103 records/second. Loss is 0.31926584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006972528238739366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20760/60000][Iteration 2173][Wall Clock 105.248499742s] Trained 120 records in 0.042979051 seconds. Throughput is 2792.0579 records/second. Loss is 0.19918771. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006971556051310652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 20880/60000][Iteration 2174][Wall Clock 105.292263873s] Trained 120 records in 0.043764131 seconds. Throughput is 2741.9717 records/second. Loss is 0.3954205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006970584134950508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 21000/60000][Iteration 2175][Wall Clock 105.338155817s] Trained 120 records in 0.045891944 seconds. Throughput is 2614.838 records/second. Loss is 0.31146976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006969612489545581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 21120/60000][Iteration 2176][Wall Clock 105.381224867s] Trained 120 records in 0.04306905 seconds. Throughput is 2786.2236 records/second. Loss is 0.44781405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006968641114982578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 21240/60000][Iteration 2177][Wall Clock 105.423094667s] Trained 120 records in 0.0418698 seconds. Throughput is 2866.0276 records/second. Loss is 0.4355508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006967670011148272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 21360/60000][Iteration 2178][Wall Clock 105.465435646s] Trained 120 records in 0.042340979 seconds. Throughput is 2834.1338 records/second. Loss is 0.40620816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006966699177929497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 21480/60000][Iteration 2179][Wall Clock 105.507407817s] Trained 120 records in 0.041972171 seconds. Throughput is 2859.037 records/second. Loss is 0.35298148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006965728615213151. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:51 INFO  DistriOptimizer$:406 - [Epoch 5 21600/60000][Iteration 2180][Wall Clock 105.549979594s] Trained 120 records in 0.042571777 seconds. Throughput is 2818.769 records/second. Loss is 0.38102886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006964758322886196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 21720/60000][Iteration 2181][Wall Clock 105.594154622s] Trained 120 records in 0.044175028 seconds. Throughput is 2716.4668 records/second. Loss is 0.30146375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006963788300835655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 21840/60000][Iteration 2182][Wall Clock 105.636856088s] Trained 120 records in 0.042701466 seconds. Throughput is 2810.208 records/second. Loss is 0.38945377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006962818548948615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 21960/60000][Iteration 2183][Wall Clock 105.684837586s] Trained 120 records in 0.047981498 seconds. Throughput is 2500.964 records/second. Loss is 0.42324126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069618490671122255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22080/60000][Iteration 2184][Wall Clock 105.736239396s] Trained 120 records in 0.05140181 seconds. Throughput is 2334.548 records/second. Loss is 0.39494067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006960879855213699. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22200/60000][Iteration 2185][Wall Clock 105.781586901s] Trained 120 records in 0.045347505 seconds. Throughput is 2646.2317 records/second. Loss is 0.26236334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006959910913140311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22320/60000][Iteration 2186][Wall Clock 105.825604904s] Trained 120 records in 0.044018003 seconds. Throughput is 2726.1572 records/second. Loss is 0.31341597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006958942240779402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22440/60000][Iteration 2187][Wall Clock 105.868364279s] Trained 120 records in 0.042759375 seconds. Throughput is 2806.402 records/second. Loss is 0.35404572. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006957973838018369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22560/60000][Iteration 2188][Wall Clock 105.911339776s] Trained 120 records in 0.042975497 seconds. Throughput is 2792.2888 records/second. Loss is 0.36798796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006957005704744678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22680/60000][Iteration 2189][Wall Clock 105.95484142s] Trained 120 records in 0.043501644 seconds. Throughput is 2758.5164 records/second. Loss is 0.29269648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006956037840845855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22800/60000][Iteration 2190][Wall Clock 105.998450092s] Trained 120 records in 0.043608672 seconds. Throughput is 2751.746 records/second. Loss is 0.37747926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006955070246209487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 22920/60000][Iteration 2191][Wall Clock 106.044078033s] Trained 120 records in 0.045627941 seconds. Throughput is 2629.9675 records/second. Loss is 0.4228516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006954102920723227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23040/60000][Iteration 2192][Wall Clock 106.088807376s] Trained 120 records in 0.044729343 seconds. Throughput is 2682.8025 records/second. Loss is 0.35372108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006953135864274787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23160/60000][Iteration 2193][Wall Clock 106.137186787s] Trained 120 records in 0.048379411 seconds. Throughput is 2480.394 records/second. Loss is 0.37697214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006952169076751946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23280/60000][Iteration 2194][Wall Clock 106.182489211s] Trained 120 records in 0.045302424 seconds. Throughput is 2648.8647 records/second. Loss is 0.29130962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006951202558042541. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23400/60000][Iteration 2195][Wall Clock 106.22581749s] Trained 120 records in 0.043328279 seconds. Throughput is 2769.554 records/second. Loss is 0.28582668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006950236308034473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23520/60000][Iteration 2196][Wall Clock 106.269714886s] Trained 120 records in 0.043897396 seconds. Throughput is 2733.6472 records/second. Loss is 0.3274444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006949270326615705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23640/60000][Iteration 2197][Wall Clock 106.313597276s] Trained 120 records in 0.04388239 seconds. Throughput is 2734.5823 records/second. Loss is 0.26021114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006948304613674263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23760/60000][Iteration 2198][Wall Clock 106.358312072s] Trained 120 records in 0.044714796 seconds. Throughput is 2683.6753 records/second. Loss is 0.3202281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006947339169098236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 23880/60000][Iteration 2199][Wall Clock 106.403238347s] Trained 120 records in 0.044926275 seconds. Throughput is 2671.0427 records/second. Loss is 0.30462566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006946373992775771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 24000/60000][Iteration 2200][Wall Clock 106.446960226s] Trained 120 records in 0.043721879 seconds. Throughput is 2744.621 records/second. Loss is 0.3413066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006945409084595083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 24120/60000][Iteration 2201][Wall Clock 106.490422146s] Trained 120 records in 0.04346192 seconds. Throughput is 2761.0378 records/second. Loss is 0.30554396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006944444444444445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:52 INFO  DistriOptimizer$:406 - [Epoch 5 24240/60000][Iteration 2202][Wall Clock 106.534770391s] Trained 120 records in 0.044348245 seconds. Throughput is 2705.857 records/second. Loss is 0.37374642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006943480072212193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 24360/60000][Iteration 2203][Wall Clock 106.578254846s] Trained 120 records in 0.043484455 seconds. Throughput is 2759.6067 records/second. Loss is 0.28726247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006942515967786726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 24480/60000][Iteration 2204][Wall Clock 106.620921319s] Trained 120 records in 0.042666473 seconds. Throughput is 2812.5127 records/second. Loss is 0.4384295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069415521310565035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 24600/60000][Iteration 2205][Wall Clock 106.66469279s] Trained 120 records in 0.043771471 seconds. Throughput is 2741.5117 records/second. Loss is 0.37230462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00694058856191005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 24720/60000][Iteration 2206][Wall Clock 106.708572499s] Trained 120 records in 0.043879709 seconds. Throughput is 2734.7493 records/second. Loss is 0.32091415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006939625260235947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 24840/60000][Iteration 2207][Wall Clock 106.751190494s] Trained 120 records in 0.042617995 seconds. Throughput is 2815.712 records/second. Loss is 0.325349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006938662225922842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 24960/60000][Iteration 2208][Wall Clock 106.793671991s] Trained 120 records in 0.042481497 seconds. Throughput is 2824.7593 records/second. Loss is 0.3656081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006937699458859442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25080/60000][Iteration 2209][Wall Clock 106.835683851s] Trained 120 records in 0.04201186 seconds. Throughput is 2856.3362 records/second. Loss is 0.3769204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069367369589345175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25200/60000][Iteration 2210][Wall Clock 106.885019483s] Trained 120 records in 0.049335632 seconds. Throughput is 2432.319 records/second. Loss is 0.39816046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006935774726036899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25320/60000][Iteration 2211][Wall Clock 106.947732257s] Trained 120 records in 0.062712774 seconds. Throughput is 1913.4857 records/second. Loss is 0.340629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006934812760055479. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25440/60000][Iteration 2212][Wall Clock 106.995074042s] Trained 120 records in 0.047341785 seconds. Throughput is 2534.7585 records/second. Loss is 0.41437486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006933851060879212. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25560/60000][Iteration 2213][Wall Clock 107.041283593s] Trained 120 records in 0.046209551 seconds. Throughput is 2596.8657 records/second. Loss is 0.39760128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006932889628397116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25680/60000][Iteration 2214][Wall Clock 107.085463416s] Trained 120 records in 0.044179823 seconds. Throughput is 2716.172 records/second. Loss is 0.34461203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006931928462498267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25800/60000][Iteration 2215][Wall Clock 107.131369286s] Trained 120 records in 0.04590587 seconds. Throughput is 2614.045 records/second. Loss is 0.4116871. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006930967563071804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 25920/60000][Iteration 2216][Wall Clock 107.17944674s] Trained 120 records in 0.048077454 seconds. Throughput is 2495.9724 records/second. Loss is 0.46063775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00693000693000693. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26040/60000][Iteration 2217][Wall Clock 107.228216477s] Trained 120 records in 0.048769737 seconds. Throughput is 2460.5422 records/second. Loss is 0.32812986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006929046563192905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26160/60000][Iteration 2218][Wall Clock 107.284213747s] Trained 120 records in 0.05599727 seconds. Throughput is 2142.9617 records/second. Loss is 0.29696688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069280864625190525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26280/60000][Iteration 2219][Wall Clock 107.33125283s] Trained 120 records in 0.047039083 seconds. Throughput is 2551.07 records/second. Loss is 0.31437206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006927126627874758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26400/60000][Iteration 2220][Wall Clock 107.373635587s] Trained 120 records in 0.042382757 seconds. Throughput is 2831.34 records/second. Loss is 0.30536693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006926167059149467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26520/60000][Iteration 2221][Wall Clock 107.416218347s] Trained 120 records in 0.04258276 seconds. Throughput is 2818.0417 records/second. Loss is 0.34112304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006925207756232688. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26640/60000][Iteration 2222][Wall Clock 107.459447473s] Trained 120 records in 0.043229126 seconds. Throughput is 2775.9062 records/second. Loss is 0.38000613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006924248719013987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26760/60000][Iteration 2223][Wall Clock 107.503075041s] Trained 120 records in 0.043627568 seconds. Throughput is 2750.5544 records/second. Loss is 0.3794553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006923289947382997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:53 INFO  DistriOptimizer$:406 - [Epoch 5 26880/60000][Iteration 2224][Wall Clock 107.546306288s] Trained 120 records in 0.043231247 seconds. Throughput is 2775.77 records/second. Loss is 0.4158241. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006922331441229407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27000/60000][Iteration 2225][Wall Clock 107.590209248s] Trained 120 records in 0.04390296 seconds. Throughput is 2733.301 records/second. Loss is 0.36098593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069213732004429675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27120/60000][Iteration 2226][Wall Clock 107.634689518s] Trained 120 records in 0.04448027 seconds. Throughput is 2697.8252 records/second. Loss is 0.38408026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006920415224913495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27240/60000][Iteration 2227][Wall Clock 107.678740088s] Trained 120 records in 0.04405057 seconds. Throughput is 2724.1418 records/second. Loss is 0.3388408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006919457514530861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27360/60000][Iteration 2228][Wall Clock 107.723104756s] Trained 120 records in 0.044364668 seconds. Throughput is 2704.8552 records/second. Loss is 0.3234774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006918500069185001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27480/60000][Iteration 2229][Wall Clock 107.76730233s] Trained 120 records in 0.044197574 seconds. Throughput is 2715.081 records/second. Loss is 0.48503983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00691754288876591. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27600/60000][Iteration 2230][Wall Clock 107.810527595s] Trained 120 records in 0.043225265 seconds. Throughput is 2776.154 records/second. Loss is 0.36832494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006916585973163646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27720/60000][Iteration 2231][Wall Clock 107.852854431s] Trained 120 records in 0.042326836 seconds. Throughput is 2835.0806 records/second. Loss is 0.44193542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006915629322268327. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27840/60000][Iteration 2232][Wall Clock 107.894826262s] Trained 120 records in 0.041971831 seconds. Throughput is 2859.0603 records/second. Loss is 0.29422718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006914672935970128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 27960/60000][Iteration 2233][Wall Clock 107.938460732s] Trained 120 records in 0.04363447 seconds. Throughput is 2750.1194 records/second. Loss is 0.34670243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069137168141592915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28080/60000][Iteration 2234][Wall Clock 107.982391347s] Trained 120 records in 0.043930615 seconds. Throughput is 2731.58 records/second. Loss is 0.38432536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006912760956726116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28200/60000][Iteration 2235][Wall Clock 108.025257543s] Trained 120 records in 0.042866196 seconds. Throughput is 2799.4087 records/second. Loss is 0.41239092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006911805363560962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28320/60000][Iteration 2236][Wall Clock 108.068891748s] Trained 120 records in 0.043634205 seconds. Throughput is 2750.136 records/second. Loss is 0.24374042. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00691085003455425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28440/60000][Iteration 2237][Wall Clock 108.126983666s] Trained 120 records in 0.058091918 seconds. Throughput is 2065.692 records/second. Loss is 0.26938474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006909894969596462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28560/60000][Iteration 2238][Wall Clock 108.173559636s] Trained 120 records in 0.04657597 seconds. Throughput is 2576.4358 records/second. Loss is 0.31506124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00690894016857814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28680/60000][Iteration 2239][Wall Clock 108.217075979s] Trained 120 records in 0.043516343 seconds. Throughput is 2757.5847 records/second. Loss is 0.38776964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006907985631389887. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28800/60000][Iteration 2240][Wall Clock 108.260199639s] Trained 120 records in 0.04312366 seconds. Throughput is 2782.6953 records/second. Loss is 0.29467028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069070313579223655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 28920/60000][Iteration 2241][Wall Clock 108.303581907s] Trained 120 records in 0.043382268 seconds. Throughput is 2766.1072 records/second. Loss is 0.30939326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006906077348066299. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 29040/60000][Iteration 2242][Wall Clock 108.346964746s] Trained 120 records in 0.043382839 seconds. Throughput is 2766.0708 records/second. Loss is 0.33513394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0069051236017124715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 29160/60000][Iteration 2243][Wall Clock 108.390677711s] Trained 120 records in 0.043712965 seconds. Throughput is 2745.181 records/second. Loss is 0.43748236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006904170118751727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 29280/60000][Iteration 2244][Wall Clock 108.433499553s] Trained 120 records in 0.042821842 seconds. Throughput is 2802.308 records/second. Loss is 0.37332374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006903216899074969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 29400/60000][Iteration 2245][Wall Clock 108.483399959s] Trained 120 records in 0.049900406 seconds. Throughput is 2404.79 records/second. Loss is 0.25386456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006902263942573164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:54 INFO  DistriOptimizer$:406 - [Epoch 5 29520/60000][Iteration 2246][Wall Clock 108.529358723s] Trained 120 records in 0.045958764 seconds. Throughput is 2611.0361 records/second. Loss is 0.37992507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006901311249137336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 29640/60000][Iteration 2247][Wall Clock 108.576172956s] Trained 120 records in 0.046814233 seconds. Throughput is 2563.323 records/second. Loss is 0.36460167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00690035881865857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 29760/60000][Iteration 2248][Wall Clock 108.620135101s] Trained 120 records in 0.043962145 seconds. Throughput is 2729.6213 records/second. Loss is 0.32495007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006899406651028011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 29880/60000][Iteration 2249][Wall Clock 108.663629103s] Trained 120 records in 0.043494002 seconds. Throughput is 2759.0012 records/second. Loss is 0.3721219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006898454746136866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30000/60000][Iteration 2250][Wall Clock 108.707391772s] Trained 120 records in 0.043762669 seconds. Throughput is 2742.063 records/second. Loss is 0.37314567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006897503103876397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30120/60000][Iteration 2251][Wall Clock 108.75086094s] Trained 120 records in 0.043469168 seconds. Throughput is 2760.5774 records/second. Loss is 0.41725725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006896551724137932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30240/60000][Iteration 2252][Wall Clock 108.793491676s] Trained 120 records in 0.042630736 seconds. Throughput is 2814.8706 records/second. Loss is 0.35928676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068956006068128526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30360/60000][Iteration 2253][Wall Clock 108.836605311s] Trained 120 records in 0.043113635 seconds. Throughput is 2783.3423 records/second. Loss is 0.2568641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006894649751792608. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30480/60000][Iteration 2254][Wall Clock 108.878265418s] Trained 120 records in 0.041660107 seconds. Throughput is 2880.4534 records/second. Loss is 0.38989475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068936991589687024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30600/60000][Iteration 2255][Wall Clock 108.920438373s] Trained 120 records in 0.042172955 seconds. Throughput is 2845.4255 records/second. Loss is 0.31670502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006892748828232699. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30720/60000][Iteration 2256][Wall Clock 108.96401052s] Trained 120 records in 0.043572147 seconds. Throughput is 2754.053 records/second. Loss is 0.34436512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006891798759476223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30840/60000][Iteration 2257][Wall Clock 109.007044483s] Trained 120 records in 0.043033963 seconds. Throughput is 2788.4954 records/second. Loss is 0.27993155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006890848952590959. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 30960/60000][Iteration 2258][Wall Clock 109.049084301s] Trained 120 records in 0.042039818 seconds. Throughput is 2854.4365 records/second. Loss is 0.3406317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006889899407468651. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31080/60000][Iteration 2259][Wall Clock 109.090481794s] Trained 120 records in 0.041397493 seconds. Throughput is 2898.7263 records/second. Loss is 0.4327439. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006888950124001102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31200/60000][Iteration 2260][Wall Clock 109.132983457s] Trained 120 records in 0.042501663 seconds. Throughput is 2823.419 records/second. Loss is 0.33672172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006888001102080176. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31320/60000][Iteration 2261][Wall Clock 109.174443227s] Trained 120 records in 0.04145977 seconds. Throughput is 2894.372 records/second. Loss is 0.42503357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006887052341597796. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31440/60000][Iteration 2262][Wall Clock 109.216431883s] Trained 120 records in 0.041988656 seconds. Throughput is 2857.9148 records/second. Loss is 0.40627962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006886103842445945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31560/60000][Iteration 2263][Wall Clock 109.265103123s] Trained 120 records in 0.04867124 seconds. Throughput is 2465.5217 records/second. Loss is 0.33623526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006885155604516663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31680/60000][Iteration 2264][Wall Clock 109.314366949s] Trained 120 records in 0.049263826 seconds. Throughput is 2435.8643 records/second. Loss is 0.36971873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068842076277020525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31800/60000][Iteration 2265][Wall Clock 109.359960708s] Trained 120 records in 0.045593759 seconds. Throughput is 2631.9392 records/second. Loss is 0.3293928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006883259911894273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 31920/60000][Iteration 2266][Wall Clock 109.402333877s] Trained 120 records in 0.042373169 seconds. Throughput is 2831.9807 records/second. Loss is 0.4265591. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006882312456985547. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 32040/60000][Iteration 2267][Wall Clock 109.445676666s] Trained 120 records in 0.043342789 seconds. Throughput is 2768.6267 records/second. Loss is 0.2603992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006881365262868153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 32160/60000][Iteration 2268][Wall Clock 109.496801554s] Trained 120 records in 0.051124888 seconds. Throughput is 2347.1934 records/second. Loss is 0.36520085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068804183294344295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:55 INFO  DistriOptimizer$:406 - [Epoch 5 32280/60000][Iteration 2269][Wall Clock 109.539518115s] Trained 120 records in 0.042716561 seconds. Throughput is 2809.2148 records/second. Loss is 0.43930978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068794716565767754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 32400/60000][Iteration 2270][Wall Clock 109.583240218s] Trained 120 records in 0.043722103 seconds. Throughput is 2744.6072 records/second. Loss is 0.37211606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006878525244187647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 32520/60000][Iteration 2271][Wall Clock 109.626544462s] Trained 120 records in 0.043304244 seconds. Throughput is 2771.091 records/second. Loss is 0.35327873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00687757909215956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 32640/60000][Iteration 2272][Wall Clock 109.679154524s] Trained 120 records in 0.052610062 seconds. Throughput is 2280.9324 records/second. Loss is 0.4299202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068766332003850905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 32760/60000][Iteration 2273][Wall Clock 109.721231607s] Trained 120 records in 0.042077083 seconds. Throughput is 2851.9087 records/second. Loss is 0.35456195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006875687568756875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 32880/60000][Iteration 2274][Wall Clock 109.765175649s] Trained 120 records in 0.043944042 seconds. Throughput is 2730.7456 records/second. Loss is 0.42554435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006874742197167606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33000/60000][Iteration 2275][Wall Clock 109.808993142s] Trained 120 records in 0.043817493 seconds. Throughput is 2738.632 records/second. Loss is 0.37485015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006873797085510036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33120/60000][Iteration 2276][Wall Clock 109.852031214s] Trained 120 records in 0.043038072 seconds. Throughput is 2788.229 records/second. Loss is 0.37408337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006872852233676976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33240/60000][Iteration 2277][Wall Clock 109.894163389s] Trained 120 records in 0.042132175 seconds. Throughput is 2848.1794 records/second. Loss is 0.37189415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006871907641561297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33360/60000][Iteration 2278][Wall Clock 109.936254634s] Trained 120 records in 0.042091245 seconds. Throughput is 2850.949 records/second. Loss is 0.2963223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00687096330905593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33480/60000][Iteration 2279][Wall Clock 109.98178015s] Trained 120 records in 0.045525516 seconds. Throughput is 2635.8843 records/second. Loss is 0.29722166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006870019236053861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33600/60000][Iteration 2280][Wall Clock 110.024266369s] Trained 120 records in 0.042486219 seconds. Throughput is 2824.445 records/second. Loss is 0.34997833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006869075422448139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33720/60000][Iteration 2281][Wall Clock 110.066460014s] Trained 120 records in 0.042193645 seconds. Throughput is 2844.0303 records/second. Loss is 0.36102042. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006868131868131869. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33840/60000][Iteration 2282][Wall Clock 110.112732475s] Trained 120 records in 0.046272461 seconds. Throughput is 2593.3352 records/second. Loss is 0.41899845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006867188572998215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 33960/60000][Iteration 2283][Wall Clock 110.154993715s] Trained 120 records in 0.04226124 seconds. Throughput is 2839.4814 records/second. Loss is 0.27411512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006866245536940402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34080/60000][Iteration 2284][Wall Clock 110.196582895s] Trained 120 records in 0.04158918 seconds. Throughput is 2885.366 records/second. Loss is 0.34793174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00686530275985171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34200/60000][Iteration 2285][Wall Clock 110.239054056s] Trained 120 records in 0.042471161 seconds. Throughput is 2825.4468 records/second. Loss is 0.52544147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00686436024162548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34320/60000][Iteration 2286][Wall Clock 110.281153213s] Trained 120 records in 0.042099157 seconds. Throughput is 2850.4136 records/second. Loss is 0.25326723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068634179821551134. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34440/60000][Iteration 2287][Wall Clock 110.322767669s] Trained 120 records in 0.041614456 seconds. Throughput is 2883.6135 records/second. Loss is 0.2686803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006862475981334065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34560/60000][Iteration 2288][Wall Clock 110.364352599s] Trained 120 records in 0.04158493 seconds. Throughput is 2885.6606 records/second. Loss is 0.36865667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006861534239055853. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34680/60000][Iteration 2289][Wall Clock 110.406991268s] Trained 120 records in 0.042638669 seconds. Throughput is 2814.3467 records/second. Loss is 0.26783022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006860592755214051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34800/60000][Iteration 2290][Wall Clock 110.460749596s] Trained 120 records in 0.053758328 seconds. Throughput is 2232.2124 records/second. Loss is 0.26599887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006859651529702291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:56 INFO  DistriOptimizer$:406 - [Epoch 5 34920/60000][Iteration 2291][Wall Clock 110.50926053s] Trained 120 records in 0.048510934 seconds. Throughput is 2473.6692 records/second. Loss is 0.3491095. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006858710562414267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35040/60000][Iteration 2292][Wall Clock 110.55390949s] Trained 120 records in 0.04464896 seconds. Throughput is 2687.6326 records/second. Loss is 0.29270077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006857769853243725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35160/60000][Iteration 2293][Wall Clock 110.596812759s] Trained 120 records in 0.042903269 seconds. Throughput is 2796.9895 records/second. Loss is 0.45416898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006856829402084476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35280/60000][Iteration 2294][Wall Clock 110.63943223s] Trained 120 records in 0.042619471 seconds. Throughput is 2815.6145 records/second. Loss is 0.3643684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006855889208830385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35400/60000][Iteration 2295][Wall Clock 110.681243445s] Trained 120 records in 0.041811215 seconds. Throughput is 2870.0432 records/second. Loss is 0.38657114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006854949273375377. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35520/60000][Iteration 2296][Wall Clock 110.723820134s] Trained 120 records in 0.042576689 seconds. Throughput is 2818.4436 records/second. Loss is 0.4229494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006854009595613434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35640/60000][Iteration 2297][Wall Clock 110.765180817s] Trained 120 records in 0.041360683 seconds. Throughput is 2901.306 records/second. Loss is 0.32699126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006853070175438596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35760/60000][Iteration 2298][Wall Clock 110.813792109s] Trained 120 records in 0.048611292 seconds. Throughput is 2468.5623 records/second. Loss is 0.29577312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006852131012744964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 35880/60000][Iteration 2299][Wall Clock 110.859946036s] Trained 120 records in 0.046153927 seconds. Throughput is 2599.9956 records/second. Loss is 0.41039068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006851192107426692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36000/60000][Iteration 2300][Wall Clock 110.902640994s] Trained 120 records in 0.042694958 seconds. Throughput is 2810.6362 records/second. Loss is 0.39141136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006850253459377997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36120/60000][Iteration 2301][Wall Clock 110.945047941s] Trained 120 records in 0.042406947 seconds. Throughput is 2829.725 records/second. Loss is 0.32001248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006849315068493151. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36240/60000][Iteration 2302][Wall Clock 110.987966086s] Trained 120 records in 0.042918145 seconds. Throughput is 2796.0203 records/second. Loss is 0.38540176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006848376934666485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36360/60000][Iteration 2303][Wall Clock 111.031283643s] Trained 120 records in 0.043317557 seconds. Throughput is 2770.2393 records/second. Loss is 0.5133314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006847439057792386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36480/60000][Iteration 2304][Wall Clock 111.073961148s] Trained 120 records in 0.042677505 seconds. Throughput is 2811.7856 records/second. Loss is 0.40055454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006846501437765303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36600/60000][Iteration 2305][Wall Clock 111.116522667s] Trained 120 records in 0.042561519 seconds. Throughput is 2819.4482 records/second. Loss is 0.3001406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006845564074479737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36720/60000][Iteration 2306][Wall Clock 111.159112018s] Trained 120 records in 0.042589351 seconds. Throughput is 2817.6057 records/second. Loss is 0.38596794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006844626967830253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36840/60000][Iteration 2307][Wall Clock 111.201048527s] Trained 120 records in 0.041936509 seconds. Throughput is 2861.4685 records/second. Loss is 0.52101624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00684369011771147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 36960/60000][Iteration 2308][Wall Clock 111.243097382s] Trained 120 records in 0.042048855 seconds. Throughput is 2853.8232 records/second. Loss is 0.31274357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006842753524018065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 37080/60000][Iteration 2309][Wall Clock 111.285397761s] Trained 120 records in 0.042300379 seconds. Throughput is 2836.854 records/second. Loss is 0.3719791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006841817186644773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 37200/60000][Iteration 2310][Wall Clock 111.32721476s] Trained 120 records in 0.041816999 seconds. Throughput is 2869.6465 records/second. Loss is 0.41016665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006840881105486387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 37320/60000][Iteration 2311][Wall Clock 111.3685985s] Trained 120 records in 0.04138374 seconds. Throughput is 2899.6897 records/second. Loss is 0.35870042. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006839945280437756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 37440/60000][Iteration 2312][Wall Clock 111.410256483s] Trained 120 records in 0.041657983 seconds. Throughput is 2880.6003 records/second. Loss is 0.36407593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00683900971139379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 37560/60000][Iteration 2313][Wall Clock 111.452363233s] Trained 120 records in 0.04210675 seconds. Throughput is 2849.8992 records/second. Loss is 0.34226596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006838074398249452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 37680/60000][Iteration 2314][Wall Clock 111.494209622s] Trained 120 records in 0.041846389 seconds. Throughput is 2867.6309 records/second. Loss is 0.3165012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068371393408997675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:57 INFO  DistriOptimizer$:406 - [Epoch 5 37800/60000][Iteration 2315][Wall Clock 111.535673753s] Trained 120 records in 0.041464131 seconds. Throughput is 2894.0676 records/second. Loss is 0.4744794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006836204539239814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 37920/60000][Iteration 2316][Wall Clock 111.585092701s] Trained 120 records in 0.049418948 seconds. Throughput is 2428.2185 records/second. Loss is 0.3159031. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00683526999316473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38040/60000][Iteration 2317][Wall Clock 111.645373076s] Trained 120 records in 0.060280375 seconds. Throughput is 1990.6976 records/second. Loss is 0.31524175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00683433570256971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38160/60000][Iteration 2318][Wall Clock 111.692427545s] Trained 120 records in 0.047054469 seconds. Throughput is 2550.2358 records/second. Loss is 0.33177873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006833401667350007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38280/60000][Iteration 2319][Wall Clock 111.734086121s] Trained 120 records in 0.041658576 seconds. Throughput is 2880.5593 records/second. Loss is 0.26841578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00683246788740093. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38400/60000][Iteration 2320][Wall Clock 111.775752956s] Trained 120 records in 0.041666835 seconds. Throughput is 2879.9883 records/second. Loss is 0.38047913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006831534362617844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38520/60000][Iteration 2321][Wall Clock 111.818041255s] Trained 120 records in 0.042288299 seconds. Throughput is 2837.6643 records/second. Loss is 0.2910985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068306010928961755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38640/60000][Iteration 2322][Wall Clock 111.859438954s] Trained 120 records in 0.041397699 seconds. Throughput is 2898.712 records/second. Loss is 0.45561373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006829668078131403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38760/60000][Iteration 2323][Wall Clock 111.901574417s] Trained 120 records in 0.042135463 seconds. Throughput is 2847.9573 records/second. Loss is 0.36369148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006828735318219066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 38880/60000][Iteration 2324][Wall Clock 111.943411884s] Trained 120 records in 0.041837467 seconds. Throughput is 2868.2424 records/second. Loss is 0.28167826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00682780281305476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39000/60000][Iteration 2325][Wall Clock 111.994677193s] Trained 120 records in 0.051265309 seconds. Throughput is 2340.7642 records/second. Loss is 0.3564228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006826870562534134. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39120/60000][Iteration 2326][Wall Clock 112.040091851s] Trained 120 records in 0.045414658 seconds. Throughput is 2642.3188 records/second. Loss is 0.2980506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006825938566552901. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39240/60000][Iteration 2327][Wall Clock 112.082412059s] Trained 120 records in 0.042320208 seconds. Throughput is 2835.525 records/second. Loss is 0.3768368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006825006825006825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39360/60000][Iteration 2328][Wall Clock 112.125146812s] Trained 120 records in 0.042734753 seconds. Throughput is 2808.019 records/second. Loss is 0.2888693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006824075337791729. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39480/60000][Iteration 2329][Wall Clock 112.167697957s] Trained 120 records in 0.042551145 seconds. Throughput is 2820.1357 records/second. Loss is 0.349557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006823144104803494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39600/60000][Iteration 2330][Wall Clock 112.209624194s] Trained 120 records in 0.041926237 seconds. Throughput is 2862.1694 records/second. Loss is 0.38813844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006822213125938055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39720/60000][Iteration 2331][Wall Clock 112.251868755s] Trained 120 records in 0.042244561 seconds. Throughput is 2840.6023 records/second. Loss is 0.30484137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068212824010914054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39840/60000][Iteration 2332][Wall Clock 112.293710427s] Trained 120 records in 0.041841672 seconds. Throughput is 2867.9543 records/second. Loss is 0.26869243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006820351930159597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 39960/60000][Iteration 2333][Wall Clock 112.335884918s] Trained 120 records in 0.042174491 seconds. Throughput is 2845.3218 records/second. Loss is 0.2851718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006819421713038734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 40080/60000][Iteration 2334][Wall Clock 112.377952282s] Trained 120 records in 0.042067364 seconds. Throughput is 2852.5676 records/second. Loss is 0.35968268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006818491749624982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 40200/60000][Iteration 2335][Wall Clock 112.42067804s] Trained 120 records in 0.042725758 seconds. Throughput is 2808.6104 records/second. Loss is 0.32076707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006817562039814562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 40320/60000][Iteration 2336][Wall Clock 112.46336765s] Trained 120 records in 0.04268961 seconds. Throughput is 2810.9885 records/second. Loss is 0.32778874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006816632583503749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:58 INFO  DistriOptimizer$:406 - [Epoch 5 40440/60000][Iteration 2337][Wall Clock 112.505129532s] Trained 120 records in 0.041761882 seconds. Throughput is 2873.4336 records/second. Loss is 0.40174595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006815703380588877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 40560/60000][Iteration 2338][Wall Clock 112.547442575s] Trained 120 records in 0.042313043 seconds. Throughput is 2836.005 records/second. Loss is 0.30844948. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006814774430966335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 40680/60000][Iteration 2339][Wall Clock 112.589678296s] Trained 120 records in 0.042235721 seconds. Throughput is 2841.197 records/second. Loss is 0.3428964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00681384573453257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 40800/60000][Iteration 2340][Wall Clock 112.632395211s] Trained 120 records in 0.042716915 seconds. Throughput is 2809.1914 records/second. Loss is 0.26426494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068129172911840855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 40920/60000][Iteration 2341][Wall Clock 112.675859998s] Trained 120 records in 0.043464787 seconds. Throughput is 2760.8555 records/second. Loss is 0.39728492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006811989100817439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41040/60000][Iteration 2342][Wall Clock 112.732940663s] Trained 120 records in 0.057080665 seconds. Throughput is 2102.288 records/second. Loss is 0.3382981. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006811061163329247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41160/60000][Iteration 2343][Wall Clock 112.778555676s] Trained 120 records in 0.045615013 seconds. Throughput is 2630.713 records/second. Loss is 0.29082265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006810133478616182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41280/60000][Iteration 2344][Wall Clock 112.821138783s] Trained 120 records in 0.042583107 seconds. Throughput is 2818.0188 records/second. Loss is 0.38816652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068092060465749695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41400/60000][Iteration 2345][Wall Clock 112.865557525s] Trained 120 records in 0.044418742 seconds. Throughput is 2701.5625 records/second. Loss is 0.3495662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006808278867102396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41520/60000][Iteration 2346][Wall Clock 112.907631102s] Trained 120 records in 0.042073577 seconds. Throughput is 2852.1462 records/second. Loss is 0.27397892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068073519400953025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41640/60000][Iteration 2347][Wall Clock 112.95038044s] Trained 120 records in 0.042749338 seconds. Throughput is 2807.061 records/second. Loss is 0.32475516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006806425265450586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41760/60000][Iteration 2348][Wall Clock 112.993897692s] Trained 120 records in 0.043517252 seconds. Throughput is 2757.527 records/second. Loss is 0.26229465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006805498843065197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 41880/60000][Iteration 2349][Wall Clock 113.036380764s] Trained 120 records in 0.042483072 seconds. Throughput is 2824.6545 records/second. Loss is 0.4184791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006804572672836146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42000/60000][Iteration 2350][Wall Clock 113.078120547s] Trained 120 records in 0.041739783 seconds. Throughput is 2874.955 records/second. Loss is 0.33840504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006803646754660498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42120/60000][Iteration 2351][Wall Clock 113.132171751s] Trained 120 records in 0.054051204 seconds. Throughput is 2220.117 records/second. Loss is 0.35668913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006802721088435375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42240/60000][Iteration 2352][Wall Clock 113.177848528s] Trained 120 records in 0.045676777 seconds. Throughput is 2627.1558 records/second. Loss is 0.33746225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006801795674057952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42360/60000][Iteration 2353][Wall Clock 113.219698267s] Trained 120 records in 0.041849739 seconds. Throughput is 2867.4014 records/second. Loss is 0.28184435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0068008705114254615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42480/60000][Iteration 2354][Wall Clock 113.26119909s] Trained 120 records in 0.041500823 seconds. Throughput is 2891.509 records/second. Loss is 0.25641444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006799945600435196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42600/60000][Iteration 2355][Wall Clock 113.302468219s] Trained 120 records in 0.041269129 seconds. Throughput is 2907.7427 records/second. Loss is 0.39862052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006799020940984498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42720/60000][Iteration 2356][Wall Clock 113.343729164s] Trained 120 records in 0.041260945 seconds. Throughput is 2908.319 records/second. Loss is 0.4295304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006798096532970768. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42840/60000][Iteration 2357][Wall Clock 113.385564535s] Trained 120 records in 0.041835371 seconds. Throughput is 2868.3862 records/second. Loss is 0.31040803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006797172376291463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 42960/60000][Iteration 2358][Wall Clock 113.427615883s] Trained 120 records in 0.042051348 seconds. Throughput is 2853.654 records/second. Loss is 0.36999366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006796248470844094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 43080/60000][Iteration 2359][Wall Clock 113.46936649s] Trained 120 records in 0.041750607 seconds. Throughput is 2874.2097 records/second. Loss is 0.44894212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00679532481652623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:54:59 INFO  DistriOptimizer$:406 - [Epoch 5 43200/60000][Iteration 2360][Wall Clock 113.510651395s] Trained 120 records in 0.041284905 seconds. Throughput is 2906.6313 records/second. Loss is 0.37052548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006794401413235494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 43320/60000][Iteration 2361][Wall Clock 113.552092457s] Trained 120 records in 0.041441062 seconds. Throughput is 2895.6787 records/second. Loss is 0.295984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006793478260869566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 43440/60000][Iteration 2362][Wall Clock 113.593549824s] Trained 120 records in 0.041457367 seconds. Throughput is 2894.5398 records/second. Loss is 0.36150768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006792555359326179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 43560/60000][Iteration 2363][Wall Clock 113.634892858s] Trained 120 records in 0.041343034 seconds. Throughput is 2902.5447 records/second. Loss is 0.29688403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006791632708503125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 43680/60000][Iteration 2364][Wall Clock 113.676527367s] Trained 120 records in 0.041634509 seconds. Throughput is 2882.2246 records/second. Loss is 0.37284675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006790710308298248. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 43800/60000][Iteration 2365][Wall Clock 113.718355342s] Trained 120 records in 0.041827975 seconds. Throughput is 2868.8933 records/second. Loss is 0.33188632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006789788158609452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 43920/60000][Iteration 2366][Wall Clock 113.760243955s] Trained 120 records in 0.041888613 seconds. Throughput is 2864.7402 records/second. Loss is 0.45915183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006788866259334691. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44040/60000][Iteration 2367][Wall Clock 113.809272166s] Trained 120 records in 0.049028211 seconds. Throughput is 2447.5706 records/second. Loss is 0.37868723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006787944610371979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44160/60000][Iteration 2368][Wall Clock 113.858768606s] Trained 120 records in 0.04949644 seconds. Throughput is 2424.4167 records/second. Loss is 0.38340348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006787023211619384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44280/60000][Iteration 2369][Wall Clock 113.900664734s] Trained 120 records in 0.041896128 seconds. Throughput is 2864.2266 records/second. Loss is 0.32639226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067861020629750276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44400/60000][Iteration 2370][Wall Clock 113.942337213s] Trained 120 records in 0.041672479 seconds. Throughput is 2879.5984 records/second. Loss is 0.34557745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006785181164337088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44520/60000][Iteration 2371][Wall Clock 113.984984415s] Trained 120 records in 0.042647202 seconds. Throughput is 2813.7837 records/second. Loss is 0.3225895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067842605156037995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44640/60000][Iteration 2372][Wall Clock 114.027720543s] Trained 120 records in 0.042736128 seconds. Throughput is 2807.9287 records/second. Loss is 0.34050888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00678334011667345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44760/60000][Iteration 2373][Wall Clock 114.069777692s] Trained 120 records in 0.042057149 seconds. Throughput is 2853.2605 records/second. Loss is 0.29056597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006782419967444384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 44880/60000][Iteration 2374][Wall Clock 114.112298094s] Trained 120 records in 0.042520402 seconds. Throughput is 2822.1746 records/second. Loss is 0.2535697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006781500067815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45000/60000][Iteration 2375][Wall Clock 114.153493877s] Trained 120 records in 0.041195783 seconds. Throughput is 2912.9194 records/second. Loss is 0.23748961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067805804176837535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45120/60000][Iteration 2376][Wall Clock 114.195088286s] Trained 120 records in 0.041594409 seconds. Throughput is 2885.0032 records/second. Loss is 0.33155644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006779661016949152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45240/60000][Iteration 2377][Wall Clock 114.236794739s] Trained 120 records in 0.041706453 seconds. Throughput is 2877.2524 records/second. Loss is 0.32417428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067787418655097615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45360/60000][Iteration 2378][Wall Clock 114.290192488s] Trained 120 records in 0.053397749 seconds. Throughput is 2247.2856 records/second. Loss is 0.39425695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067778229632641995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45480/60000][Iteration 2379][Wall Clock 114.333288238s] Trained 120 records in 0.04309575 seconds. Throughput is 2784.4973 records/second. Loss is 0.2918097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006776904310111141. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45600/60000][Iteration 2380][Wall Clock 114.375088677s] Trained 120 records in 0.041800439 seconds. Throughput is 2870.7832 records/second. Loss is 0.3950796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067759859059493156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45720/60000][Iteration 2381][Wall Clock 114.416837153s] Trained 120 records in 0.041748476 seconds. Throughput is 2874.3564 records/second. Loss is 0.3220435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006775067750677507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45840/60000][Iteration 2382][Wall Clock 114.458711654s] Trained 120 records in 0.041874501 seconds. Throughput is 2865.7058 records/second. Loss is 0.2752439. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006774149844194554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:00 INFO  DistriOptimizer$:406 - [Epoch 5 45960/60000][Iteration 2383][Wall Clock 114.500221714s] Trained 120 records in 0.04151006 seconds. Throughput is 2890.8655 records/second. Loss is 0.36944813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067732321863993505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46080/60000][Iteration 2384][Wall Clock 114.542031241s] Trained 120 records in 0.041809527 seconds. Throughput is 2870.1594 records/second. Loss is 0.3629965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006772314777190844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46200/60000][Iteration 2385][Wall Clock 114.587434803s] Trained 120 records in 0.045403562 seconds. Throughput is 2642.9644 records/second. Loss is 0.4138805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00677139761646804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46320/60000][Iteration 2386][Wall Clock 114.628957139s] Trained 120 records in 0.041522336 seconds. Throughput is 2890.0107 records/second. Loss is 0.35063854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006770480704129993. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46440/60000][Iteration 2387][Wall Clock 114.670244637s] Trained 120 records in 0.041287498 seconds. Throughput is 2906.449 records/second. Loss is 0.29720822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006769564040075819. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46560/60000][Iteration 2388][Wall Clock 114.711960991s] Trained 120 records in 0.041716354 seconds. Throughput is 2876.5696 records/second. Loss is 0.31099418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006768647624204684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46680/60000][Iteration 2389][Wall Clock 114.754576346s] Trained 120 records in 0.042615355 seconds. Throughput is 2815.8865 records/second. Loss is 0.3408972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00676773145641581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46800/60000][Iteration 2390][Wall Clock 114.796167455s] Trained 120 records in 0.041591109 seconds. Throughput is 2885.2322 records/second. Loss is 0.334281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006766815536608472. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 46920/60000][Iteration 2391][Wall Clock 114.837304905s] Trained 120 records in 0.04113745 seconds. Throughput is 2917.05 records/second. Loss is 0.40126705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006765899864682003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47040/60000][Iteration 2392][Wall Clock 114.888643494s] Trained 120 records in 0.051338589 seconds. Throughput is 2337.4229 records/second. Loss is 0.29737365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067649844405357875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47160/60000][Iteration 2393][Wall Clock 114.939364718s] Trained 120 records in 0.050721224 seconds. Throughput is 2365.8735 records/second. Loss is 0.3560632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006764069264069263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47280/60000][Iteration 2394][Wall Clock 114.981726742s] Trained 120 records in 0.042362024 seconds. Throughput is 2832.7258 records/second. Loss is 0.35971245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006763154335181929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47400/60000][Iteration 2395][Wall Clock 115.023279044s] Trained 120 records in 0.041552302 seconds. Throughput is 2887.9268 records/second. Loss is 0.40302235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067622396537733295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47520/60000][Iteration 2396][Wall Clock 115.06466143s] Trained 120 records in 0.041382386 seconds. Throughput is 2899.7844 records/second. Loss is 0.3011605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067613252197430695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47640/60000][Iteration 2397][Wall Clock 115.106487328s] Trained 120 records in 0.041825898 seconds. Throughput is 2869.036 records/second. Loss is 0.42669076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006760411032990805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47760/60000][Iteration 2398][Wall Clock 115.14773014s] Trained 120 records in 0.041242812 seconds. Throughput is 2909.598 records/second. Loss is 0.3883483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00675949709341625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 47880/60000][Iteration 2399][Wall Clock 115.188728947s] Trained 120 records in 0.040998807 seconds. Throughput is 2926.9146 records/second. Loss is 0.2915253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006758583400919167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 48000/60000][Iteration 2400][Wall Clock 115.230320951s] Trained 120 records in 0.041592004 seconds. Throughput is 2885.17 records/second. Loss is 0.3058858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067576699553993785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 48120/60000][Iteration 2401][Wall Clock 115.271568824s] Trained 120 records in 0.041247873 seconds. Throughput is 2909.2407 records/second. Loss is 0.28143406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006756756756756757. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 48240/60000][Iteration 2402][Wall Clock 115.312339523s] Trained 120 records in 0.040770699 seconds. Throughput is 2943.2903 records/second. Loss is 0.38584027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006755843804891231. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 48360/60000][Iteration 2403][Wall Clock 115.353356772s] Trained 120 records in 0.041017249 seconds. Throughput is 2925.5984 records/second. Loss is 0.41503412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006754931099702784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 48480/60000][Iteration 2404][Wall Clock 115.40412635s] Trained 120 records in 0.050769578 seconds. Throughput is 2363.62 records/second. Loss is 0.36227313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067540186410914495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 48600/60000][Iteration 2405][Wall Clock 115.4516522s] Trained 120 records in 0.04752585 seconds. Throughput is 2524.9417 records/second. Loss is 0.35548684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006753106428957321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:01 INFO  DistriOptimizer$:406 - [Epoch 5 48720/60000][Iteration 2406][Wall Clock 115.493848276s] Trained 120 records in 0.042196076 seconds. Throughput is 2843.8662 records/second. Loss is 0.29174232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00675219446320054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 48840/60000][Iteration 2407][Wall Clock 115.535488572s] Trained 120 records in 0.041640296 seconds. Throughput is 2881.824 records/second. Loss is 0.27988493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006751282743721307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 48960/60000][Iteration 2408][Wall Clock 115.577723216s] Trained 120 records in 0.042234644 seconds. Throughput is 2841.2693 records/second. Loss is 0.37160745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006750371270419873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49080/60000][Iteration 2409][Wall Clock 115.61999531s] Trained 120 records in 0.042272094 seconds. Throughput is 2838.7522 records/second. Loss is 0.40165547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006749460043196544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49200/60000][Iteration 2410][Wall Clock 115.662834195s] Trained 120 records in 0.042838885 seconds. Throughput is 2801.1934 records/second. Loss is 0.38680914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00674854906195168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49320/60000][Iteration 2411][Wall Clock 115.704930172s] Trained 120 records in 0.042095977 seconds. Throughput is 2850.6287 records/second. Loss is 0.41782758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006747638326585695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49440/60000][Iteration 2412][Wall Clock 115.7467505s] Trained 120 records in 0.041820328 seconds. Throughput is 2869.418 records/second. Loss is 0.32377192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006746727836999056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49560/60000][Iteration 2413][Wall Clock 115.788184524s] Trained 120 records in 0.041434024 seconds. Throughput is 2896.1707 records/second. Loss is 0.36522076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006745817593092283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49680/60000][Iteration 2414][Wall Clock 115.829586088s] Trained 120 records in 0.041401564 seconds. Throughput is 2898.4412 records/second. Loss is 0.3496877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006744907594765951. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49800/60000][Iteration 2415][Wall Clock 115.871356745s] Trained 120 records in 0.041770657 seconds. Throughput is 2872.83 records/second. Loss is 0.26725146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00674399784192069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 49920/60000][Iteration 2416][Wall Clock 115.913790447s] Trained 120 records in 0.042433702 seconds. Throughput is 2827.941 records/second. Loss is 0.4066827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006743088334457181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50040/60000][Iteration 2417][Wall Clock 115.965733469s] Trained 120 records in 0.051943022 seconds. Throughput is 2310.2236 records/second. Loss is 0.3575402. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006742179072276159. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50160/60000][Iteration 2418][Wall Clock 116.035635196s] Trained 120 records in 0.069901727 seconds. Throughput is 1716.6958 records/second. Loss is 0.320936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006741270055278414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50280/60000][Iteration 2419][Wall Clock 116.085447572s] Trained 120 records in 0.049812376 seconds. Throughput is 2409.0398 records/second. Loss is 0.29931104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067403612833647885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50400/60000][Iteration 2420][Wall Clock 116.129346492s] Trained 120 records in 0.04389892 seconds. Throughput is 2733.5522 records/second. Loss is 0.2331598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067394527564361775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50520/60000][Iteration 2421][Wall Clock 116.17165669s] Trained 120 records in 0.042310198 seconds. Throughput is 2836.1958 records/second. Loss is 0.23957208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006738544474393531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50640/60000][Iteration 2422][Wall Clock 116.214094642s] Trained 120 records in 0.042437952 seconds. Throughput is 2827.6577 records/second. Loss is 0.35281786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006737636437137852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50760/60000][Iteration 2423][Wall Clock 116.25715124s] Trained 120 records in 0.043056598 seconds. Throughput is 2787.0293 records/second. Loss is 0.43106398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006736728644570197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 50880/60000][Iteration 2424][Wall Clock 116.300788869s] Trained 120 records in 0.043637629 seconds. Throughput is 2749.9202 records/second. Loss is 0.2984196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006735821096591675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 51000/60000][Iteration 2425][Wall Clock 116.344578878s] Trained 120 records in 0.043790009 seconds. Throughput is 2740.351 records/second. Loss is 0.33802453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006734913793103449. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 51120/60000][Iteration 2426][Wall Clock 116.387279443s] Trained 120 records in 0.042700565 seconds. Throughput is 2810.267 records/second. Loss is 0.2593244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006734006734006734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 51240/60000][Iteration 2427][Wall Clock 116.428987236s] Trained 120 records in 0.041707793 seconds. Throughput is 2877.1602 records/second. Loss is 0.43862122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006733099919202801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 51360/60000][Iteration 2428][Wall Clock 116.470692216s] Trained 120 records in 0.04170498 seconds. Throughput is 2877.3542 records/second. Loss is 0.2392113. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006732193348592971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:02 INFO  DistriOptimizer$:406 - [Epoch 5 51480/60000][Iteration 2429][Wall Clock 116.512042333s] Trained 120 records in 0.041350117 seconds. Throughput is 2902.0474 records/second. Loss is 0.3121533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006731287022078622. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 51600/60000][Iteration 2430][Wall Clock 116.554324128s] Trained 120 records in 0.042281795 seconds. Throughput is 2838.1008 records/second. Loss is 0.37637153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006730380939561179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 51720/60000][Iteration 2431][Wall Clock 116.604970604s] Trained 120 records in 0.050646476 seconds. Throughput is 2369.3652 records/second. Loss is 0.3404326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006729475100942127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 51840/60000][Iteration 2432][Wall Clock 116.653658669s] Trained 120 records in 0.048688065 seconds. Throughput is 2464.6697 records/second. Loss is 0.37588227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006728569506122999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 51960/60000][Iteration 2433][Wall Clock 116.696122567s] Trained 120 records in 0.042463898 seconds. Throughput is 2825.93 records/second. Loss is 0.37398237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006727664155005382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52080/60000][Iteration 2434][Wall Clock 116.738261623s] Trained 120 records in 0.042139056 seconds. Throughput is 2847.7144 records/second. Loss is 0.36068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006726759047490918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52200/60000][Iteration 2435][Wall Clock 116.780286161s] Trained 120 records in 0.042024538 seconds. Throughput is 2855.4746 records/second. Loss is 0.38606307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006725854183481302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52320/60000][Iteration 2436][Wall Clock 116.821882837s] Trained 120 records in 0.041596676 seconds. Throughput is 2884.8457 records/second. Loss is 0.35285276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006724949562878278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52440/60000][Iteration 2437][Wall Clock 116.863749627s] Trained 120 records in 0.04186679 seconds. Throughput is 2866.2336 records/second. Loss is 0.3244349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006724045185583647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52560/60000][Iteration 2438][Wall Clock 116.905914147s] Trained 120 records in 0.04216452 seconds. Throughput is 2845.9946 records/second. Loss is 0.24833632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006723141051499261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52680/60000][Iteration 2439][Wall Clock 116.947909736s] Trained 120 records in 0.041995589 seconds. Throughput is 2857.4429 records/second. Loss is 0.35452712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006722237160527024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52800/60000][Iteration 2440][Wall Clock 116.990730427s] Trained 120 records in 0.042820691 seconds. Throughput is 2802.3835 records/second. Loss is 0.3985147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006721333512568894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 52920/60000][Iteration 2441][Wall Clock 117.034873998s] Trained 120 records in 0.044143571 seconds. Throughput is 2718.4026 records/second. Loss is 0.47888306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006720430107526882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53040/60000][Iteration 2442][Wall Clock 117.079414616s] Trained 120 records in 0.044540618 seconds. Throughput is 2694.1702 records/second. Loss is 0.3781457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006719526945303051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53160/60000][Iteration 2443][Wall Clock 117.135417751s] Trained 120 records in 0.056003135 seconds. Throughput is 2142.7373 records/second. Loss is 0.38096726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067186240257995165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53280/60000][Iteration 2444][Wall Clock 117.1796994s] Trained 120 records in 0.044281649 seconds. Throughput is 2709.926 records/second. Loss is 0.3336108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006717721348918447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53400/60000][Iteration 2445][Wall Clock 117.221478444s] Trained 120 records in 0.041779044 seconds. Throughput is 2872.2534 records/second. Loss is 0.29826394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006716818914562064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53520/60000][Iteration 2446][Wall Clock 117.264577759s] Trained 120 records in 0.043099315 seconds. Throughput is 2784.267 records/second. Loss is 0.30642682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006715916722632639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53640/60000][Iteration 2447][Wall Clock 117.306831236s] Trained 120 records in 0.042253477 seconds. Throughput is 2840.0032 records/second. Loss is 0.26816842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067150147730325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53760/60000][Iteration 2448][Wall Clock 117.348952777s] Trained 120 records in 0.042121541 seconds. Throughput is 2848.8987 records/second. Loss is 0.36813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006714113065664025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 53880/60000][Iteration 2449][Wall Clock 117.391250224s] Trained 120 records in 0.042297447 seconds. Throughput is 2837.0508 records/second. Loss is 0.29977456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006713211600429645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 54000/60000][Iteration 2450][Wall Clock 117.433562029s] Trained 120 records in 0.042311805 seconds. Throughput is 2836.088 records/second. Loss is 0.33940086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006712310377231843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:03 INFO  DistriOptimizer$:406 - [Epoch 5 54120/60000][Iteration 2451][Wall Clock 117.47648231s] Trained 120 records in 0.042920281 seconds. Throughput is 2795.881 records/second. Loss is 0.24010338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006711409395973154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 54240/60000][Iteration 2452][Wall Clock 117.52209669s] Trained 120 records in 0.04561438 seconds. Throughput is 2630.7493 records/second. Loss is 0.26880667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067105086565561675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 54360/60000][Iteration 2453][Wall Clock 117.564034935s] Trained 120 records in 0.041938245 seconds. Throughput is 2861.35 records/second. Loss is 0.2869369. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0067096081588835215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 54480/60000][Iteration 2454][Wall Clock 117.605800213s] Trained 120 records in 0.041765278 seconds. Throughput is 2873.2002 records/second. Loss is 0.28996304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006708707902857909. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 54600/60000][Iteration 2455][Wall Clock 117.646992717s] Trained 120 records in 0.041192504 seconds. Throughput is 2913.1514 records/second. Loss is 0.3700464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006707807888382076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 54720/60000][Iteration 2456][Wall Clock 117.688757924s] Trained 120 records in 0.041765207 seconds. Throughput is 2873.205 records/second. Loss is 0.3124877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006706908115358819. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 54840/60000][Iteration 2457][Wall Clock 117.730473061s] Trained 120 records in 0.041715137 seconds. Throughput is 2876.6536 records/second. Loss is 0.27105695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006706008583690987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 54960/60000][Iteration 2458][Wall Clock 117.783903378s] Trained 120 records in 0.053430317 seconds. Throughput is 2245.9158 records/second. Loss is 0.40506345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006705109293281481. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55080/60000][Iteration 2459][Wall Clock 117.828704809s] Trained 120 records in 0.044801431 seconds. Throughput is 2678.4858 records/second. Loss is 0.35375324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006704210244033253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55200/60000][Iteration 2460][Wall Clock 117.870314627s] Trained 120 records in 0.041609818 seconds. Throughput is 2883.9348 records/second. Loss is 0.41358545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00670331143584931. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55320/60000][Iteration 2461][Wall Clock 117.912385664s] Trained 120 records in 0.042071037 seconds. Throughput is 2852.3186 records/second. Loss is 0.26110086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006702412868632708. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55440/60000][Iteration 2462][Wall Clock 117.954639553s] Trained 120 records in 0.042253889 seconds. Throughput is 2839.9753 records/second. Loss is 0.35493946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006701514542286557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55560/60000][Iteration 2463][Wall Clock 117.997846048s] Trained 120 records in 0.043206495 seconds. Throughput is 2777.3604 records/second. Loss is 0.33786258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006700616456714018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55680/60000][Iteration 2464][Wall Clock 118.041353348s] Trained 120 records in 0.0435073 seconds. Throughput is 2758.1577 records/second. Loss is 0.2460323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006699718611818304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55800/60000][Iteration 2465][Wall Clock 118.08452182s] Trained 120 records in 0.043168472 seconds. Throughput is 2779.8066 records/second. Loss is 0.29360193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00669882100750268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 55920/60000][Iteration 2466][Wall Clock 118.128525541s] Trained 120 records in 0.044003721 seconds. Throughput is 2727.042 records/second. Loss is 0.30316606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006697923643670462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56040/60000][Iteration 2467][Wall Clock 118.171754182s] Trained 120 records in 0.043228641 seconds. Throughput is 2775.9373 records/second. Loss is 0.43388262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00669702652022502. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56160/60000][Iteration 2468][Wall Clock 118.21998619s] Trained 120 records in 0.048232008 seconds. Throughput is 2487.9744 records/second. Loss is 0.35569614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006696129637069773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56280/60000][Iteration 2469][Wall Clock 118.26355891s] Trained 120 records in 0.04357272 seconds. Throughput is 2754.0168 records/second. Loss is 0.32406345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006695232994108195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56400/60000][Iteration 2470][Wall Clock 118.305428447s] Trained 120 records in 0.041869537 seconds. Throughput is 2866.0457 records/second. Loss is 0.34222844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006694336591243808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56520/60000][Iteration 2471][Wall Clock 118.347340031s] Trained 120 records in 0.041911584 seconds. Throughput is 2863.1702 records/second. Loss is 0.28029233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006693440428380187. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56640/60000][Iteration 2472][Wall Clock 118.388989091s] Trained 120 records in 0.04164906 seconds. Throughput is 2881.2175 records/second. Loss is 0.43252888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006692544505420961. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56760/60000][Iteration 2473][Wall Clock 118.430789717s] Trained 120 records in 0.041800626 seconds. Throughput is 2870.7705 records/second. Loss is 0.27159795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066916488222698075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:04 INFO  DistriOptimizer$:406 - [Epoch 5 56880/60000][Iteration 2474][Wall Clock 118.47303582s] Trained 120 records in 0.042246103 seconds. Throughput is 2840.4988 records/second. Loss is 0.24133658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066907533788304555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57000/60000][Iteration 2475][Wall Clock 118.51587968s] Trained 120 records in 0.04284386 seconds. Throughput is 2800.8682 records/second. Loss is 0.32089603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00668985817500669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57120/60000][Iteration 2476][Wall Clock 118.56095515s] Trained 120 records in 0.04507547 seconds. Throughput is 2662.202 records/second. Loss is 0.41439062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006688963210702341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57240/60000][Iteration 2477][Wall Clock 118.605692606s] Trained 120 records in 0.044737456 seconds. Throughput is 2682.3162 records/second. Loss is 0.35236853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006688068485821295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57360/60000][Iteration 2478][Wall Clock 118.65023776s] Trained 120 records in 0.044545154 seconds. Throughput is 2693.8958 records/second. Loss is 0.3241594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006687174000267487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57480/60000][Iteration 2479][Wall Clock 118.694463004s] Trained 120 records in 0.044225244 seconds. Throughput is 2713.3823 records/second. Loss is 0.3524212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006686279753944905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57600/60000][Iteration 2480][Wall Clock 118.736646998s] Trained 120 records in 0.042183994 seconds. Throughput is 2844.6807 records/second. Loss is 0.39669636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006685385746757588. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57720/60000][Iteration 2481][Wall Clock 118.779035633s] Trained 120 records in 0.042388635 seconds. Throughput is 2830.9473 records/second. Loss is 0.30440357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066844919786096255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57840/60000][Iteration 2482][Wall Clock 118.82077667s] Trained 120 records in 0.041741037 seconds. Throughput is 2874.8687 records/second. Loss is 0.38841814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00668359844940516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 57960/60000][Iteration 2483][Wall Clock 118.862576959s] Trained 120 records in 0.041800289 seconds. Throughput is 2870.7935 records/second. Loss is 0.37692073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066827051590483836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58080/60000][Iteration 2484][Wall Clock 118.905864183s] Trained 120 records in 0.043287224 seconds. Throughput is 2772.1804 records/second. Loss is 0.3436294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006681812107443539. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58200/60000][Iteration 2485][Wall Clock 118.965136106s] Trained 120 records in 0.059271923 seconds. Throughput is 2024.5673 records/second. Loss is 0.30120298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006680919294494923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58320/60000][Iteration 2486][Wall Clock 119.012188528s] Trained 120 records in 0.047052422 seconds. Throughput is 2550.347 records/second. Loss is 0.43015558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006680026720106881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58440/60000][Iteration 2487][Wall Clock 119.054452201s] Trained 120 records in 0.042263673 seconds. Throughput is 2839.3179 records/second. Loss is 0.3695825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066791343841838095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58560/60000][Iteration 2488][Wall Clock 119.096477734s] Trained 120 records in 0.042025533 seconds. Throughput is 2855.407 records/second. Loss is 0.26295182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006678242286630159. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58680/60000][Iteration 2489][Wall Clock 119.139157473s] Trained 120 records in 0.042679739 seconds. Throughput is 2811.6387 records/second. Loss is 0.26388904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006677350427350427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58800/60000][Iteration 2490][Wall Clock 119.181620437s] Trained 120 records in 0.042462964 seconds. Throughput is 2825.9922 records/second. Loss is 0.34230804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006676458806249165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 58920/60000][Iteration 2491][Wall Clock 119.223536123s] Trained 120 records in 0.041915686 seconds. Throughput is 2862.8901 records/second. Loss is 0.3519521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006675567423230975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 59040/60000][Iteration 2492][Wall Clock 119.266403533s] Trained 120 records in 0.04286741 seconds. Throughput is 2799.3293 records/second. Loss is 0.22642796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006674676278200508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 59160/60000][Iteration 2493][Wall Clock 119.317351149s] Trained 120 records in 0.050947616 seconds. Throughput is 2355.3604 records/second. Loss is 0.4476881. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006673785371062467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 59280/60000][Iteration 2494][Wall Clock 119.362051157s] Trained 120 records in 0.044700008 seconds. Throughput is 2684.5632 records/second. Loss is 0.37010017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066728947017216066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 59400/60000][Iteration 2495][Wall Clock 119.403937373s] Trained 120 records in 0.041886216 seconds. Throughput is 2864.9043 records/second. Loss is 0.45526516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006672004270082733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 59520/60000][Iteration 2496][Wall Clock 119.446119691s] Trained 120 records in 0.042182318 seconds. Throughput is 2844.7937 records/second. Loss is 0.29854918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066711140760507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:05 INFO  DistriOptimizer$:406 - [Epoch 5 59640/60000][Iteration 2497][Wall Clock 119.4887374s] Trained 120 records in 0.042617709 seconds. Throughput is 2815.731 records/second. Loss is 0.38308147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006670224119530416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:06 INFO  DistriOptimizer$:406 - [Epoch 5 59760/60000][Iteration 2498][Wall Clock 119.531438953s] Trained 120 records in 0.042701553 seconds. Throughput is 2810.2021 records/second. Loss is 0.41412488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006669334400426837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:06 INFO  DistriOptimizer$:406 - [Epoch 5 59880/60000][Iteration 2499][Wall Clock 119.573300504s] Trained 120 records in 0.041861551 seconds. Throughput is 2866.5923 records/second. Loss is 0.38708344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006668444918644972. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:06 INFO  DistriOptimizer$:406 - [Epoch 5 60000/60000][Iteration 2500][Wall Clock 119.614844682s] Trained 120 records in 0.041544178 seconds. Throughput is 2888.4915 records/second. Loss is 0.3463435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006667555674089879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:06 INFO  DistriOptimizer$:451 - [Epoch 5 60000/60000][Iteration 2500][Wall Clock 119.614844682s] Epoch finished. Wall clock time is 120428.989105 ms
2019-10-23 15:55:06 INFO  DistriOptimizer$:111 - [Epoch 5 60000/60000][Iteration 2500][Wall Clock 119.614844682s] Validate model...
2019-10-23 15:55:06 INFO  DistriOptimizer$:177 - [Epoch 5 60000/60000][Iteration 2500][Wall Clock 119.614844682s] validate model throughput is 14563.413 records/second
2019-10-23 15:55:06 INFO  DistriOptimizer$:180 - [Epoch 5 60000/60000][Iteration 2500][Wall Clock 119.614844682s] Top1Accuracy is Accuracy(correct: 9156, count: 10000, accuracy: 0.9156)
2019-10-23 15:55:06 INFO  DistriOptimizer$:220 - [Wall Clock 120.428989105s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:55:06 INFO  DistriOptimizer$:225 - [Wall Clock 120.428989105s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:55:06 INFO  DistriOptimizer$:406 - [Epoch 6 120/60000][Iteration 2501][Wall Clock 120.477237421s] Trained 120 records in 0.048248316 seconds. Throughput is 2487.1333 records/second. Loss is 0.3346571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006666666666666667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:06 INFO  DistriOptimizer$:406 - [Epoch 6 240/60000][Iteration 2502][Wall Clock 120.519337588s] Trained 120 records in 0.042100167 seconds. Throughput is 2850.345 records/second. Loss is 0.3502536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006665777896280496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:06 INFO  DistriOptimizer$:406 - [Epoch 6 360/60000][Iteration 2503][Wall Clock 120.560347589s] Trained 120 records in 0.041010001 seconds. Throughput is 2926.1155 records/second. Loss is 0.37018824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006664889362836577. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 480/60000][Iteration 2504][Wall Clock 120.603059434s] Trained 120 records in 0.042711845 seconds. Throughput is 2809.525 records/second. Loss is 0.3045115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066640010662401715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 600/60000][Iteration 2505][Wall Clock 120.644509602s] Trained 120 records in 0.041450168 seconds. Throughput is 2895.0425 records/second. Loss is 0.26802957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006663113006396589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 720/60000][Iteration 2506][Wall Clock 120.68602106s] Trained 120 records in 0.041511458 seconds. Throughput is 2890.768 records/second. Loss is 0.35090435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066622251832111935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 840/60000][Iteration 2507][Wall Clock 120.726711465s] Trained 120 records in 0.040690405 seconds. Throughput is 2949.0984 records/second. Loss is 0.2757159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006661337596589396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 960/60000][Iteration 2508][Wall Clock 120.768352117s] Trained 120 records in 0.041640652 seconds. Throughput is 2881.7993 records/second. Loss is 0.30620793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006660450246436659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1080/60000][Iteration 2509][Wall Clock 120.809365447s] Trained 120 records in 0.04101333 seconds. Throughput is 2925.878 records/second. Loss is 0.25284532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006659563132658497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1200/60000][Iteration 2510][Wall Clock 120.861126363s] Trained 120 records in 0.051760916 seconds. Throughput is 2318.3516 records/second. Loss is 0.36292753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006658676255160474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1320/60000][Iteration 2511][Wall Clock 120.908608913s] Trained 120 records in 0.04748255 seconds. Throughput is 2527.2441 records/second. Loss is 0.30058235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006657789613848202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1440/60000][Iteration 2512][Wall Clock 120.953901272s] Trained 120 records in 0.045292359 seconds. Throughput is 2649.4536 records/second. Loss is 0.32164493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006656903208627347. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1560/60000][Iteration 2513][Wall Clock 120.996033815s] Trained 120 records in 0.042132543 seconds. Throughput is 2848.1548 records/second. Loss is 0.40295333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00665601703940362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1680/60000][Iteration 2514][Wall Clock 121.037949802s] Trained 120 records in 0.041915987 seconds. Throughput is 2862.8694 records/second. Loss is 0.2656016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006655131106082789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1800/60000][Iteration 2515][Wall Clock 121.087756896s] Trained 120 records in 0.049807094 seconds. Throughput is 2409.2954 records/second. Loss is 0.39482504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006654245408570667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 1920/60000][Iteration 2516][Wall Clock 121.130214262s] Trained 120 records in 0.042457366 seconds. Throughput is 2826.3647 records/second. Loss is 0.24558298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00665335994677312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2040/60000][Iteration 2517][Wall Clock 121.171408799s] Trained 120 records in 0.041194537 seconds. Throughput is 2913.0078 records/second. Loss is 0.3452259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006652474720596061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2160/60000][Iteration 2518][Wall Clock 121.212111962s] Trained 120 records in 0.040703163 seconds. Throughput is 2948.1738 records/second. Loss is 0.25402743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006651589729945457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2280/60000][Iteration 2519][Wall Clock 121.263368684s] Trained 120 records in 0.051256722 seconds. Throughput is 2341.1562 records/second. Loss is 0.31072742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006650704974727321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2400/60000][Iteration 2520][Wall Clock 121.305394921s] Trained 120 records in 0.042026237 seconds. Throughput is 2855.3591 records/second. Loss is 0.31899774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006649820454847719. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2520/60000][Iteration 2521][Wall Clock 121.347153762s] Trained 120 records in 0.041758841 seconds. Throughput is 2873.6428 records/second. Loss is 0.36288914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006648936170212766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2640/60000][Iteration 2522][Wall Clock 121.388904048s] Trained 120 records in 0.041750286 seconds. Throughput is 2874.232 records/second. Loss is 0.22585787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066480521207286265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2760/60000][Iteration 2523][Wall Clock 121.430355535s] Trained 120 records in 0.041451487 seconds. Throughput is 2894.9504 records/second. Loss is 0.2883312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006647168306301516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 2880/60000][Iteration 2524][Wall Clock 121.472915181s] Trained 120 records in 0.042559646 seconds. Throughput is 2819.5723 records/second. Loss is 0.22824118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006646284726837698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 3000/60000][Iteration 2525][Wall Clock 121.514285143s] Trained 120 records in 0.041369962 seconds. Throughput is 2900.6553 records/second. Loss is 0.3854214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006645401382243488. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:07 INFO  DistriOptimizer$:406 - [Epoch 6 3120/60000][Iteration 2526][Wall Clock 121.555232621s] Trained 120 records in 0.040947478 seconds. Throughput is 2930.5835 records/second. Loss is 0.21886529. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00664451827242525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 3240/60000][Iteration 2527][Wall Clock 121.596517921s] Trained 120 records in 0.0412853 seconds. Throughput is 2906.6038 records/second. Loss is 0.4305912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006643635397289398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 3360/60000][Iteration 2528][Wall Clock 121.637256007s] Trained 120 records in 0.040738086 seconds. Throughput is 2945.6465 records/second. Loss is 0.33070564. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006642752756742394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 3480/60000][Iteration 2529][Wall Clock 121.682814128s] Trained 120 records in 0.045558121 seconds. Throughput is 2633.998 records/second. Loss is 0.3193135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066418703506907545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 3600/60000][Iteration 2530][Wall Clock 121.724494229s] Trained 120 records in 0.041680101 seconds. Throughput is 2879.0718 records/second. Loss is 0.3243823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006640988179041041. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 3720/60000][Iteration 2531][Wall Clock 121.765348607s] Trained 120 records in 0.040854378 seconds. Throughput is 2937.2615 records/second. Loss is 0.25212654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006640106241699867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 3840/60000][Iteration 2532][Wall Clock 121.806587842s] Trained 120 records in 0.041239235 seconds. Throughput is 2909.8503 records/second. Loss is 0.36177436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006639224538573895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 3960/60000][Iteration 2533][Wall Clock 121.847488532s] Trained 120 records in 0.04090069 seconds. Throughput is 2933.936 records/second. Loss is 0.3322727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006638343069569835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4080/60000][Iteration 2534][Wall Clock 121.888410632s] Trained 120 records in 0.0409221 seconds. Throughput is 2932.4006 records/second. Loss is 0.29503012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006637461834594451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4200/60000][Iteration 2535][Wall Clock 121.929181648s] Trained 120 records in 0.040771016 seconds. Throughput is 2943.2673 records/second. Loss is 0.35817325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006636580833554552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4320/60000][Iteration 2536][Wall Clock 121.969554729s] Trained 120 records in 0.040373081 seconds. Throughput is 2972.2776 records/second. Loss is 0.33835247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006635700066357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4440/60000][Iteration 2537][Wall Clock 122.025280506s] Trained 120 records in 0.055725777 seconds. Throughput is 2153.402 records/second. Loss is 0.29122838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006634819532908704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4560/60000][Iteration 2538][Wall Clock 122.073100531s] Trained 120 records in 0.047820025 seconds. Throughput is 2509.409 records/second. Loss is 0.302801. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006633939233116624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4680/60000][Iteration 2539][Wall Clock 122.116238595s] Trained 120 records in 0.043138064 seconds. Throughput is 2781.7659 records/second. Loss is 0.28465953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066330591668877685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4800/60000][Iteration 2540][Wall Clock 122.159119056s] Trained 120 records in 0.042880461 seconds. Throughput is 2798.4773 records/second. Loss is 0.34191468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006632179334129195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 4920/60000][Iteration 2541][Wall Clock 122.202703978s] Trained 120 records in 0.043584922 seconds. Throughput is 2753.2458 records/second. Loss is 0.24190426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006631299734748011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5040/60000][Iteration 2542][Wall Clock 122.244269287s] Trained 120 records in 0.041565309 seconds. Throughput is 2887.023 records/second. Loss is 0.3169386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006630420368651373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5160/60000][Iteration 2543][Wall Clock 122.285606644s] Trained 120 records in 0.041337357 seconds. Throughput is 2902.9434 records/second. Loss is 0.37454233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006629541235746487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5280/60000][Iteration 2544][Wall Clock 122.3267571s] Trained 120 records in 0.041150456 seconds. Throughput is 2916.1282 records/second. Loss is 0.3309325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006628662335940607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5400/60000][Iteration 2545][Wall Clock 122.374905449s] Trained 120 records in 0.048148349 seconds. Throughput is 2492.2974 records/second. Loss is 0.37620983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006627783669141039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5520/60000][Iteration 2546][Wall Clock 122.41984625s] Trained 120 records in 0.044940801 seconds. Throughput is 2670.1794 records/second. Loss is 0.45190996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006626905235255136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5640/60000][Iteration 2547][Wall Clock 122.461325393s] Trained 120 records in 0.041479143 seconds. Throughput is 2893.0203 records/second. Loss is 0.31091955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066260270341903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5760/60000][Iteration 2548][Wall Clock 122.502907967s] Trained 120 records in 0.041582574 seconds. Throughput is 2885.8242 records/second. Loss is 0.2858115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066251490658539814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:08 INFO  DistriOptimizer$:406 - [Epoch 6 5880/60000][Iteration 2549][Wall Clock 122.544478607s] Trained 120 records in 0.04157064 seconds. Throughput is 2886.6526 records/second. Loss is 0.38444874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006624271330153683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6000/60000][Iteration 2550][Wall Clock 122.586160392s] Trained 120 records in 0.041681785 seconds. Throughput is 2878.9553 records/second. Loss is 0.27126428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066233938269969535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6120/60000][Iteration 2551][Wall Clock 122.629905573s] Trained 120 records in 0.043745181 seconds. Throughput is 2743.1592 records/second. Loss is 0.39231187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006622516556291391. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6240/60000][Iteration 2552][Wall Clock 122.672739446s] Trained 120 records in 0.042833873 seconds. Throughput is 2801.5212 records/second. Loss is 0.33072093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006621639517944643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6360/60000][Iteration 2553][Wall Clock 122.715163593s] Trained 120 records in 0.042424147 seconds. Throughput is 2828.578 records/second. Loss is 0.33206254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066207627118644065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6480/60000][Iteration 2554][Wall Clock 122.757230029s] Trained 120 records in 0.042066436 seconds. Throughput is 2852.6306 records/second. Loss is 0.4419588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006619886137958426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6600/60000][Iteration 2555][Wall Clock 122.800287897s] Trained 120 records in 0.043057868 seconds. Throughput is 2786.9473 records/second. Loss is 0.39201933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006619009796134498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6720/60000][Iteration 2556][Wall Clock 122.843603144s] Trained 120 records in 0.043315247 seconds. Throughput is 2770.387 records/second. Loss is 0.4438798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006618133686300463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6840/60000][Iteration 2557][Wall Clock 122.885359052s] Trained 120 records in 0.041755908 seconds. Throughput is 2873.845 records/second. Loss is 0.34335813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006617257808364214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 6960/60000][Iteration 2558][Wall Clock 122.927772731s] Trained 120 records in 0.042413679 seconds. Throughput is 2829.276 records/second. Loss is 0.40751886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066163821622336905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7080/60000][Iteration 2559][Wall Clock 122.970282126s] Trained 120 records in 0.042509395 seconds. Throughput is 2822.9053 records/second. Loss is 0.27948612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006615506747816882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7200/60000][Iteration 2560][Wall Clock 123.012764336s] Trained 120 records in 0.04248221 seconds. Throughput is 2824.712 records/second. Loss is 0.31460887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006614631565021828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7320/60000][Iteration 2561][Wall Clock 123.058641811s] Trained 120 records in 0.045877475 seconds. Throughput is 2615.6626 records/second. Loss is 0.38226834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006613756613756614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7440/60000][Iteration 2562][Wall Clock 123.100755343s] Trained 120 records in 0.042113532 seconds. Throughput is 2849.4404 records/second. Loss is 0.36346823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006612881893929374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7560/60000][Iteration 2563][Wall Clock 123.14971202s] Trained 120 records in 0.048956677 seconds. Throughput is 2451.1467 records/second. Loss is 0.320466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006612007405448294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7680/60000][Iteration 2564][Wall Clock 123.199744427s] Trained 120 records in 0.050032407 seconds. Throughput is 2398.4456 records/second. Loss is 0.30941582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006611133148221606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7800/60000][Iteration 2565][Wall Clock 123.247461051s] Trained 120 records in 0.047716624 seconds. Throughput is 2514.8467 records/second. Loss is 0.37181923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006610259122157589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 7920/60000][Iteration 2566][Wall Clock 123.290518248s] Trained 120 records in 0.043057197 seconds. Throughput is 2786.9905 records/second. Loss is 0.36210153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006609385327164575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 8040/60000][Iteration 2567][Wall Clock 123.332460639s] Trained 120 records in 0.041942391 seconds. Throughput is 2861.0671 records/second. Loss is 0.28605548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006608511763150939. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 8160/60000][Iteration 2568][Wall Clock 123.373640873s] Trained 120 records in 0.041180234 seconds. Throughput is 2914.0193 records/second. Loss is 0.340635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006607638430025109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 8280/60000][Iteration 2569][Wall Clock 123.415325137s] Trained 120 records in 0.041684264 seconds. Throughput is 2878.7842 records/second. Loss is 0.2253664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066067653276955605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 8400/60000][Iteration 2570][Wall Clock 123.457371295s] Trained 120 records in 0.042046158 seconds. Throughput is 2854.006 records/second. Loss is 0.33921576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006605892456070815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 8520/60000][Iteration 2571][Wall Clock 123.508733264s] Trained 120 records in 0.051361969 seconds. Throughput is 2336.359 records/second. Loss is 0.26770934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066050198150594455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:09 INFO  DistriOptimizer$:406 - [Epoch 6 8640/60000][Iteration 2572][Wall Clock 123.56506807s] Trained 120 records in 0.056334806 seconds. Throughput is 2130.1218 records/second. Loss is 0.42415237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066041474045700705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 8760/60000][Iteration 2573][Wall Clock 123.607295251s] Trained 120 records in 0.042227181 seconds. Throughput is 2841.7715 records/second. Loss is 0.32128647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006603275224511357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 8880/60000][Iteration 2574][Wall Clock 123.650429136s] Trained 120 records in 0.043133885 seconds. Throughput is 2782.0356 records/second. Loss is 0.31331816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006602403274792024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9000/60000][Iteration 2575][Wall Clock 123.69379883s] Trained 120 records in 0.043369694 seconds. Throughput is 2766.909 records/second. Loss is 0.33462968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006601531555320834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9120/60000][Iteration 2576][Wall Clock 123.738219234s] Trained 120 records in 0.044420404 seconds. Throughput is 2701.4614 records/second. Loss is 0.39345577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0066006600660066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9240/60000][Iteration 2577][Wall Clock 123.780848029s] Trained 120 records in 0.042628795 seconds. Throughput is 2814.9985 records/second. Loss is 0.2285476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006599788806758183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9360/60000][Iteration 2578][Wall Clock 123.822743311s] Trained 120 records in 0.041895282 seconds. Throughput is 2864.2844 records/second. Loss is 0.3128781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006598917777484493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9480/60000][Iteration 2579][Wall Clock 123.865073902s] Trained 120 records in 0.042330591 seconds. Throughput is 2834.8293 records/second. Loss is 0.4883272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006598046978094484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9600/60000][Iteration 2580][Wall Clock 123.906634635s] Trained 120 records in 0.041560733 seconds. Throughput is 2887.3408 records/second. Loss is 0.2614153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006597176408497163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9720/60000][Iteration 2581][Wall Clock 123.948060333s] Trained 120 records in 0.041425698 seconds. Throughput is 2896.7527 records/second. Loss is 0.31635237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006596306068601583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9840/60000][Iteration 2582][Wall Clock 123.990166056s] Trained 120 records in 0.042105723 seconds. Throughput is 2849.9688 records/second. Loss is 0.3034311. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006595435958316845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 9960/60000][Iteration 2583][Wall Clock 124.032406874s] Trained 120 records in 0.042240818 seconds. Throughput is 2840.8542 records/second. Loss is 0.4504123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006594566077552097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10080/60000][Iteration 2584][Wall Clock 124.074524284s] Trained 120 records in 0.04211741 seconds. Throughput is 2849.178 records/second. Loss is 0.28947648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006593696426216537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10200/60000][Iteration 2585][Wall Clock 124.117030349s] Trained 120 records in 0.042506065 seconds. Throughput is 2823.1265 records/second. Loss is 0.35511604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006592827004219409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10320/60000][Iteration 2586][Wall Clock 124.159478645s] Trained 120 records in 0.042448296 seconds. Throughput is 2826.9685 records/second. Loss is 0.34973404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006591957811470007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10440/60000][Iteration 2587][Wall Clock 124.20114115s] Trained 120 records in 0.041662505 seconds. Throughput is 2880.2876 records/second. Loss is 0.21819519. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00659108884787767. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10560/60000][Iteration 2588][Wall Clock 124.24258602s] Trained 120 records in 0.04144487 seconds. Throughput is 2895.4126 records/second. Loss is 0.24499129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006590220113351787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10680/60000][Iteration 2589][Wall Clock 124.290227413s] Trained 120 records in 0.047641393 seconds. Throughput is 2518.818 records/second. Loss is 0.3525672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006589351607801792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10800/60000][Iteration 2590][Wall Clock 124.341860854s] Trained 120 records in 0.051633441 seconds. Throughput is 2324.0752 records/second. Loss is 0.36789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006588483331137172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 10920/60000][Iteration 2591][Wall Clock 124.388315989s] Trained 120 records in 0.046455135 seconds. Throughput is 2583.1375 records/second. Loss is 0.3804978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006587615283267457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 11040/60000][Iteration 2592][Wall Clock 124.436899765s] Trained 120 records in 0.048583776 seconds. Throughput is 2469.9604 records/second. Loss is 0.36101645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006586747464102227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 11160/60000][Iteration 2593][Wall Clock 124.479380838s] Trained 120 records in 0.042481073 seconds. Throughput is 2824.7874 records/second. Loss is 0.3587919. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006585879873551107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 11280/60000][Iteration 2594][Wall Clock 124.522453046s] Trained 120 records in 0.043072208 seconds. Throughput is 2786.0193 records/second. Loss is 0.43977234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006585012511523772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:10 INFO  DistriOptimizer$:406 - [Epoch 6 11400/60000][Iteration 2595][Wall Clock 124.564041407s] Trained 120 records in 0.041588361 seconds. Throughput is 2885.4226 records/second. Loss is 0.3343666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006584145377929944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 11520/60000][Iteration 2596][Wall Clock 124.605695399s] Trained 120 records in 0.041653992 seconds. Throughput is 2880.8765 records/second. Loss is 0.26979968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006583278472679394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 11640/60000][Iteration 2597][Wall Clock 124.650693s] Trained 120 records in 0.044997601 seconds. Throughput is 2666.8088 records/second. Loss is 0.29076168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006582411795681938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 11760/60000][Iteration 2598][Wall Clock 124.702377861s] Trained 120 records in 0.051684861 seconds. Throughput is 2321.7632 records/second. Loss is 0.32554865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00658154534684744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 11880/60000][Iteration 2599][Wall Clock 124.748590857s] Trained 120 records in 0.046212996 seconds. Throughput is 2596.672 records/second. Loss is 0.36766604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006580679126085812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12000/60000][Iteration 2600][Wall Clock 124.791724877s] Trained 120 records in 0.04313402 seconds. Throughput is 2782.0269 records/second. Loss is 0.3817354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006579813133307014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12120/60000][Iteration 2601][Wall Clock 124.835096498s] Trained 120 records in 0.043371621 seconds. Throughput is 2766.7861 records/second. Loss is 0.2549363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006578947368421052. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12240/60000][Iteration 2602][Wall Clock 124.887296872s] Trained 120 records in 0.052200374 seconds. Throughput is 2298.8342 records/second. Loss is 0.37047842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006578081831337982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12360/60000][Iteration 2603][Wall Clock 124.930267893s] Trained 120 records in 0.042971021 seconds. Throughput is 2792.5796 records/second. Loss is 0.3482842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006577216521967903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12480/60000][Iteration 2604][Wall Clock 124.971884955s] Trained 120 records in 0.041617062 seconds. Throughput is 2883.4329 records/second. Loss is 0.3097684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006576351440220966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12600/60000][Iteration 2605][Wall Clock 125.015663962s] Trained 120 records in 0.043779007 seconds. Throughput is 2741.0398 records/second. Loss is 0.38925102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006575486586007365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12720/60000][Iteration 2606][Wall Clock 125.06175763s] Trained 120 records in 0.046093668 seconds. Throughput is 2603.3945 records/second. Loss is 0.2578856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006574621959237344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12840/60000][Iteration 2607][Wall Clock 125.103846149s] Trained 120 records in 0.042088519 seconds. Throughput is 2851.1338 records/second. Loss is 0.36505303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006573757559821194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 12960/60000][Iteration 2608][Wall Clock 125.145404133s] Trained 120 records in 0.041557984 seconds. Throughput is 2887.532 records/second. Loss is 0.38058254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006572893387669252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13080/60000][Iteration 2609][Wall Clock 125.186857261s] Trained 120 records in 0.041453128 seconds. Throughput is 2894.836 records/second. Loss is 0.23341797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006572029442691903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13200/60000][Iteration 2610][Wall Clock 125.227505387s] Trained 120 records in 0.040648126 seconds. Throughput is 2952.1658 records/second. Loss is 0.27493528. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006571165724799579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13320/60000][Iteration 2611][Wall Clock 125.268907891s] Trained 120 records in 0.041402504 seconds. Throughput is 2898.3755 records/second. Loss is 0.30377674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006570302233902759. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13440/60000][Iteration 2612][Wall Clock 125.310856976s] Trained 120 records in 0.041949085 seconds. Throughput is 2860.6106 records/second. Loss is 0.25621352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00656943896991197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13560/60000][Iteration 2613][Wall Clock 125.353000158s] Trained 120 records in 0.042143182 seconds. Throughput is 2847.4358 records/second. Loss is 0.30540195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006568575932737783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13680/60000][Iteration 2614][Wall Clock 125.398396993s] Trained 120 records in 0.045396835 seconds. Throughput is 2643.3562 records/second. Loss is 0.25555784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006567713122290817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13800/60000][Iteration 2615][Wall Clock 125.464483232s] Trained 120 records in 0.066086239 seconds. Throughput is 1815.8092 records/second. Loss is 0.3592235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065668505384817435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:11 INFO  DistriOptimizer$:406 - [Epoch 6 13920/60000][Iteration 2616][Wall Clock 125.525296487s] Trained 120 records in 0.060813255 seconds. Throughput is 1973.254 records/second. Loss is 0.2813664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006565988181221273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14040/60000][Iteration 2617][Wall Clock 125.570965287s] Trained 120 records in 0.0456688 seconds. Throughput is 2627.6145 records/second. Loss is 0.45364916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006565126050420168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14160/60000][Iteration 2618][Wall Clock 125.620005626s] Trained 120 records in 0.049040339 seconds. Throughput is 2446.965 records/second. Loss is 0.2591012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006564264145989235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14280/60000][Iteration 2619][Wall Clock 125.671805794s] Trained 120 records in 0.051800168 seconds. Throughput is 2316.5947 records/second. Loss is 0.32523468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065634024678393275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14400/60000][Iteration 2620][Wall Clock 125.715339183s] Trained 120 records in 0.043533389 seconds. Throughput is 2756.505 records/second. Loss is 0.29958263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006562541015881349. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14520/60000][Iteration 2621][Wall Clock 125.767994951s] Trained 120 records in 0.052655768 seconds. Throughput is 2278.9526 records/second. Loss is 0.30459034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006561679790026247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14640/60000][Iteration 2622][Wall Clock 125.812637343s] Trained 120 records in 0.044642392 seconds. Throughput is 2688.028 records/second. Loss is 0.32276535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006560818790185015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14760/60000][Iteration 2623][Wall Clock 125.858462544s] Trained 120 records in 0.045825201 seconds. Throughput is 2618.6465 records/second. Loss is 0.34944096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006559958016268696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 14880/60000][Iteration 2624][Wall Clock 125.900361312s] Trained 120 records in 0.041898768 seconds. Throughput is 2864.046 records/second. Loss is 0.34775788. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006559097468188378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15000/60000][Iteration 2625][Wall Clock 125.955076033s] Trained 120 records in 0.054714721 seconds. Throughput is 2193.194 records/second. Loss is 0.35591254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006558237145855195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15120/60000][Iteration 2626][Wall Clock 125.998829688s] Trained 120 records in 0.043753655 seconds. Throughput is 2742.6282 records/second. Loss is 0.36582643. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006557377049180329. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15240/60000][Iteration 2627][Wall Clock 126.042132393s] Trained 120 records in 0.043302705 seconds. Throughput is 2771.1895 records/second. Loss is 0.5884363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006556517178075007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15360/60000][Iteration 2628][Wall Clock 126.085049283s] Trained 120 records in 0.04291689 seconds. Throughput is 2796.102 records/second. Loss is 0.42202872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006555657532450506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15480/60000][Iteration 2629][Wall Clock 126.129153152s] Trained 120 records in 0.044103869 seconds. Throughput is 2720.8499 records/second. Loss is 0.32613304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006554798112218143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15600/60000][Iteration 2630][Wall Clock 126.172866945s] Trained 120 records in 0.043713793 seconds. Throughput is 2745.129 records/second. Loss is 0.3496474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006553938917289291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15720/60000][Iteration 2631][Wall Clock 126.217367728s] Trained 120 records in 0.044500783 seconds. Throughput is 2696.5818 records/second. Loss is 0.27045575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00655307994757536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15840/60000][Iteration 2632][Wall Clock 126.260055753s] Trained 120 records in 0.042688025 seconds. Throughput is 2811.093 records/second. Loss is 0.3501654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006552221202987813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 15960/60000][Iteration 2633][Wall Clock 126.302144837s] Trained 120 records in 0.042089084 seconds. Throughput is 2851.0957 records/second. Loss is 0.38987586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006551362683438156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 16080/60000][Iteration 2634][Wall Clock 126.344934442s] Trained 120 records in 0.042789605 seconds. Throughput is 2804.4194 records/second. Loss is 0.36505443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00655050438883794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 16200/60000][Iteration 2635][Wall Clock 126.387313819s] Trained 120 records in 0.042379377 seconds. Throughput is 2831.566 records/second. Loss is 0.38661855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006549646319098768. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 16320/60000][Iteration 2636][Wall Clock 126.429679031s] Trained 120 records in 0.042365212 seconds. Throughput is 2832.5127 records/second. Loss is 0.33726686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006548788474132285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 16440/60000][Iteration 2637][Wall Clock 126.471422295s] Trained 120 records in 0.041743264 seconds. Throughput is 2874.7153 records/second. Loss is 0.41465995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006547930853850183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 16560/60000][Iteration 2638][Wall Clock 126.512746039s] Trained 120 records in 0.041323744 seconds. Throughput is 2903.8994 records/second. Loss is 0.25252303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006547073458164201. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:12 INFO  DistriOptimizer$:406 - [Epoch 6 16680/60000][Iteration 2639][Wall Clock 126.553859424s] Trained 120 records in 0.041113385 seconds. Throughput is 2918.7576 records/second. Loss is 0.26558134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006546216286986122. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 16800/60000][Iteration 2640][Wall Clock 126.600986101s] Trained 120 records in 0.047126677 seconds. Throughput is 2546.3284 records/second. Loss is 0.2799044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006545359340227779. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 16920/60000][Iteration 2641][Wall Clock 126.65209393s] Trained 120 records in 0.051107829 seconds. Throughput is 2347.9768 records/second. Loss is 0.35854855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006544502617801047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17040/60000][Iteration 2642][Wall Clock 126.694437941s] Trained 120 records in 0.042344011 seconds. Throughput is 2833.931 records/second. Loss is 0.33724287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006543646119617851. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17160/60000][Iteration 2643][Wall Clock 126.73606347s] Trained 120 records in 0.041625529 seconds. Throughput is 2882.8462 records/second. Loss is 0.258565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00654278984559016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17280/60000][Iteration 2644][Wall Clock 126.777765734s] Trained 120 records in 0.041702264 seconds. Throughput is 2877.5417 records/second. Loss is 0.37507984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006541933795629989. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17400/60000][Iteration 2645][Wall Clock 126.819812521s] Trained 120 records in 0.042046787 seconds. Throughput is 2853.9636 records/second. Loss is 0.26755437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006541077969649398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17520/60000][Iteration 2646][Wall Clock 126.862080861s] Trained 120 records in 0.04226834 seconds. Throughput is 2839.0044 records/second. Loss is 0.3345195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006540222367560498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17640/60000][Iteration 2647][Wall Clock 126.904188283s] Trained 120 records in 0.042107422 seconds. Throughput is 2849.854 records/second. Loss is 0.2351093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006539366989275439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17760/60000][Iteration 2648][Wall Clock 126.945812971s] Trained 120 records in 0.041624688 seconds. Throughput is 2882.9045 records/second. Loss is 0.42173657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065385118347064215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 17880/60000][Iteration 2649][Wall Clock 126.988286899s] Trained 120 records in 0.042473928 seconds. Throughput is 2825.2627 records/second. Loss is 0.2980057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00653765690376569. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18000/60000][Iteration 2650][Wall Clock 127.030825072s] Trained 120 records in 0.042538173 seconds. Throughput is 2820.9956 records/second. Loss is 0.3741798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006536802196365538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18120/60000][Iteration 2651][Wall Clock 127.081070374s] Trained 120 records in 0.050245302 seconds. Throughput is 2388.283 records/second. Loss is 0.29493034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006535947712418301. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18240/60000][Iteration 2652][Wall Clock 127.131832259s] Trained 120 records in 0.050761885 seconds. Throughput is 2363.9783 records/second. Loss is 0.34048292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006535093451836361. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18360/60000][Iteration 2653][Wall Clock 127.173788064s] Trained 120 records in 0.041955805 seconds. Throughput is 2860.1523 records/second. Loss is 0.2977646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006534239414532149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18480/60000][Iteration 2654][Wall Clock 127.218876246s] Trained 120 records in 0.045088182 seconds. Throughput is 2661.4512 records/second. Loss is 0.32230598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006533385600418136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18600/60000][Iteration 2655][Wall Clock 127.262022454s] Trained 120 records in 0.043146208 seconds. Throughput is 2781.241 records/second. Loss is 0.32584193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006532532009406846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18720/60000][Iteration 2656][Wall Clock 127.305355876s] Trained 120 records in 0.043333422 seconds. Throughput is 2769.225 records/second. Loss is 0.31011295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006531678641410842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18840/60000][Iteration 2657][Wall Clock 127.347331643s] Trained 120 records in 0.041975767 seconds. Throughput is 2858.7922 records/second. Loss is 0.33864567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006530825496342737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 18960/60000][Iteration 2658][Wall Clock 127.38913837s] Trained 120 records in 0.041806727 seconds. Throughput is 2870.3513 records/second. Loss is 0.20072998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006529972574115189. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 19080/60000][Iteration 2659][Wall Clock 127.430936945s] Trained 120 records in 0.041798575 seconds. Throughput is 2870.9111 records/second. Loss is 0.1932789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006529119874640899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 19200/60000][Iteration 2660][Wall Clock 127.473976202s] Trained 120 records in 0.043039257 seconds. Throughput is 2788.152 records/second. Loss is 0.27660123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006528267397832615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:13 INFO  DistriOptimizer$:406 - [Epoch 6 19320/60000][Iteration 2661][Wall Clock 127.516834866s] Trained 120 records in 0.042858664 seconds. Throughput is 2799.9006 records/second. Loss is 0.34561887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006527415143603133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 19440/60000][Iteration 2662][Wall Clock 127.559808727s] Trained 120 records in 0.042973861 seconds. Throughput is 2792.395 records/second. Loss is 0.47961304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006526563111865292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 19560/60000][Iteration 2663][Wall Clock 127.60309931s] Trained 120 records in 0.043290583 seconds. Throughput is 2771.9656 records/second. Loss is 0.20648853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006525711302531976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 19680/60000][Iteration 2664][Wall Clock 127.647230069s] Trained 120 records in 0.044130759 seconds. Throughput is 2719.192 records/second. Loss is 0.25001857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006524859715516117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 19800/60000][Iteration 2665][Wall Clock 127.701854523s] Trained 120 records in 0.054624454 seconds. Throughput is 2196.8184 records/second. Loss is 0.27019942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00652400835073069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 19920/60000][Iteration 2666][Wall Clock 127.752664572s] Trained 120 records in 0.050810049 seconds. Throughput is 2361.7375 records/second. Loss is 0.31135082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065231572080887154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20040/60000][Iteration 2667][Wall Clock 127.808877155s] Trained 120 records in 0.056212583 seconds. Throughput is 2134.7534 records/second. Loss is 0.2917417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006522306287503262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20160/60000][Iteration 2668][Wall Clock 127.860535711s] Trained 120 records in 0.051658556 seconds. Throughput is 2322.9453 records/second. Loss is 0.20117706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00652145558888744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20280/60000][Iteration 2669][Wall Clock 127.916183303s] Trained 120 records in 0.055647592 seconds. Throughput is 2156.4275 records/second. Loss is 0.30978355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006520605112154408. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20400/60000][Iteration 2670][Wall Clock 127.963034081s] Trained 120 records in 0.046850778 seconds. Throughput is 2561.3235 records/second. Loss is 0.24418181. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006519754857217368. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20520/60000][Iteration 2671][Wall Clock 128.012301923s] Trained 120 records in 0.049267842 seconds. Throughput is 2435.6658 records/second. Loss is 0.2659163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00651890482398957. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20640/60000][Iteration 2672][Wall Clock 128.06747979s] Trained 120 records in 0.055177867 seconds. Throughput is 2174.785 records/second. Loss is 0.35391167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065180550123843045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20760/60000][Iteration 2673][Wall Clock 128.112406488s] Trained 120 records in 0.044926698 seconds. Throughput is 2671.0176 records/second. Loss is 0.31377023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006517205422314911. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 20880/60000][Iteration 2674][Wall Clock 128.161310384s] Trained 120 records in 0.048903896 seconds. Throughput is 2453.7922 records/second. Loss is 0.37753358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065163560536947735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 21000/60000][Iteration 2675][Wall Clock 128.210513676s] Trained 120 records in 0.049203292 seconds. Throughput is 2438.8613 records/second. Loss is 0.37057132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00651550690643732. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 21120/60000][Iteration 2676][Wall Clock 128.260392723s] Trained 120 records in 0.049879047 seconds. Throughput is 2405.8198 records/second. Loss is 0.4329876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065146579804560255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 21240/60000][Iteration 2677][Wall Clock 128.315323141s] Trained 120 records in 0.054930418 seconds. Throughput is 2184.582 records/second. Loss is 0.29585734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006513809275664409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 21360/60000][Iteration 2678][Wall Clock 128.387378906s] Trained 120 records in 0.072055765 seconds. Throughput is 1665.3768 records/second. Loss is 0.28283417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006512960791976032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 21480/60000][Iteration 2679][Wall Clock 128.444163005s] Trained 120 records in 0.056784099 seconds. Throughput is 2113.2676 records/second. Loss is 0.44063652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006512112529304506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:14 INFO  DistriOptimizer$:406 - [Epoch 6 21600/60000][Iteration 2680][Wall Clock 128.500944901s] Trained 120 records in 0.056781896 seconds. Throughput is 2113.3496 records/second. Loss is 0.30995008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065112644875634845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 21720/60000][Iteration 2681][Wall Clock 128.556793724s] Trained 120 records in 0.055848823 seconds. Throughput is 2148.6577 records/second. Loss is 0.40235215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006510416666666667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 21840/60000][Iteration 2682][Wall Clock 128.611451062s] Trained 120 records in 0.054657338 seconds. Throughput is 2195.4966 records/second. Loss is 0.320354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006509569066527796. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 21960/60000][Iteration 2683][Wall Clock 128.658772087s] Trained 120 records in 0.047321025 seconds. Throughput is 2535.8706 records/second. Loss is 0.28710702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006508721687060661. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22080/60000][Iteration 2684][Wall Clock 128.714494177s] Trained 120 records in 0.05572209 seconds. Throughput is 2153.5444 records/second. Loss is 0.29794434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006507874528179097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22200/60000][Iteration 2685][Wall Clock 128.759276196s] Trained 120 records in 0.044782019 seconds. Throughput is 2679.647 records/second. Loss is 0.28855148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065070275897969815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22320/60000][Iteration 2686][Wall Clock 128.812209454s] Trained 120 records in 0.052933258 seconds. Throughput is 2267.0059 records/second. Loss is 0.25699028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065061808718282375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22440/60000][Iteration 2687][Wall Clock 128.859657957s] Trained 120 records in 0.047448503 seconds. Throughput is 2529.0576 records/second. Loss is 0.20866193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006505334374186834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22560/60000][Iteration 2688][Wall Clock 128.905927376s] Trained 120 records in 0.046269419 seconds. Throughput is 2593.5056 records/second. Loss is 0.45042974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065044880967867836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22680/60000][Iteration 2689][Wall Clock 128.95224391s] Trained 120 records in 0.046316534 seconds. Throughput is 2590.8674 records/second. Loss is 0.2982559. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065036420395421434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22800/60000][Iteration 2690][Wall Clock 129.002399237s] Trained 120 records in 0.050155327 seconds. Throughput is 2392.5674 records/second. Loss is 0.29387173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006502796202367018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 22920/60000][Iteration 2691][Wall Clock 129.058509056s] Trained 120 records in 0.056109819 seconds. Throughput is 2138.663 records/second. Loss is 0.26629755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006501950585175552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23040/60000][Iteration 2692][Wall Clock 129.100753011s] Trained 120 records in 0.042243955 seconds. Throughput is 2840.6433 records/second. Loss is 0.31713244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00650110518788194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23160/60000][Iteration 2693][Wall Clock 129.143522813s] Trained 120 records in 0.042769802 seconds. Throughput is 2805.718 records/second. Loss is 0.27836928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0065002600104004165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23280/60000][Iteration 2694][Wall Clock 129.185950723s] Trained 120 records in 0.04242791 seconds. Throughput is 2828.327 records/second. Loss is 0.2693473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006499415052645261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23400/60000][Iteration 2695][Wall Clock 129.228384294s] Trained 120 records in 0.042433571 seconds. Throughput is 2827.9497 records/second. Loss is 0.32793078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006498570314530803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23520/60000][Iteration 2696][Wall Clock 129.270624735s] Trained 120 records in 0.042240441 seconds. Throughput is 2840.8794 records/second. Loss is 0.31479993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00649772579597141. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23640/60000][Iteration 2697][Wall Clock 129.31319946s] Trained 120 records in 0.042574725 seconds. Throughput is 2818.5737 records/second. Loss is 0.4147238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006496881496881496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23760/60000][Iteration 2698][Wall Clock 129.356132479s] Trained 120 records in 0.042933019 seconds. Throughput is 2795.0515 records/second. Loss is 0.46553934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006496037417175523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 23880/60000][Iteration 2699][Wall Clock 129.398149054s] Trained 120 records in 0.042016575 seconds. Throughput is 2856.0159 records/second. Loss is 0.38101283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006495193556767992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 24000/60000][Iteration 2700][Wall Clock 129.440206203s] Trained 120 records in 0.042057149 seconds. Throughput is 2853.2605 records/second. Loss is 0.28877813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006494349915573451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 24120/60000][Iteration 2701][Wall Clock 129.482410894s] Trained 120 records in 0.042204691 seconds. Throughput is 2843.286 records/second. Loss is 0.42305502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006493506493506493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:15 INFO  DistriOptimizer$:406 - [Epoch 6 24240/60000][Iteration 2702][Wall Clock 129.524272474s] Trained 120 records in 0.04186158 seconds. Throughput is 2866.5903 records/second. Loss is 0.3820295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006492663290481756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 24360/60000][Iteration 2703][Wall Clock 129.566165579s] Trained 120 records in 0.041893105 seconds. Throughput is 2864.433 records/second. Loss is 0.29829845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006491820306413918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 24480/60000][Iteration 2704][Wall Clock 129.616530435s] Trained 120 records in 0.050364856 seconds. Throughput is 2382.6138 records/second. Loss is 0.19630122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006490977541217708. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 24600/60000][Iteration 2705][Wall Clock 129.664694072s] Trained 120 records in 0.048163637 seconds. Throughput is 2491.506 records/second. Loss is 0.41177794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006490134994807892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 24720/60000][Iteration 2706][Wall Clock 129.707012032s] Trained 120 records in 0.04231796 seconds. Throughput is 2835.6755 records/second. Loss is 0.28989002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006489292667099286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 24840/60000][Iteration 2707][Wall Clock 129.748801927s] Trained 120 records in 0.041789895 seconds. Throughput is 2871.5076 records/second. Loss is 0.37904513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006488450558006748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 24960/60000][Iteration 2708][Wall Clock 129.790933877s] Trained 120 records in 0.04213195 seconds. Throughput is 2848.1948 records/second. Loss is 0.24246915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064876086674451805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25080/60000][Iteration 2709][Wall Clock 129.832707828s] Trained 120 records in 0.041773951 seconds. Throughput is 2872.6035 records/second. Loss is 0.35191125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006486766995329528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25200/60000][Iteration 2710][Wall Clock 129.87399092s] Trained 120 records in 0.041283092 seconds. Throughput is 2906.759 records/second. Loss is 0.37453422. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064859255415747824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25320/60000][Iteration 2711][Wall Clock 129.915265048s] Trained 120 records in 0.041274128 seconds. Throughput is 2907.3904 records/second. Loss is 0.27077124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00648508430609598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25440/60000][Iteration 2712][Wall Clock 129.957019812s] Trained 120 records in 0.041754764 seconds. Throughput is 2873.9236 records/second. Loss is 0.36729002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006484243288808196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25560/60000][Iteration 2713][Wall Clock 129.999016919s] Trained 120 records in 0.041997107 seconds. Throughput is 2857.3396 records/second. Loss is 0.31658337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006483402489626556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25680/60000][Iteration 2714][Wall Clock 130.04509649s] Trained 120 records in 0.046079571 seconds. Throughput is 2604.191 records/second. Loss is 0.35372856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006482561908466226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25800/60000][Iteration 2715][Wall Clock 130.100546867s] Trained 120 records in 0.055450377 seconds. Throughput is 2164.0972 records/second. Loss is 0.3412472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006481721545242416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 25920/60000][Iteration 2716][Wall Clock 130.148318878s] Trained 120 records in 0.047772011 seconds. Throughput is 2511.931 records/second. Loss is 0.28151926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006480881399870382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26040/60000][Iteration 2717][Wall Clock 130.194064322s] Trained 120 records in 0.045745444 seconds. Throughput is 2623.2122 records/second. Loss is 0.28300476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006480041472265422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26160/60000][Iteration 2718][Wall Clock 130.235857207s] Trained 120 records in 0.041792885 seconds. Throughput is 2871.3022 records/second. Loss is 0.33722445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006479201762342879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26280/60000][Iteration 2719][Wall Clock 130.277206615s] Trained 120 records in 0.041349408 seconds. Throughput is 2902.0972 records/second. Loss is 0.30435345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064783622700181395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26400/60000][Iteration 2720][Wall Clock 130.318447847s] Trained 120 records in 0.041241232 seconds. Throughput is 2909.7095 records/second. Loss is 0.22233194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006477522995206633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26520/60000][Iteration 2721][Wall Clock 130.360589456s] Trained 120 records in 0.042141609 seconds. Throughput is 2847.542 records/second. Loss is 0.23871498. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006476683937823834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26640/60000][Iteration 2722][Wall Clock 130.401928507s] Trained 120 records in 0.041339051 seconds. Throughput is 2902.8242 records/second. Loss is 0.23152085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006475845097785261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26760/60000][Iteration 2723][Wall Clock 130.444041452s] Trained 120 records in 0.042112945 seconds. Throughput is 2849.48 records/second. Loss is 0.39962038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006475006475006475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 26880/60000][Iteration 2724][Wall Clock 130.488107577s] Trained 120 records in 0.044066125 seconds. Throughput is 2723.1804 records/second. Loss is 0.3176078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006474168069403082. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:16 INFO  DistriOptimizer$:406 - [Epoch 6 27000/60000][Iteration 2725][Wall Clock 130.530550037s] Trained 120 records in 0.04244246 seconds. Throughput is 2827.3574 records/second. Loss is 0.2554769. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006473329880890731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27120/60000][Iteration 2726][Wall Clock 130.573118999s] Trained 120 records in 0.042568962 seconds. Throughput is 2818.9553 records/second. Loss is 0.27298853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006472491909385114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27240/60000][Iteration 2727][Wall Clock 130.615049084s] Trained 120 records in 0.041930085 seconds. Throughput is 2861.907 records/second. Loss is 0.28612196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064716541548019675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27360/60000][Iteration 2728][Wall Clock 130.656547102s] Trained 120 records in 0.041498018 seconds. Throughput is 2891.7046 records/second. Loss is 0.3428474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006470816617057073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27480/60000][Iteration 2729][Wall Clock 130.698223741s] Trained 120 records in 0.041676639 seconds. Throughput is 2879.3108 records/second. Loss is 0.38288322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006469979296066253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27600/60000][Iteration 2730][Wall Clock 130.739954878s] Trained 120 records in 0.041731137 seconds. Throughput is 2875.5505 records/second. Loss is 0.34446457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064691421917453746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27720/60000][Iteration 2731][Wall Clock 130.79309261s] Trained 120 records in 0.053137732 seconds. Throughput is 2258.2825 records/second. Loss is 0.25118476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00646830530401035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27840/60000][Iteration 2732][Wall Clock 130.840300053s] Trained 120 records in 0.047207443 seconds. Throughput is 2541.9722 records/second. Loss is 0.28488734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006467468632777131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 27960/60000][Iteration 2733][Wall Clock 130.881822738s] Trained 120 records in 0.041522685 seconds. Throughput is 2889.9866 records/second. Loss is 0.3026546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006466632177961717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28080/60000][Iteration 2734][Wall Clock 130.924117252s] Trained 120 records in 0.042294514 seconds. Throughput is 2837.2476 records/second. Loss is 0.2755099. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006465795939480151. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28200/60000][Iteration 2735][Wall Clock 130.967228671s] Trained 120 records in 0.043111419 seconds. Throughput is 2783.4854 records/second. Loss is 0.345236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064649599172485125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28320/60000][Iteration 2736][Wall Clock 131.011141055s] Trained 120 records in 0.043912384 seconds. Throughput is 2732.7144 records/second. Loss is 0.39553115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006464124111182934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28440/60000][Iteration 2737][Wall Clock 131.053552571s] Trained 120 records in 0.042411516 seconds. Throughput is 2829.4202 records/second. Loss is 0.23826861. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006463288521199586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28560/60000][Iteration 2738][Wall Clock 131.096645326s] Trained 120 records in 0.043092755 seconds. Throughput is 2784.691 records/second. Loss is 0.2962756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006462453147214682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28680/60000][Iteration 2739][Wall Clock 131.140621274s] Trained 120 records in 0.043975948 seconds. Throughput is 2728.7644 records/second. Loss is 0.30423057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006461617989144482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28800/60000][Iteration 2740][Wall Clock 131.190690673s] Trained 120 records in 0.050069399 seconds. Throughput is 2396.6733 records/second. Loss is 0.34825248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006460783046905285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 28920/60000][Iteration 2741][Wall Clock 131.24340347s] Trained 120 records in 0.052712797 seconds. Throughput is 2276.487 records/second. Loss is 0.27660662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006459948320413436. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 29040/60000][Iteration 2742][Wall Clock 131.292728877s] Trained 120 records in 0.049325407 seconds. Throughput is 2432.8232 records/second. Loss is 0.3320213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006459113809585325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 29160/60000][Iteration 2743][Wall Clock 131.345104378s] Trained 120 records in 0.052375501 seconds. Throughput is 2291.1477 records/second. Loss is 0.26764062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006458279514337381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 29280/60000][Iteration 2744][Wall Clock 131.395190671s] Trained 120 records in 0.050086293 seconds. Throughput is 2395.865 records/second. Loss is 0.3313132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006457445434586078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 29400/60000][Iteration 2745][Wall Clock 131.437802594s] Trained 120 records in 0.042611923 seconds. Throughput is 2816.1133 records/second. Loss is 0.3081585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006456611570247934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 29520/60000][Iteration 2746][Wall Clock 131.480183738s] Trained 120 records in 0.042381144 seconds. Throughput is 2831.4478 records/second. Loss is 0.29268348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006455777921239509. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:17 INFO  DistriOptimizer$:406 - [Epoch 6 29640/60000][Iteration 2747][Wall Clock 131.522458525s] Trained 120 records in 0.042274787 seconds. Throughput is 2838.5713 records/second. Loss is 0.28042802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006454944487477408. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 29760/60000][Iteration 2748][Wall Clock 131.565370961s] Trained 120 records in 0.042912436 seconds. Throughput is 2796.3923 records/second. Loss is 0.34259155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006454111268878276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 29880/60000][Iteration 2749][Wall Clock 131.607430444s] Trained 120 records in 0.042059483 seconds. Throughput is 2853.1023 records/second. Loss is 0.3830524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006453278265358803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30000/60000][Iteration 2750][Wall Clock 131.650223167s] Trained 120 records in 0.042792723 seconds. Throughput is 2804.215 records/second. Loss is 0.32911414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064524454768357204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30120/60000][Iteration 2751][Wall Clock 131.692273861s] Trained 120 records in 0.042050694 seconds. Throughput is 2853.6985 records/second. Loss is 0.25634658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064516129032258064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30240/60000][Iteration 2752][Wall Clock 131.736361835s] Trained 120 records in 0.044087974 seconds. Throughput is 2721.8308 records/second. Loss is 0.4391875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006450780544445878. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30360/60000][Iteration 2753][Wall Clock 131.781275541s] Trained 120 records in 0.044913706 seconds. Throughput is 2671.7903 records/second. Loss is 0.22510271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006449948400412797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30480/60000][Iteration 2754][Wall Clock 131.82272549s] Trained 120 records in 0.041449949 seconds. Throughput is 2895.0579 records/second. Loss is 0.41522253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006449116471043468. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30600/60000][Iteration 2755][Wall Clock 131.86421706s] Trained 120 records in 0.04149157 seconds. Throughput is 2892.1536 records/second. Loss is 0.24715328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006448284756254836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30720/60000][Iteration 2756][Wall Clock 131.904937724s] Trained 120 records in 0.040720664 seconds. Throughput is 2946.9067 records/second. Loss is 0.33394557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006447453255963894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30840/60000][Iteration 2757][Wall Clock 131.945711932s] Trained 120 records in 0.040774208 seconds. Throughput is 2943.0369 records/second. Loss is 0.3792996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006446621970087674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 30960/60000][Iteration 2758][Wall Clock 131.998501918s] Trained 120 records in 0.052789986 seconds. Throughput is 2273.1584 records/second. Loss is 0.28797996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006445790898543251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31080/60000][Iteration 2759][Wall Clock 132.042997676s] Trained 120 records in 0.044495758 seconds. Throughput is 2696.8862 records/second. Loss is 0.3610307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006444960041247744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31200/60000][Iteration 2760][Wall Clock 132.084341524s] Trained 120 records in 0.041343848 seconds. Throughput is 2902.4873 records/second. Loss is 0.2744497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006444129398118314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31320/60000][Iteration 2761][Wall Clock 132.126025964s] Trained 120 records in 0.04168444 seconds. Throughput is 2878.772 records/second. Loss is 0.35200405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006443298969072165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31440/60000][Iteration 2762][Wall Clock 132.16887251s] Trained 120 records in 0.042846546 seconds. Throughput is 2800.6926 records/second. Loss is 0.26431137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006442468754026543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31560/60000][Iteration 2763][Wall Clock 132.210244441s] Trained 120 records in 0.041371931 seconds. Throughput is 2900.5173 records/second. Loss is 0.3536724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006441638752898738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31680/60000][Iteration 2764][Wall Clock 132.251903443s] Trained 120 records in 0.041659002 seconds. Throughput is 2880.53 records/second. Loss is 0.31460592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064408089656060805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31800/60000][Iteration 2765][Wall Clock 132.294989683s] Trained 120 records in 0.04308624 seconds. Throughput is 2785.112 records/second. Loss is 0.30618557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006439979392065946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 31920/60000][Iteration 2766][Wall Clock 132.345004852s] Trained 120 records in 0.050015169 seconds. Throughput is 2399.272 records/second. Loss is 0.30263728. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006439150032195751. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 32040/60000][Iteration 2767][Wall Clock 132.390894788s] Trained 120 records in 0.045889936 seconds. Throughput is 2614.9524 records/second. Loss is 0.40278387. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006438320885912954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 32160/60000][Iteration 2768][Wall Clock 132.432379868s] Trained 120 records in 0.04148508 seconds. Throughput is 2892.6062 records/second. Loss is 0.2651224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006437491953135059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 32280/60000][Iteration 2769][Wall Clock 132.474110921s] Trained 120 records in 0.041731053 seconds. Throughput is 2875.5566 records/second. Loss is 0.3547506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006436663233779609. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:18 INFO  DistriOptimizer$:406 - [Epoch 6 32400/60000][Iteration 2770][Wall Clock 132.515259021s] Trained 120 records in 0.0411481 seconds. Throughput is 2916.295 records/second. Loss is 0.30385655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006435834727764191. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 32520/60000][Iteration 2771][Wall Clock 132.556196773s] Trained 120 records in 0.040937752 seconds. Throughput is 2931.2798 records/second. Loss is 0.36041552. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006435006435006435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 32640/60000][Iteration 2772][Wall Clock 132.600765371s] Trained 120 records in 0.044568598 seconds. Throughput is 2692.4788 records/second. Loss is 0.3230849. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006434178355424013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 32760/60000][Iteration 2773][Wall Clock 132.642356183s] Trained 120 records in 0.041590812 seconds. Throughput is 2885.2524 records/second. Loss is 0.4825748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006433350488934638. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 32880/60000][Iteration 2774][Wall Clock 132.683443912s] Trained 120 records in 0.041087729 seconds. Throughput is 2920.58 records/second. Loss is 0.29843566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006432522835456066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33000/60000][Iteration 2775][Wall Clock 132.724892493s] Trained 120 records in 0.041448581 seconds. Throughput is 2895.1533 records/second. Loss is 0.3962823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006431695394906097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33120/60000][Iteration 2776][Wall Clock 132.765660977s] Trained 120 records in 0.040768484 seconds. Throughput is 2943.45 records/second. Loss is 0.35632783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006430868167202571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33240/60000][Iteration 2777][Wall Clock 132.80753565s] Trained 120 records in 0.041874673 seconds. Throughput is 2865.694 records/second. Loss is 0.23075147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006430041152263374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33360/60000][Iteration 2778][Wall Clock 132.848618816s] Trained 120 records in 0.041083166 seconds. Throughput is 2920.9045 records/second. Loss is 0.2883629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006429214350006429. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33480/60000][Iteration 2779][Wall Clock 132.889541202s] Trained 120 records in 0.040922386 seconds. Throughput is 2932.3804 records/second. Loss is 0.2981087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006428387760349704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33600/60000][Iteration 2780][Wall Clock 132.931804291s] Trained 120 records in 0.042263089 seconds. Throughput is 2839.357 records/second. Loss is 0.2716931. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006427561383211209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33720/60000][Iteration 2781][Wall Clock 132.974860364s] Trained 120 records in 0.043056073 seconds. Throughput is 2787.0632 records/second. Loss is 0.27278286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006426735218508998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33840/60000][Iteration 2782][Wall Clock 133.016873917s] Trained 120 records in 0.042013553 seconds. Throughput is 2856.2212 records/second. Loss is 0.39126676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006425909266161162. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 33960/60000][Iteration 2783][Wall Clock 133.057924101s] Trained 120 records in 0.041050184 seconds. Throughput is 2923.2512 records/second. Loss is 0.23313917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00642508352608584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34080/60000][Iteration 2784][Wall Clock 133.106520207s] Trained 120 records in 0.048596106 seconds. Throughput is 2469.3337 records/second. Loss is 0.30607656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006424257998201208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34200/60000][Iteration 2785][Wall Clock 133.154965095s] Trained 120 records in 0.048444888 seconds. Throughput is 2477.0415 records/second. Loss is 0.34668905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006423432682425488. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34320/60000][Iteration 2786][Wall Clock 133.198458054s] Trained 120 records in 0.043492959 seconds. Throughput is 2759.0674 records/second. Loss is 0.3543715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064226075786769435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34440/60000][Iteration 2787][Wall Clock 133.23996268s] Trained 120 records in 0.041504626 seconds. Throughput is 2891.2441 records/second. Loss is 0.28055182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006421782686873876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34560/60000][Iteration 2788][Wall Clock 133.281596903s] Trained 120 records in 0.041634223 seconds. Throughput is 2882.2441 records/second. Loss is 0.30735525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006420958006934635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34680/60000][Iteration 2789][Wall Clock 133.322678276s] Trained 120 records in 0.041081373 seconds. Throughput is 2921.032 records/second. Loss is 0.26638994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006420133538777607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34800/60000][Iteration 2790][Wall Clock 133.37274606s] Trained 120 records in 0.050067784 seconds. Throughput is 2396.7507 records/second. Loss is 0.33057934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006419309282321222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 34920/60000][Iteration 2791][Wall Clock 133.414590135s] Trained 120 records in 0.041844075 seconds. Throughput is 2867.7896 records/second. Loss is 0.33719185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006418485237483953. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 35040/60000][Iteration 2792][Wall Clock 133.457304585s] Trained 120 records in 0.04271445 seconds. Throughput is 2809.3538 records/second. Loss is 0.26881775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006417661404184315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:19 INFO  DistriOptimizer$:406 - [Epoch 6 35160/60000][Iteration 2793][Wall Clock 133.508528407s] Trained 120 records in 0.051223822 seconds. Throughput is 2342.66 records/second. Loss is 0.26076558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006416837782340862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 35280/60000][Iteration 2794][Wall Clock 133.550722342s] Trained 120 records in 0.042193935 seconds. Throughput is 2844.0107 records/second. Loss is 0.2263947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006416014371872193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 35400/60000][Iteration 2795][Wall Clock 133.593111523s] Trained 120 records in 0.042389181 seconds. Throughput is 2830.9111 records/second. Loss is 0.3776907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006415191172696946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 35520/60000][Iteration 2796][Wall Clock 133.636007295s] Trained 120 records in 0.042895772 seconds. Throughput is 2797.4785 records/second. Loss is 0.33118388. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006414368184733803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 35640/60000][Iteration 2797][Wall Clock 133.678639263s] Trained 120 records in 0.042631968 seconds. Throughput is 2814.789 records/second. Loss is 0.26328385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006413545407901487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 35760/60000][Iteration 2798][Wall Clock 133.721419044s] Trained 120 records in 0.042779781 seconds. Throughput is 2805.0635 records/second. Loss is 0.29382795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006412722842118764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 35880/60000][Iteration 2799][Wall Clock 133.763566329s] Trained 120 records in 0.042147285 seconds. Throughput is 2847.1584 records/second. Loss is 0.3111682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006411900487304437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36000/60000][Iteration 2800][Wall Clock 133.80703929s] Trained 120 records in 0.043472961 seconds. Throughput is 2760.3364 records/second. Loss is 0.3313631. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006411078343377356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36120/60000][Iteration 2801][Wall Clock 133.852828251s] Trained 120 records in 0.045788961 seconds. Throughput is 2620.719 records/second. Loss is 0.39398968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00641025641025641. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36240/60000][Iteration 2802][Wall Clock 133.896880331s] Trained 120 records in 0.04405208 seconds. Throughput is 2724.0486 records/second. Loss is 0.15455769. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006409434687860531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36360/60000][Iteration 2803][Wall Clock 133.940809975s] Trained 120 records in 0.043929644 seconds. Throughput is 2731.6406 records/second. Loss is 0.3197512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00640861317610869. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36480/60000][Iteration 2804][Wall Clock 133.985954953s] Trained 120 records in 0.045144978 seconds. Throughput is 2658.103 records/second. Loss is 0.24813159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064077918749199025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36600/60000][Iteration 2805][Wall Clock 134.049314796s] Trained 120 records in 0.063359843 seconds. Throughput is 1893.9441 records/second. Loss is 0.29342106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006406970784213224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36720/60000][Iteration 2806][Wall Clock 134.103293858s] Trained 120 records in 0.053979062 seconds. Throughput is 2223.0842 records/second. Loss is 0.22695859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064061499039077515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36840/60000][Iteration 2807][Wall Clock 134.147468508s] Trained 120 records in 0.04417465 seconds. Throughput is 2716.4902 records/second. Loss is 0.1982416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006405329233922624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 36960/60000][Iteration 2808][Wall Clock 134.193030413s] Trained 120 records in 0.045561905 seconds. Throughput is 2633.7793 records/second. Loss is 0.35388464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006404508774177021. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 37080/60000][Iteration 2809][Wall Clock 134.237114639s] Trained 120 records in 0.044084226 seconds. Throughput is 2722.0623 records/second. Loss is 0.33902678. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006403688524590165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 37200/60000][Iteration 2810][Wall Clock 134.281287527s] Trained 120 records in 0.044172888 seconds. Throughput is 2716.5986 records/second. Loss is 0.30732906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006402868485081316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 37320/60000][Iteration 2811][Wall Clock 134.340347467s] Trained 120 records in 0.05905994 seconds. Throughput is 2031.8341 records/second. Loss is 0.35421598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006402048655569782. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 37440/60000][Iteration 2812][Wall Clock 134.3918113s] Trained 120 records in 0.051463833 seconds. Throughput is 2331.7346 records/second. Loss is 0.31913888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0064012290359749075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 37560/60000][Iteration 2813][Wall Clock 134.436605035s] Trained 120 records in 0.044793735 seconds. Throughput is 2678.946 records/second. Loss is 0.30716294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006400409626216078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:20 INFO  DistriOptimizer$:406 - [Epoch 6 37680/60000][Iteration 2814][Wall Clock 134.489580012s] Trained 120 records in 0.052974977 seconds. Throughput is 2265.2205 records/second. Loss is 0.27638808. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006399590426212722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 37800/60000][Iteration 2815][Wall Clock 134.535711913s] Trained 120 records in 0.046131901 seconds. Throughput is 2601.2368 records/second. Loss is 0.23330127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00639877143588431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 37920/60000][Iteration 2816][Wall Clock 134.58227257s] Trained 120 records in 0.046560657 seconds. Throughput is 2577.2832 records/second. Loss is 0.41501194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006397952655150352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38040/60000][Iteration 2817][Wall Clock 134.624223511s] Trained 120 records in 0.041950941 seconds. Throughput is 2860.4841 records/second. Loss is 0.308662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006397134083930399. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38160/60000][Iteration 2818][Wall Clock 134.6649726s] Trained 120 records in 0.040749089 seconds. Throughput is 2944.851 records/second. Loss is 0.27193096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006396315722144045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38280/60000][Iteration 2819][Wall Clock 134.712072309s] Trained 120 records in 0.047099709 seconds. Throughput is 2547.7864 records/second. Loss is 0.2768884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006395497569710923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38400/60000][Iteration 2820][Wall Clock 134.75786292s] Trained 120 records in 0.045790611 seconds. Throughput is 2620.6245 records/second. Loss is 0.30409417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006394679626550709. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38520/60000][Iteration 2821][Wall Clock 134.799313968s] Trained 120 records in 0.041451048 seconds. Throughput is 2894.9812 records/second. Loss is 0.3057545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00639386189258312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38640/60000][Iteration 2822][Wall Clock 134.840461196s] Trained 120 records in 0.041147228 seconds. Throughput is 2916.357 records/second. Loss is 0.28079304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006393044367727912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38760/60000][Iteration 2823][Wall Clock 134.881443068s] Trained 120 records in 0.040981872 seconds. Throughput is 2928.124 records/second. Loss is 0.35038504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063922270519048835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 38880/60000][Iteration 2824][Wall Clock 134.922484437s] Trained 120 records in 0.041041369 seconds. Throughput is 2923.879 records/second. Loss is 0.2802143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006391409945033875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39000/60000][Iteration 2825][Wall Clock 134.963586099s] Trained 120 records in 0.041101662 seconds. Throughput is 2919.59 records/second. Loss is 0.384188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006390593047034765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39120/60000][Iteration 2826][Wall Clock 135.005833467s] Trained 120 records in 0.042247368 seconds. Throughput is 2840.4138 records/second. Loss is 0.40016863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006389776357827477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39240/60000][Iteration 2827][Wall Clock 135.048151757s] Trained 120 records in 0.04231829 seconds. Throughput is 2835.6536 records/second. Loss is 0.39981166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006388959877331971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39360/60000][Iteration 2828][Wall Clock 135.089913715s] Trained 120 records in 0.041761958 seconds. Throughput is 2873.4285 records/second. Loss is 0.26090053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006388143605468252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39480/60000][Iteration 2829][Wall Clock 135.131199338s] Trained 120 records in 0.041285623 seconds. Throughput is 2906.5808 records/second. Loss is 0.22035931. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006387327542156362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39600/60000][Iteration 2830][Wall Clock 135.176222677s] Trained 120 records in 0.045023339 seconds. Throughput is 2665.2842 records/second. Loss is 0.35004577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006386511687316388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39720/60000][Iteration 2831][Wall Clock 135.217079416s] Trained 120 records in 0.040856739 seconds. Throughput is 2937.092 records/second. Loss is 0.2975157. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006385696040868454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39840/60000][Iteration 2832][Wall Clock 135.258720486s] Trained 120 records in 0.04164107 seconds. Throughput is 2881.7703 records/second. Loss is 0.33015716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006384880602732729. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 39960/60000][Iteration 2833][Wall Clock 135.299687769s] Trained 120 records in 0.040967283 seconds. Throughput is 2929.1667 records/second. Loss is 0.25146717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006384065372829418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 40080/60000][Iteration 2834][Wall Clock 135.340603834s] Trained 120 records in 0.040916065 seconds. Throughput is 2932.8333 records/second. Loss is 0.34708777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006383250351078769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 40200/60000][Iteration 2835][Wall Clock 135.382068678s] Trained 120 records in 0.041464844 seconds. Throughput is 2894.018 records/second. Loss is 0.31849334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006382435537401071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 40320/60000][Iteration 2836][Wall Clock 135.423436055s] Trained 120 records in 0.041367377 seconds. Throughput is 2900.8364 records/second. Loss is 0.29818237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006381620931716655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:21 INFO  DistriOptimizer$:406 - [Epoch 6 40440/60000][Iteration 2837][Wall Clock 135.464638503s] Trained 120 records in 0.041202448 seconds. Throughput is 2912.4482 records/second. Loss is 0.2772287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00638080653394589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 40560/60000][Iteration 2838][Wall Clock 135.51780368s] Trained 120 records in 0.053165177 seconds. Throughput is 2257.1165 records/second. Loss is 0.18277521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006379992344009187. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 40680/60000][Iteration 2839][Wall Clock 135.563621627s] Trained 120 records in 0.045817947 seconds. Throughput is 2619.061 records/second. Loss is 0.27024066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006379178361826996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 40800/60000][Iteration 2840][Wall Clock 135.607137757s] Trained 120 records in 0.04351613 seconds. Throughput is 2757.5981 records/second. Loss is 0.27882668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006378364587319811. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 40920/60000][Iteration 2841][Wall Clock 135.650505908s] Trained 120 records in 0.043368151 seconds. Throughput is 2767.0076 records/second. Loss is 0.3591929. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006377551020408163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41040/60000][Iteration 2842][Wall Clock 135.691874929s] Trained 120 records in 0.041369021 seconds. Throughput is 2900.7212 records/second. Loss is 0.2219892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006376737661012626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41160/60000][Iteration 2843][Wall Clock 135.732792922s] Trained 120 records in 0.040917993 seconds. Throughput is 2932.695 records/second. Loss is 0.40094385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006375924509053813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41280/60000][Iteration 2844][Wall Clock 135.775111262s] Trained 120 records in 0.04231834 seconds. Throughput is 2835.65 records/second. Loss is 0.32013527. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006375111564452378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41400/60000][Iteration 2845][Wall Clock 135.817286616s] Trained 120 records in 0.042175354 seconds. Throughput is 2845.2637 records/second. Loss is 0.27871698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006374298827129016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41520/60000][Iteration 2846][Wall Clock 135.866164871s] Trained 120 records in 0.048878255 seconds. Throughput is 2455.0793 records/second. Loss is 0.2411478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006373486297004462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41640/60000][Iteration 2847][Wall Clock 135.913781823s] Trained 120 records in 0.047616952 seconds. Throughput is 2520.1108 records/second. Loss is 0.32134864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006372673973999491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41760/60000][Iteration 2848][Wall Clock 135.95531601s] Trained 120 records in 0.041534187 seconds. Throughput is 2889.1863 records/second. Loss is 0.28531373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006371861858034919. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 41880/60000][Iteration 2849][Wall Clock 135.996984607s] Trained 120 records in 0.041668597 seconds. Throughput is 2879.8665 records/second. Loss is 0.25378904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006371049949031601. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42000/60000][Iteration 2850][Wall Clock 136.03826129s] Trained 120 records in 0.041276683 seconds. Throughput is 2907.2104 records/second. Loss is 0.19605964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006370238246910435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42120/60000][Iteration 2851][Wall Clock 136.080030213s] Trained 120 records in 0.041768923 seconds. Throughput is 2872.9492 records/second. Loss is 0.3692199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006369426751592356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42240/60000][Iteration 2852][Wall Clock 136.122413168s] Trained 120 records in 0.042382955 seconds. Throughput is 2831.327 records/second. Loss is 0.25497475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006368615462998344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42360/60000][Iteration 2853][Wall Clock 136.163958029s] Trained 120 records in 0.041544861 seconds. Throughput is 2888.4438 records/second. Loss is 0.32855833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006367804381049415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42480/60000][Iteration 2854][Wall Clock 136.204940625s] Trained 120 records in 0.040982596 seconds. Throughput is 2928.0723 records/second. Loss is 0.37873897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063669935056666245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42600/60000][Iteration 2855][Wall Clock 136.246593554s] Trained 120 records in 0.041652929 seconds. Throughput is 2880.95 records/second. Loss is 0.18351914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006366182836771072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42720/60000][Iteration 2856][Wall Clock 136.289141129s] Trained 120 records in 0.042547575 seconds. Throughput is 2820.372 records/second. Loss is 0.28744206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006365372374283895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42840/60000][Iteration 2857][Wall Clock 136.33120949s] Trained 120 records in 0.042068361 seconds. Throughput is 2852.5 records/second. Loss is 0.33445626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063645621181262725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 42960/60000][Iteration 2858][Wall Clock 136.375870132s] Trained 120 records in 0.044660642 seconds. Throughput is 2686.9294 records/second. Loss is 0.29300588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006363752068219422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 43080/60000][Iteration 2859][Wall Clock 136.416402418s] Trained 120 records in 0.040532286 seconds. Throughput is 2960.6028 records/second. Loss is 0.24653985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006362942224484601. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 43200/60000][Iteration 2860][Wall Clock 136.456842911s] Trained 120 records in 0.040440493 seconds. Throughput is 2967.323 records/second. Loss is 0.3289418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006362132586843109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:22 INFO  DistriOptimizer$:406 - [Epoch 6 43320/60000][Iteration 2861][Wall Clock 136.497222861s] Trained 120 records in 0.04037995 seconds. Throughput is 2971.772 records/second. Loss is 0.21425278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006361323155216285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 43440/60000][Iteration 2862][Wall Clock 136.538412398s] Trained 120 records in 0.041189537 seconds. Throughput is 2913.3613 records/second. Loss is 0.32044008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006360513929525506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 43560/60000][Iteration 2863][Wall Clock 136.579569386s] Trained 120 records in 0.041156988 seconds. Throughput is 2915.6653 records/second. Loss is 0.3623556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00635970490969219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 43680/60000][Iteration 2864][Wall Clock 136.635522308s] Trained 120 records in 0.055952922 seconds. Throughput is 2144.6602 records/second. Loss is 0.3443585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006358896095637797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 43800/60000][Iteration 2865][Wall Clock 136.683834299s] Trained 120 records in 0.048311991 seconds. Throughput is 2483.8555 records/second. Loss is 0.38742167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006358087487283825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 43920/60000][Iteration 2866][Wall Clock 136.72941685s] Trained 120 records in 0.045582551 seconds. Throughput is 2632.5862 records/second. Loss is 0.27400103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006357279084551812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44040/60000][Iteration 2867][Wall Clock 136.770734627s] Trained 120 records in 0.041317777 seconds. Throughput is 2904.3188 records/second. Loss is 0.32072717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006356470887363336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44160/60000][Iteration 2868][Wall Clock 136.811931016s] Trained 120 records in 0.041196389 seconds. Throughput is 2912.8767 records/second. Loss is 0.3826685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006355662895640016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44280/60000][Iteration 2869][Wall Clock 136.853185017s] Trained 120 records in 0.041254001 seconds. Throughput is 2908.8086 records/second. Loss is 0.2998644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063548551093035085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44400/60000][Iteration 2870][Wall Clock 136.894206187s] Trained 120 records in 0.04102117 seconds. Throughput is 2925.3188 records/second. Loss is 0.23286936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063540475282755126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44520/60000][Iteration 2871][Wall Clock 136.93515224s] Trained 120 records in 0.040946053 seconds. Throughput is 2930.6855 records/second. Loss is 0.3607058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063532401524777635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44640/60000][Iteration 2872][Wall Clock 136.985010327s] Trained 120 records in 0.049858087 seconds. Throughput is 2406.8313 records/second. Loss is 0.346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006352432981832042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44760/60000][Iteration 2873][Wall Clock 137.026555849s] Trained 120 records in 0.041545522 seconds. Throughput is 2888.398 records/second. Loss is 0.33055872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063516260162601625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 44880/60000][Iteration 2874][Wall Clock 137.068187497s] Trained 120 records in 0.041631648 seconds. Throughput is 2882.4226 records/second. Loss is 0.36986583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006350819255683983. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45000/60000][Iteration 2875][Wall Clock 137.109859396s] Trained 120 records in 0.041671899 seconds. Throughput is 2879.6384 records/second. Loss is 0.29690856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063500127000254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45120/60000][Iteration 2876][Wall Clock 137.15341351s] Trained 120 records in 0.043554114 seconds. Throughput is 2755.1934 records/second. Loss is 0.23949914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006349206349206348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45240/60000][Iteration 2877][Wall Clock 137.196248845s] Trained 120 records in 0.042835335 seconds. Throughput is 2801.4255 records/second. Loss is 0.26273867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006348400203148806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45360/60000][Iteration 2878][Wall Clock 137.239643969s] Trained 120 records in 0.043395124 seconds. Throughput is 2765.2876 records/second. Loss is 0.28394607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063475942617747865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45480/60000][Iteration 2879][Wall Clock 137.281104249s] Trained 120 records in 0.04146028 seconds. Throughput is 2894.3364 records/second. Loss is 0.3610882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063467885250063465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45600/60000][Iteration 2880][Wall Clock 137.321986931s] Trained 120 records in 0.040882682 seconds. Throughput is 2935.2283 records/second. Loss is 0.29842058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006345982992765579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45720/60000][Iteration 2881][Wall Clock 137.363435305s] Trained 120 records in 0.041448374 seconds. Throughput is 2895.168 records/second. Loss is 0.33713955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006345177664974619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45840/60000][Iteration 2882][Wall Clock 137.404836964s] Trained 120 records in 0.041401659 seconds. Throughput is 2898.4346 records/second. Loss is 0.2531822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00634437254155564. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 45960/60000][Iteration 2883][Wall Clock 137.446175607s] Trained 120 records in 0.041338643 seconds. Throughput is 2902.853 records/second. Loss is 0.34647048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006343567622430855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:23 INFO  DistriOptimizer$:406 - [Epoch 6 46080/60000][Iteration 2884][Wall Clock 137.487697432s] Trained 120 records in 0.041521825 seconds. Throughput is 2890.0464 records/second. Loss is 0.33697924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006342762907522517. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 46200/60000][Iteration 2885][Wall Clock 137.528742154s] Trained 120 records in 0.041044722 seconds. Throughput is 2923.6401 records/second. Loss is 0.3074535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006341958396752918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 46320/60000][Iteration 2886][Wall Clock 137.573033476s] Trained 120 records in 0.044291322 seconds. Throughput is 2709.3345 records/second. Loss is 0.3179606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063411540900443885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 46440/60000][Iteration 2887][Wall Clock 137.614703683s] Trained 120 records in 0.041670207 seconds. Throughput is 2879.7554 records/second. Loss is 0.4240302. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063403499873193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 46560/60000][Iteration 2888][Wall Clock 137.656289848s] Trained 120 records in 0.041586165 seconds. Throughput is 2885.5752 records/second. Loss is 0.28410614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006339546088500064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 46680/60000][Iteration 2889][Wall Clock 137.704015237s] Trained 120 records in 0.047725389 seconds. Throughput is 2514.3848 records/second. Loss is 0.28309172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006338742393509129. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 46800/60000][Iteration 2890][Wall Clock 137.754983687s] Trained 120 records in 0.05096845 seconds. Throughput is 2354.3977 records/second. Loss is 0.39549732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006337938902268983. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 46920/60000][Iteration 2891][Wall Clock 137.799310754s] Trained 120 records in 0.044327067 seconds. Throughput is 2707.1497 records/second. Loss is 0.26905975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063371356147021544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47040/60000][Iteration 2892][Wall Clock 137.840841698s] Trained 120 records in 0.041530944 seconds. Throughput is 2889.4119 records/second. Loss is 0.26032677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063363325307312125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47160/60000][Iteration 2893][Wall Clock 137.882148501s] Trained 120 records in 0.041306803 seconds. Throughput is 2905.0906 records/second. Loss is 0.2613278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063355296502787635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47280/60000][Iteration 2894][Wall Clock 137.924005999s] Trained 120 records in 0.041857498 seconds. Throughput is 2866.8699 records/second. Loss is 0.34490886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063347269732674525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47400/60000][Iteration 2895][Wall Clock 137.965532144s] Trained 120 records in 0.041526145 seconds. Throughput is 2889.7456 records/second. Loss is 0.2889193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006333924499619965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47520/60000][Iteration 2896][Wall Clock 138.00728443s] Trained 120 records in 0.041752286 seconds. Throughput is 2874.094 records/second. Loss is 0.23343855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006333122229259024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47640/60000][Iteration 2897][Wall Clock 138.049318861s] Trained 120 records in 0.042034431 seconds. Throughput is 2854.8025 records/second. Loss is 0.26367417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006332320162107396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47760/60000][Iteration 2898][Wall Clock 138.097259508s] Trained 120 records in 0.047940647 seconds. Throughput is 2503.0952 records/second. Loss is 0.35388705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006331518298087881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 47880/60000][Iteration 2899][Wall Clock 138.142145568s] Trained 120 records in 0.04488606 seconds. Throughput is 2673.4358 records/second. Loss is 0.34669307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006330716637123322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48000/60000][Iteration 2900][Wall Clock 138.183755272s] Trained 120 records in 0.041609704 seconds. Throughput is 2883.9426 records/second. Loss is 0.29331067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006329915179136599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48120/60000][Iteration 2901][Wall Clock 138.224855596s] Trained 120 records in 0.041100324 seconds. Throughput is 2919.685 records/second. Loss is 0.28392208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006329113924050633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48240/60000][Iteration 2902][Wall Clock 138.265938961s] Trained 120 records in 0.041083365 seconds. Throughput is 2920.8901 records/second. Loss is 0.2707861. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006328312871788381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48360/60000][Iteration 2903][Wall Clock 138.306826862s] Trained 120 records in 0.040887901 seconds. Throughput is 2934.8535 records/second. Loss is 0.3145022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006327512022272842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48480/60000][Iteration 2904][Wall Clock 138.347993434s] Trained 120 records in 0.041166572 seconds. Throughput is 2914.9863 records/second. Loss is 0.3025318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006326711375427053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48600/60000][Iteration 2905][Wall Clock 138.389157545s] Trained 120 records in 0.041164111 seconds. Throughput is 2915.1606 records/second. Loss is 0.33484086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006325910931174089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48720/60000][Iteration 2906][Wall Clock 138.430581614s] Trained 120 records in 0.041424069 seconds. Throughput is 2896.8665 records/second. Loss is 0.33533475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006325110689437066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:24 INFO  DistriOptimizer$:406 - [Epoch 6 48840/60000][Iteration 2907][Wall Clock 138.471716846s] Trained 120 records in 0.041135232 seconds. Throughput is 2917.2073 records/second. Loss is 0.23289266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006324310650139135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 48960/60000][Iteration 2908][Wall Clock 138.512745814s] Trained 120 records in 0.041028968 seconds. Throughput is 2924.7627 records/second. Loss is 0.37627372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006323510813203491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49080/60000][Iteration 2909][Wall Clock 138.553562597s] Trained 120 records in 0.040816783 seconds. Throughput is 2939.967 records/second. Loss is 0.2222547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006322711178553364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49200/60000][Iteration 2910][Wall Clock 138.593715927s] Trained 120 records in 0.04015333 seconds. Throughput is 2988.5442 records/second. Loss is 0.24863799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006321911746112025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49320/60000][Iteration 2911][Wall Clock 138.634124092s] Trained 120 records in 0.040408165 seconds. Throughput is 2969.6968 records/second. Loss is 0.24525322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006321112515802781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49440/60000][Iteration 2912][Wall Clock 138.675066514s] Trained 120 records in 0.040942422 seconds. Throughput is 2930.9453 records/second. Loss is 0.25482073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006320313487548982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49560/60000][Iteration 2913][Wall Clock 138.715645801s] Trained 120 records in 0.040579287 seconds. Throughput is 2957.1738 records/second. Loss is 0.2660237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006319514661274014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49680/60000][Iteration 2914][Wall Clock 138.761267653s] Trained 120 records in 0.045621852 seconds. Throughput is 2630.3184 records/second. Loss is 0.29394212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006318716036901302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49800/60000][Iteration 2915][Wall Clock 138.813802978s] Trained 120 records in 0.052535325 seconds. Throughput is 2284.1772 records/second. Loss is 0.27873316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006317917614354309. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 49920/60000][Iteration 2916][Wall Clock 138.863228362s] Trained 120 records in 0.049425384 seconds. Throughput is 2427.9023 records/second. Loss is 0.3628947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063171193935565376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50040/60000][Iteration 2917][Wall Clock 138.903703846s] Trained 120 records in 0.040475484 seconds. Throughput is 2964.7576 records/second. Loss is 0.32204482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006316321374431531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50160/60000][Iteration 2918][Wall Clock 138.943735844s] Trained 120 records in 0.040031998 seconds. Throughput is 2997.602 records/second. Loss is 0.33374417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006315523556902867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50280/60000][Iteration 2919][Wall Clock 138.98428867s] Trained 120 records in 0.040552826 seconds. Throughput is 2959.1033 records/second. Loss is 0.22980163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006314725940894165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50400/60000][Iteration 2920][Wall Clock 139.025535482s] Trained 120 records in 0.041246812 seconds. Throughput is 2909.3157 records/second. Loss is 0.28015321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006313928526329082. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50520/60000][Iteration 2921][Wall Clock 139.067435874s] Trained 120 records in 0.041900392 seconds. Throughput is 2863.935 records/second. Loss is 0.31180707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006313131313131313. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50640/60000][Iteration 2922][Wall Clock 139.108339676s] Trained 120 records in 0.040903802 seconds. Throughput is 2933.7126 records/second. Loss is 0.26961696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006312334301224593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50760/60000][Iteration 2923][Wall Clock 139.149865118s] Trained 120 records in 0.041525442 seconds. Throughput is 2889.7947 records/second. Loss is 0.3120212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006311537490532694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 50880/60000][Iteration 2924][Wall Clock 139.191068819s] Trained 120 records in 0.041203701 seconds. Throughput is 2912.3599 records/second. Loss is 0.29879862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006310740880979427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 51000/60000][Iteration 2925][Wall Clock 139.244273553s] Trained 120 records in 0.053204734 seconds. Throughput is 2255.4385 records/second. Loss is 0.2914344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063099444724886425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 51120/60000][Iteration 2926][Wall Clock 139.285734451s] Trained 120 records in 0.041460898 seconds. Throughput is 2894.2932 records/second. Loss is 0.28606072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006309148264984228. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 51240/60000][Iteration 2927][Wall Clock 139.326623787s] Trained 120 records in 0.040889336 seconds. Throughput is 2934.7505 records/second. Loss is 0.29390314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063083522583901085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 51360/60000][Iteration 2928][Wall Clock 139.367362622s] Trained 120 records in 0.040738835 seconds. Throughput is 2945.5923 records/second. Loss is 0.27275547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006307556452630252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 51480/60000][Iteration 2929][Wall Clock 139.407977673s] Trained 120 records in 0.040615051 seconds. Throughput is 2954.5696 records/second. Loss is 0.2704987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006306760847628658. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 51600/60000][Iteration 2930][Wall Clock 139.448532967s] Trained 120 records in 0.040555294 seconds. Throughput is 2958.923 records/second. Loss is 0.25931475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006305965443309371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:25 INFO  DistriOptimizer$:406 - [Epoch 6 51720/60000][Iteration 2931][Wall Clock 139.489240088s] Trained 120 records in 0.040707121 seconds. Throughput is 2947.887 records/second. Loss is 0.3025305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006305170239596469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 51840/60000][Iteration 2932][Wall Clock 139.530264085s] Trained 120 records in 0.041023997 seconds. Throughput is 2925.1172 records/second. Loss is 0.20159917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0063043752364140716. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 51960/60000][Iteration 2933][Wall Clock 139.570604055s] Trained 120 records in 0.04033997 seconds. Throughput is 2974.7173 records/second. Loss is 0.26828262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006303580433686334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52080/60000][Iteration 2934][Wall Clock 139.61171663s] Trained 120 records in 0.041112575 seconds. Throughput is 2918.815 records/second. Loss is 0.3983327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006302785831337451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52200/60000][Iteration 2935][Wall Clock 139.653299989s] Trained 120 records in 0.041583359 seconds. Throughput is 2885.7698 records/second. Loss is 0.33443826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006301991429291657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52320/60000][Iteration 2936][Wall Clock 139.696530641s] Trained 120 records in 0.043230652 seconds. Throughput is 2775.808 records/second. Loss is 0.3432215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00630119722747322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52440/60000][Iteration 2937][Wall Clock 139.737701713s] Trained 120 records in 0.041171072 seconds. Throughput is 2914.668 records/second. Loss is 0.23295577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006300403225806451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52560/60000][Iteration 2938][Wall Clock 139.779582526s] Trained 120 records in 0.041880813 seconds. Throughput is 2865.274 records/second. Loss is 0.30744496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062996094242156984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52680/60000][Iteration 2939][Wall Clock 139.821013434s] Trained 120 records in 0.041430908 seconds. Throughput is 2896.3882 records/second. Loss is 0.235074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062988158226253465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52800/60000][Iteration 2940][Wall Clock 139.86590757s] Trained 120 records in 0.044894136 seconds. Throughput is 2672.9548 records/second. Loss is 0.2574439. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062980224209598186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 52920/60000][Iteration 2941][Wall Clock 139.917608194s] Trained 120 records in 0.051700624 seconds. Throughput is 2321.0552 records/second. Loss is 0.37620035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006297229219143576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53040/60000][Iteration 2942][Wall Clock 139.959507322s] Trained 120 records in 0.041899128 seconds. Throughput is 2864.0212 records/second. Loss is 0.3666534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006296436217101121. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53160/60000][Iteration 2943][Wall Clock 140.000844364s] Trained 120 records in 0.041337042 seconds. Throughput is 2902.9653 records/second. Loss is 0.2714111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006295643414756988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53280/60000][Iteration 2944][Wall Clock 140.042320102s] Trained 120 records in 0.041475738 seconds. Throughput is 2893.2576 records/second. Loss is 0.23059398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006294850812035755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53400/60000][Iteration 2945][Wall Clock 140.083177038s] Trained 120 records in 0.040856936 seconds. Throughput is 2937.078 records/second. Loss is 0.33803943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062940584088620345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53520/60000][Iteration 2946][Wall Clock 140.124054579s] Trained 120 records in 0.040877541 seconds. Throughput is 2935.5974 records/second. Loss is 0.2691633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062932662051604785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53640/60000][Iteration 2947][Wall Clock 140.16489927s] Trained 120 records in 0.040844691 seconds. Throughput is 2937.9585 records/second. Loss is 0.281668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006292474200855777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53760/60000][Iteration 2948][Wall Clock 140.205633795s] Trained 120 records in 0.040734525 seconds. Throughput is 2945.904 records/second. Loss is 0.29086807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062916823958726565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 53880/60000][Iteration 2949][Wall Clock 140.246926843s] Trained 120 records in 0.041293048 seconds. Throughput is 2906.058 records/second. Loss is 0.2217359. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006290890790135884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 54000/60000][Iteration 2950][Wall Clock 140.28731503s] Trained 120 records in 0.040388187 seconds. Throughput is 2971.166 records/second. Loss is 0.2688483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006290099383570261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 54120/60000][Iteration 2951][Wall Clock 140.334916288s] Trained 120 records in 0.047601258 seconds. Throughput is 2520.942 records/second. Loss is 0.30605313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006289308176100628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 54240/60000][Iteration 2952][Wall Clock 140.382139951s] Trained 120 records in 0.047223663 seconds. Throughput is 2541.0989 records/second. Loss is 0.24111955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006288517167651868. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 54360/60000][Iteration 2953][Wall Clock 140.423529535s] Trained 120 records in 0.041389584 seconds. Throughput is 2899.28 records/second. Loss is 0.28252512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006287726358148894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:26 INFO  DistriOptimizer$:406 - [Epoch 6 54480/60000][Iteration 2954][Wall Clock 140.464397514s] Trained 120 records in 0.040867979 seconds. Throughput is 2936.2842 records/second. Loss is 0.22426595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00628693574751666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 54600/60000][Iteration 2955][Wall Clock 140.50559923s] Trained 120 records in 0.041201716 seconds. Throughput is 2912.5002 records/second. Loss is 0.30508322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006286145335680161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 54720/60000][Iteration 2956][Wall Clock 140.546916176s] Trained 120 records in 0.041316946 seconds. Throughput is 2904.3774 records/second. Loss is 0.28964236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006285355122564424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 54840/60000][Iteration 2957][Wall Clock 140.588012554s] Trained 120 records in 0.041096378 seconds. Throughput is 2919.9653 records/second. Loss is 0.32675114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006284565108094519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 54960/60000][Iteration 2958][Wall Clock 140.628692106s] Trained 120 records in 0.040679552 seconds. Throughput is 2949.885 records/second. Loss is 0.25625575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006283775292195551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55080/60000][Iteration 2959][Wall Clock 140.66959108s] Trained 120 records in 0.040898974 seconds. Throughput is 2934.0588 records/second. Loss is 0.48930266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062829856747926615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55200/60000][Iteration 2960][Wall Clock 140.710210802s] Trained 120 records in 0.040619722 seconds. Throughput is 2954.2297 records/second. Loss is 0.24857846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062821962558110315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55320/60000][Iteration 2961][Wall Clock 140.751003607s] Trained 120 records in 0.040792805 seconds. Throughput is 2941.6953 records/second. Loss is 0.22438882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006281407035175879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55440/60000][Iteration 2962][Wall Clock 140.791613804s] Trained 120 records in 0.040610197 seconds. Throughput is 2954.9229 records/second. Loss is 0.24204044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00628061801281246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55560/60000][Iteration 2963][Wall Clock 140.832390903s] Trained 120 records in 0.040777099 seconds. Throughput is 2942.8284 records/second. Loss is 0.28869888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006279829188646069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55680/60000][Iteration 2964][Wall Clock 140.87321886s] Trained 120 records in 0.040827957 seconds. Throughput is 2939.1626 records/second. Loss is 0.26293686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006279040562602035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55800/60000][Iteration 2965][Wall Clock 140.924557779s] Trained 120 records in 0.051338919 seconds. Throughput is 2337.408 records/second. Loss is 0.35169303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006278252134605726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 55920/60000][Iteration 2966][Wall Clock 140.975373431s] Trained 120 records in 0.050815652 seconds. Throughput is 2361.477 records/second. Loss is 0.34382975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006277463904582549. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56040/60000][Iteration 2967][Wall Clock 141.020542837s] Trained 120 records in 0.045169406 seconds. Throughput is 2656.6655 records/second. Loss is 0.18839437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006276675872457947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56160/60000][Iteration 2968][Wall Clock 141.062294186s] Trained 120 records in 0.041751349 seconds. Throughput is 2874.1587 records/second. Loss is 0.2525987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006275888038157399. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56280/60000][Iteration 2969][Wall Clock 141.103364795s] Trained 120 records in 0.041070609 seconds. Throughput is 2921.7974 records/second. Loss is 0.24719377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062751004016064265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56400/60000][Iteration 2970][Wall Clock 141.144791819s] Trained 120 records in 0.041427024 seconds. Throughput is 2896.66 records/second. Loss is 0.39522445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006274312962730582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56520/60000][Iteration 2971][Wall Clock 141.187852221s] Trained 120 records in 0.043060402 seconds. Throughput is 2786.783 records/second. Loss is 0.2968884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006273525721455458. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56640/60000][Iteration 2972][Wall Clock 141.230326328s] Trained 120 records in 0.042474107 seconds. Throughput is 2825.2507 records/second. Loss is 0.21720466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006272738677706687. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56760/60000][Iteration 2973][Wall Clock 141.271373485s] Trained 120 records in 0.041047157 seconds. Throughput is 2923.4668 records/second. Loss is 0.26831186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006271951831409934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 56880/60000][Iteration 2974][Wall Clock 141.312764633s] Trained 120 records in 0.041391148 seconds. Throughput is 2899.1707 records/second. Loss is 0.40797615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062711651824909065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 57000/60000][Iteration 2975][Wall Clock 141.353903516s] Trained 120 records in 0.041138883 seconds. Throughput is 2916.9485 records/second. Loss is 0.25549436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006270378730875345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 57120/60000][Iteration 2976][Wall Clock 141.394516826s] Trained 120 records in 0.04061331 seconds. Throughput is 2954.6965 records/second. Loss is 0.30107293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006269592476489029. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:27 INFO  DistriOptimizer$:406 - [Epoch 6 57240/60000][Iteration 2977][Wall Clock 141.435261052s] Trained 120 records in 0.040744226 seconds. Throughput is 2945.2026 records/second. Loss is 0.28861699. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006268806419257773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 57360/60000][Iteration 2978][Wall Clock 141.487497203s] Trained 120 records in 0.052236151 seconds. Throughput is 2297.2595 records/second. Loss is 0.29031098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006268020559107433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 57480/60000][Iteration 2979][Wall Clock 141.531362369s] Trained 120 records in 0.043865166 seconds. Throughput is 2735.6558 records/second. Loss is 0.25664744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062672348959639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 57600/60000][Iteration 2980][Wall Clock 141.573004618s] Trained 120 records in 0.041642249 seconds. Throughput is 2881.6887 records/second. Loss is 0.25567505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062664494297531015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 57720/60000][Iteration 2981][Wall Clock 141.614661108s] Trained 120 records in 0.04165649 seconds. Throughput is 2880.7036 records/second. Loss is 0.30585384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006265664160401002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 57840/60000][Iteration 2982][Wall Clock 141.656075695s] Trained 120 records in 0.041414587 seconds. Throughput is 2897.5298 records/second. Loss is 0.38437086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006264879087833605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 57960/60000][Iteration 2983][Wall Clock 141.697039363s] Trained 120 records in 0.040963668 seconds. Throughput is 2929.425 records/second. Loss is 0.25466144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006264094211976948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58080/60000][Iteration 2984][Wall Clock 141.737978014s] Trained 120 records in 0.040938651 seconds. Throughput is 2931.2153 records/second. Loss is 0.21436714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006263309532757109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58200/60000][Iteration 2985][Wall Clock 141.779196057s] Trained 120 records in 0.041218043 seconds. Throughput is 2911.3464 records/second. Loss is 0.24183327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006262525050100201. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58320/60000][Iteration 2986][Wall Clock 141.819618703s] Trained 120 records in 0.040422646 seconds. Throughput is 2968.633 records/second. Loss is 0.3133516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006261740763932373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58440/60000][Iteration 2987][Wall Clock 141.860632144s] Trained 120 records in 0.041013441 seconds. Throughput is 2925.87 records/second. Loss is 0.31958646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006260956674179815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58560/60000][Iteration 2988][Wall Clock 141.902781726s] Trained 120 records in 0.042149582 seconds. Throughput is 2847.0034 records/second. Loss is 0.20555255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00626017278076875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58680/60000][Iteration 2989][Wall Clock 141.945763568s] Trained 120 records in 0.042981842 seconds. Throughput is 2791.8767 records/second. Loss is 0.4085469. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006259389083625439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58800/60000][Iteration 2990][Wall Clock 141.994660391s] Trained 120 records in 0.048896823 seconds. Throughput is 2454.1472 records/second. Loss is 0.26253992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00625860558267618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 58920/60000][Iteration 2991][Wall Clock 142.046948854s] Trained 120 records in 0.052288463 seconds. Throughput is 2294.9614 records/second. Loss is 0.29173952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00625782227784731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59040/60000][Iteration 2992][Wall Clock 142.088996037s] Trained 120 records in 0.042047183 seconds. Throughput is 2853.9368 records/second. Loss is 0.32763407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006257039169065198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59160/60000][Iteration 2993][Wall Clock 142.13096017s] Trained 120 records in 0.041964133 seconds. Throughput is 2859.585 records/second. Loss is 0.28692815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006256256256256257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59280/60000][Iteration 2994][Wall Clock 142.177385798s] Trained 120 records in 0.046425628 seconds. Throughput is 2584.779 records/second. Loss is 0.2708276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006255473539346928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59400/60000][Iteration 2995][Wall Clock 142.218995801s] Trained 120 records in 0.041610003 seconds. Throughput is 2883.9219 records/second. Loss is 0.22463539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006254691018263698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59520/60000][Iteration 2996][Wall Clock 142.260074742s] Trained 120 records in 0.041078941 seconds. Throughput is 2921.2048 records/second. Loss is 0.24681959. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006253908692933083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59640/60000][Iteration 2997][Wall Clock 142.302866744s] Trained 120 records in 0.042792002 seconds. Throughput is 2804.2622 records/second. Loss is 0.29006815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00625312656328164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59760/60000][Iteration 2998][Wall Clock 142.344628012s] Trained 120 records in 0.041761268 seconds. Throughput is 2873.476 records/second. Loss is 0.20152266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006252344629235963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 59880/60000][Iteration 2999][Wall Clock 142.386144372s] Trained 120 records in 0.04151636 seconds. Throughput is 2890.4268 records/second. Loss is 0.35621884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00625156289072268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:406 - [Epoch 6 60000/60000][Iteration 3000][Wall Clock 142.427143872s] Trained 120 records in 0.0409995 seconds. Throughput is 2926.865 records/second. Loss is 0.3368943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006250781347668459. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:28 INFO  DistriOptimizer$:451 - [Epoch 6 60000/60000][Iteration 3000][Wall Clock 142.427143872s] Epoch finished. Wall clock time is 143258.852331 ms
2019-10-23 15:55:28 INFO  DistriOptimizer$:111 - [Epoch 6 60000/60000][Iteration 3000][Wall Clock 142.427143872s] Validate model...
2019-10-23 15:55:29 INFO  DistriOptimizer$:177 - [Epoch 6 60000/60000][Iteration 3000][Wall Clock 142.427143872s] validate model throughput is 15068.129 records/second
2019-10-23 15:55:29 INFO  DistriOptimizer$:180 - [Epoch 6 60000/60000][Iteration 3000][Wall Clock 142.427143872s] Top1Accuracy is Accuracy(correct: 9243, count: 10000, accuracy: 0.9243)
2019-10-23 15:55:29 INFO  DistriOptimizer$:220 - [Wall Clock 143.258852331s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:55:29 INFO  DistriOptimizer$:225 - [Wall Clock 143.258852331s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:55:29 INFO  DistriOptimizer$:406 - [Epoch 7 120/60000][Iteration 3001][Wall Clock 143.309252599s] Trained 120 records in 0.050400268 seconds. Throughput is 2380.9397 records/second. Loss is 0.32061872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062499999999999995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:29 INFO  DistriOptimizer$:406 - [Epoch 7 240/60000][Iteration 3002][Wall Clock 143.350374173s] Trained 120 records in 0.041121574 seconds. Throughput is 2918.1763 records/second. Loss is 0.34134537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006249218847644044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:29 INFO  DistriOptimizer$:406 - [Epoch 7 360/60000][Iteration 3003][Wall Clock 143.399417531s] Trained 120 records in 0.049043358 seconds. Throughput is 2446.8145 records/second. Loss is 0.3660938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006248437890527368. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:29 INFO  DistriOptimizer$:406 - [Epoch 7 480/60000][Iteration 3004][Wall Clock 143.446725759s] Trained 120 records in 0.047308228 seconds. Throughput is 2536.5566 records/second. Loss is 0.24292098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006247657128576784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:29 INFO  DistriOptimizer$:406 - [Epoch 7 600/60000][Iteration 3005][Wall Clock 143.48824942s] Trained 120 records in 0.041523661 seconds. Throughput is 2889.9185 records/second. Loss is 0.27220482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006246876561719141. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:29 INFO  DistriOptimizer$:406 - [Epoch 7 720/60000][Iteration 3006][Wall Clock 143.529984216s] Trained 120 records in 0.041734796 seconds. Throughput is 2875.2986 records/second. Loss is 0.35857046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006246096189881325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:29 INFO  DistriOptimizer$:406 - [Epoch 7 840/60000][Iteration 3007][Wall Clock 143.571360451s] Trained 120 records in 0.041376235 seconds. Throughput is 2900.2153 records/second. Loss is 0.4406568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006245316012990257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 960/60000][Iteration 3008][Wall Clock 143.612556559s] Trained 120 records in 0.041196108 seconds. Throughput is 2912.8965 records/second. Loss is 0.3491515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006244536030972899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1080/60000][Iteration 3009][Wall Clock 143.65690557s] Trained 120 records in 0.044349011 seconds. Throughput is 2705.81 records/second. Loss is 0.31584412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006243756243756244. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1200/60000][Iteration 3010][Wall Clock 143.698892532s] Trained 120 records in 0.041986962 seconds. Throughput is 2858.03 records/second. Loss is 0.45697293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006242976651267325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1320/60000][Iteration 3011][Wall Clock 143.740522734s] Trained 120 records in 0.041630202 seconds. Throughput is 2882.5227 records/second. Loss is 0.30583626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006242197253433209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1440/60000][Iteration 3012][Wall Clock 143.782144407s] Trained 120 records in 0.041621673 seconds. Throughput is 2883.1133 records/second. Loss is 0.24947725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006241418050181001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1560/60000][Iteration 3013][Wall Clock 143.825824377s] Trained 120 records in 0.04367997 seconds. Throughput is 2747.2546 records/second. Loss is 0.27917764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006240639041437843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1680/60000][Iteration 3014][Wall Clock 143.874713964s] Trained 120 records in 0.048889587 seconds. Throughput is 2454.5103 records/second. Loss is 0.2788272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006239860227130912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1800/60000][Iteration 3015][Wall Clock 143.919721568s] Trained 120 records in 0.045007604 seconds. Throughput is 2666.216 records/second. Loss is 0.44442752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006239081607187422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 1920/60000][Iteration 3016][Wall Clock 143.960579807s] Trained 120 records in 0.040858239 seconds. Throughput is 2936.9841 records/second. Loss is 0.36871418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006238303181534623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2040/60000][Iteration 3017][Wall Clock 144.001748031s] Trained 120 records in 0.041168224 seconds. Throughput is 2914.8694 records/second. Loss is 0.35063213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062375249500997995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2160/60000][Iteration 3018][Wall Clock 144.042992454s] Trained 120 records in 0.041244423 seconds. Throughput is 2909.4844 records/second. Loss is 0.39670697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062367469128102775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2280/60000][Iteration 3019][Wall Clock 144.084835339s] Trained 120 records in 0.041842885 seconds. Throughput is 2867.871 records/second. Loss is 0.36216778. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006235969069593414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2400/60000][Iteration 3020][Wall Clock 144.12606699s] Trained 120 records in 0.041231651 seconds. Throughput is 2910.3855 records/second. Loss is 0.31015235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006235191420376605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2520/60000][Iteration 3021][Wall Clock 144.16804589s] Trained 120 records in 0.0419789 seconds. Throughput is 2858.579 records/second. Loss is 0.27824083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006234413965087281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2640/60000][Iteration 3022][Wall Clock 144.209925231s] Trained 120 records in 0.041879341 seconds. Throughput is 2865.3745 records/second. Loss is 0.2691077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006233636703652911. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2760/60000][Iteration 3023][Wall Clock 144.251362879s] Trained 120 records in 0.041437648 seconds. Throughput is 2895.9172 records/second. Loss is 0.35071817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006232859636000997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 2880/60000][Iteration 3024][Wall Clock 144.293234569s] Trained 120 records in 0.04187169 seconds. Throughput is 2865.8982 records/second. Loss is 0.3152322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00623208276205908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 3000/60000][Iteration 3025][Wall Clock 144.334996132s] Trained 120 records in 0.041761563 seconds. Throughput is 2873.4558 records/second. Loss is 0.26555538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006231306081754736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 3120/60000][Iteration 3026][Wall Clock 144.376625496s] Trained 120 records in 0.041629364 seconds. Throughput is 2882.5808 records/second. Loss is 0.3950389. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006230529595015576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 3240/60000][Iteration 3027][Wall Clock 144.420348975s] Trained 120 records in 0.043723479 seconds. Throughput is 2744.5208 records/second. Loss is 0.247576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00622975330176925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 3360/60000][Iteration 3028][Wall Clock 144.465496449s] Trained 120 records in 0.045147474 seconds. Throughput is 2657.956 records/second. Loss is 0.51222825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006228977201943441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 3480/60000][Iteration 3029][Wall Clock 144.506267853s] Trained 120 records in 0.040771404 seconds. Throughput is 2943.2395 records/second. Loss is 0.20520397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00622820129546587. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 3600/60000][Iteration 3030][Wall Clock 144.556306279s] Trained 120 records in 0.050038426 seconds. Throughput is 2398.157 records/second. Loss is 0.29757324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006227425582264292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:30 INFO  DistriOptimizer$:406 - [Epoch 7 3720/60000][Iteration 3031][Wall Clock 144.60251929s] Trained 120 records in 0.046213011 seconds. Throughput is 2596.6711 records/second. Loss is 0.31151444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006226650062266501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 3840/60000][Iteration 3032][Wall Clock 144.645232907s] Trained 120 records in 0.042713617 seconds. Throughput is 2809.4087 records/second. Loss is 0.33248618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006225874735400323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 3960/60000][Iteration 3033][Wall Clock 144.686214577s] Trained 120 records in 0.04098167 seconds. Throughput is 2928.1384 records/second. Loss is 0.293193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006225099601593625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4080/60000][Iteration 3034][Wall Clock 144.727056792s] Trained 120 records in 0.040842215 seconds. Throughput is 2938.1362 records/second. Loss is 0.3352045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006224324660774306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4200/60000][Iteration 3035][Wall Clock 144.767350322s] Trained 120 records in 0.04029353 seconds. Throughput is 2978.1458 records/second. Loss is 0.18061161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006223549912870301. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4320/60000][Iteration 3036][Wall Clock 144.808290739s] Trained 120 records in 0.040940417 seconds. Throughput is 2931.0886 records/second. Loss is 0.2923797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006222775357809583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4440/60000][Iteration 3037][Wall Clock 144.848972289s] Trained 120 records in 0.04068155 seconds. Throughput is 2949.7402 records/second. Loss is 0.32227883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006222000995520159. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4560/60000][Iteration 3038][Wall Clock 144.89248052s] Trained 120 records in 0.043508231 seconds. Throughput is 2758.0989 records/second. Loss is 0.26675606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006221226825930073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4680/60000][Iteration 3039][Wall Clock 144.940819038s] Trained 120 records in 0.048338518 seconds. Throughput is 2482.4924 records/second. Loss is 0.37311348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006220452848967405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4800/60000][Iteration 3040][Wall Clock 144.986335719s] Trained 120 records in 0.045516681 seconds. Throughput is 2636.396 records/second. Loss is 0.34058282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006219679064560268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 4920/60000][Iteration 3041][Wall Clock 145.026491752s] Trained 120 records in 0.040156033 seconds. Throughput is 2988.343 records/second. Loss is 0.40135106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006218905472636815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5040/60000][Iteration 3042][Wall Clock 145.067320171s] Trained 120 records in 0.040828419 seconds. Throughput is 2939.1294 records/second. Loss is 0.2695626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006218132073125233. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5160/60000][Iteration 3043][Wall Clock 145.108641324s] Trained 120 records in 0.041321153 seconds. Throughput is 2904.0815 records/second. Loss is 0.2658385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006217358865953743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5280/60000][Iteration 3044][Wall Clock 145.150828964s] Trained 120 records in 0.04218764 seconds. Throughput is 2844.435 records/second. Loss is 0.19892135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006216585851050603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5400/60000][Iteration 3045][Wall Clock 145.192087771s] Trained 120 records in 0.041258807 seconds. Throughput is 2908.47 records/second. Loss is 0.29411322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006215813028344107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5520/60000][Iteration 3046][Wall Clock 145.232790117s] Trained 120 records in 0.040702346 seconds. Throughput is 2948.233 records/second. Loss is 0.26310688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006215040397762586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5640/60000][Iteration 3047][Wall Clock 145.273484478s] Trained 120 records in 0.040694361 seconds. Throughput is 2948.8115 records/second. Loss is 0.36873138. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006214267959234403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5760/60000][Iteration 3048][Wall Clock 145.314235754s] Trained 120 records in 0.040751276 seconds. Throughput is 2944.693 records/second. Loss is 0.35762757. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006213495712687958. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 5880/60000][Iteration 3049][Wall Clock 145.355615229s] Trained 120 records in 0.041379475 seconds. Throughput is 2899.9885 records/second. Loss is 0.3835469. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00621272365805169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 6000/60000][Iteration 3050][Wall Clock 145.396677662s] Trained 120 records in 0.041062433 seconds. Throughput is 2922.3792 records/second. Loss is 0.23001604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062119517952540695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 6120/60000][Iteration 3051][Wall Clock 145.438506922s] Trained 120 records in 0.04182926 seconds. Throughput is 2868.8054 records/second. Loss is 0.24107075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006211180124223603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 6240/60000][Iteration 3052][Wall Clock 145.479630795s] Trained 120 records in 0.041123873 seconds. Throughput is 2918.013 records/second. Loss is 0.26452193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006210408644888834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 6360/60000][Iteration 3053][Wall Clock 145.521425115s] Trained 120 records in 0.04179432 seconds. Throughput is 2871.2036 records/second. Loss is 0.349101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00620963735717834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:31 INFO  DistriOptimizer$:406 - [Epoch 7 6480/60000][Iteration 3054][Wall Clock 145.565586753s] Trained 120 records in 0.044161638 seconds. Throughput is 2717.2905 records/second. Loss is 0.32046887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062088662610207375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 6600/60000][Iteration 3055][Wall Clock 145.606221493s] Trained 120 records in 0.04063474 seconds. Throughput is 2953.1382 records/second. Loss is 0.3485813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006208095356344674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 6720/60000][Iteration 3056][Wall Clock 145.646774704s] Trained 120 records in 0.040553211 seconds. Throughput is 2959.0752 records/second. Loss is 0.35743713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006207324643078833. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 6840/60000][Iteration 3057][Wall Clock 145.701126507s] Trained 120 records in 0.054351803 seconds. Throughput is 2207.8384 records/second. Loss is 0.261745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006206554121151936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 6960/60000][Iteration 3058][Wall Clock 145.744596115s] Trained 120 records in 0.043469608 seconds. Throughput is 2760.5493 records/second. Loss is 0.28441164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006205783790492738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7080/60000][Iteration 3059][Wall Clock 145.785902323s] Trained 120 records in 0.041306208 seconds. Throughput is 2905.1323 records/second. Loss is 0.2710791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006205013651030032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7200/60000][Iteration 3060][Wall Clock 145.826979379s] Trained 120 records in 0.041077056 seconds. Throughput is 2921.3389 records/second. Loss is 0.29818237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006204243702692642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7320/60000][Iteration 3061][Wall Clock 145.868357946s] Trained 120 records in 0.041378567 seconds. Throughput is 2900.052 records/second. Loss is 0.32465908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006203473945409429. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7440/60000][Iteration 3062][Wall Clock 145.909540882s] Trained 120 records in 0.041182936 seconds. Throughput is 2913.8284 records/second. Loss is 0.32049176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062027043791092916. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7560/60000][Iteration 3063][Wall Clock 145.953809289s] Trained 120 records in 0.044268407 seconds. Throughput is 2710.7368 records/second. Loss is 0.3771574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006201935003721161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7680/60000][Iteration 3064][Wall Clock 145.996707776s] Trained 120 records in 0.042898487 seconds. Throughput is 2797.3015 records/second. Loss is 0.35463944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0062011658191740045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7800/60000][Iteration 3065][Wall Clock 146.047674476s] Trained 120 records in 0.0509667 seconds. Throughput is 2354.4785 records/second. Loss is 0.23987924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006200396825396825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 7920/60000][Iteration 3066][Wall Clock 146.09276343s] Trained 120 records in 0.045088954 seconds. Throughput is 2661.4058 records/second. Loss is 0.3260848. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006199628022318661. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8040/60000][Iteration 3067][Wall Clock 146.133871843s] Trained 120 records in 0.041108413 seconds. Throughput is 2919.1104 records/second. Loss is 0.26903617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061988594098685845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8160/60000][Iteration 3068][Wall Clock 146.175225473s] Trained 120 records in 0.04135363 seconds. Throughput is 2901.8008 records/second. Loss is 0.254605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006198090987975704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8280/60000][Iteration 3069][Wall Clock 146.216436144s] Trained 120 records in 0.041210671 seconds. Throughput is 2911.8672 records/second. Loss is 0.32121035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006197322756569162. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8400/60000][Iteration 3070][Wall Clock 146.259090946s] Trained 120 records in 0.042654802 seconds. Throughput is 2813.2825 records/second. Loss is 0.2716997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006196554715578139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8520/60000][Iteration 3071][Wall Clock 146.301416483s] Trained 120 records in 0.042325537 seconds. Throughput is 2835.1677 records/second. Loss is 0.22226743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006195786864931847. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8640/60000][Iteration 3072][Wall Clock 146.343324873s] Trained 120 records in 0.04190839 seconds. Throughput is 2863.3884 records/second. Loss is 0.23621629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006195019204559534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8760/60000][Iteration 3073][Wall Clock 146.385335454s] Trained 120 records in 0.042010581 seconds. Throughput is 2856.4233 records/second. Loss is 0.3306246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061942517343904855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 8880/60000][Iteration 3074][Wall Clock 146.427471644s] Trained 120 records in 0.04213619 seconds. Throughput is 2847.9082 records/second. Loss is 0.23918012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00619348445435402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 9000/60000][Iteration 3075][Wall Clock 146.469122119s] Trained 120 records in 0.041650475 seconds. Throughput is 2881.1196 records/second. Loss is 0.2714819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00619271736437949. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 9120/60000][Iteration 3076][Wall Clock 146.511188865s] Trained 120 records in 0.042066746 seconds. Throughput is 2852.6096 records/second. Loss is 0.3627395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006191950464396285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 9240/60000][Iteration 3077][Wall Clock 146.552242537s] Trained 120 records in 0.041053672 seconds. Throughput is 2923.003 records/second. Loss is 0.33716863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006191183754333828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:32 INFO  DistriOptimizer$:406 - [Epoch 7 9360/60000][Iteration 3078][Wall Clock 146.593312561s] Trained 120 records in 0.041070024 seconds. Throughput is 2921.8389 records/second. Loss is 0.43282458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006190417234121579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 9480/60000][Iteration 3079][Wall Clock 146.634345357s] Trained 120 records in 0.041032796 seconds. Throughput is 2924.49 records/second. Loss is 0.29461756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006189650903689031. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 9600/60000][Iteration 3080][Wall Clock 146.678452854s] Trained 120 records in 0.044107497 seconds. Throughput is 2720.626 records/second. Loss is 0.26224032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006188884762965714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 9720/60000][Iteration 3081][Wall Clock 146.719024481s] Trained 120 records in 0.040571627 seconds. Throughput is 2957.7322 records/second. Loss is 0.25003773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061881188118811875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 9840/60000][Iteration 3082][Wall Clock 146.759029963s] Trained 120 records in 0.040005482 seconds. Throughput is 2999.5889 records/second. Loss is 0.36219493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006187353050365054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 9960/60000][Iteration 3083][Wall Clock 146.806969244s] Trained 120 records in 0.047939281 seconds. Throughput is 2503.1665 records/second. Loss is 0.28182507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006186587478346944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10080/60000][Iteration 3084][Wall Clock 146.855332953s] Trained 120 records in 0.048363709 seconds. Throughput is 2481.1992 records/second. Loss is 0.28886378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006185822095756526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10200/60000][Iteration 3085][Wall Clock 146.899815153s] Trained 120 records in 0.0444822 seconds. Throughput is 2697.7083 records/second. Loss is 0.20519467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006185056902523503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10320/60000][Iteration 3086][Wall Clock 146.941141883s] Trained 120 records in 0.04132673 seconds. Throughput is 2903.6897 records/second. Loss is 0.22015955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006184291898577613. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10440/60000][Iteration 3087][Wall Clock 146.982033135s] Trained 120 records in 0.040891252 seconds. Throughput is 2934.613 records/second. Loss is 0.3354086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006183527083848627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10560/60000][Iteration 3088][Wall Clock 147.025936021s] Trained 120 records in 0.043902886 seconds. Throughput is 2733.3057 records/second. Loss is 0.26644528. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006182762458266353. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10680/60000][Iteration 3089][Wall Clock 147.0724658s] Trained 120 records in 0.046529779 seconds. Throughput is 2578.9937 records/second. Loss is 0.30448902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006181998021760633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10800/60000][Iteration 3090][Wall Clock 147.116026603s] Trained 120 records in 0.043560803 seconds. Throughput is 2754.7703 records/second. Loss is 0.26270273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006181233774261343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 10920/60000][Iteration 3091][Wall Clock 147.157166318s] Trained 120 records in 0.041139715 seconds. Throughput is 2916.8894 records/second. Loss is 0.23979379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006180469715698394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11040/60000][Iteration 3092][Wall Clock 147.209170133s] Trained 120 records in 0.052003815 seconds. Throughput is 2307.523 records/second. Loss is 0.33699936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00617970584600173. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11160/60000][Iteration 3093][Wall Clock 147.250468447s] Trained 120 records in 0.041298314 seconds. Throughput is 2905.6875 records/second. Loss is 0.30598098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006178942165101334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11280/60000][Iteration 3094][Wall Clock 147.291649491s] Trained 120 records in 0.041181044 seconds. Throughput is 2913.9622 records/second. Loss is 0.27405274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006178178672927221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11400/60000][Iteration 3095][Wall Clock 147.332868161s] Trained 120 records in 0.04121867 seconds. Throughput is 2911.3022 records/second. Loss is 0.22258301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006177415369409439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11520/60000][Iteration 3096][Wall Clock 147.374246648s] Trained 120 records in 0.041378487 seconds. Throughput is 2900.0576 records/second. Loss is 0.24288794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006176652254478073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11640/60000][Iteration 3097][Wall Clock 147.415746866s] Trained 120 records in 0.041500218 seconds. Throughput is 2891.551 records/second. Loss is 0.28949702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00617588932806324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11760/60000][Iteration 3098][Wall Clock 147.456484861s] Trained 120 records in 0.040737995 seconds. Throughput is 2945.653 records/second. Loss is 0.30036762. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061751265900950965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 11880/60000][Iteration 3099][Wall Clock 147.497724887s] Trained 120 records in 0.041240026 seconds. Throughput is 2909.7944 records/second. Loss is 0.3304261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006174364040503828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 12000/60000][Iteration 3100][Wall Clock 147.538451038s] Trained 120 records in 0.040726151 seconds. Throughput is 2946.5098 records/second. Loss is 0.22188142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006173601679219656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:33 INFO  DistriOptimizer$:406 - [Epoch 7 12120/60000][Iteration 3101][Wall Clock 147.578698927s] Trained 120 records in 0.040247889 seconds. Throughput is 2981.523 records/second. Loss is 0.35905418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006172839506172839. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 12240/60000][Iteration 3102][Wall Clock 147.618708586s] Trained 120 records in 0.040009659 seconds. Throughput is 2999.276 records/second. Loss is 0.23272654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006172077521293667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 12360/60000][Iteration 3103][Wall Clock 147.658271725s] Trained 120 records in 0.039563139 seconds. Throughput is 3033.1265 records/second. Loss is 0.3380932. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006171315724512466. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 12480/60000][Iteration 3104][Wall Clock 147.699049732s] Trained 120 records in 0.040778007 seconds. Throughput is 2942.7627 records/second. Loss is 0.30918843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061705541157595955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 12600/60000][Iteration 3105][Wall Clock 147.739215603s] Trained 120 records in 0.040165871 seconds. Throughput is 2987.611 records/second. Loss is 0.31025022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006169792694965449. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 12720/60000][Iteration 3106][Wall Clock 147.783342663s] Trained 120 records in 0.04412706 seconds. Throughput is 2719.42 records/second. Loss is 0.2676668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006169031462060457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 12840/60000][Iteration 3107][Wall Clock 147.824122849s] Trained 120 records in 0.040780186 seconds. Throughput is 2942.6055 records/second. Loss is 0.20361702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00616827041697508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 12960/60000][Iteration 3108][Wall Clock 147.865507779s] Trained 120 records in 0.04138493 seconds. Throughput is 2899.6062 records/second. Loss is 0.25281933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006167509559639818. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13080/60000][Iteration 3109][Wall Clock 147.90582209s] Trained 120 records in 0.040314311 seconds. Throughput is 2976.6106 records/second. Loss is 0.35048792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061667488899852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13200/60000][Iteration 3110][Wall Clock 147.95584755s] Trained 120 records in 0.05002546 seconds. Throughput is 2398.7786 records/second. Loss is 0.3167084. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006165988407941794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13320/60000][Iteration 3111][Wall Clock 148.004980031s] Trained 120 records in 0.049132481 seconds. Throughput is 2442.3762 records/second. Loss is 0.32674664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006165228113440198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13440/60000][Iteration 3112][Wall Clock 148.047787368s] Trained 120 records in 0.042807337 seconds. Throughput is 2803.2578 records/second. Loss is 0.31544957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006164468006411047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13560/60000][Iteration 3113][Wall Clock 148.091010165s] Trained 120 records in 0.043222797 seconds. Throughput is 2776.3127 records/second. Loss is 0.18680845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00616370808678501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13680/60000][Iteration 3114][Wall Clock 148.134433693s] Trained 120 records in 0.043423528 seconds. Throughput is 2763.4788 records/second. Loss is 0.2137742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006162948354492789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13800/60000][Iteration 3115][Wall Clock 148.177023866s] Trained 120 records in 0.042590173 seconds. Throughput is 2817.5513 records/second. Loss is 0.2640626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006162188809465122. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 13920/60000][Iteration 3116][Wall Clock 148.219154744s] Trained 120 records in 0.042130878 seconds. Throughput is 2848.2673 records/second. Loss is 0.34187782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006161429451632779. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14040/60000][Iteration 3117][Wall Clock 148.261471041s] Trained 120 records in 0.042316297 seconds. Throughput is 2835.787 records/second. Loss is 0.24321637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006160670280926565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14160/60000][Iteration 3118][Wall Clock 148.308894052s] Trained 120 records in 0.047423011 seconds. Throughput is 2530.417 records/second. Loss is 0.42907244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006159911297277319. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14280/60000][Iteration 3119][Wall Clock 148.354309531s] Trained 120 records in 0.045415479 seconds. Throughput is 2642.271 records/second. Loss is 0.29647356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006159152500615914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14400/60000][Iteration 3120][Wall Clock 148.395374517s] Trained 120 records in 0.041064986 seconds. Throughput is 2922.1975 records/second. Loss is 0.36425844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061583938908732596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14520/60000][Iteration 3121][Wall Clock 148.436544669s] Trained 120 records in 0.041170152 seconds. Throughput is 2914.733 records/second. Loss is 0.3435821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006157635467980295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14640/60000][Iteration 3122][Wall Clock 148.479027081s] Trained 120 records in 0.042482412 seconds. Throughput is 2824.6982 records/second. Loss is 0.28261048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006156877231867996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14760/60000][Iteration 3123][Wall Clock 148.521068298s] Trained 120 records in 0.042041217 seconds. Throughput is 2854.3418 records/second. Loss is 0.272121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006156119182467373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:34 INFO  DistriOptimizer$:406 - [Epoch 7 14880/60000][Iteration 3124][Wall Clock 148.562466117s] Trained 120 records in 0.041397819 seconds. Throughput is 2898.7036 records/second. Loss is 0.37132722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006155361319709467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15000/60000][Iteration 3125][Wall Clock 148.602903354s] Trained 120 records in 0.040437237 seconds. Throughput is 2967.5618 records/second. Loss is 0.3058512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006154603643525357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15120/60000][Iteration 3126][Wall Clock 148.643241924s] Trained 120 records in 0.04033857 seconds. Throughput is 2974.8206 records/second. Loss is 0.25690702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006153846153846154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15240/60000][Iteration 3127][Wall Clock 148.684072186s] Trained 120 records in 0.040830262 seconds. Throughput is 2938.9966 records/second. Loss is 0.44115686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006153088850603003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15360/60000][Iteration 3128][Wall Clock 148.724885985s] Trained 120 records in 0.040813799 seconds. Throughput is 2940.182 records/second. Loss is 0.26346672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006152331733727083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15480/60000][Iteration 3129][Wall Clock 148.765788511s] Trained 120 records in 0.040902526 seconds. Throughput is 2933.8042 records/second. Loss is 0.24026994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006151574803149607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15600/60000][Iteration 3130][Wall Clock 148.807320397s] Trained 120 records in 0.041531886 seconds. Throughput is 2889.3462 records/second. Loss is 0.21752925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006150818058801821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15720/60000][Iteration 3131][Wall Clock 148.848306222s] Trained 120 records in 0.040985825 seconds. Throughput is 2927.8413 records/second. Loss is 0.38849238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006150061500615007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15840/60000][Iteration 3132][Wall Clock 148.892930634s] Trained 120 records in 0.044624412 seconds. Throughput is 2689.111 records/second. Loss is 0.2542872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006149305128520478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 15960/60000][Iteration 3133][Wall Clock 148.93303595s] Trained 120 records in 0.040105316 seconds. Throughput is 2992.122 records/second. Loss is 0.2771004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006148548942449582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16080/60000][Iteration 3134][Wall Clock 148.974388997s] Trained 120 records in 0.041353047 seconds. Throughput is 2901.8418 records/second. Loss is 0.31388935. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006147792942333702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16200/60000][Iteration 3135][Wall Clock 149.015374157s] Trained 120 records in 0.04098516 seconds. Throughput is 2927.8892 records/second. Loss is 0.29997385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006147037128104254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16320/60000][Iteration 3136][Wall Clock 149.056007653s] Trained 120 records in 0.040633496 seconds. Throughput is 2953.2285 records/second. Loss is 0.25814053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006146281499692686. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16440/60000][Iteration 3137][Wall Clock 149.108974943s] Trained 120 records in 0.05296729 seconds. Throughput is 2265.549 records/second. Loss is 0.32291046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006145526057030482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16560/60000][Iteration 3138][Wall Clock 149.154835401s] Trained 120 records in 0.045860458 seconds. Throughput is 2616.6333 records/second. Loss is 0.45512202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006144770800049158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16680/60000][Iteration 3139][Wall Clock 149.196880498s] Trained 120 records in 0.042045097 seconds. Throughput is 2854.0784 records/second. Loss is 0.29893443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006144015728680265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16800/60000][Iteration 3140][Wall Clock 149.237929591s] Trained 120 records in 0.041049093 seconds. Throughput is 2923.3289 records/second. Loss is 0.45292726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006143260842855387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 16920/60000][Iteration 3141][Wall Clock 149.278839181s] Trained 120 records in 0.04090959 seconds. Throughput is 2933.2976 records/second. Loss is 0.24722739. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006142506142506142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 17040/60000][Iteration 3142][Wall Clock 149.320421231s] Trained 120 records in 0.04158205 seconds. Throughput is 2885.8606 records/second. Loss is 0.3236264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006141751627564181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 17160/60000][Iteration 3143][Wall Clock 149.361233408s] Trained 120 records in 0.040812177 seconds. Throughput is 2940.299 records/second. Loss is 0.36163944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006140997297961189. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 17280/60000][Iteration 3144][Wall Clock 149.401836494s] Trained 120 records in 0.040603086 seconds. Throughput is 2955.4404 records/second. Loss is 0.34794208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006140243153628884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 17400/60000][Iteration 3145][Wall Clock 149.4525924s] Trained 120 records in 0.050755906 seconds. Throughput is 2364.2568 records/second. Loss is 0.29043734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006139489194499017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 17520/60000][Iteration 3146][Wall Clock 149.493518229s] Trained 120 records in 0.040925829 seconds. Throughput is 2932.1335 records/second. Loss is 0.2570706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006138735420503376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 17640/60000][Iteration 3147][Wall Clock 149.534550026s] Trained 120 records in 0.041031797 seconds. Throughput is 2924.5613 records/second. Loss is 0.40946695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006137981831573778. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:35 INFO  DistriOptimizer$:406 - [Epoch 7 17760/60000][Iteration 3148][Wall Clock 149.575429975s] Trained 120 records in 0.040879949 seconds. Throughput is 2935.4243 records/second. Loss is 0.32977587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006137228427642077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 17880/60000][Iteration 3149][Wall Clock 149.616095537s] Trained 120 records in 0.040665562 seconds. Throughput is 2950.8997 records/second. Loss is 0.3678242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006136475208640158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18000/60000][Iteration 3150][Wall Clock 149.657610191s] Trained 120 records in 0.041514654 seconds. Throughput is 2890.5457 records/second. Loss is 0.24425052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006135722174499939. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18120/60000][Iteration 3151][Wall Clock 149.70112578s] Trained 120 records in 0.043515589 seconds. Throughput is 2757.6323 records/second. Loss is 0.2554451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006134969325153374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18240/60000][Iteration 3152][Wall Clock 149.742087944s] Trained 120 records in 0.040962164 seconds. Throughput is 2929.5327 records/second. Loss is 0.29528305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00613421666053245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18360/60000][Iteration 3153][Wall Clock 149.782806948s] Trained 120 records in 0.040719004 seconds. Throughput is 2947.027 records/second. Loss is 0.25442326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006133464180569185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18480/60000][Iteration 3154][Wall Clock 149.824540015s] Trained 120 records in 0.041733067 seconds. Throughput is 2875.4177 records/second. Loss is 0.24582419. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006132711885195634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18600/60000][Iteration 3155][Wall Clock 149.866248618s] Trained 120 records in 0.041708603 seconds. Throughput is 2877.1042 records/second. Loss is 0.35256463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00613195977434388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18720/60000][Iteration 3156][Wall Clock 149.907587746s] Trained 120 records in 0.041339128 seconds. Throughput is 2902.8188 records/second. Loss is 0.3794386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061312078479460455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18840/60000][Iteration 3157][Wall Clock 149.948316178s] Trained 120 records in 0.040728432 seconds. Throughput is 2946.3447 records/second. Loss is 0.24082597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006130456105934282. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 18960/60000][Iteration 3158][Wall Clock 149.992716113s] Trained 120 records in 0.044399935 seconds. Throughput is 2702.7065 records/second. Loss is 0.28615153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061297045482407745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19080/60000][Iteration 3159][Wall Clock 150.033882239s] Trained 120 records in 0.041166126 seconds. Throughput is 2915.018 records/second. Loss is 0.29715043. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006128953174797744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19200/60000][Iteration 3160][Wall Clock 150.075585759s] Trained 120 records in 0.04170352 seconds. Throughput is 2877.455 records/second. Loss is 0.19023295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006128201985537443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19320/60000][Iteration 3161][Wall Clock 150.117127212s] Trained 120 records in 0.041541453 seconds. Throughput is 2888.681 records/second. Loss is 0.32586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006127450980392157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19440/60000][Iteration 3162][Wall Clock 150.157942895s] Trained 120 records in 0.040815683 seconds. Throughput is 2940.0464 records/second. Loss is 0.32567495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006126700159294204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19560/60000][Iteration 3163][Wall Clock 150.213187889s] Trained 120 records in 0.055244994 seconds. Throughput is 2172.1426 records/second. Loss is 0.28067198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006125949522175937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19680/60000][Iteration 3164][Wall Clock 150.25932953s] Trained 120 records in 0.046141641 seconds. Throughput is 2600.6877 records/second. Loss is 0.29253086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006125199068969742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19800/60000][Iteration 3165][Wall Clock 150.301458831s] Trained 120 records in 0.042129301 seconds. Throughput is 2848.3738 records/second. Loss is 0.2239487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006124448799608035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 19920/60000][Iteration 3166][Wall Clock 150.342009331s] Trained 120 records in 0.0405505 seconds. Throughput is 2959.273 records/second. Loss is 0.35105002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061236987140232705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 20040/60000][Iteration 3167][Wall Clock 150.382193883s] Trained 120 records in 0.040184552 seconds. Throughput is 2986.222 records/second. Loss is 0.23585127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006122948812147931. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 20160/60000][Iteration 3168][Wall Clock 150.422988689s] Trained 120 records in 0.040794806 seconds. Throughput is 2941.551 records/second. Loss is 0.29233044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006122199093914534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 20280/60000][Iteration 3169][Wall Clock 150.46424468s] Trained 120 records in 0.041255991 seconds. Throughput is 2908.6685 records/second. Loss is 0.2530301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006121449559255632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 20400/60000][Iteration 3170][Wall Clock 150.505499706s] Trained 120 records in 0.041255026 seconds. Throughput is 2908.7363 records/second. Loss is 0.22973397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006120700208103807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:36 INFO  DistriOptimizer$:406 - [Epoch 7 20520/60000][Iteration 3171][Wall Clock 150.55513019s] Trained 120 records in 0.049630484 seconds. Throughput is 2417.8687 records/second. Loss is 0.3712518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006119951040391677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 20640/60000][Iteration 3172][Wall Clock 150.599018709s] Trained 120 records in 0.043888519 seconds. Throughput is 2734.2002 records/second. Loss is 0.34933928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006119202056051891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 20760/60000][Iteration 3173][Wall Clock 150.641193721s] Trained 120 records in 0.042175012 seconds. Throughput is 2845.2866 records/second. Loss is 0.23116966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006118453255017132. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 20880/60000][Iteration 3174][Wall Clock 150.682571636s] Trained 120 records in 0.041377915 seconds. Throughput is 2900.098 records/second. Loss is 0.19998816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006117704637220115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21000/60000][Iteration 3175][Wall Clock 150.723621023s] Trained 120 records in 0.041049387 seconds. Throughput is 2923.3079 records/second. Loss is 0.36022776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006116956202593589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21120/60000][Iteration 3176][Wall Clock 150.76480114s] Trained 120 records in 0.041180117 seconds. Throughput is 2914.0278 records/second. Loss is 0.31318885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061162079510703364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21240/60000][Iteration 3177][Wall Clock 150.80600774s] Trained 120 records in 0.0412066 seconds. Throughput is 2912.155 records/second. Loss is 0.26443198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006115459882583171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21360/60000][Iteration 3178][Wall Clock 150.846960899s] Trained 120 records in 0.040953159 seconds. Throughput is 2930.1768 records/second. Loss is 0.22253387. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006114711997064938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21480/60000][Iteration 3179][Wall Clock 150.888436499s] Trained 120 records in 0.0414756 seconds. Throughput is 2893.2673 records/second. Loss is 0.26776606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00611396429444852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21600/60000][Iteration 3180][Wall Clock 150.930101704s] Trained 120 records in 0.041665205 seconds. Throughput is 2880.101 records/second. Loss is 0.25263312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006113216774666829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21720/60000][Iteration 3181][Wall Clock 150.971552874s] Trained 120 records in 0.04145117 seconds. Throughput is 2894.9724 records/second. Loss is 0.25611156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006112469437652811. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21840/60000][Iteration 3182][Wall Clock 151.01322829s] Trained 120 records in 0.041675416 seconds. Throughput is 2879.3955 records/second. Loss is 0.2930245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006111722283339445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 21960/60000][Iteration 3183][Wall Clock 151.058075622s] Trained 120 records in 0.044847332 seconds. Throughput is 2675.7444 records/second. Loss is 0.3063871. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006110975311659741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22080/60000][Iteration 3184][Wall Clock 151.100653387s] Trained 120 records in 0.042577765 seconds. Throughput is 2818.3723 records/second. Loss is 0.22199602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006110228522546743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22200/60000][Iteration 3185][Wall Clock 151.143915722s] Trained 120 records in 0.043262335 seconds. Throughput is 2773.7754 records/second. Loss is 0.28431842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006109481915933529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22320/60000][Iteration 3186][Wall Clock 151.18617181s] Trained 120 records in 0.042256088 seconds. Throughput is 2839.8276 records/second. Loss is 0.260933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006108735491753207. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22440/60000][Iteration 3187][Wall Clock 151.229109189s] Trained 120 records in 0.042937379 seconds. Throughput is 2794.7676 records/second. Loss is 0.20713933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061079892499389206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22560/60000][Iteration 3188][Wall Clock 151.279910162s] Trained 120 records in 0.050800973 seconds. Throughput is 2362.1594 records/second. Loss is 0.39399216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061072431904238425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22680/60000][Iteration 3189][Wall Clock 151.33303431s] Trained 120 records in 0.053124148 seconds. Throughput is 2258.8596 records/second. Loss is 0.29514444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006106497313141183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22800/60000][Iteration 3190][Wall Clock 151.376609161s] Trained 120 records in 0.043574851 seconds. Throughput is 2753.882 records/second. Loss is 0.2587692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006105751618024179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 22920/60000][Iteration 3191][Wall Clock 151.41841768s] Trained 120 records in 0.041808519 seconds. Throughput is 2870.2285 records/second. Loss is 0.3279947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006105006105006106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 23040/60000][Iteration 3192][Wall Clock 151.46027568s] Trained 120 records in 0.041858 seconds. Throughput is 2866.8357 records/second. Loss is 0.19100639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061042607740202665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 23160/60000][Iteration 3193][Wall Clock 151.501402264s] Trained 120 records in 0.041126584 seconds. Throughput is 2917.8208 records/second. Loss is 0.28968194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006103515625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:37 INFO  DistriOptimizer$:406 - [Epoch 7 23280/60000][Iteration 3194][Wall Clock 151.542346242s] Trained 120 records in 0.040943978 seconds. Throughput is 2930.834 records/second. Loss is 0.3077113. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006102770657878676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 23400/60000][Iteration 3195][Wall Clock 151.583872616s] Trained 120 records in 0.041526374 seconds. Throughput is 2889.7297 records/second. Loss is 0.25925726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061020258725897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 23520/60000][Iteration 3196][Wall Clock 151.624233642s] Trained 120 records in 0.040361026 seconds. Throughput is 2973.1653 records/second. Loss is 0.29266632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006101281269066504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 23640/60000][Iteration 3197][Wall Clock 151.664318386s] Trained 120 records in 0.040084744 seconds. Throughput is 2993.6575 records/second. Loss is 0.34704074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0061005368472425575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 23760/60000][Iteration 3198][Wall Clock 151.71842767s] Trained 120 records in 0.054109284 seconds. Throughput is 2217.7341 records/second. Loss is 0.2309947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006099792607051359. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 23880/60000][Iteration 3199][Wall Clock 151.759754158s] Trained 120 records in 0.041326488 seconds. Throughput is 2903.7065 records/second. Loss is 0.3415986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006099048548426445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24000/60000][Iteration 3200][Wall Clock 151.800402573s] Trained 120 records in 0.040648415 seconds. Throughput is 2952.1445 records/second. Loss is 0.29531923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006098304671301378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24120/60000][Iteration 3201][Wall Clock 151.841614347s] Trained 120 records in 0.041211774 seconds. Throughput is 2911.7893 records/second. Loss is 0.24508902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060975609756097554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24240/60000][Iteration 3202][Wall Clock 151.882414575s] Trained 120 records in 0.040800228 seconds. Throughput is 2941.16 records/second. Loss is 0.23365416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006096817461285209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24360/60000][Iteration 3203][Wall Clock 151.922799232s] Trained 120 records in 0.040384657 seconds. Throughput is 2971.4255 records/second. Loss is 0.34344128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060960741282614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24480/60000][Iteration 3204][Wall Clock 151.964135561s] Trained 120 records in 0.041336329 seconds. Throughput is 2903.0154 records/second. Loss is 0.29657805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060953309764720225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24600/60000][Iteration 3205][Wall Clock 152.005631559s] Trained 120 records in 0.041495998 seconds. Throughput is 2891.8452 records/second. Loss is 0.3497004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006094588005850805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24720/60000][Iteration 3206][Wall Clock 152.048100794s] Trained 120 records in 0.042469235 seconds. Throughput is 2825.575 records/second. Loss is 0.27524796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006093845216331505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24840/60000][Iteration 3207][Wall Clock 152.09105499s] Trained 120 records in 0.042954196 seconds. Throughput is 2793.6736 records/second. Loss is 0.19852428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060931026078479165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 24960/60000][Iteration 3208][Wall Clock 152.135170865s] Trained 120 records in 0.044115875 seconds. Throughput is 2720.1094 records/second. Loss is 0.27734998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006092360180333861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25080/60000][Iteration 3209][Wall Clock 152.176648937s] Trained 120 records in 0.041478072 seconds. Throughput is 2893.095 records/second. Loss is 0.27507865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006091617933723197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25200/60000][Iteration 3210][Wall Clock 152.217074543s] Trained 120 records in 0.040425606 seconds. Throughput is 2968.4155 records/second. Loss is 0.46557188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006090875867949812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25320/60000][Iteration 3211][Wall Clock 152.258192539s] Trained 120 records in 0.041117996 seconds. Throughput is 2918.4302 records/second. Loss is 0.2621958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006090133982947625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25440/60000][Iteration 3212][Wall Clock 152.29955415s] Trained 120 records in 0.041361611 seconds. Throughput is 2901.241 records/second. Loss is 0.1873704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006089392278650591. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25560/60000][Iteration 3213][Wall Clock 152.349821757s] Trained 120 records in 0.050267607 seconds. Throughput is 2387.2231 records/second. Loss is 0.3205509. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060886507549926935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25680/60000][Iteration 3214][Wall Clock 152.401079091s] Trained 120 records in 0.051257334 seconds. Throughput is 2341.1284 records/second. Loss is 0.2051869. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00608790941190795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25800/60000][Iteration 3215][Wall Clock 152.442689681s] Trained 120 records in 0.04161059 seconds. Throughput is 2883.881 records/second. Loss is 0.3200788. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006087168249330412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 25920/60000][Iteration 3216][Wall Clock 152.483391095s] Trained 120 records in 0.040701414 seconds. Throughput is 2948.3005 records/second. Loss is 0.26845863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006086427267194157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 26040/60000][Iteration 3217][Wall Clock 152.524680261s] Trained 120 records in 0.041289166 seconds. Throughput is 2906.3315 records/second. Loss is 0.26918492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006085686465433301. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:38 INFO  DistriOptimizer$:406 - [Epoch 7 26160/60000][Iteration 3218][Wall Clock 152.565694055s] Trained 120 records in 0.041013794 seconds. Throughput is 2925.845 records/second. Loss is 0.2968652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006084945843981988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 26280/60000][Iteration 3219][Wall Clock 152.606903371s] Trained 120 records in 0.041209316 seconds. Throughput is 2911.963 records/second. Loss is 0.31283405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006084205402774397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 26400/60000][Iteration 3220][Wall Clock 152.647759279s] Trained 120 records in 0.040855908 seconds. Throughput is 2937.1519 records/second. Loss is 0.3617512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006083465141744737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 26520/60000][Iteration 3221][Wall Clock 152.689318878s] Trained 120 records in 0.041559599 seconds. Throughput is 2887.4197 records/second. Loss is 0.2403608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00608272506082725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 26640/60000][Iteration 3222][Wall Clock 152.730713584s] Trained 120 records in 0.041394706 seconds. Throughput is 2898.9214 records/second. Loss is 0.29411608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060819851599562096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 26760/60000][Iteration 3223][Wall Clock 152.771476911s] Trained 120 records in 0.040763327 seconds. Throughput is 2943.8225 records/second. Loss is 0.32149607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006081245439065921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 26880/60000][Iteration 3224][Wall Clock 152.821248012s] Trained 120 records in 0.049771101 seconds. Throughput is 2411.0376 records/second. Loss is 0.26766542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006080505898090721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27000/60000][Iteration 3225][Wall Clock 152.866222197s] Trained 120 records in 0.044974185 seconds. Throughput is 2668.1973 records/second. Loss is 0.24850698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006079766536964981. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27120/60000][Iteration 3226][Wall Clock 152.907994622s] Trained 120 records in 0.041772425 seconds. Throughput is 2872.7085 records/second. Loss is 0.31635755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060790273556231. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27240/60000][Iteration 3227][Wall Clock 152.949440005s] Trained 120 records in 0.041445383 seconds. Throughput is 2895.377 records/second. Loss is 0.2681493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006078288353999514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27360/60000][Iteration 3228][Wall Clock 152.990741807s] Trained 120 records in 0.041301802 seconds. Throughput is 2905.4421 records/second. Loss is 0.2694842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060775495320286865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27480/60000][Iteration 3229][Wall Clock 153.032491556s] Trained 120 records in 0.041749749 seconds. Throughput is 2874.2688 records/second. Loss is 0.33908254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006076810889645115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27600/60000][Iteration 3230][Wall Clock 153.07436666s] Trained 120 records in 0.041875104 seconds. Throughput is 2865.6646 records/second. Loss is 0.2740948. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060760724267833275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27720/60000][Iteration 3231][Wall Clock 153.116100069s] Trained 120 records in 0.041733409 seconds. Throughput is 2875.394 records/second. Loss is 0.41753444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006075334143377886. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27840/60000][Iteration 3232][Wall Clock 153.157660817s] Trained 120 records in 0.041560748 seconds. Throughput is 2887.3398 records/second. Loss is 0.27175984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006074596039363383. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 27960/60000][Iteration 3233][Wall Clock 153.199125772s] Trained 120 records in 0.041464955 seconds. Throughput is 2894.0103 records/second. Loss is 0.2883218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006073858114674441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28080/60000][Iteration 3234][Wall Clock 153.242964585s] Trained 120 records in 0.043838813 seconds. Throughput is 2737.3003 records/second. Loss is 0.19080184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006073120369245719. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28200/60000][Iteration 3235][Wall Clock 153.283777181s] Trained 120 records in 0.040812596 seconds. Throughput is 2940.2688 records/second. Loss is 0.25754353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006072382803011902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28320/60000][Iteration 3236][Wall Clock 153.327109282s] Trained 120 records in 0.043332101 seconds. Throughput is 2769.3096 records/second. Loss is 0.2899268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006071645415907711. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28440/60000][Iteration 3237][Wall Clock 153.368303637s] Trained 120 records in 0.041194355 seconds. Throughput is 2913.0205 records/second. Loss is 0.2337423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006070908207867897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28560/60000][Iteration 3238][Wall Clock 153.41809492s] Trained 120 records in 0.049791283 seconds. Throughput is 2410.0603 records/second. Loss is 0.28656837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006070171178827242. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28680/60000][Iteration 3239][Wall Clock 153.466939959s] Trained 120 records in 0.048845039 seconds. Throughput is 2456.749 records/second. Loss is 0.23474093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006069434328720562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28800/60000][Iteration 3240][Wall Clock 153.510367251s] Trained 120 records in 0.043427292 seconds. Throughput is 2763.2393 records/second. Loss is 0.365941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006068697657482704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:39 INFO  DistriOptimizer$:406 - [Epoch 7 28920/60000][Iteration 3241][Wall Clock 153.55203142s] Trained 120 records in 0.041664169 seconds. Throughput is 2880.1726 records/second. Loss is 0.26073846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006067961165048544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29040/60000][Iteration 3242][Wall Clock 153.593226648s] Trained 120 records in 0.041195228 seconds. Throughput is 2912.9587 records/second. Loss is 0.3543211. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006067224851352991. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29160/60000][Iteration 3243][Wall Clock 153.634586908s] Trained 120 records in 0.04136026 seconds. Throughput is 2901.3357 records/second. Loss is 0.30569777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006066488716330988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29280/60000][Iteration 3244][Wall Clock 153.676698602s] Trained 120 records in 0.042111694 seconds. Throughput is 2849.5647 records/second. Loss is 0.28828776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006065752759917505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29400/60000][Iteration 3245][Wall Clock 153.717866619s] Trained 120 records in 0.041168017 seconds. Throughput is 2914.8843 records/second. Loss is 0.21720076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060650169820475495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29520/60000][Iteration 3246][Wall Clock 153.759480766s] Trained 120 records in 0.041614147 seconds. Throughput is 2883.6345 records/second. Loss is 0.33018526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006064281382656155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29640/60000][Iteration 3247][Wall Clock 153.80033331s] Trained 120 records in 0.040852544 seconds. Throughput is 2937.3936 records/second. Loss is 0.20622557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00606354596167839. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29760/60000][Iteration 3248][Wall Clock 153.841271146s] Trained 120 records in 0.040937836 seconds. Throughput is 2931.2737 records/second. Loss is 0.29580978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006062810719049351. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 29880/60000][Iteration 3249][Wall Clock 153.881977503s] Trained 120 records in 0.040706357 seconds. Throughput is 2947.9424 records/second. Loss is 0.17817524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006062075654704171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30000/60000][Iteration 3250][Wall Clock 153.924049097s] Trained 120 records in 0.042071594 seconds. Throughput is 2852.2808 records/second. Loss is 0.21143264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060613407685780095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30120/60000][Iteration 3251][Wall Clock 153.982872138s] Trained 120 records in 0.058823041 seconds. Throughput is 2040.017 records/second. Loss is 0.3921152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060606060606060615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30240/60000][Iteration 3252][Wall Clock 154.029791642s] Trained 120 records in 0.046919504 seconds. Throughput is 2557.5718 records/second. Loss is 0.2499896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006059871530723549. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30360/60000][Iteration 3253][Wall Clock 154.081389059s] Trained 120 records in 0.051597417 seconds. Throughput is 2325.6978 records/second. Loss is 0.28742525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00605913717886573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30480/60000][Iteration 3254][Wall Clock 154.125381927s] Trained 120 records in 0.043992868 seconds. Throughput is 2727.7148 records/second. Loss is 0.21671261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00605840300496789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30600/60000][Iteration 3255][Wall Clock 154.169255998s] Trained 120 records in 0.043874071 seconds. Throughput is 2735.1006 records/second. Loss is 0.2631112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00605766900896535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30720/60000][Iteration 3256][Wall Clock 154.212191581s] Trained 120 records in 0.042935583 seconds. Throughput is 2794.8845 records/second. Loss is 0.19834876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060569351907934586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30840/60000][Iteration 3257][Wall Clock 154.255116309s] Trained 120 records in 0.042924728 seconds. Throughput is 2795.5913 records/second. Loss is 0.2630914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006056201550387597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 30960/60000][Iteration 3258][Wall Clock 154.298011788s] Trained 120 records in 0.042895479 seconds. Throughput is 2797.4978 records/second. Loss is 0.22695245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006055468087683178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 31080/60000][Iteration 3259][Wall Clock 154.343764442s] Trained 120 records in 0.045752654 seconds. Throughput is 2622.7986 records/second. Loss is 0.2181601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006054734802615645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 31200/60000][Iteration 3260][Wall Clock 154.38758994s] Trained 120 records in 0.043825498 seconds. Throughput is 2738.1318 records/second. Loss is 0.31615496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006054001695120474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 31320/60000][Iteration 3261][Wall Clock 154.433915111s] Trained 120 records in 0.046325171 seconds. Throughput is 2590.3845 records/second. Loss is 0.3678776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006053268765133172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 31440/60000][Iteration 3262][Wall Clock 154.477602305s] Trained 120 records in 0.043687194 seconds. Throughput is 2746.8003 records/second. Loss is 0.3096403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006052536012589275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:40 INFO  DistriOptimizer$:406 - [Epoch 7 31560/60000][Iteration 3263][Wall Clock 154.529868867s] Trained 120 records in 0.052266562 seconds. Throughput is 2295.923 records/second. Loss is 0.21266946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060518034374243525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 31680/60000][Iteration 3264][Wall Clock 154.581512888s] Trained 120 records in 0.051644021 seconds. Throughput is 2323.599 records/second. Loss is 0.2967661. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060510710395740045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 31800/60000][Iteration 3265][Wall Clock 154.631441746s] Trained 120 records in 0.049928858 seconds. Throughput is 2403.4197 records/second. Loss is 0.3752299. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006050338818973862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 31920/60000][Iteration 3266][Wall Clock 154.673056127s] Trained 120 records in 0.041614381 seconds. Throughput is 2883.6187 records/second. Loss is 0.23449618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006049606775559589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32040/60000][Iteration 3267][Wall Clock 154.714123898s] Trained 120 records in 0.041067771 seconds. Throughput is 2921.9993 records/second. Loss is 0.20689131. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006048874909266876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32160/60000][Iteration 3268][Wall Clock 154.755210824s] Trained 120 records in 0.041086926 seconds. Throughput is 2920.637 records/second. Loss is 0.28614753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00604814322003145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32280/60000][Iteration 3269][Wall Clock 154.795935984s] Trained 120 records in 0.04072516 seconds. Throughput is 2946.5813 records/second. Loss is 0.2792602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006047411707789067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32400/60000][Iteration 3270][Wall Clock 154.837264654s] Trained 120 records in 0.04132867 seconds. Throughput is 2903.5535 records/second. Loss is 0.2486611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006046680372475511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32520/60000][Iteration 3271][Wall Clock 154.878525572s] Trained 120 records in 0.041260918 seconds. Throughput is 2908.3213 records/second. Loss is 0.27736613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006045949214026603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32640/60000][Iteration 3272][Wall Clock 154.91950322s] Trained 120 records in 0.040977648 seconds. Throughput is 2928.4258 records/second. Loss is 0.3530789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006045218232378189. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32760/60000][Iteration 3273][Wall Clock 154.959969814s] Trained 120 records in 0.040466594 seconds. Throughput is 2965.409 records/second. Loss is 0.21678713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006044487427466151. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 32880/60000][Iteration 3274][Wall Clock 155.003383793s] Trained 120 records in 0.043413979 seconds. Throughput is 2764.0867 records/second. Loss is 0.29611972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006043756799226399. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33000/60000][Iteration 3275][Wall Clock 155.045342426s] Trained 120 records in 0.041958633 seconds. Throughput is 2859.9597 records/second. Loss is 0.24167779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006043026347594876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33120/60000][Iteration 3276][Wall Clock 155.087278491s] Trained 120 records in 0.041936065 seconds. Throughput is 2861.4988 records/second. Loss is 0.34744442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006042296072507553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33240/60000][Iteration 3277][Wall Clock 155.137765815s] Trained 120 records in 0.050487324 seconds. Throughput is 2376.8342 records/second. Loss is 0.25089484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006041565973900435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33360/60000][Iteration 3278][Wall Clock 155.184631621s] Trained 120 records in 0.046865806 seconds. Throughput is 2560.5022 records/second. Loss is 0.34011364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006040836051709557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33480/60000][Iteration 3279][Wall Clock 155.225791603s] Trained 120 records in 0.041159982 seconds. Throughput is 2915.4531 records/second. Loss is 0.34797648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006040106305870983. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33600/60000][Iteration 3280][Wall Clock 155.266825427s] Trained 120 records in 0.041033824 seconds. Throughput is 2924.4167 records/second. Loss is 0.2427219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060393767363208116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33720/60000][Iteration 3281][Wall Clock 155.308778203s] Trained 120 records in 0.041952776 seconds. Throughput is 2860.359 records/second. Loss is 0.28482386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006038647342995169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33840/60000][Iteration 3282][Wall Clock 155.349543211s] Trained 120 records in 0.040765008 seconds. Throughput is 2943.701 records/second. Loss is 0.35056618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006037918125830213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 33960/60000][Iteration 3283][Wall Clock 155.393706392s] Trained 120 records in 0.044163181 seconds. Throughput is 2717.1956 records/second. Loss is 0.26580033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006037189084762135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 34080/60000][Iteration 3284][Wall Clock 155.435368392s] Trained 120 records in 0.041662 seconds. Throughput is 2880.3225 records/second. Loss is 0.23880869. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006036460219727152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 34200/60000][Iteration 3285][Wall Clock 155.476020948s] Trained 120 records in 0.040652556 seconds. Throughput is 2951.844 records/second. Loss is 0.25842193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006035731530661516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:41 INFO  DistriOptimizer$:406 - [Epoch 7 34320/60000][Iteration 3286][Wall Clock 155.515980527s] Trained 120 records in 0.039959579 seconds. Throughput is 3003.0347 records/second. Loss is 0.23871326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006035003017501509. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 34440/60000][Iteration 3287][Wall Clock 155.555976463s] Trained 120 records in 0.039995936 seconds. Throughput is 3000.305 records/second. Loss is 0.31267956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006034274680183442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 34560/60000][Iteration 3288][Wall Clock 155.599588604s] Trained 120 records in 0.043612141 seconds. Throughput is 2751.5273 records/second. Loss is 0.3643756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006033546518643659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 34680/60000][Iteration 3289][Wall Clock 155.646337913s] Trained 120 records in 0.046749309 seconds. Throughput is 2566.8828 records/second. Loss is 0.30617085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006032818532818533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 34800/60000][Iteration 3290][Wall Clock 155.693363382s] Trained 120 records in 0.047025469 seconds. Throughput is 2551.8088 records/second. Loss is 0.21224912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006032090722644469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 34920/60000][Iteration 3291][Wall Clock 155.733907688s] Trained 120 records in 0.040544306 seconds. Throughput is 2959.725 records/second. Loss is 0.3008979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006031363088057902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35040/60000][Iteration 3292][Wall Clock 155.77434163s] Trained 120 records in 0.040433942 seconds. Throughput is 2967.8035 records/second. Loss is 0.30753556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006030635628995296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35160/60000][Iteration 3293][Wall Clock 155.815286772s] Trained 120 records in 0.040945142 seconds. Throughput is 2930.7505 records/second. Loss is 0.3955038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00602990834539315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35280/60000][Iteration 3294][Wall Clock 155.85564225s] Trained 120 records in 0.040355478 seconds. Throughput is 2973.574 records/second. Loss is 0.19671495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060291812371879895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35400/60000][Iteration 3295][Wall Clock 155.896779748s] Trained 120 records in 0.041137498 seconds. Throughput is 2917.0466 records/second. Loss is 0.36271134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006028454304316373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35520/60000][Iteration 3296][Wall Clock 155.938016452s] Trained 120 records in 0.041236704 seconds. Throughput is 2910.029 records/second. Loss is 0.29411072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006027727546714889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35640/60000][Iteration 3297][Wall Clock 155.97930182s] Trained 120 records in 0.041285368 seconds. Throughput is 2906.5986 records/second. Loss is 0.24212329. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006027000964320154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35760/60000][Iteration 3298][Wall Clock 156.02099426s] Trained 120 records in 0.04169244 seconds. Throughput is 2878.2197 records/second. Loss is 0.2862843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006026274557068821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 35880/60000][Iteration 3299][Wall Clock 156.061901568s] Trained 120 records in 0.040907308 seconds. Throughput is 2933.4612 records/second. Loss is 0.29220188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006025548324897565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36000/60000][Iteration 3300][Wall Clock 156.102610904s] Trained 120 records in 0.040709336 seconds. Throughput is 2947.7268 records/second. Loss is 0.2429188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006024822267743101. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36120/60000][Iteration 3301][Wall Clock 156.143746254s] Trained 120 records in 0.04113535 seconds. Throughput is 2917.199 records/second. Loss is 0.21363893. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006024096385542168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36240/60000][Iteration 3302][Wall Clock 156.183939712s] Trained 120 records in 0.040193458 seconds. Throughput is 2985.5605 records/second. Loss is 0.2313233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006023370678231538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36360/60000][Iteration 3303][Wall Clock 156.224012895s] Trained 120 records in 0.040073183 seconds. Throughput is 2994.5212 records/second. Loss is 0.23866187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006022645145748013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36480/60000][Iteration 3304][Wall Clock 156.274518838s] Trained 120 records in 0.050505943 seconds. Throughput is 2375.958 records/second. Loss is 0.34601972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060219197880284235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36600/60000][Iteration 3305][Wall Clock 156.324023785s] Trained 120 records in 0.049504947 seconds. Throughput is 2424.0002 records/second. Loss is 0.3702186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006021194605009634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36720/60000][Iteration 3306][Wall Clock 156.368070592s] Trained 120 records in 0.044046807 seconds. Throughput is 2724.3745 records/second. Loss is 0.17405663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006020469596628537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36840/60000][Iteration 3307][Wall Clock 156.410298232s] Trained 120 records in 0.04222764 seconds. Throughput is 2841.7405 records/second. Loss is 0.21455508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006019744762822056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 36960/60000][Iteration 3308][Wall Clock 156.454951905s] Trained 120 records in 0.044653673 seconds. Throughput is 2687.3489 records/second. Loss is 0.51486933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006019020103527146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 37080/60000][Iteration 3309][Wall Clock 156.49608552s] Trained 120 records in 0.041133615 seconds. Throughput is 2917.322 records/second. Loss is 0.30145308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00601829561868079. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:42 INFO  DistriOptimizer$:406 - [Epoch 7 37200/60000][Iteration 3310][Wall Clock 156.536988738s] Trained 120 records in 0.040903218 seconds. Throughput is 2933.7544 records/second. Loss is 0.19802938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006017571308220003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 37320/60000][Iteration 3311][Wall Clock 156.578281961s] Trained 120 records in 0.041293223 seconds. Throughput is 2906.046 records/second. Loss is 0.3134414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006016847172081829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 37440/60000][Iteration 3312][Wall Clock 156.618759566s] Trained 120 records in 0.040477605 seconds. Throughput is 2964.6023 records/second. Loss is 0.20097679. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006016123210203345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 37560/60000][Iteration 3313][Wall Clock 156.671566418s] Trained 120 records in 0.052806852 seconds. Throughput is 2272.4324 records/second. Loss is 0.3388249. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006015399422521656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 37680/60000][Iteration 3314][Wall Clock 156.720016064s] Trained 120 records in 0.048449646 seconds. Throughput is 2476.7983 records/second. Loss is 0.3025543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006014675808973896. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 37800/60000][Iteration 3315][Wall Clock 156.776225008s] Trained 120 records in 0.056208944 seconds. Throughput is 2134.8916 records/second. Loss is 0.29241735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060139523694972335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 37920/60000][Iteration 3316][Wall Clock 156.834277796s] Trained 120 records in 0.058052788 seconds. Throughput is 2067.0842 records/second. Loss is 0.25663796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006013229104028864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38040/60000][Iteration 3317][Wall Clock 156.880745652s] Trained 120 records in 0.046467856 seconds. Throughput is 2582.4304 records/second. Loss is 0.25981867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006012506012506013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38160/60000][Iteration 3318][Wall Clock 156.925165082s] Trained 120 records in 0.04441943 seconds. Throughput is 2701.5205 records/second. Loss is 0.2524438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006011783094865938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38280/60000][Iteration 3319][Wall Clock 156.968242621s] Trained 120 records in 0.043077539 seconds. Throughput is 2785.6743 records/second. Loss is 0.29851368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006011060351045924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38400/60000][Iteration 3320][Wall Clock 157.011426016s] Trained 120 records in 0.043183395 seconds. Throughput is 2778.846 records/second. Loss is 0.25161678. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006010337780983291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38520/60000][Iteration 3321][Wall Clock 157.059676502s] Trained 120 records in 0.048250486 seconds. Throughput is 2487.0217 records/second. Loss is 0.38409922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006009615384615384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38640/60000][Iteration 3322][Wall Clock 157.10211882s] Trained 120 records in 0.042442318 seconds. Throughput is 2827.3667 records/second. Loss is 0.18643135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006008893161879581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38760/60000][Iteration 3323][Wall Clock 157.143108413s] Trained 120 records in 0.040989593 seconds. Throughput is 2927.5725 records/second. Loss is 0.28295642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00600817111271329. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 38880/60000][Iteration 3324][Wall Clock 157.18400388s] Trained 120 records in 0.040895467 seconds. Throughput is 2934.3105 records/second. Loss is 0.27407548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060074492370539466. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39000/60000][Iteration 3325][Wall Clock 157.224817007s] Trained 120 records in 0.040813127 seconds. Throughput is 2940.2305 records/second. Loss is 0.26797625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006006727534839019. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39120/60000][Iteration 3326][Wall Clock 157.265005713s] Trained 120 records in 0.040188706 seconds. Throughput is 2985.9133 records/second. Loss is 0.28899774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006006006006006006. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39240/60000][Iteration 3327][Wall Clock 157.305934617s] Trained 120 records in 0.040928904 seconds. Throughput is 2931.9133 records/second. Loss is 0.26762766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006005284650492434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39360/60000][Iteration 3328][Wall Clock 157.348111792s] Trained 120 records in 0.042177175 seconds. Throughput is 2845.1409 records/second. Loss is 0.34801444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006004563468235859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39480/60000][Iteration 3329][Wall Clock 157.388724458s] Trained 120 records in 0.040612666 seconds. Throughput is 2954.7432 records/second. Loss is 0.31749883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006003842459173871. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39600/60000][Iteration 3330][Wall Clock 157.429650365s] Trained 120 records in 0.040925907 seconds. Throughput is 2932.128 records/second. Loss is 0.39550674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006003121623244088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39720/60000][Iteration 3331][Wall Clock 157.482279939s] Trained 120 records in 0.052629574 seconds. Throughput is 2280.087 records/second. Loss is 0.35366803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006002400960384154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:43 INFO  DistriOptimizer$:406 - [Epoch 7 39840/60000][Iteration 3332][Wall Clock 157.528180545s] Trained 120 records in 0.045900606 seconds. Throughput is 2614.3445 records/second. Loss is 0.28266102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060016804705317495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 39960/60000][Iteration 3333][Wall Clock 157.569280703s] Trained 120 records in 0.041100158 seconds. Throughput is 2919.6968 records/second. Loss is 0.28008375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0060009601536245806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40080/60000][Iteration 3334][Wall Clock 157.609963049s] Trained 120 records in 0.040682346 seconds. Throughput is 2949.6824 records/second. Loss is 0.23701106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.006000240009600383. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40200/60000][Iteration 3335][Wall Clock 157.650664872s] Trained 120 records in 0.040701823 seconds. Throughput is 2948.271 records/second. Loss is 0.25412592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005999520038396928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40320/60000][Iteration 3336][Wall Clock 157.691047333s] Trained 120 records in 0.040382461 seconds. Throughput is 2971.5872 records/second. Loss is 0.3280541. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00599880023995201. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40440/60000][Iteration 3337][Wall Clock 157.732185736s] Trained 120 records in 0.041138403 seconds. Throughput is 2916.9824 records/second. Loss is 0.30922896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005998080614203455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40560/60000][Iteration 3338][Wall Clock 157.773992136s] Trained 120 records in 0.0418064 seconds. Throughput is 2870.374 records/second. Loss is 0.39779225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005997361161089121. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40680/60000][Iteration 3339][Wall Clock 157.819142791s] Trained 120 records in 0.045150655 seconds. Throughput is 2657.7688 records/second. Loss is 0.3346456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005996641880546893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40800/60000][Iteration 3340][Wall Clock 157.870939221s] Trained 120 records in 0.05179643 seconds. Throughput is 2316.762 records/second. Loss is 0.30273136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005995922772514689. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 40920/60000][Iteration 3341][Wall Clock 157.911895305s] Trained 120 records in 0.040956084 seconds. Throughput is 2929.9675 records/second. Loss is 0.27598155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005995203836930455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41040/60000][Iteration 3342][Wall Clock 157.952545155s] Trained 120 records in 0.04064985 seconds. Throughput is 2952.0405 records/second. Loss is 0.26810884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005994485073732166. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41160/60000][Iteration 3343][Wall Clock 157.99369628s] Trained 120 records in 0.041151125 seconds. Throughput is 2916.0806 records/second. Loss is 0.2604245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005993766482857828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41280/60000][Iteration 3344][Wall Clock 158.034966215s] Trained 120 records in 0.041269935 seconds. Throughput is 2907.6855 records/second. Loss is 0.3266879. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005993048064245475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41400/60000][Iteration 3345][Wall Clock 158.076783285s] Trained 120 records in 0.04181707 seconds. Throughput is 2869.6416 records/second. Loss is 0.34878266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005992329817833174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41520/60000][Iteration 3346][Wall Clock 158.119458164s] Trained 120 records in 0.042674879 seconds. Throughput is 2811.9587 records/second. Loss is 0.20856868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005991611743559017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41640/60000][Iteration 3347][Wall Clock 158.16258031s] Trained 120 records in 0.043122146 seconds. Throughput is 2782.7927 records/second. Loss is 0.37419656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059908938413611315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41760/60000][Iteration 3348][Wall Clock 158.204990243s] Trained 120 records in 0.042409933 seconds. Throughput is 2829.5256 records/second. Loss is 0.2363431. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059901761111776685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 41880/60000][Iteration 3349][Wall Clock 158.246631794s] Trained 120 records in 0.041641551 seconds. Throughput is 2881.737 records/second. Loss is 0.25110683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005989458552946814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 42000/60000][Iteration 3350][Wall Clock 158.287919697s] Trained 120 records in 0.041287903 seconds. Throughput is 2906.4204 records/second. Loss is 0.18374379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005988741166606779. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 42120/60000][Iteration 3351][Wall Clock 158.32868696s] Trained 120 records in 0.040767263 seconds. Throughput is 2943.5383 records/second. Loss is 0.40406603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005988023952095809. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 42240/60000][Iteration 3352][Wall Clock 158.370986819s] Trained 120 records in 0.042299859 seconds. Throughput is 2836.889 records/second. Loss is 0.43545863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005987306909352174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 42360/60000][Iteration 3353][Wall Clock 158.412474399s] Trained 120 records in 0.04148758 seconds. Throughput is 2892.4321 records/second. Loss is 0.2123897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059865900383141765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 42480/60000][Iteration 3354][Wall Clock 158.453346011s] Trained 120 records in 0.040871612 seconds. Throughput is 2936.0232 records/second. Loss is 0.28430158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005985873338920148. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 42600/60000][Iteration 3355][Wall Clock 158.493909253s] Trained 120 records in 0.040563242 seconds. Throughput is 2958.3435 records/second. Loss is 0.330744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059851568111084505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:44 INFO  DistriOptimizer$:406 - [Epoch 7 42720/60000][Iteration 3356][Wall Clock 158.535125915s] Trained 120 records in 0.041216662 seconds. Throughput is 2911.444 records/second. Loss is 0.20713012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005984440454817474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 42840/60000][Iteration 3357][Wall Clock 158.579820896s] Trained 120 records in 0.044694981 seconds. Throughput is 2684.8652 records/second. Loss is 0.22267032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005983724269985639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 42960/60000][Iteration 3358][Wall Clock 158.634678072s] Trained 120 records in 0.054857176 seconds. Throughput is 2187.4988 records/second. Loss is 0.3220969. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059830082565513944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43080/60000][Iteration 3359][Wall Clock 158.67950824s] Trained 120 records in 0.044830168 seconds. Throughput is 2676.7688 records/second. Loss is 0.30290475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005982292414453218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43200/60000][Iteration 3360][Wall Clock 158.721038764s] Trained 120 records in 0.041530524 seconds. Throughput is 2889.4412 records/second. Loss is 0.23212269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00598157674362962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43320/60000][Iteration 3361][Wall Clock 158.762289921s] Trained 120 records in 0.041251157 seconds. Throughput is 2909.0093 records/second. Loss is 0.31149596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005980861244019139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43440/60000][Iteration 3362][Wall Clock 158.803460494s] Trained 120 records in 0.041170573 seconds. Throughput is 2914.7031 records/second. Loss is 0.3193154. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005980145915560339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43560/60000][Iteration 3363][Wall Clock 158.84566591s] Trained 120 records in 0.042205416 seconds. Throughput is 2843.237 records/second. Loss is 0.2343755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00597943075819182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43680/60000][Iteration 3364][Wall Clock 158.887396741s] Trained 120 records in 0.041730831 seconds. Throughput is 2875.5718 records/second. Loss is 0.31370804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005978715771852206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43800/60000][Iteration 3365][Wall Clock 158.929110693s] Trained 120 records in 0.041713952 seconds. Throughput is 2876.7354 records/second. Loss is 0.20290011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005978000956480153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 43920/60000][Iteration 3366][Wall Clock 158.978735014s] Trained 120 records in 0.049624321 seconds. Throughput is 2418.1692 records/second. Loss is 0.20843635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005977286312014346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44040/60000][Iteration 3367][Wall Clock 159.02390057s] Trained 120 records in 0.045165556 seconds. Throughput is 2656.8918 records/second. Loss is 0.2319727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005976571838393498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44160/60000][Iteration 3368][Wall Clock 159.065944849s] Trained 120 records in 0.042044279 seconds. Throughput is 2854.1338 records/second. Loss is 0.30555418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005975857535556352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44280/60000][Iteration 3369][Wall Clock 159.107552694s] Trained 120 records in 0.041607845 seconds. Throughput is 2884.0715 records/second. Loss is 0.24745303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059751434034416824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44400/60000][Iteration 3370][Wall Clock 159.148849743s] Trained 120 records in 0.041297049 seconds. Throughput is 2905.7766 records/second. Loss is 0.252099. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059744294419882904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44520/60000][Iteration 3371][Wall Clock 159.189885756s] Trained 120 records in 0.041036013 seconds. Throughput is 2924.2607 records/second. Loss is 0.2571279. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005973715651135006. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44640/60000][Iteration 3372][Wall Clock 159.231359964s] Trained 120 records in 0.041474208 seconds. Throughput is 2893.3645 records/second. Loss is 0.29069307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005973002030820691. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44760/60000][Iteration 3373][Wall Clock 159.272620804s] Trained 120 records in 0.04126084 seconds. Throughput is 2908.3267 records/second. Loss is 0.23145434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005972288580984234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 44880/60000][Iteration 3374][Wall Clock 159.313820679s] Trained 120 records in 0.041199875 seconds. Throughput is 2912.6304 records/second. Loss is 0.3090049. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059715753015645535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 45000/60000][Iteration 3375][Wall Clock 159.354875276s] Trained 120 records in 0.041054597 seconds. Throughput is 2922.937 records/second. Loss is 0.26490766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005970862192500597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 45120/60000][Iteration 3376][Wall Clock 159.396245819s] Trained 120 records in 0.041370543 seconds. Throughput is 2900.6145 records/second. Loss is 0.28865036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005970149253731343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 45240/60000][Iteration 3377][Wall Clock 159.437900091s] Trained 120 records in 0.041654272 seconds. Throughput is 2880.8572 records/second. Loss is 0.28800106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059694364851957974. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 45360/60000][Iteration 3378][Wall Clock 159.478628176s] Trained 120 records in 0.040728085 seconds. Throughput is 2946.3699 records/second. Loss is 0.42227954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059687238868329955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:45 INFO  DistriOptimizer$:406 - [Epoch 7 45480/60000][Iteration 3379][Wall Clock 159.519962357s] Trained 120 records in 0.041334181 seconds. Throughput is 2903.1663 records/second. Loss is 0.42643255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005968011458582001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 45600/60000][Iteration 3380][Wall Clock 159.561161223s] Trained 120 records in 0.041198866 seconds. Throughput is 2912.7017 records/second. Loss is 0.26734635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005967299200381907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 45720/60000][Iteration 3381][Wall Clock 159.606237755s] Trained 120 records in 0.045076532 seconds. Throughput is 2662.1392 records/second. Loss is 0.2626338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059665871121718375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 45840/60000][Iteration 3382][Wall Clock 159.64701629s] Trained 120 records in 0.040778535 seconds. Throughput is 2942.7246 records/second. Loss is 0.20637862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005965875193890943. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 45960/60000][Iteration 3383][Wall Clock 159.687783605s] Trained 120 records in 0.040767315 seconds. Throughput is 2943.5344 records/second. Loss is 0.21149401. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005965163445478406. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46080/60000][Iteration 3384][Wall Clock 159.735883494s] Trained 120 records in 0.048099889 seconds. Throughput is 2494.808 records/second. Loss is 0.22785015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005964451866873434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46200/60000][Iteration 3385][Wall Clock 159.789292285s] Trained 120 records in 0.053408791 seconds. Throughput is 2246.821 records/second. Loss is 0.18442068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005963740458015267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46320/60000][Iteration 3386][Wall Clock 159.834230961s] Trained 120 records in 0.044938676 seconds. Throughput is 2670.3057 records/second. Loss is 0.15077202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005963029218843173. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46440/60000][Iteration 3387][Wall Clock 159.875792041s] Trained 120 records in 0.04156108 seconds. Throughput is 2887.317 records/second. Loss is 0.2951601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005962318149296446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46560/60000][Iteration 3388][Wall Clock 159.917760044s] Trained 120 records in 0.041968003 seconds. Throughput is 2859.3213 records/second. Loss is 0.27828294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005961607249314415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46680/60000][Iteration 3389][Wall Clock 159.959558381s] Trained 120 records in 0.041798337 seconds. Throughput is 2870.9275 records/second. Loss is 0.37001598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005960896518836433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46800/60000][Iteration 3390][Wall Clock 160.00051522s] Trained 120 records in 0.040956839 seconds. Throughput is 2929.9136 records/second. Loss is 0.23616196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005960185957801884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 46920/60000][Iteration 3391][Wall Clock 160.041973051s] Trained 120 records in 0.041457831 seconds. Throughput is 2894.5073 records/second. Loss is 0.28807685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005959475566150179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47040/60000][Iteration 3392][Wall Clock 160.082765251s] Trained 120 records in 0.0407922 seconds. Throughput is 2941.7388 records/second. Loss is 0.32647616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059587653438207605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47160/60000][Iteration 3393][Wall Clock 160.132929172s] Trained 120 records in 0.050163921 seconds. Throughput is 2392.1575 records/second. Loss is 0.24763887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005958055290753099. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47280/60000][Iteration 3394][Wall Clock 160.173451903s] Trained 120 records in 0.040522731 seconds. Throughput is 2961.3008 records/second. Loss is 0.2600539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005957345406886692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47400/60000][Iteration 3395][Wall Clock 160.214576085s] Trained 120 records in 0.041124182 seconds. Throughput is 2917.991 records/second. Loss is 0.4823137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005956635692161067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47520/60000][Iteration 3396][Wall Clock 160.256143294s] Trained 120 records in 0.041567209 seconds. Throughput is 2886.8909 records/second. Loss is 0.32862172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005955926146515783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47640/60000][Iteration 3397][Wall Clock 160.297427032s] Trained 120 records in 0.041283738 seconds. Throughput is 2906.7136 records/second. Loss is 0.44311252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005955216769890424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47760/60000][Iteration 3398][Wall Clock 160.338230355s] Trained 120 records in 0.040803323 seconds. Throughput is 2940.9368 records/second. Loss is 0.31635478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005954507562224604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 47880/60000][Iteration 3399][Wall Clock 160.379194898s] Trained 120 records in 0.040964543 seconds. Throughput is 2929.3625 records/second. Loss is 0.24544148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005953798523457966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 48000/60000][Iteration 3400][Wall Clock 160.420662238s] Trained 120 records in 0.04146734 seconds. Throughput is 2893.8438 records/second. Loss is 0.32808062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005953089653530181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 48120/60000][Iteration 3401][Wall Clock 160.46195865s] Trained 120 records in 0.041296412 seconds. Throughput is 2905.8215 records/second. Loss is 0.26835525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005952380952380952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:46 INFO  DistriOptimizer$:406 - [Epoch 7 48240/60000][Iteration 3402][Wall Clock 160.502725763s] Trained 120 records in 0.040767113 seconds. Throughput is 2943.549 records/second. Loss is 0.25336593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005951672419950005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 48360/60000][Iteration 3403][Wall Clock 160.544016601s] Trained 120 records in 0.041290838 seconds. Throughput is 2906.2136 records/second. Loss is 0.3294266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005950964056177101. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 48480/60000][Iteration 3404][Wall Clock 160.585231359s] Trained 120 records in 0.041214758 seconds. Throughput is 2911.5786 records/second. Loss is 0.25377834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005950255861002023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 48600/60000][Iteration 3405][Wall Clock 160.629606848s] Trained 120 records in 0.044375489 seconds. Throughput is 2704.1956 records/second. Loss is 0.2514423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005949547834364588. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 48720/60000][Iteration 3406][Wall Clock 160.670474954s] Trained 120 records in 0.040868106 seconds. Throughput is 2936.275 records/second. Loss is 0.30447257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00594883997620464. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 48840/60000][Iteration 3407][Wall Clock 160.710881293s] Trained 120 records in 0.040406339 seconds. Throughput is 2969.831 records/second. Loss is 0.34695628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005948132286462051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 48960/60000][Iteration 3408][Wall Clock 160.751538127s] Trained 120 records in 0.040656834 seconds. Throughput is 2951.5332 records/second. Loss is 0.30023107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005947424765076722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49080/60000][Iteration 3409][Wall Clock 160.791919488s] Trained 120 records in 0.040381361 seconds. Throughput is 2971.668 records/second. Loss is 0.43512714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005946717411988583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49200/60000][Iteration 3410][Wall Clock 160.832675894s] Trained 120 records in 0.040756406 seconds. Throughput is 2944.3225 records/second. Loss is 0.2863221. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005946010227137591. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49320/60000][Iteration 3411][Wall Clock 160.883318783s] Trained 120 records in 0.050642889 seconds. Throughput is 2369.533 records/second. Loss is 0.30050674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005945303210463734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49440/60000][Iteration 3412][Wall Clock 160.927610008s] Trained 120 records in 0.044291225 seconds. Throughput is 2709.3403 records/second. Loss is 0.2213624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005944596361907027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49560/60000][Iteration 3413][Wall Clock 160.970101139s] Trained 120 records in 0.042491131 seconds. Throughput is 2824.119 records/second. Loss is 0.26196447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005943889681407514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49680/60000][Iteration 3414][Wall Clock 161.012564928s] Trained 120 records in 0.042463789 seconds. Throughput is 2825.937 records/second. Loss is 0.21233435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005943183168905266. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49800/60000][Iteration 3415][Wall Clock 161.054548504s] Trained 120 records in 0.041983576 seconds. Throughput is 2858.2607 records/second. Loss is 0.35261148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059424768243403845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 49920/60000][Iteration 3416][Wall Clock 161.096362639s] Trained 120 records in 0.041814135 seconds. Throughput is 2869.843 records/second. Loss is 0.3195484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059417706476530005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50040/60000][Iteration 3417][Wall Clock 161.137770606s] Trained 120 records in 0.041407967 seconds. Throughput is 2897.993 records/second. Loss is 0.4253101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00594106463878327. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50160/60000][Iteration 3418][Wall Clock 161.178357472s] Trained 120 records in 0.040586866 seconds. Throughput is 2956.6213 records/second. Loss is 0.3853468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005940358797671379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50280/60000][Iteration 3419][Wall Clock 161.225975652s] Trained 120 records in 0.04761818 seconds. Throughput is 2520.046 records/second. Loss is 0.29078168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005939653124257544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50400/60000][Iteration 3420][Wall Clock 161.270496725s] Trained 120 records in 0.044521073 seconds. Throughput is 2695.3528 records/second. Loss is 0.19733061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005938947618482004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50520/60000][Iteration 3421][Wall Clock 161.311310458s] Trained 120 records in 0.040813733 seconds. Throughput is 2940.1868 records/second. Loss is 0.17987925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059382422802850355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50640/60000][Iteration 3422][Wall Clock 161.351536658s] Trained 120 records in 0.0402262 seconds. Throughput is 2983.1304 records/second. Loss is 0.33297813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005937537109606934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50760/60000][Iteration 3423][Wall Clock 161.392595278s] Trained 120 records in 0.04105862 seconds. Throughput is 2922.6506 records/second. Loss is 0.2795479. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005936832106388031. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 50880/60000][Iteration 3424][Wall Clock 161.433956072s] Trained 120 records in 0.041360794 seconds. Throughput is 2901.298 records/second. Loss is 0.3470375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059361272705686806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 51000/60000][Iteration 3425][Wall Clock 161.475737261s] Trained 120 records in 0.041781189 seconds. Throughput is 2872.1057 records/second. Loss is 0.3005872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005935422602089268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:47 INFO  DistriOptimizer$:406 - [Epoch 7 51120/60000][Iteration 3426][Wall Clock 161.516395863s] Trained 120 records in 0.040658602 seconds. Throughput is 2951.405 records/second. Loss is 0.20352505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005934718100890208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 51240/60000][Iteration 3427][Wall Clock 161.556633622s] Trained 120 records in 0.040237759 seconds. Throughput is 2982.2734 records/second. Loss is 0.31060424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059340137669119395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 51360/60000][Iteration 3428][Wall Clock 161.596826031s] Trained 120 records in 0.040192409 seconds. Throughput is 2985.6384 records/second. Loss is 0.28110313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005933309600094933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 51480/60000][Iteration 3429][Wall Clock 161.64111744s] Trained 120 records in 0.044291409 seconds. Throughput is 2709.3289 records/second. Loss is 0.41670266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005932605600379687. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 51600/60000][Iteration 3430][Wall Clock 161.682062112s] Trained 120 records in 0.040944672 seconds. Throughput is 2930.7842 records/second. Loss is 0.24205181. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005931901767706727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 51720/60000][Iteration 3431][Wall Clock 161.72472725s] Trained 120 records in 0.042665138 seconds. Throughput is 2812.6008 records/second. Loss is 0.31741852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005931198102016607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 51840/60000][Iteration 3432][Wall Clock 161.767494331s] Trained 120 records in 0.042767081 seconds. Throughput is 2805.8965 records/second. Loss is 0.2860365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059304946032499115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 51960/60000][Iteration 3433][Wall Clock 161.809879297s] Trained 120 records in 0.042384966 seconds. Throughput is 2831.1924 records/second. Loss is 0.16577247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005929791271347249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52080/60000][Iteration 3434][Wall Clock 161.850851751s] Trained 120 records in 0.040972454 seconds. Throughput is 2928.797 records/second. Loss is 0.3656677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005929088106249259. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52200/60000][Iteration 3435][Wall Clock 161.891887635s] Trained 120 records in 0.041035884 seconds. Throughput is 2924.27 records/second. Loss is 0.3109403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005928385107896609. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52320/60000][Iteration 3436][Wall Clock 161.932654561s] Trained 120 records in 0.040766926 seconds. Throughput is 2943.5627 records/second. Loss is 0.28435543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005927682276229994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52440/60000][Iteration 3437][Wall Clock 161.982155654s] Trained 120 records in 0.049501093 seconds. Throughput is 2424.189 records/second. Loss is 0.28583914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005926979611190137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52560/60000][Iteration 3438][Wall Clock 162.035927721s] Trained 120 records in 0.053772067 seconds. Throughput is 2231.642 records/second. Loss is 0.21153961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005926277112717791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52680/60000][Iteration 3439][Wall Clock 162.08077886s] Trained 120 records in 0.044851139 seconds. Throughput is 2675.5173 records/second. Loss is 0.2188711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005925574780753734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52800/60000][Iteration 3440][Wall Clock 162.122594719s] Trained 120 records in 0.041815859 seconds. Throughput is 2869.7246 records/second. Loss is 0.2613985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005924872615238772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 52920/60000][Iteration 3441][Wall Clock 162.1640574s] Trained 120 records in 0.041462681 seconds. Throughput is 2894.1687 records/second. Loss is 0.21420614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005924170616113744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53040/60000][Iteration 3442][Wall Clock 162.206464024s] Trained 120 records in 0.042406624 seconds. Throughput is 2829.7468 records/second. Loss is 0.3618927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005923468783319511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53160/60000][Iteration 3443][Wall Clock 162.249712005s] Trained 120 records in 0.043247981 seconds. Throughput is 2774.6958 records/second. Loss is 0.33650336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005922767116796967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53280/60000][Iteration 3444][Wall Clock 162.291935192s] Trained 120 records in 0.042223187 seconds. Throughput is 2842.0405 records/second. Loss is 0.17944366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059220656164870305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53400/60000][Iteration 3445][Wall Clock 162.339972045s] Trained 120 records in 0.048036853 seconds. Throughput is 2498.082 records/second. Loss is 0.27547768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005921364282330649. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53520/60000][Iteration 3446][Wall Clock 162.386287433s] Trained 120 records in 0.046315388 seconds. Throughput is 2590.9316 records/second. Loss is 0.30050912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005920663114268798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53640/60000][Iteration 3447][Wall Clock 162.427907365s] Trained 120 records in 0.041619932 seconds. Throughput is 2883.2341 records/second. Loss is 0.21536447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005919962112242482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53760/60000][Iteration 3448][Wall Clock 162.469407295s] Trained 120 records in 0.04149993 seconds. Throughput is 2891.571 records/second. Loss is 0.2178503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005919261276192731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:48 INFO  DistriOptimizer$:406 - [Epoch 7 53880/60000][Iteration 3449][Wall Clock 162.511509053s] Trained 120 records in 0.042101758 seconds. Throughput is 2850.237 records/second. Loss is 0.24851547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005918560606060606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54000/60000][Iteration 3450][Wall Clock 162.553714033s] Trained 120 records in 0.04220498 seconds. Throughput is 2843.2664 records/second. Loss is 0.29905537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005917860101787194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54120/60000][Iteration 3451][Wall Clock 162.595829198s] Trained 120 records in 0.042115165 seconds. Throughput is 2849.3298 records/second. Loss is 0.18860525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00591715976331361. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54240/60000][Iteration 3452][Wall Clock 162.640360533s] Trained 120 records in 0.044531335 seconds. Throughput is 2694.7317 records/second. Loss is 0.35499826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005916459590580997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54360/60000][Iteration 3453][Wall Clock 162.6818079s] Trained 120 records in 0.041447367 seconds. Throughput is 2895.238 records/second. Loss is 0.24113503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005915759583530526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54480/60000][Iteration 3454][Wall Clock 162.72237208s] Trained 120 records in 0.04056418 seconds. Throughput is 2958.2751 records/second. Loss is 0.24762855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059150597421033955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54600/60000][Iteration 3455][Wall Clock 162.763513602s] Trained 120 records in 0.041141522 seconds. Throughput is 2916.7615 records/second. Loss is 0.2606347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005914360066240833. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54720/60000][Iteration 3456][Wall Clock 162.806186992s] Trained 120 records in 0.04267339 seconds. Throughput is 2812.057 records/second. Loss is 0.37197667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059136605558840925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54840/60000][Iteration 3457][Wall Clock 162.848123958s] Trained 120 records in 0.041936966 seconds. Throughput is 2861.4373 records/second. Loss is 0.18860309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005912961210974456. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 54960/60000][Iteration 3458][Wall Clock 162.889288792s] Trained 120 records in 0.041164834 seconds. Throughput is 2915.1096 records/second. Loss is 0.293205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005912262031453234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55080/60000][Iteration 3459][Wall Clock 162.930344108s] Trained 120 records in 0.041055316 seconds. Throughput is 2922.886 records/second. Loss is 0.40118998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005911563017261764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55200/60000][Iteration 3460][Wall Clock 162.971317382s] Trained 120 records in 0.040973274 seconds. Throughput is 2928.7385 records/second. Loss is 0.30526006. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005910864168341411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55320/60000][Iteration 3461][Wall Clock 163.012588522s] Trained 120 records in 0.04127114 seconds. Throughput is 2907.6008 records/second. Loss is 0.21964315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00591016548463357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55440/60000][Iteration 3462][Wall Clock 163.053946086s] Trained 120 records in 0.041357564 seconds. Throughput is 2901.5247 records/second. Loss is 0.38103738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005909466966079659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55560/60000][Iteration 3463][Wall Clock 163.103763394s] Trained 120 records in 0.049817308 seconds. Throughput is 2408.8013 records/second. Loss is 0.24940361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005908768612621129. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55680/60000][Iteration 3464][Wall Clock 163.15149786s] Trained 120 records in 0.047734466 seconds. Throughput is 2513.9067 records/second. Loss is 0.27099532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059080704241994565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55800/60000][Iteration 3465][Wall Clock 163.19218011s] Trained 120 records in 0.04068225 seconds. Throughput is 2949.6895 records/second. Loss is 0.31633165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005907372400756144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 55920/60000][Iteration 3466][Wall Clock 163.233541275s] Trained 120 records in 0.041361165 seconds. Throughput is 2901.2722 records/second. Loss is 0.15868668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005906674542232723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 56040/60000][Iteration 3467][Wall Clock 163.274204148s] Trained 120 records in 0.040662873 seconds. Throughput is 2951.095 records/second. Loss is 0.28322238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005905976848570754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 56160/60000][Iteration 3468][Wall Clock 163.313982413s] Trained 120 records in 0.039778265 seconds. Throughput is 3016.7227 records/second. Loss is 0.28517425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005905279319711822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 56280/60000][Iteration 3469][Wall Clock 163.354484921s] Trained 120 records in 0.040502508 seconds. Throughput is 2962.7795 records/second. Loss is 0.3817653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005904581955597544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 56400/60000][Iteration 3470][Wall Clock 163.394993969s] Trained 120 records in 0.040509048 seconds. Throughput is 2962.301 records/second. Loss is 0.253184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00590388475616956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 56520/60000][Iteration 3471][Wall Clock 163.435686164s] Trained 120 records in 0.040692195 seconds. Throughput is 2948.9685 records/second. Loss is 0.25288418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059031877213695395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:49 INFO  DistriOptimizer$:406 - [Epoch 7 56640/60000][Iteration 3472][Wall Clock 163.486709005s] Trained 120 records in 0.051022841 seconds. Throughput is 2351.8877 records/second. Loss is 0.30152833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059024908511391815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 56760/60000][Iteration 3473][Wall Clock 163.528452717s] Trained 120 records in 0.041743712 seconds. Throughput is 2874.6846 records/second. Loss is 0.24765542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005901794145420208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 56880/60000][Iteration 3474][Wall Clock 163.569459289s] Trained 120 records in 0.041006572 seconds. Throughput is 2926.36 records/second. Loss is 0.19433543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005901097604154373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57000/60000][Iteration 3475][Wall Clock 163.613994305s] Trained 120 records in 0.044535016 seconds. Throughput is 2694.509 records/second. Loss is 0.22081901. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0059004012272834555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57120/60000][Iteration 3476][Wall Clock 163.654880329s] Trained 120 records in 0.040886024 seconds. Throughput is 2934.9883 records/second. Loss is 0.17131491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058997050147492625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57240/60000][Iteration 3477][Wall Clock 163.69537398s] Trained 120 records in 0.040493651 seconds. Throughput is 2963.4275 records/second. Loss is 0.3619367. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005899008966493629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57360/60000][Iteration 3478][Wall Clock 163.736324858s] Trained 120 records in 0.040950878 seconds. Throughput is 2930.34 records/second. Loss is 0.25114292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005898313082458417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57480/60000][Iteration 3479][Wall Clock 163.776719626s] Trained 120 records in 0.040394768 seconds. Throughput is 2970.6816 records/second. Loss is 0.26924223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005897617362585515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57600/60000][Iteration 3480][Wall Clock 163.818103294s] Trained 120 records in 0.041383668 seconds. Throughput is 2899.6946 records/second. Loss is 0.25840917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005896921806816841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57720/60000][Iteration 3481][Wall Clock 163.859504864s] Trained 120 records in 0.04140157 seconds. Throughput is 2898.441 records/second. Loss is 0.1912192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005896226415094339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57840/60000][Iteration 3482][Wall Clock 163.900512193s] Trained 120 records in 0.041007329 seconds. Throughput is 2926.3062 records/second. Loss is 0.48552206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005895531187359981. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 57960/60000][Iteration 3483][Wall Clock 163.941801744s] Trained 120 records in 0.041289551 seconds. Throughput is 2906.3044 records/second. Loss is 0.24010147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005894836123555765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58080/60000][Iteration 3484][Wall Clock 163.982786517s] Trained 120 records in 0.040984773 seconds. Throughput is 2927.9167 records/second. Loss is 0.25972262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005894141223623718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58200/60000][Iteration 3485][Wall Clock 164.02366997s] Trained 120 records in 0.040883453 seconds. Throughput is 2935.1729 records/second. Loss is 0.24384274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005893446487505893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58320/60000][Iteration 3486][Wall Clock 164.064831777s] Trained 120 records in 0.041161807 seconds. Throughput is 2915.324 records/second. Loss is 0.2344344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058927519151443725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58440/60000][Iteration 3487][Wall Clock 164.106210481s] Trained 120 records in 0.041378704 seconds. Throughput is 2900.0425 records/second. Loss is 0.34155846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005892057506481263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58560/60000][Iteration 3488][Wall Clock 164.152749467s] Trained 120 records in 0.046538986 seconds. Throughput is 2578.4834 records/second. Loss is 0.225799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005891363261458701. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58680/60000][Iteration 3489][Wall Clock 164.202042123s] Trained 120 records in 0.049292656 seconds. Throughput is 2434.4397 records/second. Loss is 0.21235417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00589066918001885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58800/60000][Iteration 3490][Wall Clock 164.244778042s] Trained 120 records in 0.042735919 seconds. Throughput is 2807.9424 records/second. Loss is 0.23112737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058899752621039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 58920/60000][Iteration 3491][Wall Clock 164.285053586s] Trained 120 records in 0.040275544 seconds. Throughput is 2979.4756 records/second. Loss is 0.35885525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005889281507656066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 59040/60000][Iteration 3492][Wall Clock 164.325278287s] Trained 120 records in 0.040224701 seconds. Throughput is 2983.2415 records/second. Loss is 0.29023266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005888587916617596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 59160/60000][Iteration 3493][Wall Clock 164.36569995s] Trained 120 records in 0.040421663 seconds. Throughput is 2968.705 records/second. Loss is 0.22393158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005887894488930759. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 59280/60000][Iteration 3494][Wall Clock 164.406073851s] Trained 120 records in 0.040373901 seconds. Throughput is 2972.217 records/second. Loss is 0.3084947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005887201224537855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 59400/60000][Iteration 3495][Wall Clock 164.446283108s] Trained 120 records in 0.040209257 seconds. Throughput is 2984.3875 records/second. Loss is 0.27463883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00588650812338121. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:50 INFO  DistriOptimizer$:406 - [Epoch 7 59520/60000][Iteration 3496][Wall Clock 164.486841185s] Trained 120 records in 0.040558077 seconds. Throughput is 2958.7202 records/second. Loss is 0.34408966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005885815185403178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:51 INFO  DistriOptimizer$:406 - [Epoch 7 59640/60000][Iteration 3497][Wall Clock 164.527156309s] Trained 120 records in 0.040315124 seconds. Throughput is 2976.5503 records/second. Loss is 0.18960634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005885122410546139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:51 INFO  DistriOptimizer$:406 - [Epoch 7 59760/60000][Iteration 3498][Wall Clock 164.574142164s] Trained 120 records in 0.046985855 seconds. Throughput is 2553.9602 records/second. Loss is 0.35403377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005884429798752501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:51 INFO  DistriOptimizer$:406 - [Epoch 7 59880/60000][Iteration 3499][Wall Clock 164.622167231s] Trained 120 records in 0.048025067 seconds. Throughput is 2498.695 records/second. Loss is 0.34925228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005883737349964698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:51 INFO  DistriOptimizer$:406 - [Epoch 7 60000/60000][Iteration 3500][Wall Clock 164.662879252s] Trained 120 records in 0.040712021 seconds. Throughput is 2947.5325 records/second. Loss is 0.22979556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00588304506412519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:51 INFO  DistriOptimizer$:451 - [Epoch 7 60000/60000][Iteration 3500][Wall Clock 164.662879252s] Epoch finished. Wall clock time is 165462.731243 ms
2019-10-23 15:55:51 INFO  DistriOptimizer$:111 - [Epoch 7 60000/60000][Iteration 3500][Wall Clock 164.662879252s] Validate model...
2019-10-23 15:55:51 INFO  DistriOptimizer$:177 - [Epoch 7 60000/60000][Iteration 3500][Wall Clock 164.662879252s] validate model throughput is 15121.55 records/second
2019-10-23 15:55:51 INFO  DistriOptimizer$:180 - [Epoch 7 60000/60000][Iteration 3500][Wall Clock 164.662879252s] Top1Accuracy is Accuracy(correct: 9318, count: 10000, accuracy: 0.9318)
2019-10-23 15:55:51 INFO  DistriOptimizer$:220 - [Wall Clock 165.462731243s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:55:51 INFO  DistriOptimizer$:225 - [Wall Clock 165.462731243s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:55:51 INFO  DistriOptimizer$:406 - [Epoch 8 120/60000][Iteration 3501][Wall Clock 165.513418471s] Trained 120 records in 0.050687228 seconds. Throughput is 2367.4604 records/second. Loss is 0.30227143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058823529411764705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:51 INFO  DistriOptimizer$:406 - [Epoch 8 240/60000][Iteration 3502][Wall Clock 165.553936879s] Trained 120 records in 0.040518408 seconds. Throughput is 2961.617 records/second. Loss is 0.17605117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005881660981061051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:51 INFO  DistriOptimizer$:406 - [Epoch 8 360/60000][Iteration 3503][Wall Clock 165.594080926s] Trained 120 records in 0.040144047 seconds. Throughput is 2989.235 records/second. Loss is 0.32057515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005880969183721477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 480/60000][Iteration 3504][Wall Clock 165.635646382s] Trained 120 records in 0.041565456 seconds. Throughput is 2887.0127 records/second. Loss is 0.3374266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005880277549100317. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 600/60000][Iteration 3505][Wall Clock 165.678525161s] Trained 120 records in 0.042878779 seconds. Throughput is 2798.5872 records/second. Loss is 0.3979155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005879586077140169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 720/60000][Iteration 3506][Wall Clock 165.719247115s] Trained 120 records in 0.040721954 seconds. Throughput is 2946.8135 records/second. Loss is 0.3046032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005878894767783657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 840/60000][Iteration 3507][Wall Clock 165.760072442s] Trained 120 records in 0.040825327 seconds. Throughput is 2939.3518 records/second. Loss is 0.38217288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005878203620973431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 960/60000][Iteration 3508][Wall Clock 165.800736797s] Trained 120 records in 0.040664355 seconds. Throughput is 2950.9873 records/second. Loss is 0.26343733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005877512636652169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1080/60000][Iteration 3509][Wall Clock 165.840648635s] Trained 120 records in 0.039911838 seconds. Throughput is 3006.627 records/second. Loss is 0.23483557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005876821814762577. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1200/60000][Iteration 3510][Wall Clock 165.880487952s] Trained 120 records in 0.039839317 seconds. Throughput is 3012.0999 records/second. Loss is 0.3696613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005876131155247385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1320/60000][Iteration 3511][Wall Clock 165.92930253s] Trained 120 records in 0.048814578 seconds. Throughput is 2458.282 records/second. Loss is 0.2587055. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005875440658049354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1440/60000][Iteration 3512][Wall Clock 165.978254311s] Trained 120 records in 0.048951781 seconds. Throughput is 2451.3918 records/second. Loss is 0.30148146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005874750323111268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1560/60000][Iteration 3513][Wall Clock 166.022417518s] Trained 120 records in 0.044163207 seconds. Throughput is 2717.1938 records/second. Loss is 0.33932295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00587406015037594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1680/60000][Iteration 3514][Wall Clock 166.06339225s] Trained 120 records in 0.040974732 seconds. Throughput is 2928.634 records/second. Loss is 0.22673982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00587337013978621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1800/60000][Iteration 3515][Wall Clock 166.104639117s] Trained 120 records in 0.041246867 seconds. Throughput is 2909.3118 records/second. Loss is 0.18876569. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005872680291284943. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 1920/60000][Iteration 3516][Wall Clock 166.145452706s] Trained 120 records in 0.040813589 seconds. Throughput is 2940.1973 records/second. Loss is 0.24270938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005871990604815032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2040/60000][Iteration 3517][Wall Clock 166.186173861s] Trained 120 records in 0.040721155 seconds. Throughput is 2946.871 records/second. Loss is 0.28960386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058713010803193985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2160/60000][Iteration 3518][Wall Clock 166.226304353s] Trained 120 records in 0.040130492 seconds. Throughput is 2990.2449 records/second. Loss is 0.23158441. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005870611717740989. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2280/60000][Iteration 3519][Wall Clock 166.265697759s] Trained 120 records in 0.039393406 seconds. Throughput is 3046.195 records/second. Loss is 0.21936096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005869922517022776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2400/60000][Iteration 3520][Wall Clock 166.305971013s] Trained 120 records in 0.040273254 seconds. Throughput is 2979.645 records/second. Loss is 0.20852509. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00586923347810776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2520/60000][Iteration 3521][Wall Clock 166.347668364s] Trained 120 records in 0.041697351 seconds. Throughput is 2877.8809 records/second. Loss is 0.29772478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005868544600938967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2640/60000][Iteration 3522][Wall Clock 166.390650581s] Trained 120 records in 0.042982217 seconds. Throughput is 2791.8523 records/second. Loss is 0.33108532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005867855885459453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2760/60000][Iteration 3523][Wall Clock 166.432442379s] Trained 120 records in 0.041791798 seconds. Throughput is 2871.377 records/second. Loss is 0.2306818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005867167331612297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 2880/60000][Iteration 3524][Wall Clock 166.483537123s] Trained 120 records in 0.051094744 seconds. Throughput is 2348.5781 records/second. Loss is 0.21886125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058664789393406075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 3000/60000][Iteration 3525][Wall Clock 166.526159418s] Trained 120 records in 0.042622295 seconds. Throughput is 2815.428 records/second. Loss is 0.19050846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005865790708587518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 3120/60000][Iteration 3526][Wall Clock 166.566853612s] Trained 120 records in 0.040694194 seconds. Throughput is 2948.8235 records/second. Loss is 0.32187507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005865102639296188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:52 INFO  DistriOptimizer$:406 - [Epoch 8 3240/60000][Iteration 3527][Wall Clock 166.607063226s] Trained 120 records in 0.040209614 seconds. Throughput is 2984.3608 records/second. Loss is 0.4104192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005864414731409805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 3360/60000][Iteration 3528][Wall Clock 166.6475556s] Trained 120 records in 0.040492374 seconds. Throughput is 2963.521 records/second. Loss is 0.2270392. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005863726984871584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 3480/60000][Iteration 3529][Wall Clock 166.68808254s] Trained 120 records in 0.04052694 seconds. Throughput is 2960.9932 records/second. Loss is 0.24187164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005863039399624766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 3600/60000][Iteration 3530][Wall Clock 166.729023866s] Trained 120 records in 0.040941326 seconds. Throughput is 2931.0237 records/second. Loss is 0.25023693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005862351975612616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 3720/60000][Iteration 3531][Wall Clock 166.769722305s] Trained 120 records in 0.040698439 seconds. Throughput is 2948.516 records/second. Loss is 0.30608815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005861664712778429. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 3840/60000][Iteration 3532][Wall Clock 166.809741487s] Trained 120 records in 0.040019182 seconds. Throughput is 2998.5623 records/second. Loss is 0.23450232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005860977611065526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 3960/60000][Iteration 3533][Wall Clock 166.849846434s] Trained 120 records in 0.040104947 seconds. Throughput is 2992.1494 records/second. Loss is 0.23182496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005860290670417253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4080/60000][Iteration 3534][Wall Clock 166.890057412s] Trained 120 records in 0.040210978 seconds. Throughput is 2984.2598 records/second. Loss is 0.24744374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005859603890776984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4200/60000][Iteration 3535][Wall Clock 166.930247311s] Trained 120 records in 0.040189899 seconds. Throughput is 2985.825 records/second. Loss is 0.21964054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058589172720881185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4320/60000][Iteration 3536][Wall Clock 166.970992012s] Trained 120 records in 0.040744701 seconds. Throughput is 2945.1685 records/second. Loss is 0.25895038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005858230814294083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4440/60000][Iteration 3537][Wall Clock 167.019895708s] Trained 120 records in 0.048903696 seconds. Throughput is 2453.8022 records/second. Loss is 0.23944853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005857544517338332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4560/60000][Iteration 3538][Wall Clock 167.063131187s] Trained 120 records in 0.043235479 seconds. Throughput is 2775.4983 records/second. Loss is 0.38312963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058568583811643435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4680/60000][Iteration 3539][Wall Clock 167.104842327s] Trained 120 records in 0.04171114 seconds. Throughput is 2876.9292 records/second. Loss is 0.21971217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005856172405715624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4800/60000][Iteration 3540][Wall Clock 167.145211966s] Trained 120 records in 0.040369639 seconds. Throughput is 2972.531 records/second. Loss is 0.32067043. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005855486590935707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 4920/60000][Iteration 3541][Wall Clock 167.186141279s] Trained 120 records in 0.040929313 seconds. Throughput is 2931.884 records/second. Loss is 0.28927132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058548009367681494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5040/60000][Iteration 3542][Wall Clock 167.227582661s] Trained 120 records in 0.041441382 seconds. Throughput is 2895.6565 records/second. Loss is 0.27786586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005854115443156538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5160/60000][Iteration 3543][Wall Clock 167.26772785s] Trained 120 records in 0.040145189 seconds. Throughput is 2989.1501 records/second. Loss is 0.26733434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005853430110044485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5280/60000][Iteration 3544][Wall Clock 167.308551539s] Trained 120 records in 0.040823689 seconds. Throughput is 2939.4697 records/second. Loss is 0.21081033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058527449373756285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5400/60000][Iteration 3545][Wall Clock 167.350393079s] Trained 120 records in 0.04184154 seconds. Throughput is 2867.9631 records/second. Loss is 0.28708044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058520599250936325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5520/60000][Iteration 3546][Wall Clock 167.392825343s] Trained 120 records in 0.042432264 seconds. Throughput is 2828.0366 records/second. Loss is 0.20819902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005851375073142188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5640/60000][Iteration 3547][Wall Clock 167.438651731s] Trained 120 records in 0.045826388 seconds. Throughput is 2618.5786 records/second. Loss is 0.29184803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005850690381465013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5760/60000][Iteration 3548][Wall Clock 167.48084443s] Trained 120 records in 0.042192699 seconds. Throughput is 2844.094 records/second. Loss is 0.29554233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00585000585000585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 5880/60000][Iteration 3549][Wall Clock 167.521549009s] Trained 120 records in 0.040704579 seconds. Throughput is 2948.0713 records/second. Loss is 0.27108493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00584932147870847. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:53 INFO  DistriOptimizer$:406 - [Epoch 8 6000/60000][Iteration 3550][Wall Clock 167.570537516s] Trained 120 records in 0.048988507 seconds. Throughput is 2449.5542 records/second. Loss is 0.21087779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005848637267516669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6120/60000][Iteration 3551][Wall Clock 167.618360853s] Trained 120 records in 0.047823337 seconds. Throughput is 2509.2354 records/second. Loss is 0.27038637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058479532163742695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6240/60000][Iteration 3552][Wall Clock 167.660016478s] Trained 120 records in 0.041655625 seconds. Throughput is 2880.7634 records/second. Loss is 0.18505621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00584726932522512. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6360/60000][Iteration 3553][Wall Clock 167.701404053s] Trained 120 records in 0.041387575 seconds. Throughput is 2899.421 records/second. Loss is 0.33836251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005846585594013097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6480/60000][Iteration 3554][Wall Clock 167.743488126s] Trained 120 records in 0.042084073 seconds. Throughput is 2851.435 records/second. Loss is 0.28524205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058459020226821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6600/60000][Iteration 3555][Wall Clock 167.78650353s] Trained 120 records in 0.043015404 seconds. Throughput is 2789.6982 records/second. Loss is 0.21343157. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005845218611176059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6720/60000][Iteration 3556][Wall Clock 167.828736309s] Trained 120 records in 0.042232779 seconds. Throughput is 2841.395 records/second. Loss is 0.26272765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058445353594389245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6840/60000][Iteration 3557][Wall Clock 167.87003197s] Trained 120 records in 0.041295661 seconds. Throughput is 2905.8743 records/second. Loss is 0.2359015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00584385226741468. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 6960/60000][Iteration 3558][Wall Clock 167.910647021s] Trained 120 records in 0.040615051 seconds. Throughput is 2954.5696 records/second. Loss is 0.3667425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00584316933504733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7080/60000][Iteration 3559][Wall Clock 167.95151831s] Trained 120 records in 0.040871289 seconds. Throughput is 2936.0464 records/second. Loss is 0.22095107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005842486562280907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7200/60000][Iteration 3560][Wall Clock 167.992852592s] Trained 120 records in 0.041334282 seconds. Throughput is 2903.1592 records/second. Loss is 0.20584463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058418039490594695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7320/60000][Iteration 3561][Wall Clock 168.035272827s] Trained 120 records in 0.042420235 seconds. Throughput is 2828.8386 records/second. Loss is 0.34588355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005841121495327103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7440/60000][Iteration 3562][Wall Clock 168.082086402s] Trained 120 records in 0.046813575 seconds. Throughput is 2563.3591 records/second. Loss is 0.2728439. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005840439201027917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7560/60000][Iteration 3563][Wall Clock 168.12739107s] Trained 120 records in 0.045304668 seconds. Throughput is 2648.7336 records/second. Loss is 0.20533329. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058397570661060496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7680/60000][Iteration 3564][Wall Clock 168.16923579s] Trained 120 records in 0.04184472 seconds. Throughput is 2867.7454 records/second. Loss is 0.36235684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005839075090505664. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7800/60000][Iteration 3565][Wall Clock 168.212135282s] Trained 120 records in 0.042899492 seconds. Throughput is 2797.2358 records/second. Loss is 0.27799657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005838393274170948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 7920/60000][Iteration 3566][Wall Clock 168.254752014s] Trained 120 records in 0.042616732 seconds. Throughput is 2815.7954 records/second. Loss is 0.23701909. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005837711617046118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8040/60000][Iteration 3567][Wall Clock 168.296000281s] Trained 120 records in 0.041248267 seconds. Throughput is 2909.2131 records/second. Loss is 0.2974269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058370301190754145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8160/60000][Iteration 3568][Wall Clock 168.337002024s] Trained 120 records in 0.041001743 seconds. Throughput is 2926.7048 records/second. Loss is 0.19817816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005836348780203105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8280/60000][Iteration 3569][Wall Clock 168.38126664s] Trained 120 records in 0.044264616 seconds. Throughput is 2710.969 records/second. Loss is 0.2821189. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005835667600373483. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8400/60000][Iteration 3570][Wall Clock 168.422572423s] Trained 120 records in 0.041305783 seconds. Throughput is 2905.162 records/second. Loss is 0.13549654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005834986579530867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8520/60000][Iteration 3571][Wall Clock 168.463414653s] Trained 120 records in 0.04084223 seconds. Throughput is 2938.1353 records/second. Loss is 0.21794783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005834305717619603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8640/60000][Iteration 3572][Wall Clock 168.504182675s] Trained 120 records in 0.040768022 seconds. Throughput is 2943.4834 records/second. Loss is 0.29273403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058336250145840625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8760/60000][Iteration 3573][Wall Clock 168.544114067s] Trained 120 records in 0.039931392 seconds. Throughput is 3005.1545 records/second. Loss is 0.17972647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005832944470368642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:54 INFO  DistriOptimizer$:406 - [Epoch 8 8880/60000][Iteration 3574][Wall Clock 168.58460773s] Trained 120 records in 0.040493663 seconds. Throughput is 2963.4265 records/second. Loss is 0.19881561. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005832264084917766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9000/60000][Iteration 3575][Wall Clock 168.624782941s] Trained 120 records in 0.040175211 seconds. Throughput is 2986.9165 records/second. Loss is 0.28532937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058315838581758815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9120/60000][Iteration 3576][Wall Clock 168.665325009s] Trained 120 records in 0.040542068 seconds. Throughput is 2959.8884 records/second. Loss is 0.23000018. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058309037900874635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9240/60000][Iteration 3577][Wall Clock 168.720990289s] Trained 120 records in 0.05566528 seconds. Throughput is 2155.7422 records/second. Loss is 0.21393892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005830223880597015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9360/60000][Iteration 3578][Wall Clock 168.763833312s] Trained 120 records in 0.042843023 seconds. Throughput is 2800.9229 records/second. Loss is 0.23191795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005829544129649061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9480/60000][Iteration 3579][Wall Clock 168.804624139s] Trained 120 records in 0.040790827 seconds. Throughput is 2941.838 records/second. Loss is 0.16207194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058288645371881555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9600/60000][Iteration 3580][Wall Clock 168.845689184s] Trained 120 records in 0.041065045 seconds. Throughput is 2922.1934 records/second. Loss is 0.23873049. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005828185103158877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9720/60000][Iteration 3581][Wall Clock 168.888263679s] Trained 120 records in 0.042574495 seconds. Throughput is 2818.5889 records/second. Loss is 0.33180192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005827505827505827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9840/60000][Iteration 3582][Wall Clock 168.929072365s] Trained 120 records in 0.040808686 seconds. Throughput is 2940.5505 records/second. Loss is 0.27387726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005826826710173639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 9960/60000][Iteration 3583][Wall Clock 168.969393627s] Trained 120 records in 0.040321262 seconds. Throughput is 2976.0974 records/second. Loss is 0.30618554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005826147751106968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10080/60000][Iteration 3584][Wall Clock 169.009670974s] Trained 120 records in 0.040277347 seconds. Throughput is 2979.3423 records/second. Loss is 0.2784421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005825468950250495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10200/60000][Iteration 3585][Wall Clock 169.050774658s] Trained 120 records in 0.041103684 seconds. Throughput is 2919.4463 records/second. Loss is 0.2595205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005824790307548928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10320/60000][Iteration 3586][Wall Clock 169.094092099s] Trained 120 records in 0.043317441 seconds. Throughput is 2770.2468 records/second. Loss is 0.32490528. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005824111822947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10440/60000][Iteration 3587][Wall Clock 169.144510939s] Trained 120 records in 0.05041884 seconds. Throughput is 2380.0627 records/second. Loss is 0.3732931. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058234334963894714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10560/60000][Iteration 3588][Wall Clock 169.190687645s] Trained 120 records in 0.046176706 seconds. Throughput is 2598.713 records/second. Loss is 0.24214847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005822755327821125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10680/60000][Iteration 3589][Wall Clock 169.232563323s] Trained 120 records in 0.041875678 seconds. Throughput is 2865.6252 records/second. Loss is 0.24190149. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005822077317186773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10800/60000][Iteration 3590][Wall Clock 169.273329412s] Trained 120 records in 0.040766089 seconds. Throughput is 2943.623 records/second. Loss is 0.21926482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005821399464431249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 10920/60000][Iteration 3591][Wall Clock 169.313994561s] Trained 120 records in 0.040665149 seconds. Throughput is 2950.9297 records/second. Loss is 0.124152176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005820721769499418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 11040/60000][Iteration 3592][Wall Clock 169.357730348s] Trained 120 records in 0.043735787 seconds. Throughput is 2743.7485 records/second. Loss is 0.31705913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005820044232336166. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 11160/60000][Iteration 3593][Wall Clock 169.397419812s] Trained 120 records in 0.039689464 seconds. Throughput is 3023.4724 records/second. Loss is 0.19493502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005819366852886406. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 11280/60000][Iteration 3594][Wall Clock 169.437428388s] Trained 120 records in 0.040008576 seconds. Throughput is 2999.357 records/second. Loss is 0.22002295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005818689631095078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 11400/60000][Iteration 3595][Wall Clock 169.478463634s] Trained 120 records in 0.041035246 seconds. Throughput is 2924.3154 records/second. Loss is 0.25723037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005818012566907145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 11520/60000][Iteration 3596][Wall Clock 169.519414972s] Trained 120 records in 0.040951338 seconds. Throughput is 2930.3071 records/second. Loss is 0.24343482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005817335660267597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:55 INFO  DistriOptimizer$:406 - [Epoch 8 11640/60000][Iteration 3597][Wall Clock 169.560029296s] Trained 120 records in 0.040614324 seconds. Throughput is 2954.6226 records/second. Loss is 0.32014382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058166589111214514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 11760/60000][Iteration 3598][Wall Clock 169.600827763s] Trained 120 records in 0.040798467 seconds. Throughput is 2941.287 records/second. Loss is 0.26227194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005815982319413749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 11880/60000][Iteration 3599][Wall Clock 169.640736532s] Trained 120 records in 0.039908769 seconds. Throughput is 3006.858 records/second. Loss is 0.2710809. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005815305885089556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12000/60000][Iteration 3600][Wall Clock 169.680633203s] Trained 120 records in 0.039896671 seconds. Throughput is 3007.7698 records/second. Loss is 0.29168707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005814629608093965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12120/60000][Iteration 3601][Wall Clock 169.721461109s] Trained 120 records in 0.040827906 seconds. Throughput is 2939.166 records/second. Loss is 0.2565719. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005813953488372092. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12240/60000][Iteration 3602][Wall Clock 169.761524287s] Trained 120 records in 0.040063178 seconds. Throughput is 2995.2693 records/second. Loss is 0.34191605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005813277525869085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12360/60000][Iteration 3603][Wall Clock 169.802133022s] Trained 120 records in 0.040608735 seconds. Throughput is 2955.0293 records/second. Loss is 0.35151243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005812601720530109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12480/60000][Iteration 3604][Wall Clock 169.855790055s] Trained 120 records in 0.053657033 seconds. Throughput is 2236.4263 records/second. Loss is 0.23374967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00581192607230036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12600/60000][Iteration 3605][Wall Clock 169.900719888s] Trained 120 records in 0.044929833 seconds. Throughput is 2670.8313 records/second. Loss is 0.27833223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005811250581125058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12720/60000][Iteration 3606][Wall Clock 169.941109576s] Trained 120 records in 0.040389688 seconds. Throughput is 2971.0554 records/second. Loss is 0.24082229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005810575246949448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12840/60000][Iteration 3607][Wall Clock 169.982408282s] Trained 120 records in 0.041298706 seconds. Throughput is 2905.6602 records/second. Loss is 0.28391275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005809900069718801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 12960/60000][Iteration 3608][Wall Clock 170.023962357s] Trained 120 records in 0.041554075 seconds. Throughput is 2887.8035 records/second. Loss is 0.38184604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005809225049378413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13080/60000][Iteration 3609][Wall Clock 170.064366142s] Trained 120 records in 0.040403785 seconds. Throughput is 2970.0188 records/second. Loss is 0.1920244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058085501858736064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13200/60000][Iteration 3610][Wall Clock 170.104211051s] Trained 120 records in 0.039844909 seconds. Throughput is 3011.6772 records/second. Loss is 0.17623264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005807875479149727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13320/60000][Iteration 3611][Wall Clock 170.155763895s] Trained 120 records in 0.051552844 seconds. Throughput is 2327.7087 records/second. Loss is 0.19799614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005807200929152149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13440/60000][Iteration 3612][Wall Clock 170.198324743s] Trained 120 records in 0.042560848 seconds. Throughput is 2819.4927 records/second. Loss is 0.34238335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005806526535826269. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13560/60000][Iteration 3613][Wall Clock 170.250896449s] Trained 120 records in 0.052571706 seconds. Throughput is 2282.5967 records/second. Loss is 0.31064567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058058522991175105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13680/60000][Iteration 3614][Wall Clock 170.294434663s] Trained 120 records in 0.043538214 seconds. Throughput is 2756.1995 records/second. Loss is 0.18525887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005805178218971323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13800/60000][Iteration 3615][Wall Clock 170.334570786s] Trained 120 records in 0.040136123 seconds. Throughput is 2989.8254 records/second. Loss is 0.40462285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005804504295333179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 13920/60000][Iteration 3616][Wall Clock 170.375766739s] Trained 120 records in 0.041195953 seconds. Throughput is 2912.9077 records/second. Loss is 0.2438745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005803830528148578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 14040/60000][Iteration 3617][Wall Clock 170.415428025s] Trained 120 records in 0.039661286 seconds. Throughput is 3025.6206 records/second. Loss is 0.2618245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005803156917363045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 14160/60000][Iteration 3618][Wall Clock 170.457354374s] Trained 120 records in 0.041926349 seconds. Throughput is 2862.1619 records/second. Loss is 0.32651266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005802483462922131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 14280/60000][Iteration 3619][Wall Clock 170.497941239s] Trained 120 records in 0.040586865 seconds. Throughput is 2956.6213 records/second. Loss is 0.22614312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0058018101647714084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 14400/60000][Iteration 3620][Wall Clock 170.538990415s] Trained 120 records in 0.041049176 seconds. Throughput is 2923.323 records/second. Loss is 0.2645853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00580113702285648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:56 INFO  DistriOptimizer$:406 - [Epoch 8 14520/60000][Iteration 3621][Wall Clock 170.579131438s] Trained 120 records in 0.040141023 seconds. Throughput is 2989.4604 records/second. Loss is 0.19006382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00580046403712297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 14640/60000][Iteration 3622][Wall Clock 170.619149327s] Trained 120 records in 0.040017889 seconds. Throughput is 2998.659 records/second. Loss is 0.18148221. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005799791207516529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 14760/60000][Iteration 3623][Wall Clock 170.659752562s] Trained 120 records in 0.040603235 seconds. Throughput is 2955.4294 records/second. Loss is 0.24257569. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005799118533982834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 14880/60000][Iteration 3624][Wall Clock 170.700386406s] Trained 120 records in 0.040633844 seconds. Throughput is 2953.2034 records/second. Loss is 0.17873873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057984460164675865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15000/60000][Iteration 3625][Wall Clock 170.74084445s] Trained 120 records in 0.040458044 seconds. Throughput is 2966.0356 records/second. Loss is 0.21444467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005797773654916512. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15120/60000][Iteration 3626][Wall Clock 170.780913665s] Trained 120 records in 0.040069215 seconds. Throughput is 2994.8179 records/second. Loss is 0.19212086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005797101449275362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15240/60000][Iteration 3627][Wall Clock 170.821733724s] Trained 120 records in 0.040820059 seconds. Throughput is 2939.7312 records/second. Loss is 0.2521471. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005796429399489914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15360/60000][Iteration 3628][Wall Clock 170.862347744s] Trained 120 records in 0.04061402 seconds. Throughput is 2954.6448 records/second. Loss is 0.25946385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00579575750550597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15480/60000][Iteration 3629][Wall Clock 170.902197121s] Trained 120 records in 0.039849377 seconds. Throughput is 3011.3394 records/second. Loss is 0.22540049. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005795085767269356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15600/60000][Iteration 3630][Wall Clock 170.941892036s] Trained 120 records in 0.039694915 seconds. Throughput is 3023.0571 records/second. Loss is 0.4194023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005794414184725924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15720/60000][Iteration 3631][Wall Clock 170.994798677s] Trained 120 records in 0.052906641 seconds. Throughput is 2268.1462 records/second. Loss is 0.26512673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005793742757821553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15840/60000][Iteration 3632][Wall Clock 171.039136351s] Trained 120 records in 0.044337674 seconds. Throughput is 2706.502 records/second. Loss is 0.1854951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005793071486502144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 15960/60000][Iteration 3633][Wall Clock 171.080855404s] Trained 120 records in 0.041719053 seconds. Throughput is 2876.3835 records/second. Loss is 0.19905685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005792400370713624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16080/60000][Iteration 3634][Wall Clock 171.124133101s] Trained 120 records in 0.043277697 seconds. Throughput is 2772.7908 records/second. Loss is 0.30699673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005791729410401947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16200/60000][Iteration 3635][Wall Clock 171.165772555s] Trained 120 records in 0.041639454 seconds. Throughput is 2881.882 records/second. Loss is 0.2841301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005791058605513088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16320/60000][Iteration 3636][Wall Clock 171.213272794s] Trained 120 records in 0.047500239 seconds. Throughput is 2526.3032 records/second. Loss is 0.23507832. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005790387955993052. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16440/60000][Iteration 3637][Wall Clock 171.256604741s] Trained 120 records in 0.043331947 seconds. Throughput is 2769.3193 records/second. Loss is 0.30063927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005789717461787865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16560/60000][Iteration 3638][Wall Clock 171.298198361s] Trained 120 records in 0.04159362 seconds. Throughput is 2885.0579 records/second. Loss is 0.26212835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00578904712284358. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16680/60000][Iteration 3639][Wall Clock 171.348175546s] Trained 120 records in 0.049977185 seconds. Throughput is 2401.0957 records/second. Loss is 0.2788104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005788376939106275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16800/60000][Iteration 3640][Wall Clock 171.392765215s] Trained 120 records in 0.044589669 seconds. Throughput is 2691.2063 records/second. Loss is 0.29660785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005787706910522051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 16920/60000][Iteration 3641][Wall Clock 171.433992161s] Trained 120 records in 0.041226946 seconds. Throughput is 2910.7178 records/second. Loss is 0.20228992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005787037037037038. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 17040/60000][Iteration 3642][Wall Clock 171.474563151s] Trained 120 records in 0.04057099 seconds. Throughput is 2957.7786 records/second. Loss is 0.26020905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005786367318597384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 17160/60000][Iteration 3643][Wall Clock 171.515025254s] Trained 120 records in 0.040462103 seconds. Throughput is 2965.738 records/second. Loss is 0.14937827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005785697755149271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:57 INFO  DistriOptimizer$:406 - [Epoch 8 17280/60000][Iteration 3644][Wall Clock 171.5551618s] Trained 120 records in 0.040136546 seconds. Throughput is 2989.794 records/second. Loss is 0.26451686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005785028346638898. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 17400/60000][Iteration 3645][Wall Clock 171.595551856s] Trained 120 records in 0.040390056 seconds. Throughput is 2971.0283 records/second. Loss is 0.192499. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005784359093012494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 17520/60000][Iteration 3646][Wall Clock 171.635588078s] Trained 120 records in 0.040036222 seconds. Throughput is 2997.2856 records/second. Loss is 0.23959602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00578368999421631. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 17640/60000][Iteration 3647][Wall Clock 171.675915917s] Trained 120 records in 0.040327839 seconds. Throughput is 2975.6118 records/second. Loss is 0.23347467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005783021050196622. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 17760/60000][Iteration 3648][Wall Clock 171.716006346s] Trained 120 records in 0.040090429 seconds. Throughput is 2993.233 records/second. Loss is 0.25852534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005782352260899734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 17880/60000][Iteration 3649][Wall Clock 171.757057124s] Trained 120 records in 0.041050778 seconds. Throughput is 2923.209 records/second. Loss is 0.30050603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00578168362627197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18000/60000][Iteration 3650][Wall Clock 171.798522762s] Trained 120 records in 0.041465638 seconds. Throughput is 2893.9626 records/second. Loss is 0.22139253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005781015146259684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18120/60000][Iteration 3651][Wall Clock 171.8400271s] Trained 120 records in 0.041504338 seconds. Throughput is 2891.264 records/second. Loss is 0.3260719. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005780346820809249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18240/60000][Iteration 3652][Wall Clock 171.881033005s] Trained 120 records in 0.041005905 seconds. Throughput is 2926.4077 records/second. Loss is 0.26665607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005779678649867068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18360/60000][Iteration 3653][Wall Clock 171.922400392s] Trained 120 records in 0.041367387 seconds. Throughput is 2900.836 records/second. Loss is 0.23931941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005779010633379566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18480/60000][Iteration 3654][Wall Clock 171.963105103s] Trained 120 records in 0.040704711 seconds. Throughput is 2948.0615 records/second. Loss is 0.26858386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005778342771293194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18600/60000][Iteration 3655][Wall Clock 172.003883298s] Trained 120 records in 0.040778195 seconds. Throughput is 2942.7493 records/second. Loss is 0.38432088. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005777675063554426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18720/60000][Iteration 3656][Wall Clock 172.044758265s] Trained 120 records in 0.040874967 seconds. Throughput is 2935.7822 records/second. Loss is 0.22555895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005777007510109763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18840/60000][Iteration 3657][Wall Clock 172.093325856s] Trained 120 records in 0.048567591 seconds. Throughput is 2470.7834 records/second. Loss is 0.1863258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00577634011090573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 18960/60000][Iteration 3658][Wall Clock 172.148216289s] Trained 120 records in 0.054890433 seconds. Throughput is 2186.1733 records/second. Loss is 0.22952668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005775672865888876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19080/60000][Iteration 3659][Wall Clock 172.192392614s] Trained 120 records in 0.044176325 seconds. Throughput is 2716.3872 records/second. Loss is 0.24235092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005775005775005775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19200/60000][Iteration 3660][Wall Clock 172.233788774s] Trained 120 records in 0.04139616 seconds. Throughput is 2898.8196 records/second. Loss is 0.37822026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005774338838203026. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19320/60000][Iteration 3661][Wall Clock 172.276719926s] Trained 120 records in 0.042931152 seconds. Throughput is 2795.173 records/second. Loss is 0.23786227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005773672055427252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19440/60000][Iteration 3662][Wall Clock 172.31944929s] Trained 120 records in 0.042729364 seconds. Throughput is 2808.3733 records/second. Loss is 0.1955689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057730054266251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19560/60000][Iteration 3663][Wall Clock 172.360983763s] Trained 120 records in 0.041534473 seconds. Throughput is 2889.1663 records/second. Loss is 0.25728494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005772338951743246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19680/60000][Iteration 3664][Wall Clock 172.402392753s] Trained 120 records in 0.04140899 seconds. Throughput is 2897.9214 records/second. Loss is 0.1546486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005771672630728385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19800/60000][Iteration 3665][Wall Clock 172.443772795s] Trained 120 records in 0.041380042 seconds. Throughput is 2899.9487 records/second. Loss is 0.20763749. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005771006463527239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 19920/60000][Iteration 3666][Wall Clock 172.494539471s] Trained 120 records in 0.050766676 seconds. Throughput is 2363.7554 records/second. Loss is 0.12852532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057703404500865545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 20040/60000][Iteration 3667][Wall Clock 172.535394823s] Trained 120 records in 0.040855352 seconds. Throughput is 2937.1917 records/second. Loss is 0.26489332. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005769674590353104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:58 INFO  DistriOptimizer$:406 - [Epoch 8 20160/60000][Iteration 3668][Wall Clock 172.577906956s] Trained 120 records in 0.042512133 seconds. Throughput is 2822.7236 records/second. Loss is 0.2521224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005769008884273682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 20280/60000][Iteration 3669][Wall Clock 172.619851943s] Trained 120 records in 0.041944987 seconds. Throughput is 2860.8901 records/second. Loss is 0.22898279. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005768343331795108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 20400/60000][Iteration 3670][Wall Clock 172.660488974s] Trained 120 records in 0.040637031 seconds. Throughput is 2952.9717 records/second. Loss is 0.21755539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005767677932864229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 20520/60000][Iteration 3671][Wall Clock 172.701547659s] Trained 120 records in 0.041058685 seconds. Throughput is 2922.646 records/second. Loss is 0.25160205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057670126874279125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 20640/60000][Iteration 3672][Wall Clock 172.742414824s] Trained 120 records in 0.040867165 seconds. Throughput is 2936.3428 records/second. Loss is 0.3212415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005766347595433053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 20760/60000][Iteration 3673][Wall Clock 172.782855234s] Trained 120 records in 0.04044041 seconds. Throughput is 2967.3289 records/second. Loss is 0.43361324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005765682656826568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 20880/60000][Iteration 3674][Wall Clock 172.823868048s] Trained 120 records in 0.041012814 seconds. Throughput is 2925.915 records/second. Loss is 0.2207223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005765017871555402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21000/60000][Iteration 3675][Wall Clock 172.866857902s] Trained 120 records in 0.042989854 seconds. Throughput is 2791.3562 records/second. Loss is 0.23615538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005764353239566521. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21120/60000][Iteration 3676][Wall Clock 172.907861847s] Trained 120 records in 0.041003945 seconds. Throughput is 2926.5476 records/second. Loss is 0.30800363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005763688760806917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21240/60000][Iteration 3677][Wall Clock 172.94858025s] Trained 120 records in 0.040718403 seconds. Throughput is 2947.0703 records/second. Loss is 0.27643815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005763024435223605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21360/60000][Iteration 3678][Wall Clock 172.98986901s] Trained 120 records in 0.04128876 seconds. Throughput is 2906.36 records/second. Loss is 0.2754971. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005762360262763628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21480/60000][Iteration 3679][Wall Clock 173.033726696s] Trained 120 records in 0.043857686 seconds. Throughput is 2736.1226 records/second. Loss is 0.26768458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005761696243374049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21600/60000][Iteration 3680][Wall Clock 173.074488862s] Trained 120 records in 0.040762166 seconds. Throughput is 2943.9062 records/second. Loss is 0.28064364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005761032377001958. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21720/60000][Iteration 3681][Wall Clock 173.115132151s] Trained 120 records in 0.040643289 seconds. Throughput is 2952.5168 records/second. Loss is 0.2034821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00576036866359447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21840/60000][Iteration 3682][Wall Clock 173.15630667s] Trained 120 records in 0.041174519 seconds. Throughput is 2914.4238 records/second. Loss is 0.2771064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005759705103098721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 21960/60000][Iteration 3683][Wall Clock 173.197580124s] Trained 120 records in 0.041273454 seconds. Throughput is 2907.438 records/second. Loss is 0.23064585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005759041695461875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22080/60000][Iteration 3684][Wall Clock 173.245506552s] Trained 120 records in 0.047926428 seconds. Throughput is 2503.8376 records/second. Loss is 0.2850546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005758378440631118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22200/60000][Iteration 3685][Wall Clock 173.294306979s] Trained 120 records in 0.048800427 seconds. Throughput is 2458.9949 records/second. Loss is 0.27386206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005757715338553662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22320/60000][Iteration 3686][Wall Clock 173.338187658s] Trained 120 records in 0.043880679 seconds. Throughput is 2734.6887 records/second. Loss is 0.23784989. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057570523891767415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22440/60000][Iteration 3687][Wall Clock 173.387924218s] Trained 120 records in 0.04973656 seconds. Throughput is 2412.7122 records/second. Loss is 0.2430605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005756389592447617. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22560/60000][Iteration 3688][Wall Clock 173.433087506s] Trained 120 records in 0.045163288 seconds. Throughput is 2657.0254 records/second. Loss is 0.30026972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005755726948313572. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22680/60000][Iteration 3689][Wall Clock 173.475146586s] Trained 120 records in 0.04205908 seconds. Throughput is 2853.1296 records/second. Loss is 0.30486572. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005755064456721915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22800/60000][Iteration 3690][Wall Clock 173.516859537s] Trained 120 records in 0.041712951 seconds. Throughput is 2876.8044 records/second. Loss is 0.28989404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005754402117619979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:55:59 INFO  DistriOptimizer$:406 - [Epoch 8 22920/60000][Iteration 3691][Wall Clock 173.557814786s] Trained 120 records in 0.040955249 seconds. Throughput is 2930.0273 records/second. Loss is 0.22880653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005753739930955121. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23040/60000][Iteration 3692][Wall Clock 173.606200181s] Trained 120 records in 0.048385395 seconds. Throughput is 2480.0872 records/second. Loss is 0.29109532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005753077896674721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23160/60000][Iteration 3693][Wall Clock 173.650430439s] Trained 120 records in 0.044230258 seconds. Throughput is 2713.075 records/second. Loss is 0.16889666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005752416014726185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23280/60000][Iteration 3694][Wall Clock 173.691534344s] Trained 120 records in 0.041103905 seconds. Throughput is 2919.4307 records/second. Loss is 0.23506114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005751754285056943. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23400/60000][Iteration 3695][Wall Clock 173.732319809s] Trained 120 records in 0.040785465 seconds. Throughput is 2942.2246 records/second. Loss is 0.20643315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005751092707614447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23520/60000][Iteration 3696][Wall Clock 173.7728633s] Trained 120 records in 0.040543491 seconds. Throughput is 2959.7847 records/second. Loss is 0.27573574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005750431282346176. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23640/60000][Iteration 3697][Wall Clock 173.813507854s] Trained 120 records in 0.040644554 seconds. Throughput is 2952.425 records/second. Loss is 0.33037868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005749770009199632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23760/60000][Iteration 3698][Wall Clock 173.854602038s] Trained 120 records in 0.041094184 seconds. Throughput is 2920.1213 records/second. Loss is 0.2617029. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005749108888122341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 23880/60000][Iteration 3699][Wall Clock 173.895055158s] Trained 120 records in 0.04045312 seconds. Throughput is 2966.3965 records/second. Loss is 0.19979382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005748447919061853. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24000/60000][Iteration 3700][Wall Clock 173.937945018s] Trained 120 records in 0.04288986 seconds. Throughput is 2797.8643 records/second. Loss is 0.35432068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005747787101965743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24120/60000][Iteration 3701][Wall Clock 173.981631524s] Trained 120 records in 0.043686506 seconds. Throughput is 2746.8438 records/second. Loss is 0.24553686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005747126436781609. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24240/60000][Iteration 3702][Wall Clock 174.02200767s] Trained 120 records in 0.040376146 seconds. Throughput is 2972.052 records/second. Loss is 0.2662556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005746465923457073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24360/60000][Iteration 3703][Wall Clock 174.063047217s] Trained 120 records in 0.041039547 seconds. Throughput is 2924.0088 records/second. Loss is 0.29468712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005745805561939783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24480/60000][Iteration 3704][Wall Clock 174.103604835s] Trained 120 records in 0.040557618 seconds. Throughput is 2958.7537 records/second. Loss is 0.2621888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00574514535217741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24600/60000][Iteration 3705][Wall Clock 174.14455387s] Trained 120 records in 0.040949035 seconds. Throughput is 2930.472 records/second. Loss is 0.19687349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005744485294117647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24720/60000][Iteration 3706][Wall Clock 174.185472371s] Trained 120 records in 0.040918501 seconds. Throughput is 2932.659 records/second. Loss is 0.47335377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005743825387708214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24840/60000][Iteration 3707][Wall Clock 174.22585426s] Trained 120 records in 0.040381889 seconds. Throughput is 2971.6292 records/second. Loss is 0.28774625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005743165632896853. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 24960/60000][Iteration 3708][Wall Clock 174.266724932s] Trained 120 records in 0.040870672 seconds. Throughput is 2936.0908 records/second. Loss is 0.28072664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005742506029631331. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 25080/60000][Iteration 3709][Wall Clock 174.307550237s] Trained 120 records in 0.040825305 seconds. Throughput is 2939.3535 records/second. Loss is 0.35423496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005741846577859439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 25200/60000][Iteration 3710][Wall Clock 174.351817935s] Trained 120 records in 0.044267698 seconds. Throughput is 2710.78 records/second. Loss is 0.2392986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005741187277528993. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 25320/60000][Iteration 3711][Wall Clock 174.409120193s] Trained 120 records in 0.057302258 seconds. Throughput is 2094.1582 records/second. Loss is 0.25130317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057405281285878304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 25440/60000][Iteration 3712][Wall Clock 174.455490728s] Trained 120 records in 0.046370535 seconds. Throughput is 2587.85 records/second. Loss is 0.29284564. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005739869130983814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 25560/60000][Iteration 3713][Wall Clock 174.49672507s] Trained 120 records in 0.041234342 seconds. Throughput is 2910.1958 records/second. Loss is 0.28349647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005739210284664831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:00 INFO  DistriOptimizer$:406 - [Epoch 8 25680/60000][Iteration 3714][Wall Clock 174.537804473s] Trained 120 records in 0.041079403 seconds. Throughput is 2921.172 records/second. Loss is 0.36343357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005738551589578791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 25800/60000][Iteration 3715][Wall Clock 174.578527884s] Trained 120 records in 0.040723411 seconds. Throughput is 2946.708 records/second. Loss is 0.21292542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005737893045673629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 25920/60000][Iteration 3716][Wall Clock 174.619369419s] Trained 120 records in 0.040841535 seconds. Throughput is 2938.1853 records/second. Loss is 0.21335264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005737234652897304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26040/60000][Iteration 3717][Wall Clock 174.660502651s] Trained 120 records in 0.041133232 seconds. Throughput is 2917.349 records/second. Loss is 0.2361078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005736576411197797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26160/60000][Iteration 3718][Wall Clock 174.701953203s] Trained 120 records in 0.041450552 seconds. Throughput is 2895.0156 records/second. Loss is 0.4017185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057359183205231154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26280/60000][Iteration 3719][Wall Clock 174.75026076s] Trained 120 records in 0.048307557 seconds. Throughput is 2484.0835 records/second. Loss is 0.22834463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005735260380821289. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26400/60000][Iteration 3720][Wall Clock 174.793325587s] Trained 120 records in 0.043064827 seconds. Throughput is 2786.4968 records/second. Loss is 0.26758346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005734602592040372. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26520/60000][Iteration 3721][Wall Clock 174.834822466s] Trained 120 records in 0.041496879 seconds. Throughput is 2891.7837 records/second. Loss is 0.30322462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005733944954128441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26640/60000][Iteration 3722][Wall Clock 174.879490941s] Trained 120 records in 0.044668475 seconds. Throughput is 2686.4585 records/second. Loss is 0.25084272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005733287467033597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26760/60000][Iteration 3723][Wall Clock 174.920474022s] Trained 120 records in 0.040983081 seconds. Throughput is 2928.0376 records/second. Loss is 0.17164211. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005732630130703967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 26880/60000][Iteration 3724][Wall Clock 174.961385173s] Trained 120 records in 0.040911151 seconds. Throughput is 2933.1858 records/second. Loss is 0.3004373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005731972945087699. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27000/60000][Iteration 3725][Wall Clock 175.00239628s] Trained 120 records in 0.041011107 seconds. Throughput is 2926.0366 records/second. Loss is 0.29475218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005731315910132966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27120/60000][Iteration 3726][Wall Clock 175.04326752s] Trained 120 records in 0.04087124 seconds. Throughput is 2936.0498 records/second. Loss is 0.3223663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057306590257879654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27240/60000][Iteration 3727][Wall Clock 175.0851618s] Trained 120 records in 0.04189428 seconds. Throughput is 2864.3528 records/second. Loss is 0.2744779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005730002292000917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27360/60000][Iteration 3728][Wall Clock 175.126219063s] Trained 120 records in 0.041057263 seconds. Throughput is 2922.7473 records/second. Loss is 0.33942398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005729345708720064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27480/60000][Iteration 3729][Wall Clock 175.166743638s] Trained 120 records in 0.040524575 seconds. Throughput is 2961.166 records/second. Loss is 0.27282587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057286892758936754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27600/60000][Iteration 3730][Wall Clock 175.206987392s] Trained 120 records in 0.040243754 seconds. Throughput is 2981.8293 records/second. Loss is 0.23645696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005728032993470042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27720/60000][Iteration 3731][Wall Clock 175.247130064s] Trained 120 records in 0.040142672 seconds. Throughput is 2989.3376 records/second. Loss is 0.19916907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00572737686139748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27840/60000][Iteration 3732][Wall Clock 175.287705823s] Trained 120 records in 0.040575759 seconds. Throughput is 2957.431 records/second. Loss is 0.21244708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005726720879624328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 27960/60000][Iteration 3733][Wall Clock 175.328329919s] Trained 120 records in 0.040624096 seconds. Throughput is 2953.9119 records/second. Loss is 0.18462631. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057260650480989465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 28080/60000][Iteration 3734][Wall Clock 175.368340534s] Trained 120 records in 0.040010615 seconds. Throughput is 2999.204 records/second. Loss is 0.24204172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005725409366769725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 28200/60000][Iteration 3735][Wall Clock 175.409667477s] Trained 120 records in 0.041326943 seconds. Throughput is 2903.6746 records/second. Loss is 0.26952362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00572475383558507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 28320/60000][Iteration 3736][Wall Clock 175.456642198s] Trained 120 records in 0.046974721 seconds. Throughput is 2554.5654 records/second. Loss is 0.3249938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005724098454493418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 28440/60000][Iteration 3737][Wall Clock 175.505814158s] Trained 120 records in 0.04917196 seconds. Throughput is 2440.415 records/second. Loss is 0.31515065. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005723443223443223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:01 INFO  DistriOptimizer$:406 - [Epoch 8 28560/60000][Iteration 3738][Wall Clock 175.548410633s] Trained 120 records in 0.042596475 seconds. Throughput is 2817.1345 records/second. Loss is 0.23865582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005722788142382969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 28680/60000][Iteration 3739][Wall Clock 175.590405s] Trained 120 records in 0.041994367 seconds. Throughput is 2857.5261 records/second. Loss is 0.22460587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005722133211261158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 28800/60000][Iteration 3740][Wall Clock 175.631874057s] Trained 120 records in 0.041469057 seconds. Throughput is 2893.7239 records/second. Loss is 0.27997786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005721478430026319. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 28920/60000][Iteration 3741][Wall Clock 175.672687024s] Trained 120 records in 0.040812967 seconds. Throughput is 2940.2422 records/second. Loss is 0.27467144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005720823798627002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29040/60000][Iteration 3742][Wall Clock 175.713377759s] Trained 120 records in 0.040690735 seconds. Throughput is 2949.0742 records/second. Loss is 0.33428776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005720169317011783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29160/60000][Iteration 3743][Wall Clock 175.757896351s] Trained 120 records in 0.044518592 seconds. Throughput is 2695.503 records/second. Loss is 0.25660092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057195149851292605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29280/60000][Iteration 3744][Wall Clock 175.798499025s] Trained 120 records in 0.040602674 seconds. Throughput is 2955.4705 records/second. Loss is 0.23307952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005718860802928057. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29400/60000][Iteration 3745][Wall Clock 175.839273896s] Trained 120 records in 0.040774871 seconds. Throughput is 2942.989 records/second. Loss is 0.24033064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005718206770356816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29520/60000][Iteration 3746][Wall Clock 175.890632048s] Trained 120 records in 0.051358152 seconds. Throughput is 2336.5327 records/second. Loss is 0.26705334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005717552887364208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29640/60000][Iteration 3747][Wall Clock 175.9316766s] Trained 120 records in 0.041044552 seconds. Throughput is 2923.6523 records/second. Loss is 0.26846248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005716899153898925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29760/60000][Iteration 3748][Wall Clock 175.972627068s] Trained 120 records in 0.040950468 seconds. Throughput is 2930.3694 records/second. Loss is 0.20783712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005716245569909683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 29880/60000][Iteration 3749][Wall Clock 176.013663602s] Trained 120 records in 0.041036534 seconds. Throughput is 2924.2234 records/second. Loss is 0.33228505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005715592135345221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30000/60000][Iteration 3750][Wall Clock 176.05524076s] Trained 120 records in 0.041577158 seconds. Throughput is 2886.2002 records/second. Loss is 0.21169147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005714938850154303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30120/60000][Iteration 3751][Wall Clock 176.096637113s] Trained 120 records in 0.041396353 seconds. Throughput is 2898.8062 records/second. Loss is 0.19724229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005714285714285714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30240/60000][Iteration 3752][Wall Clock 176.137517055s] Trained 120 records in 0.040879942 seconds. Throughput is 2935.4248 records/second. Loss is 0.317928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005713632727688264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30360/60000][Iteration 3753][Wall Clock 176.17863094s] Trained 120 records in 0.041113885 seconds. Throughput is 2918.7222 records/second. Loss is 0.22577256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005712979890310786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30480/60000][Iteration 3754][Wall Clock 176.21907508s] Trained 120 records in 0.04044414 seconds. Throughput is 2967.0554 records/second. Loss is 0.23910522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005712327202102137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30600/60000][Iteration 3755][Wall Clock 176.260155716s] Trained 120 records in 0.041080636 seconds. Throughput is 2921.0842 records/second. Loss is 0.2995476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005711674663011195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30720/60000][Iteration 3756][Wall Clock 176.300959744s] Trained 120 records in 0.040804028 seconds. Throughput is 2940.886 records/second. Loss is 0.3006902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005711022272986865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30840/60000][Iteration 3757][Wall Clock 176.342654694s] Trained 120 records in 0.04169495 seconds. Throughput is 2878.0464 records/second. Loss is 0.23324461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005710370031978072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 30960/60000][Iteration 3758][Wall Clock 176.385379801s] Trained 120 records in 0.042725107 seconds. Throughput is 2808.6528 records/second. Loss is 0.3067972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057097179399337675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 31080/60000][Iteration 3759][Wall Clock 176.426945522s] Trained 120 records in 0.041565721 seconds. Throughput is 2886.9944 records/second. Loss is 0.31663096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005709065996802923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 31200/60000][Iteration 3760][Wall Clock 176.468339105s] Trained 120 records in 0.041393583 seconds. Throughput is 2899.0002 records/second. Loss is 0.31635123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005708414202534536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:02 INFO  DistriOptimizer$:406 - [Epoch 8 31320/60000][Iteration 3761][Wall Clock 176.520122042s] Trained 120 records in 0.051782937 seconds. Throughput is 2317.3657 records/second. Loss is 0.18289547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005707762557077625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 31440/60000][Iteration 3762][Wall Clock 176.568046543s] Trained 120 records in 0.047924501 seconds. Throughput is 2503.9385 records/second. Loss is 0.31083304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005707111060381235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 31560/60000][Iteration 3763][Wall Clock 176.613339568s] Trained 120 records in 0.045293025 seconds. Throughput is 2649.4146 records/second. Loss is 0.19823582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057064597123944304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 31680/60000][Iteration 3764][Wall Clock 176.65463922s] Trained 120 records in 0.041299652 seconds. Throughput is 2905.5935 records/second. Loss is 0.18321733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005705808513066301. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 31800/60000][Iteration 3765][Wall Clock 176.696043012s] Trained 120 records in 0.041403792 seconds. Throughput is 2898.2852 records/second. Loss is 0.17374597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005705157462345961. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 31920/60000][Iteration 3766][Wall Clock 176.737203998s] Trained 120 records in 0.041160986 seconds. Throughput is 2915.382 records/second. Loss is 0.26288012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005704506560182544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32040/60000][Iteration 3767][Wall Clock 176.778402151s] Trained 120 records in 0.041198153 seconds. Throughput is 2912.752 records/second. Loss is 0.31308806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005703855806525211. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32160/60000][Iteration 3768][Wall Clock 176.818804277s] Trained 120 records in 0.040402126 seconds. Throughput is 2970.1409 records/second. Loss is 0.2225355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005703205201323143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32280/60000][Iteration 3769][Wall Clock 176.859778451s] Trained 120 records in 0.040974174 seconds. Throughput is 2928.674 records/second. Loss is 0.2632744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005702554744525547. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32400/60000][Iteration 3770][Wall Clock 176.900870343s] Trained 120 records in 0.041091892 seconds. Throughput is 2920.2842 records/second. Loss is 0.21120706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0057019044360816515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32520/60000][Iteration 3771][Wall Clock 176.941350253s] Trained 120 records in 0.04047991 seconds. Throughput is 2964.4336 records/second. Loss is 0.30083266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005701254275940707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32640/60000][Iteration 3772][Wall Clock 176.989292522s] Trained 120 records in 0.047942269 seconds. Throughput is 2503.0105 records/second. Loss is 0.29891247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00570060426405199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32760/60000][Iteration 3773][Wall Clock 177.035717884s] Trained 120 records in 0.046425362 seconds. Throughput is 2584.7942 records/second. Loss is 0.35106885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005699954400364797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 32880/60000][Iteration 3774][Wall Clock 177.077785523s] Trained 120 records in 0.042067639 seconds. Throughput is 2852.5488 records/second. Loss is 0.25305012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005699304684828451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33000/60000][Iteration 3775][Wall Clock 177.119120123s] Trained 120 records in 0.0413346 seconds. Throughput is 2903.137 records/second. Loss is 0.27876112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005698655117392296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33120/60000][Iteration 3776][Wall Clock 177.160427759s] Trained 120 records in 0.041307636 seconds. Throughput is 2905.032 records/second. Loss is 0.25178805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005698005698005698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33240/60000][Iteration 3777][Wall Clock 177.201390426s] Trained 120 records in 0.040962667 seconds. Throughput is 2929.4968 records/second. Loss is 0.262865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00569735642661805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33360/60000][Iteration 3778][Wall Clock 177.241942155s] Trained 120 records in 0.040551729 seconds. Throughput is 2959.1833 records/second. Loss is 0.33307654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005696707303178763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33480/60000][Iteration 3779][Wall Clock 177.282019607s] Trained 120 records in 0.040077452 seconds. Throughput is 2994.2024 records/second. Loss is 0.25862205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005696058327637275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33600/60000][Iteration 3780][Wall Clock 177.322929631s] Trained 120 records in 0.040910024 seconds. Throughput is 2933.2664 records/second. Loss is 0.29224163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056954094999430455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33720/60000][Iteration 3781][Wall Clock 177.363953133s] Trained 120 records in 0.041023502 seconds. Throughput is 2925.1526 records/second. Loss is 0.2219051. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056947608200455585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33840/60000][Iteration 3782][Wall Clock 177.404450868s] Trained 120 records in 0.040497735 seconds. Throughput is 2963.1287 records/second. Loss is 0.3412797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005694112287894317. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 33960/60000][Iteration 3783][Wall Clock 177.444461239s] Trained 120 records in 0.040010371 seconds. Throughput is 2999.2224 records/second. Loss is 0.1580119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005693463903438852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 34080/60000][Iteration 3784][Wall Clock 177.48797544s] Trained 120 records in 0.043514201 seconds. Throughput is 2757.7205 records/second. Loss is 0.2952512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005692815666628714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:03 INFO  DistriOptimizer$:406 - [Epoch 8 34200/60000][Iteration 3785][Wall Clock 177.528349309s] Trained 120 records in 0.040373869 seconds. Throughput is 2972.2195 records/second. Loss is 0.19208498. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005692167577413479. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 34320/60000][Iteration 3786][Wall Clock 177.57102729s] Trained 120 records in 0.042677981 seconds. Throughput is 2811.7544 records/second. Loss is 0.22880273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005691519635742743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 34440/60000][Iteration 3787][Wall Clock 177.633535217s] Trained 120 records in 0.062507927 seconds. Throughput is 1919.7565 records/second. Loss is 0.21170063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005690871841566128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 34560/60000][Iteration 3788][Wall Clock 177.675153182s] Trained 120 records in 0.041617965 seconds. Throughput is 2883.3704 records/second. Loss is 0.2308979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005690224194833276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 34680/60000][Iteration 3789][Wall Clock 177.715753921s] Trained 120 records in 0.040600739 seconds. Throughput is 2955.611 records/second. Loss is 0.36989608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005689576695493855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 34800/60000][Iteration 3790][Wall Clock 177.756303749s] Trained 120 records in 0.040549828 seconds. Throughput is 2959.322 records/second. Loss is 0.26543683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005688929343497554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 34920/60000][Iteration 3791][Wall Clock 177.796600957s] Trained 120 records in 0.040297208 seconds. Throughput is 2977.874 records/second. Loss is 0.19161375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005688282138794084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35040/60000][Iteration 3792][Wall Clock 177.837747428s] Trained 120 records in 0.041146471 seconds. Throughput is 2916.4104 records/second. Loss is 0.24106437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005687635081333181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35160/60000][Iteration 3793][Wall Clock 177.878744292s] Trained 120 records in 0.040996864 seconds. Throughput is 2927.0532 records/second. Loss is 0.24645567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005686988171064605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35280/60000][Iteration 3794][Wall Clock 177.919215594s] Trained 120 records in 0.040471302 seconds. Throughput is 2965.0642 records/second. Loss is 0.19695024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005686341407938133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35400/60000][Iteration 3795][Wall Clock 177.959796591s] Trained 120 records in 0.040580997 seconds. Throughput is 2957.0493 records/second. Loss is 0.1397409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005685694791903571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35520/60000][Iteration 3796][Wall Clock 178.000457051s] Trained 120 records in 0.04066046 seconds. Throughput is 2951.27 records/second. Loss is 0.27067918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005685048322910745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35640/60000][Iteration 3797][Wall Clock 178.041658978s] Trained 120 records in 0.041201927 seconds. Throughput is 2912.485 records/second. Loss is 0.27291408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005684402000909505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35760/60000][Iteration 3798][Wall Clock 178.083533009s] Trained 120 records in 0.041874031 seconds. Throughput is 2865.7378 records/second. Loss is 0.16278924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056837558258497215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 35880/60000][Iteration 3799][Wall Clock 178.136589726s] Trained 120 records in 0.053056717 seconds. Throughput is 2261.7307 records/second. Loss is 0.2897531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005683109797681291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36000/60000][Iteration 3800][Wall Clock 178.182074006s] Trained 120 records in 0.04548428 seconds. Throughput is 2638.2742 records/second. Loss is 0.22616862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005682463916354131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36120/60000][Iteration 3801][Wall Clock 178.223071432s] Trained 120 records in 0.040997426 seconds. Throughput is 2927.013 records/second. Loss is 0.36918107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005681818181818182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36240/60000][Iteration 3802][Wall Clock 178.263979074s] Trained 120 records in 0.040907642 seconds. Throughput is 2933.437 records/second. Loss is 0.25152275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005681172594023407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36360/60000][Iteration 3803][Wall Clock 178.304581826s] Trained 120 records in 0.040602752 seconds. Throughput is 2955.4648 records/second. Loss is 0.4155277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005680527152919791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36480/60000][Iteration 3804][Wall Clock 178.345280967s] Trained 120 records in 0.040699141 seconds. Throughput is 2948.4653 records/second. Loss is 0.17268588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005679881858457344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36600/60000][Iteration 3805][Wall Clock 178.389847968s] Trained 120 records in 0.044567001 seconds. Throughput is 2692.5752 records/second. Loss is 0.23752867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005679236710586097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36720/60000][Iteration 3806][Wall Clock 178.430129729s] Trained 120 records in 0.040281761 seconds. Throughput is 2979.0156 records/second. Loss is 0.19429111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056785917092561046. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36840/60000][Iteration 3807][Wall Clock 178.470347947s] Trained 120 records in 0.040218218 seconds. Throughput is 2983.7224 records/second. Loss is 0.23621108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005677946854417443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 36960/60000][Iteration 3808][Wall Clock 178.510091562s] Trained 120 records in 0.039743615 seconds. Throughput is 3019.353 records/second. Loss is 0.19359538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005677302146020211. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:04 INFO  DistriOptimizer$:406 - [Epoch 8 37080/60000][Iteration 3809][Wall Clock 178.550583073s] Trained 120 records in 0.040491511 seconds. Throughput is 2963.5842 records/second. Loss is 0.1874066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005676657584014532. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 37200/60000][Iteration 3810][Wall Clock 178.593561859s] Trained 120 records in 0.042978786 seconds. Throughput is 2792.0752 records/second. Loss is 0.33423766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00567601316835055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 37320/60000][Iteration 3811][Wall Clock 178.64488217s] Trained 120 records in 0.051320311 seconds. Throughput is 2338.2556 records/second. Loss is 0.21568112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056753688989784334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 37440/60000][Iteration 3812][Wall Clock 178.694920773s] Trained 120 records in 0.050038603 seconds. Throughput is 2398.1484 records/second. Loss is 0.2476705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005674724775848372. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 37560/60000][Iteration 3813][Wall Clock 178.741271159s] Trained 120 records in 0.046350386 seconds. Throughput is 2588.975 records/second. Loss is 0.2212093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005674080798910576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 37680/60000][Iteration 3814][Wall Clock 178.784350563s] Trained 120 records in 0.043079404 seconds. Throughput is 2785.554 records/second. Loss is 0.29159096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005673436968115285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 37800/60000][Iteration 3815][Wall Clock 178.828178468s] Trained 120 records in 0.043827905 seconds. Throughput is 2737.9817 records/second. Loss is 0.2685696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005672793283412753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 37920/60000][Iteration 3816][Wall Clock 178.871952389s] Trained 120 records in 0.043773921 seconds. Throughput is 2741.3584 records/second. Loss is 0.31708273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005672149744753262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38040/60000][Iteration 3817][Wall Clock 178.913020099s] Trained 120 records in 0.04106771 seconds. Throughput is 2922.004 records/second. Loss is 0.22610638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056715063520871144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38160/60000][Iteration 3818][Wall Clock 178.954060124s] Trained 120 records in 0.041040025 seconds. Throughput is 2923.9749 records/second. Loss is 0.27085176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005670863105364636. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38280/60000][Iteration 3819][Wall Clock 178.99522701s] Trained 120 records in 0.041166886 seconds. Throughput is 2914.964 records/second. Loss is 0.30595458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005670220004536176. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38400/60000][Iteration 3820][Wall Clock 179.036031427s] Trained 120 records in 0.040804417 seconds. Throughput is 2940.8582 records/second. Loss is 0.25621983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005669577049552103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38520/60000][Iteration 3821][Wall Clock 179.077234917s] Trained 120 records in 0.04120349 seconds. Throughput is 2912.3745 records/second. Loss is 0.21608815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005668934240362812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38640/60000][Iteration 3822][Wall Clock 179.118263942s] Trained 120 records in 0.041029025 seconds. Throughput is 2924.7588 records/second. Loss is 0.2733101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005668291576918717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38760/60000][Iteration 3823][Wall Clock 179.160943715s] Trained 120 records in 0.042679773 seconds. Throughput is 2811.6365 records/second. Loss is 0.2370471. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005667649059170256. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 38880/60000][Iteration 3824][Wall Clock 179.205592748s] Trained 120 records in 0.044649033 seconds. Throughput is 2687.6282 records/second. Loss is 0.22558832. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00566700668706789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 39000/60000][Iteration 3825][Wall Clock 179.253443742s] Trained 120 records in 0.047850994 seconds. Throughput is 2507.785 records/second. Loss is 0.3752117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005666364460562103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 39120/60000][Iteration 3826][Wall Clock 179.309410487s] Trained 120 records in 0.055966745 seconds. Throughput is 2144.1304 records/second. Loss is 0.37115887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005665722379603399. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 39240/60000][Iteration 3827][Wall Clock 179.363190632s] Trained 120 records in 0.053780145 seconds. Throughput is 2231.3066 records/second. Loss is 0.33872563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056650804441423066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 39360/60000][Iteration 3828][Wall Clock 179.413975432s] Trained 120 records in 0.0507848 seconds. Throughput is 2362.9116 records/second. Loss is 0.23948015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005664438654129376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 39480/60000][Iteration 3829][Wall Clock 179.454802368s] Trained 120 records in 0.040826936 seconds. Throughput is 2939.236 records/second. Loss is 0.3734684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056637970095151785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 39600/60000][Iteration 3830][Wall Clock 179.494913435s] Trained 120 records in 0.040111067 seconds. Throughput is 2991.6929 records/second. Loss is 0.23037711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005663155510250311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:05 INFO  DistriOptimizer$:406 - [Epoch 8 39720/60000][Iteration 3831][Wall Clock 179.535847759s] Trained 120 records in 0.040934324 seconds. Throughput is 2931.5251 records/second. Loss is 0.4023333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056625141562853904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 39840/60000][Iteration 3832][Wall Clock 179.576777831s] Trained 120 records in 0.040930072 seconds. Throughput is 2931.8296 records/second. Loss is 0.18105775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005661872947571056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 39960/60000][Iteration 3833][Wall Clock 179.617322005s] Trained 120 records in 0.040544174 seconds. Throughput is 2959.7346 records/second. Loss is 0.38058245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005661231884057971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40080/60000][Iteration 3834][Wall Clock 179.657608359s] Trained 120 records in 0.040286354 seconds. Throughput is 2978.676 records/second. Loss is 0.22147498. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056605909656968195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40200/60000][Iteration 3835][Wall Clock 179.698007225s] Trained 120 records in 0.040398866 seconds. Throughput is 2970.3804 records/second. Loss is 0.22877301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005659950192438307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40320/60000][Iteration 3836][Wall Clock 179.739660475s] Trained 120 records in 0.04165325 seconds. Throughput is 2880.9277 records/second. Loss is 0.34100673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005659309564233164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40440/60000][Iteration 3837][Wall Clock 179.788162778s] Trained 120 records in 0.048502303 seconds. Throughput is 2474.1094 records/second. Loss is 0.2220243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005658669081032142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40560/60000][Iteration 3838][Wall Clock 179.831740146s] Trained 120 records in 0.043577368 seconds. Throughput is 2753.723 records/second. Loss is 0.17457072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005658028742786013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40680/60000][Iteration 3839][Wall Clock 179.873149841s] Trained 120 records in 0.041409695 seconds. Throughput is 2897.8723 records/second. Loss is 0.24324393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005657388549445576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40800/60000][Iteration 3840][Wall Clock 179.913958029s] Trained 120 records in 0.040808188 seconds. Throughput is 2940.5862 records/second. Loss is 0.33031902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005656748500961648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 40920/60000][Iteration 3841][Wall Clock 179.954210699s] Trained 120 records in 0.04025267 seconds. Throughput is 2981.1687 records/second. Loss is 0.31929392. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005656108597285068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41040/60000][Iteration 3842][Wall Clock 179.995851632s] Trained 120 records in 0.041640933 seconds. Throughput is 2881.7798 records/second. Loss is 0.25028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005655468838366701. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41160/60000][Iteration 3843][Wall Clock 180.037724426s] Trained 120 records in 0.041872794 seconds. Throughput is 2865.8225 records/second. Loss is 0.23022145. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00565482922415743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41280/60000][Iteration 3844][Wall Clock 180.078046858s] Trained 120 records in 0.040322432 seconds. Throughput is 2976.011 records/second. Loss is 0.19671468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005654189754608165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41400/60000][Iteration 3845][Wall Clock 180.121516282s] Trained 120 records in 0.043469424 seconds. Throughput is 2760.561 records/second. Loss is 0.23144417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005653550429669832. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41520/60000][Iteration 3846][Wall Clock 180.161932261s] Trained 120 records in 0.040415979 seconds. Throughput is 2969.1226 records/second. Loss is 0.3135555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056529112492933855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41640/60000][Iteration 3847][Wall Clock 180.201819411s] Trained 120 records in 0.03988715 seconds. Throughput is 3008.4878 records/second. Loss is 0.17108668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005652272213429799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41760/60000][Iteration 3848][Wall Clock 180.242401654s] Trained 120 records in 0.040582243 seconds. Throughput is 2956.9583 records/second. Loss is 0.36962128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005651633322030066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 41880/60000][Iteration 3849][Wall Clock 180.282444675s] Trained 120 records in 0.040043021 seconds. Throughput is 2996.7769 records/second. Loss is 0.2526224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005650994575045208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 42000/60000][Iteration 3850][Wall Clock 180.322781302s] Trained 120 records in 0.040336627 seconds. Throughput is 2974.9636 records/second. Loss is 0.18152852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005650355972426263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 42120/60000][Iteration 3851][Wall Clock 180.362843356s] Trained 120 records in 0.040062054 seconds. Throughput is 2995.353 records/second. Loss is 0.27184492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005649717514124294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 42240/60000][Iteration 3852][Wall Clock 180.404348556s] Trained 120 records in 0.0415052 seconds. Throughput is 2891.204 records/second. Loss is 0.37228912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005649079200090386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 42360/60000][Iteration 3853][Wall Clock 180.45637845s] Trained 120 records in 0.052029894 seconds. Throughput is 2306.3665 records/second. Loss is 0.18413536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056484410302756445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 42480/60000][Iteration 3854][Wall Clock 180.49871172s] Trained 120 records in 0.04233327 seconds. Throughput is 2834.65 records/second. Loss is 0.17432028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005647803004631199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:06 INFO  DistriOptimizer$:406 - [Epoch 8 42600/60000][Iteration 3855][Wall Clock 180.539079789s] Trained 120 records in 0.040368069 seconds. Throughput is 2972.6465 records/second. Loss is 0.26482326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056471651231082. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 42720/60000][Iteration 3856][Wall Clock 180.579452843s] Trained 120 records in 0.040373054 seconds. Throughput is 2972.2795 records/second. Loss is 0.2058191. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005646527385657821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 42840/60000][Iteration 3857][Wall Clock 180.619551441s] Trained 120 records in 0.040098598 seconds. Throughput is 2992.6235 records/second. Loss is 0.23729067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005645889792231256. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 42960/60000][Iteration 3858][Wall Clock 180.660308651s] Trained 120 records in 0.04075721 seconds. Throughput is 2944.2644 records/second. Loss is 0.17475456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005645252342779722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43080/60000][Iteration 3859][Wall Clock 180.700274615s] Trained 120 records in 0.039965964 seconds. Throughput is 3002.555 records/second. Loss is 0.17039707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056446150372544595. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43200/60000][Iteration 3860][Wall Clock 180.740513037s] Trained 120 records in 0.040238422 seconds. Throughput is 2982.2244 records/second. Loss is 0.32646117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005643977875606727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43320/60000][Iteration 3861][Wall Clock 180.782495641s] Trained 120 records in 0.041982604 seconds. Throughput is 2858.327 records/second. Loss is 0.27722973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056433408577878106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43440/60000][Iteration 3862][Wall Clock 180.830220018s] Trained 120 records in 0.047724377 seconds. Throughput is 2514.4382 records/second. Loss is 0.29995394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005642703983749013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43560/60000][Iteration 3863][Wall Clock 180.874584148s] Trained 120 records in 0.04436413 seconds. Throughput is 2704.888 records/second. Loss is 0.2962897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005642067253441661. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43680/60000][Iteration 3864][Wall Clock 180.91567496s] Trained 120 records in 0.041090812 seconds. Throughput is 2920.3608 records/second. Loss is 0.19831419. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005641430666817104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43800/60000][Iteration 3865][Wall Clock 180.959856539s] Trained 120 records in 0.044181579 seconds. Throughput is 2716.0642 records/second. Loss is 0.35656604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005640794223826714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 43920/60000][Iteration 3866][Wall Clock 181.000907516s] Trained 120 records in 0.041050977 seconds. Throughput is 2923.1946 records/second. Loss is 0.2992218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056401579244218835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44040/60000][Iteration 3867][Wall Clock 181.042788712s] Trained 120 records in 0.041881196 seconds. Throughput is 2865.2476 records/second. Loss is 0.22050898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005639521768554027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44160/60000][Iteration 3868][Wall Clock 181.083951046s] Trained 120 records in 0.041162334 seconds. Throughput is 2915.2866 records/second. Loss is 0.19007938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00563888575617458. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44280/60000][Iteration 3869][Wall Clock 181.12480731s] Trained 120 records in 0.040856264 seconds. Throughput is 2937.126 records/second. Loss is 0.23002945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005638249887235002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44400/60000][Iteration 3870][Wall Clock 181.165853651s] Trained 120 records in 0.041046341 seconds. Throughput is 2923.525 records/second. Loss is 0.23940018. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005637614161686774. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44520/60000][Iteration 3871][Wall Clock 181.205981919s] Trained 120 records in 0.040128268 seconds. Throughput is 2990.4106 records/second. Loss is 0.12757029. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005636978579481398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44640/60000][Iteration 3872][Wall Clock 181.246833274s] Trained 120 records in 0.040851355 seconds. Throughput is 2937.479 records/second. Loss is 0.2255977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056363431405703985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44760/60000][Iteration 3873][Wall Clock 181.287470463s] Trained 120 records in 0.040637189 seconds. Throughput is 2952.9602 records/second. Loss is 0.23448738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00563570784490532. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 44880/60000][Iteration 3874][Wall Clock 181.327517536s] Trained 120 records in 0.040047073 seconds. Throughput is 2996.4739 records/second. Loss is 0.2545831. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005635072692437733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 45000/60000][Iteration 3875][Wall Clock 181.367383415s] Trained 120 records in 0.039865879 seconds. Throughput is 3010.093 records/second. Loss is 0.2357799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005634437683119225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 45120/60000][Iteration 3876][Wall Clock 181.407584548s] Trained 120 records in 0.040201133 seconds. Throughput is 2984.9907 records/second. Loss is 0.2665187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005633802816901409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 45240/60000][Iteration 3877][Wall Clock 181.448670764s] Trained 120 records in 0.041086216 seconds. Throughput is 2920.6875 records/second. Loss is 0.31785336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056331680937359175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:07 INFO  DistriOptimizer$:406 - [Epoch 8 45360/60000][Iteration 3878][Wall Clock 181.489598107s] Trained 120 records in 0.040927343 seconds. Throughput is 2932.0251 records/second. Loss is 0.20379324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056325335135744056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 45480/60000][Iteration 3879][Wall Clock 181.538362442s] Trained 120 records in 0.048764335 seconds. Throughput is 2460.8147 records/second. Loss is 0.26903883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005631899076368551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 45600/60000][Iteration 3880][Wall Clock 181.587675171s] Trained 120 records in 0.049312729 seconds. Throughput is 2433.4487 records/second. Loss is 0.38711122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005631264782070053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 45720/60000][Iteration 3881][Wall Clock 181.629262856s] Trained 120 records in 0.041587685 seconds. Throughput is 2885.4697 records/second. Loss is 0.20423636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00563063063063063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 45840/60000][Iteration 3882][Wall Clock 181.670401464s] Trained 120 records in 0.041138608 seconds. Throughput is 2916.968 records/second. Loss is 0.15164153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005629996622002027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 45960/60000][Iteration 3883][Wall Clock 181.712022864s] Trained 120 records in 0.0416214 seconds. Throughput is 2883.1323 records/second. Loss is 0.2556145. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005629362756136005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46080/60000][Iteration 3884][Wall Clock 181.753387378s] Trained 120 records in 0.041364514 seconds. Throughput is 2901.0374 records/second. Loss is 0.22134472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005628729032984352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46200/60000][Iteration 3885][Wall Clock 181.800284064s] Trained 120 records in 0.046896686 seconds. Throughput is 2558.8162 records/second. Loss is 0.3130883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005628095452498874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46320/60000][Iteration 3886][Wall Clock 181.853952854s] Trained 120 records in 0.05366879 seconds. Throughput is 2235.9363 records/second. Loss is 0.29038513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005627462014631401. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46440/60000][Iteration 3887][Wall Clock 181.896283776s] Trained 120 records in 0.042330922 seconds. Throughput is 2834.8071 records/second. Loss is 0.27357963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005626828719333783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46560/60000][Iteration 3888][Wall Clock 181.944064757s] Trained 120 records in 0.047780981 seconds. Throughput is 2511.4597 records/second. Loss is 0.26153293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005626195566557893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46680/60000][Iteration 3889][Wall Clock 181.987657296s] Trained 120 records in 0.043592539 seconds. Throughput is 2752.7646 records/second. Loss is 0.23585889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056255625562556255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46800/60000][Iteration 3890][Wall Clock 182.029203546s] Trained 120 records in 0.04154625 seconds. Throughput is 2888.3472 records/second. Loss is 0.30957347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005624929688378895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 46920/60000][Iteration 3891][Wall Clock 182.069647712s] Trained 120 records in 0.040444166 seconds. Throughput is 2967.0535 records/second. Loss is 0.27161664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00562429696287964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47040/60000][Iteration 3892][Wall Clock 182.110009577s] Trained 120 records in 0.040361865 seconds. Throughput is 2973.1033 records/second. Loss is 0.29048118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005623664379709819. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47160/60000][Iteration 3893][Wall Clock 182.150432608s] Trained 120 records in 0.040423031 seconds. Throughput is 2968.6047 records/second. Loss is 0.30239624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005623031938821413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47280/60000][Iteration 3894][Wall Clock 182.190736652s] Trained 120 records in 0.040304044 seconds. Throughput is 2977.369 records/second. Loss is 0.28440514. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056223996401664235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47400/60000][Iteration 3895][Wall Clock 182.231195873s] Trained 120 records in 0.040459221 seconds. Throughput is 2965.9495 records/second. Loss is 0.28631824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005621767483696875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47520/60000][Iteration 3896][Wall Clock 182.271508458s] Trained 120 records in 0.040312585 seconds. Throughput is 2976.738 records/second. Loss is 0.2520719. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005621135469364812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47640/60000][Iteration 3897][Wall Clock 182.311224466s] Trained 120 records in 0.039716008 seconds. Throughput is 3021.4517 records/second. Loss is 0.23392585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005620503597122303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47760/60000][Iteration 3898][Wall Clock 182.351376174s] Trained 120 records in 0.040151708 seconds. Throughput is 2988.6648 records/second. Loss is 0.2219982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005619871866921434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 47880/60000][Iteration 3899][Wall Clock 182.391985124s] Trained 120 records in 0.04060895 seconds. Throughput is 2955.0137 records/second. Loss is 0.12539992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005619240278714317. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 48000/60000][Iteration 3900][Wall Clock 182.432161837s] Trained 120 records in 0.040176713 seconds. Throughput is 2986.805 records/second. Loss is 0.17642274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056186088324530845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 48120/60000][Iteration 3901][Wall Clock 182.472131228s] Trained 120 records in 0.039969391 seconds. Throughput is 3002.2974 records/second. Loss is 0.30294278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056179775280898875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:08 INFO  DistriOptimizer$:406 - [Epoch 8 48240/60000][Iteration 3902][Wall Clock 182.511469492s] Trained 120 records in 0.039338264 seconds. Throughput is 3050.465 records/second. Loss is 0.3011333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005617346365576902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 48360/60000][Iteration 3903][Wall Clock 182.551228533s] Trained 120 records in 0.039759041 seconds. Throughput is 3018.1816 records/second. Loss is 0.21960896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056167153448663226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 48480/60000][Iteration 3904][Wall Clock 182.591017093s] Trained 120 records in 0.03978856 seconds. Throughput is 3015.9424 records/second. Loss is 0.22458915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005616084465910367. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 48600/60000][Iteration 3905][Wall Clock 182.634617921s] Trained 120 records in 0.043600828 seconds. Throughput is 2752.2415 records/second. Loss is 0.21494548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005615453728661276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 48720/60000][Iteration 3906][Wall Clock 182.682799776s] Trained 120 records in 0.048181855 seconds. Throughput is 2490.5642 records/second. Loss is 0.2681714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005614823133071308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 48840/60000][Iteration 3907][Wall Clock 182.729789839s] Trained 120 records in 0.046990063 seconds. Throughput is 2553.7314 records/second. Loss is 0.21806812. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005614192679092746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 48960/60000][Iteration 3908][Wall Clock 182.772757369s] Trained 120 records in 0.04296753 seconds. Throughput is 2792.8064 records/second. Loss is 0.26863936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005613562366677894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49080/60000][Iteration 3909][Wall Clock 182.813142445s] Trained 120 records in 0.040385076 seconds. Throughput is 2971.3948 records/second. Loss is 0.21599177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056129321957790745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49200/60000][Iteration 3910][Wall Clock 182.853817169s] Trained 120 records in 0.040674724 seconds. Throughput is 2950.235 records/second. Loss is 0.23745374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005612302166348636. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49320/60000][Iteration 3911][Wall Clock 182.895029237s] Trained 120 records in 0.041212068 seconds. Throughput is 2911.7686 records/second. Loss is 0.24403709. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005611672278338945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49440/60000][Iteration 3912][Wall Clock 182.946302053s] Trained 120 records in 0.051272816 seconds. Throughput is 2340.4214 records/second. Loss is 0.19299768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056110425317023906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49560/60000][Iteration 3913][Wall Clock 182.98645556s] Trained 120 records in 0.040153507 seconds. Throughput is 2988.531 records/second. Loss is 0.26918834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005610412926391382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49680/60000][Iteration 3914][Wall Clock 183.03305142s] Trained 120 records in 0.04659586 seconds. Throughput is 2575.3362 records/second. Loss is 0.33421013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005609783462358353. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49800/60000][Iteration 3915][Wall Clock 183.07537996s] Trained 120 records in 0.04232854 seconds. Throughput is 2834.9666 records/second. Loss is 0.25722137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005609154139555756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 49920/60000][Iteration 3916][Wall Clock 183.115585668s] Trained 120 records in 0.040205708 seconds. Throughput is 2984.6506 records/second. Loss is 0.21539791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005608524957936063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50040/60000][Iteration 3917][Wall Clock 183.155733245s] Trained 120 records in 0.040147577 seconds. Throughput is 2988.9724 records/second. Loss is 0.2123953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005607895917451772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50160/60000][Iteration 3918][Wall Clock 183.195722863s] Trained 120 records in 0.039989618 seconds. Throughput is 3000.779 records/second. Loss is 0.24283709. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056072670180554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50280/60000][Iteration 3919][Wall Clock 183.236239205s] Trained 120 records in 0.040516342 seconds. Throughput is 2961.7678 records/second. Loss is 0.37463275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005606638259699484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50400/60000][Iteration 3920][Wall Clock 183.276709043s] Trained 120 records in 0.040469838 seconds. Throughput is 2965.1714 records/second. Loss is 0.3068828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056060096423365844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50520/60000][Iteration 3921][Wall Clock 183.317047805s] Trained 120 records in 0.040338762 seconds. Throughput is 2974.8062 records/second. Loss is 0.18634415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005605381165919282. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50640/60000][Iteration 3922][Wall Clock 183.357497784s] Trained 120 records in 0.040449979 seconds. Throughput is 2966.627 records/second. Loss is 0.23012702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005604752830400179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50760/60000][Iteration 3923][Wall Clock 183.398466845s] Trained 120 records in 0.040969061 seconds. Throughput is 2929.0396 records/second. Loss is 0.21925148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005604124635731899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 50880/60000][Iteration 3924][Wall Clock 183.442805603s] Trained 120 records in 0.044338758 seconds. Throughput is 2706.4358 records/second. Loss is 0.28247076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005603496581867084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 51000/60000][Iteration 3925][Wall Clock 183.483658694s] Trained 120 records in 0.040853091 seconds. Throughput is 2937.3542 records/second. Loss is 0.17024066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005602868668758404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:09 INFO  DistriOptimizer$:406 - [Epoch 8 51120/60000][Iteration 3926][Wall Clock 183.524050766s] Trained 120 records in 0.040392072 seconds. Throughput is 2970.8801 records/second. Loss is 0.31890056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0056022408963585435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 51240/60000][Iteration 3927][Wall Clock 183.565066564s] Trained 120 records in 0.041015798 seconds. Throughput is 2925.7021 records/second. Loss is 0.21253024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00560161326462021. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 51360/60000][Iteration 3928][Wall Clock 183.605328001s] Trained 120 records in 0.040261437 seconds. Throughput is 2980.5195 records/second. Loss is 0.28028148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005600985773496135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 51480/60000][Iteration 3929][Wall Clock 183.645402213s] Trained 120 records in 0.040074212 seconds. Throughput is 2994.4446 records/second. Loss is 0.27811992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005600358422939068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 51600/60000][Iteration 3930][Wall Clock 183.685607418s] Trained 120 records in 0.040205205 seconds. Throughput is 2984.688 records/second. Loss is 0.27463034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055997312129017806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 51720/60000][Iteration 3931][Wall Clock 183.725629842s] Trained 120 records in 0.040022424 seconds. Throughput is 2998.319 records/second. Loss is 0.2238235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005599104143337066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 51840/60000][Iteration 3932][Wall Clock 183.765244968s] Trained 120 records in 0.039615126 seconds. Throughput is 3029.146 records/second. Loss is 0.24490719. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005598477214197739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 51960/60000][Iteration 3933][Wall Clock 183.818398331s] Trained 120 records in 0.053153363 seconds. Throughput is 2257.6182 records/second. Loss is 0.21859144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005597850425436633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52080/60000][Iteration 3934][Wall Clock 183.86478267s] Trained 120 records in 0.046384339 seconds. Throughput is 2587.08 records/second. Loss is 0.195321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005597223777006605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52200/60000][Iteration 3935][Wall Clock 183.906324659s] Trained 120 records in 0.041541989 seconds. Throughput is 2888.6436 records/second. Loss is 0.13391265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005596597268860533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52320/60000][Iteration 3936][Wall Clock 183.947702333s] Trained 120 records in 0.041377674 seconds. Throughput is 2900.1147 records/second. Loss is 0.22949527. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005595970900951316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52440/60000][Iteration 3937][Wall Clock 183.988907741s] Trained 120 records in 0.041205408 seconds. Throughput is 2912.2393 records/second. Loss is 0.32305112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005595344673231872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52560/60000][Iteration 3938][Wall Clock 184.030090415s] Trained 120 records in 0.041182674 seconds. Throughput is 2913.8467 records/second. Loss is 0.32087854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005594718585655142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52680/60000][Iteration 3939][Wall Clock 184.07061029s] Trained 120 records in 0.040519875 seconds. Throughput is 2961.5098 records/second. Loss is 0.337026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005594092638174088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52800/60000][Iteration 3940][Wall Clock 184.111226657s] Trained 120 records in 0.040616367 seconds. Throughput is 2954.4739 records/second. Loss is 0.292741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005593466830741693. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 52920/60000][Iteration 3941][Wall Clock 184.16078832s] Trained 120 records in 0.049561663 seconds. Throughput is 2421.226 records/second. Loss is 0.19105579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005592841163310962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53040/60000][Iteration 3942][Wall Clock 184.204418342s] Trained 120 records in 0.043630022 seconds. Throughput is 2750.3997 records/second. Loss is 0.18965374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005592215635834918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53160/60000][Iteration 3943][Wall Clock 184.249202844s] Trained 120 records in 0.044784502 seconds. Throughput is 2679.4985 records/second. Loss is 0.24987459. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005591590248266607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53280/60000][Iteration 3944][Wall Clock 184.28986885s] Trained 120 records in 0.040666006 seconds. Throughput is 2950.8677 records/second. Loss is 0.2744274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005590965000559096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53400/60000][Iteration 3945][Wall Clock 184.330401162s] Trained 120 records in 0.040532312 seconds. Throughput is 2960.6008 records/second. Loss is 0.16080125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005590339892665473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53520/60000][Iteration 3946][Wall Clock 184.370669594s] Trained 120 records in 0.040268432 seconds. Throughput is 2980.0017 records/second. Loss is 0.21805185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005589714924538848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53640/60000][Iteration 3947][Wall Clock 184.411726784s] Trained 120 records in 0.04105719 seconds. Throughput is 2922.7522 records/second. Loss is 0.22688751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005589090096132349. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53760/60000][Iteration 3948][Wall Clock 184.451953852s] Trained 120 records in 0.040227068 seconds. Throughput is 2983.0662 records/second. Loss is 0.33614793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005588465407399128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:10 INFO  DistriOptimizer$:406 - [Epoch 8 53880/60000][Iteration 3949][Wall Clock 184.491946494s] Trained 120 records in 0.039992642 seconds. Throughput is 3000.552 records/second. Loss is 0.26079905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005587840858292356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54000/60000][Iteration 3950][Wall Clock 184.532609672s] Trained 120 records in 0.040663178 seconds. Throughput is 2951.0728 records/second. Loss is 0.26386327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005587216448765225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54120/60000][Iteration 3951][Wall Clock 184.573768555s] Trained 120 records in 0.041158883 seconds. Throughput is 2915.531 records/second. Loss is 0.28820503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00558659217877095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54240/60000][Iteration 3952][Wall Clock 184.614828002s] Trained 120 records in 0.041059447 seconds. Throughput is 2922.5918 records/second. Loss is 0.3493718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005585968048262764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54360/60000][Iteration 3953][Wall Clock 184.655474489s] Trained 120 records in 0.040646487 seconds. Throughput is 2952.2847 records/second. Loss is 0.23530464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005585344057193923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54480/60000][Iteration 3954][Wall Clock 184.695930683s] Trained 120 records in 0.040456194 seconds. Throughput is 2966.1711 records/second. Loss is 0.17535049. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005584720205517704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54600/60000][Iteration 3955][Wall Clock 184.736352375s] Trained 120 records in 0.040421692 seconds. Throughput is 2968.7031 records/second. Loss is 0.2571662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005584096493187403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54720/60000][Iteration 3956][Wall Clock 184.776839689s] Trained 120 records in 0.040487314 seconds. Throughput is 2963.8914 records/second. Loss is 0.33915803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005583472920156337. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54840/60000][Iteration 3957][Wall Clock 184.817218833s] Trained 120 records in 0.040379144 seconds. Throughput is 2971.8313 records/second. Loss is 0.19032785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005582849486377848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 54960/60000][Iteration 3958][Wall Clock 184.857478709s] Trained 120 records in 0.040259876 seconds. Throughput is 2980.6353 records/second. Loss is 0.23227398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005582226191805292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55080/60000][Iteration 3959][Wall Clock 184.906129011s] Trained 120 records in 0.048650302 seconds. Throughput is 2466.5828 records/second. Loss is 0.24985293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005581603036392052. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55200/60000][Iteration 3960][Wall Clock 184.954986178s] Trained 120 records in 0.048857167 seconds. Throughput is 2456.1392 records/second. Loss is 0.31280085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005580980020091528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55320/60000][Iteration 3961][Wall Clock 185.003728178s] Trained 120 records in 0.048742 seconds. Throughput is 2461.9424 records/second. Loss is 0.24317193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005580357142857143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55440/60000][Iteration 3962][Wall Clock 185.050503642s] Trained 120 records in 0.046775464 seconds. Throughput is 2565.4475 records/second. Loss is 0.2001633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005579734404642339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55560/60000][Iteration 3963][Wall Clock 185.092098379s] Trained 120 records in 0.041594737 seconds. Throughput is 2884.9805 records/second. Loss is 0.21850227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005579111805400581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55680/60000][Iteration 3964][Wall Clock 185.132468692s] Trained 120 records in 0.040370313 seconds. Throughput is 2972.4814 records/second. Loss is 0.2610971. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005578489345085351. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55800/60000][Iteration 3965][Wall Clock 185.172597871s] Trained 120 records in 0.040129179 seconds. Throughput is 2990.3428 records/second. Loss is 0.18242386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005577867023650156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 55920/60000][Iteration 3966][Wall Clock 185.212938899s] Trained 120 records in 0.040341028 seconds. Throughput is 2974.6392 records/second. Loss is 0.20780823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005577244841048522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 56040/60000][Iteration 3967][Wall Clock 185.260750447s] Trained 120 records in 0.047811548 seconds. Throughput is 2509.8538 records/second. Loss is 0.28715223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005576622797233995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 56160/60000][Iteration 3968][Wall Clock 185.304603821s] Trained 120 records in 0.043853374 seconds. Throughput is 2736.3916 records/second. Loss is 0.30218557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005576000892160143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 56280/60000][Iteration 3969][Wall Clock 185.345442435s] Trained 120 records in 0.040838614 seconds. Throughput is 2938.3955 records/second. Loss is 0.1764204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005575379125780553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 56400/60000][Iteration 3970][Wall Clock 185.387011898s] Trained 120 records in 0.041569463 seconds. Throughput is 2886.7344 records/second. Loss is 0.24210691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055747574980488344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 56520/60000][Iteration 3971][Wall Clock 185.428480321s] Trained 120 records in 0.041468423 seconds. Throughput is 2893.768 records/second. Loss is 0.21680409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005574136008918618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 56640/60000][Iteration 3972][Wall Clock 185.46941226s] Trained 120 records in 0.040931939 seconds. Throughput is 2931.6958 records/second. Loss is 0.3319623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055735146583435514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:11 INFO  DistriOptimizer$:406 - [Epoch 8 56760/60000][Iteration 3973][Wall Clock 185.510405479s] Trained 120 records in 0.040993219 seconds. Throughput is 2927.3135 records/second. Loss is 0.25180203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005572893446277307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 56880/60000][Iteration 3974][Wall Clock 185.551516021s] Trained 120 records in 0.041110542 seconds. Throughput is 2918.9592 records/second. Loss is 0.31335685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055722723726735765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57000/60000][Iteration 3975][Wall Clock 185.59187349s] Trained 120 records in 0.040357469 seconds. Throughput is 2973.4272 records/second. Loss is 0.23417301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005571651437486071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57120/60000][Iteration 3976][Wall Clock 185.632763863s] Trained 120 records in 0.040890373 seconds. Throughput is 2934.676 records/second. Loss is 0.19488902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005571030640668524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57240/60000][Iteration 3977][Wall Clock 185.673250958s] Trained 120 records in 0.040487095 seconds. Throughput is 2963.9072 records/second. Loss is 0.33061215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005570409982174688. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57360/60000][Iteration 3978][Wall Clock 185.714192612s] Trained 120 records in 0.040941654 seconds. Throughput is 2931.0002 records/second. Loss is 0.2109735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005569789461958338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57480/60000][Iteration 3979][Wall Clock 185.755236119s] Trained 120 records in 0.041043507 seconds. Throughput is 2923.7266 records/second. Loss is 0.18605477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005569169079973268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57600/60000][Iteration 3980][Wall Clock 185.795478454s] Trained 120 records in 0.040242335 seconds. Throughput is 2981.934 records/second. Loss is 0.17539419. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005568548836173293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57720/60000][Iteration 3981][Wall Clock 185.839579269s] Trained 120 records in 0.044100815 seconds. Throughput is 2721.0383 records/second. Loss is 0.25819856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005567928730512249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57840/60000][Iteration 3982][Wall Clock 185.880765677s] Trained 120 records in 0.041186408 seconds. Throughput is 2913.5825 records/second. Loss is 0.25327975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005567308762943993. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 57960/60000][Iteration 3983][Wall Clock 185.921815698s] Trained 120 records in 0.041050021 seconds. Throughput is 2923.263 records/second. Loss is 0.2445738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055666889334224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58080/60000][Iteration 3984][Wall Clock 185.962933463s] Trained 120 records in 0.041117765 seconds. Throughput is 2918.4465 records/second. Loss is 0.22221477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005566069241901369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58200/60000][Iteration 3985][Wall Clock 186.004254253s] Trained 120 records in 0.04132079 seconds. Throughput is 2904.1072 records/second. Loss is 0.17367363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005565449688334817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58320/60000][Iteration 3986][Wall Clock 186.060787372s] Trained 120 records in 0.056533119 seconds. Throughput is 2122.6494 records/second. Loss is 0.40438554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005564830272676683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58440/60000][Iteration 3987][Wall Clock 186.109890212s] Trained 120 records in 0.04910284 seconds. Throughput is 2443.8506 records/second. Loss is 0.26623806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005564210994880926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58560/60000][Iteration 3988][Wall Clock 186.151139403s] Trained 120 records in 0.041249191 seconds. Throughput is 2909.148 records/second. Loss is 0.2900491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005563591854901524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58680/60000][Iteration 3989][Wall Clock 186.191581297s] Trained 120 records in 0.040441894 seconds. Throughput is 2967.2202 records/second. Loss is 0.2235641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055629728526924785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58800/60000][Iteration 3990][Wall Clock 186.233381362s] Trained 120 records in 0.041800065 seconds. Throughput is 2870.8088 records/second. Loss is 0.20376962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00556235398820781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 58920/60000][Iteration 3991][Wall Clock 186.274824311s] Trained 120 records in 0.041442949 seconds. Throughput is 2895.5469 records/second. Loss is 0.20448242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055617352614015575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 59040/60000][Iteration 3992][Wall Clock 186.316412126s] Trained 120 records in 0.041587815 seconds. Throughput is 2885.4607 records/second. Loss is 0.27754986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055611166722277835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 59160/60000][Iteration 3993][Wall Clock 186.358582737s] Trained 120 records in 0.042170611 seconds. Throughput is 2845.5837 records/second. Loss is 0.27611175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00556049822064057. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 59280/60000][Iteration 3994][Wall Clock 186.407713846s] Trained 120 records in 0.049131109 seconds. Throughput is 2442.4443 records/second. Loss is 0.20932688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005559879906594018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 59400/60000][Iteration 3995][Wall Clock 186.451984729s] Trained 120 records in 0.044270883 seconds. Throughput is 2710.5852 records/second. Loss is 0.25752825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005559261730042251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:12 INFO  DistriOptimizer$:406 - [Epoch 8 59520/60000][Iteration 3996][Wall Clock 186.493228097s] Trained 120 records in 0.041243368 seconds. Throughput is 2909.5588 records/second. Loss is 0.30323318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005558643690939411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:13 INFO  DistriOptimizer$:406 - [Epoch 8 59640/60000][Iteration 3997][Wall Clock 186.534607381s] Trained 120 records in 0.041379284 seconds. Throughput is 2900.002 records/second. Loss is 0.29593763. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005558025789239663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:13 INFO  DistriOptimizer$:406 - [Epoch 8 59760/60000][Iteration 3998][Wall Clock 186.575926545s] Trained 120 records in 0.041319164 seconds. Throughput is 2904.2212 records/second. Loss is 0.18216604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005557408024897188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:13 INFO  DistriOptimizer$:406 - [Epoch 8 59880/60000][Iteration 3999][Wall Clock 186.617860863s] Trained 120 records in 0.041934318 seconds. Throughput is 2861.618 records/second. Loss is 0.2629314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005556790397866192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:13 INFO  DistriOptimizer$:406 - [Epoch 8 60000/60000][Iteration 4000][Wall Clock 186.662248543s] Trained 120 records in 0.04438768 seconds. Throughput is 2703.453 records/second. Loss is 0.1926054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055561729081009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:13 INFO  DistriOptimizer$:451 - [Epoch 8 60000/60000][Iteration 4000][Wall Clock 186.662248543s] Epoch finished. Wall clock time is 187461.670552 ms
2019-10-23 15:56:13 INFO  DistriOptimizer$:111 - [Epoch 8 60000/60000][Iteration 4000][Wall Clock 186.662248543s] Validate model...
2019-10-23 15:56:13 INFO  DistriOptimizer$:177 - [Epoch 8 60000/60000][Iteration 4000][Wall Clock 186.662248543s] validate model throughput is 14974.341 records/second
2019-10-23 15:56:13 INFO  DistriOptimizer$:180 - [Epoch 8 60000/60000][Iteration 4000][Wall Clock 186.662248543s] Top1Accuracy is Accuracy(correct: 9352, count: 10000, accuracy: 0.9352)
2019-10-23 15:56:13 INFO  DistriOptimizer$:220 - [Wall Clock 187.461670552s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:56:13 INFO  DistriOptimizer$:225 - [Wall Clock 187.461670552s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:56:13 INFO  DistriOptimizer$:406 - [Epoch 9 120/60000][Iteration 4001][Wall Clock 187.509546947s] Trained 120 records in 0.047876395 seconds. Throughput is 2506.4543 records/second. Loss is 0.22422118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005555555555555556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:13 INFO  DistriOptimizer$:406 - [Epoch 9 240/60000][Iteration 4002][Wall Clock 187.549801048s] Trained 120 records in 0.040254101 seconds. Throughput is 2981.0627 records/second. Loss is 0.23182218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005554938340184424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:13 INFO  DistriOptimizer$:406 - [Epoch 9 360/60000][Iteration 4003][Wall Clock 187.589832443s] Trained 120 records in 0.040031395 seconds. Throughput is 2997.6472 records/second. Loss is 0.1494482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005554321261941791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 480/60000][Iteration 4004][Wall Clock 187.630075849s] Trained 120 records in 0.040243406 seconds. Throughput is 2981.855 records/second. Loss is 0.26600936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005553704320781961. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 600/60000][Iteration 4005][Wall Clock 187.670119637s] Trained 120 records in 0.040043788 seconds. Throughput is 2996.7197 records/second. Loss is 0.14469361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005553087516659262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 720/60000][Iteration 4006][Wall Clock 187.710536503s] Trained 120 records in 0.040416866 seconds. Throughput is 2969.0574 records/second. Loss is 0.3402417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005552470849528039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 840/60000][Iteration 4007][Wall Clock 187.750933511s] Trained 120 records in 0.040397008 seconds. Throughput is 2970.517 records/second. Loss is 0.24459916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00555185431934266. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 960/60000][Iteration 4008][Wall Clock 187.791222945s] Trained 120 records in 0.040289434 seconds. Throughput is 2978.4482 records/second. Loss is 0.41528624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005551237926057511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1080/60000][Iteration 4009][Wall Clock 187.832908721s] Trained 120 records in 0.041685776 seconds. Throughput is 2878.68 records/second. Loss is 0.18309492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005550621669626998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1200/60000][Iteration 4010][Wall Clock 187.889770576s] Trained 120 records in 0.056861855 seconds. Throughput is 2110.378 records/second. Loss is 0.31977698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00555000555000555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1320/60000][Iteration 4011][Wall Clock 187.93638194s] Trained 120 records in 0.046611364 seconds. Throughput is 2574.4795 records/second. Loss is 0.25254148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005549389567147614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1440/60000][Iteration 4012][Wall Clock 187.976992514s] Trained 120 records in 0.040610574 seconds. Throughput is 2954.8955 records/second. Loss is 0.24760954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005548773721007657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1560/60000][Iteration 4013][Wall Clock 188.017868621s] Trained 120 records in 0.040876107 seconds. Throughput is 2935.7004 records/second. Loss is 0.3026515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005548158011540169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1680/60000][Iteration 4014][Wall Clock 188.058797935s] Trained 120 records in 0.040929314 seconds. Throughput is 2931.884 records/second. Loss is 0.24090125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005547542438699656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1800/60000][Iteration 4015][Wall Clock 188.099989735s] Trained 120 records in 0.0411918 seconds. Throughput is 2913.2012 records/second. Loss is 0.21027327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055469270024406485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 1920/60000][Iteration 4016][Wall Clock 188.141759113s] Trained 120 records in 0.041769378 seconds. Throughput is 2872.918 records/second. Loss is 0.24853118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005546311702717693. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2040/60000][Iteration 4017][Wall Clock 188.188372041s] Trained 120 records in 0.046612928 seconds. Throughput is 2574.393 records/second. Loss is 0.21800509. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00554569653948536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2160/60000][Iteration 4018][Wall Clock 188.23115217s] Trained 120 records in 0.042780129 seconds. Throughput is 2805.0408 records/second. Loss is 0.2551012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055450815126982375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2280/60000][Iteration 4019][Wall Clock 188.279560699s] Trained 120 records in 0.048408529 seconds. Throughput is 2478.9019 records/second. Loss is 0.2941419. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005544466622310933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2400/60000][Iteration 4020][Wall Clock 188.327900375s] Trained 120 records in 0.048339676 seconds. Throughput is 2482.4329 records/second. Loss is 0.22291014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055438518682780795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2520/60000][Iteration 4021][Wall Clock 188.369367569s] Trained 120 records in 0.041467194 seconds. Throughput is 2893.854 records/second. Loss is 0.22074725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005543237250554323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2640/60000][Iteration 4022][Wall Clock 188.409862322s] Trained 120 records in 0.040494753 seconds. Throughput is 2963.347 records/second. Loss is 0.28765005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005542622769094336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2760/60000][Iteration 4023][Wall Clock 188.450751028s] Trained 120 records in 0.040888706 seconds. Throughput is 2934.796 records/second. Loss is 0.32186988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005542008423852805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 2880/60000][Iteration 4024][Wall Clock 188.491506212s] Trained 120 records in 0.040755184 seconds. Throughput is 2944.411 records/second. Loss is 0.2880053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005541394214784439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 3000/60000][Iteration 4025][Wall Clock 188.532275184s] Trained 120 records in 0.040768972 seconds. Throughput is 2943.4148 records/second. Loss is 0.3755705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005540780141843971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:14 INFO  DistriOptimizer$:406 - [Epoch 9 3120/60000][Iteration 4026][Wall Clock 188.573009894s] Trained 120 records in 0.04073471 seconds. Throughput is 2945.8906 records/second. Loss is 0.25580284. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00554016620498615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 3240/60000][Iteration 4027][Wall Clock 188.614177812s] Trained 120 records in 0.041167918 seconds. Throughput is 2914.891 records/second. Loss is 0.24608956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005539552404165743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 3360/60000][Iteration 4028][Wall Clock 188.655205627s] Trained 120 records in 0.041027815 seconds. Throughput is 2924.845 records/second. Loss is 0.3001933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005538938739337543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 3480/60000][Iteration 4029][Wall Clock 188.695936532s] Trained 120 records in 0.040730905 seconds. Throughput is 2946.1658 records/second. Loss is 0.23966804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005538325210456357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 3600/60000][Iteration 4030][Wall Clock 188.736194263s] Trained 120 records in 0.040257731 seconds. Throughput is 2980.794 records/second. Loss is 0.23519255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005537711817477018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 3720/60000][Iteration 4031][Wall Clock 188.776213907s] Trained 120 records in 0.040019644 seconds. Throughput is 2998.5276 records/second. Loss is 0.19044243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005537098560354374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 3840/60000][Iteration 4032][Wall Clock 188.816022611s] Trained 120 records in 0.039808704 seconds. Throughput is 3014.416 records/second. Loss is 0.2473742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055364854390432955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 3960/60000][Iteration 4033][Wall Clock 188.856583095s] Trained 120 records in 0.040560484 seconds. Throughput is 2958.5447 records/second. Loss is 0.24383436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005535872453498672. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4080/60000][Iteration 4034][Wall Clock 188.896841311s] Trained 120 records in 0.040258216 seconds. Throughput is 2980.7578 records/second. Loss is 0.35290128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055352596036754124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4200/60000][Iteration 4035][Wall Clock 188.941851539s] Trained 120 records in 0.045010228 seconds. Throughput is 2666.0608 records/second. Loss is 0.24913225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005534646889528448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4320/60000][Iteration 4036][Wall Clock 188.996057944s] Trained 120 records in 0.054206405 seconds. Throughput is 2213.7605 records/second. Loss is 0.2957487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005534034311012729. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4440/60000][Iteration 4037][Wall Clock 189.036779591s] Trained 120 records in 0.040721647 seconds. Throughput is 2946.8357 records/second. Loss is 0.23966528. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005533421868083223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4560/60000][Iteration 4038][Wall Clock 189.077262227s] Trained 120 records in 0.040482636 seconds. Throughput is 2964.234 records/second. Loss is 0.16849017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055328095606949216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4680/60000][Iteration 4039][Wall Clock 189.117353249s] Trained 120 records in 0.040091022 seconds. Throughput is 2993.1887 records/second. Loss is 0.14109217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005532197388802833. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4800/60000][Iteration 4040][Wall Clock 189.157473509s] Trained 120 records in 0.04012026 seconds. Throughput is 2991.0076 records/second. Loss is 0.31056634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005531585352361987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 4920/60000][Iteration 4041][Wall Clock 189.198627888s] Trained 120 records in 0.041154379 seconds. Throughput is 2915.8503 records/second. Loss is 0.23602347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055309734513274336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5040/60000][Iteration 4042][Wall Clock 189.239282128s] Trained 120 records in 0.04065424 seconds. Throughput is 2951.7217 records/second. Loss is 0.15768026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005530361685654242. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5160/60000][Iteration 4043][Wall Clock 189.279783139s] Trained 120 records in 0.040501011 seconds. Throughput is 2962.8892 records/second. Loss is 0.275715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005529750055297501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5280/60000][Iteration 4044][Wall Clock 189.320179713s] Trained 120 records in 0.040396574 seconds. Throughput is 2970.5488 records/second. Loss is 0.27777615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005529138560212319. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5400/60000][Iteration 4045][Wall Clock 189.360562717s] Trained 120 records in 0.040383004 seconds. Throughput is 2971.547 records/second. Loss is 0.36429828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005528527200353826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5520/60000][Iteration 4046][Wall Clock 189.408660823s] Trained 120 records in 0.048098106 seconds. Throughput is 2494.9006 records/second. Loss is 0.25928047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00552791597567717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5640/60000][Iteration 4047][Wall Clock 189.45585365s] Trained 120 records in 0.047192827 seconds. Throughput is 2542.7593 records/second. Loss is 0.42797172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005527304886137519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5760/60000][Iteration 4048][Wall Clock 189.497228482s] Trained 120 records in 0.041374832 seconds. Throughput is 2900.314 records/second. Loss is 0.2940907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005526693931690063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 5880/60000][Iteration 4049][Wall Clock 189.537339117s] Trained 120 records in 0.040110635 seconds. Throughput is 2991.725 records/second. Loss is 0.19221656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005526083112290008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:15 INFO  DistriOptimizer$:406 - [Epoch 9 6000/60000][Iteration 4050][Wall Clock 189.577723284s] Trained 120 records in 0.040384167 seconds. Throughput is 2971.4617 records/second. Loss is 0.24992272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005525472427892585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6120/60000][Iteration 4051][Wall Clock 189.618466803s] Trained 120 records in 0.040743519 seconds. Throughput is 2945.2537 records/second. Loss is 0.26778552. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055248618784530384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6240/60000][Iteration 4052][Wall Clock 189.659277297s] Trained 120 records in 0.040810494 seconds. Throughput is 2940.4202 records/second. Loss is 0.27794412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055242514639266375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6360/60000][Iteration 4053][Wall Clock 189.700622404s] Trained 120 records in 0.041345107 seconds. Throughput is 2902.399 records/second. Loss is 0.26176405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00552364118426867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6480/60000][Iteration 4054][Wall Clock 189.74505193s] Trained 120 records in 0.044429526 seconds. Throughput is 2700.9065 records/second. Loss is 0.25055787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005523031039434442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6600/60000][Iteration 4055][Wall Clock 189.785724052s] Trained 120 records in 0.040672122 seconds. Throughput is 2950.4238 records/second. Loss is 0.30181414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00552242102937928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6720/60000][Iteration 4056][Wall Clock 189.826252062s] Trained 120 records in 0.04052801 seconds. Throughput is 2960.915 records/second. Loss is 0.2658926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005521811154058531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6840/60000][Iteration 4057][Wall Clock 189.866665699s] Trained 120 records in 0.040413637 seconds. Throughput is 2969.2947 records/second. Loss is 0.29181308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005521201413427562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 6960/60000][Iteration 4058][Wall Clock 189.907271365s] Trained 120 records in 0.040605666 seconds. Throughput is 2955.2527 records/second. Loss is 0.30657926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055205918074417585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7080/60000][Iteration 4059][Wall Clock 189.947792536s] Trained 120 records in 0.040521171 seconds. Throughput is 2961.4148 records/second. Loss is 0.20799302. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005519982336056525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7200/60000][Iteration 4060][Wall Clock 190.000681268s] Trained 120 records in 0.052888732 seconds. Throughput is 2268.9143 records/second. Loss is 0.23674056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055193729992272875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7320/60000][Iteration 4061][Wall Clock 190.050098469s] Trained 120 records in 0.049417201 seconds. Throughput is 2428.3042 records/second. Loss is 0.27851948. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005518763796909492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7440/60000][Iteration 4062][Wall Clock 190.091475311s] Trained 120 records in 0.041376842 seconds. Throughput is 2900.173 records/second. Loss is 0.1967597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055181547290586025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7560/60000][Iteration 4063][Wall Clock 190.133236541s] Trained 120 records in 0.04176123 seconds. Throughput is 2873.4785 records/second. Loss is 0.28438476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005517545795630104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7680/60000][Iteration 4064][Wall Clock 190.174065665s] Trained 120 records in 0.040829124 seconds. Throughput is 2939.0784 records/second. Loss is 0.17922242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055169369965794995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7800/60000][Iteration 4065][Wall Clock 190.214873419s] Trained 120 records in 0.040807754 seconds. Throughput is 2940.6177 records/second. Loss is 0.37044853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005516328331862312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 7920/60000][Iteration 4066][Wall Clock 190.255246404s] Trained 120 records in 0.040372985 seconds. Throughput is 2972.2844 records/second. Loss is 0.2287769. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005515719801434087. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 8040/60000][Iteration 4067][Wall Clock 190.295883923s] Trained 120 records in 0.040637519 seconds. Throughput is 2952.9363 records/second. Loss is 0.31999335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005515111405250386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 8160/60000][Iteration 4068][Wall Clock 190.336635316s] Trained 120 records in 0.040751393 seconds. Throughput is 2944.6846 records/second. Loss is 0.3102658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005514503143266791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 8280/60000][Iteration 4069][Wall Clock 190.377713237s] Trained 120 records in 0.041077921 seconds. Throughput is 2921.2773 records/second. Loss is 0.24844164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005513895015438906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 8400/60000][Iteration 4070][Wall Clock 190.418620682s] Trained 120 records in 0.040907445 seconds. Throughput is 2933.4512 records/second. Loss is 0.19919159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005513287021722351. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 8520/60000][Iteration 4071][Wall Clock 190.459865333s] Trained 120 records in 0.041244651 seconds. Throughput is 2909.468 records/second. Loss is 0.25120685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005512679162072767. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 8640/60000][Iteration 4072][Wall Clock 190.508275051s] Trained 120 records in 0.048409718 seconds. Throughput is 2478.841 records/second. Loss is 0.28594884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055120714364458165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:16 INFO  DistriOptimizer$:406 - [Epoch 9 8760/60000][Iteration 4073][Wall Clock 190.558061027s] Trained 120 records in 0.049785976 seconds. Throughput is 2410.3174 records/second. Loss is 0.28761733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005511463844797178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 8880/60000][Iteration 4074][Wall Clock 190.598814114s] Trained 120 records in 0.040753087 seconds. Throughput is 2944.5623 records/second. Loss is 0.17536615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005510856387082552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9000/60000][Iteration 4075][Wall Clock 190.639193939s] Trained 120 records in 0.040379825 seconds. Throughput is 2971.781 records/second. Loss is 0.29517955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00551024906325766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9120/60000][Iteration 4076][Wall Clock 190.680298385s] Trained 120 records in 0.041104446 seconds. Throughput is 2919.392 records/second. Loss is 0.20480047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005509641873278237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9240/60000][Iteration 4077][Wall Clock 190.722058167s] Trained 120 records in 0.041759782 seconds. Throughput is 2873.5784 records/second. Loss is 0.1988809. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005509034817100044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9360/60000][Iteration 4078][Wall Clock 190.763604665s] Trained 120 records in 0.041546498 seconds. Throughput is 2888.33 records/second. Loss is 0.23938614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005508427894678859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9480/60000][Iteration 4079][Wall Clock 190.805172272s] Trained 120 records in 0.041567607 seconds. Throughput is 2886.8633 records/second. Loss is 0.28123066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0055078211059704785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9600/60000][Iteration 4080][Wall Clock 190.846479772s] Trained 120 records in 0.0413075 seconds. Throughput is 2905.0413 records/second. Loss is 0.19396193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005507214450930719. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9720/60000][Iteration 4081][Wall Clock 190.887038126s] Trained 120 records in 0.040558354 seconds. Throughput is 2958.7 records/second. Loss is 0.25451505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005506607929515419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9840/60000][Iteration 4082][Wall Clock 190.927139938s] Trained 120 records in 0.040101812 seconds. Throughput is 2992.3835 records/second. Loss is 0.22326007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005506001541680431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 9960/60000][Iteration 4083][Wall Clock 190.968085925s] Trained 120 records in 0.040945987 seconds. Throughput is 2930.69 records/second. Loss is 0.28939182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005505395287381634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10080/60000][Iteration 4084][Wall Clock 191.008910405s] Trained 120 records in 0.04082448 seconds. Throughput is 2939.4128 records/second. Loss is 0.1629857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00550478916657492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10200/60000][Iteration 4085][Wall Clock 191.057450578s] Trained 120 records in 0.048540173 seconds. Throughput is 2472.1792 records/second. Loss is 0.20960751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005504183179216204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10320/60000][Iteration 4086][Wall Clock 191.109845531s] Trained 120 records in 0.052394953 seconds. Throughput is 2290.2969 records/second. Loss is 0.26944068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005503577325261419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10440/60000][Iteration 4087][Wall Clock 191.150894459s] Trained 120 records in 0.041048928 seconds. Throughput is 2923.3406 records/second. Loss is 0.18392992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00550297160466652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10560/60000][Iteration 4088][Wall Clock 191.191919861s] Trained 120 records in 0.041025402 seconds. Throughput is 2925.017 records/second. Loss is 0.23241104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005502366017387477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10680/60000][Iteration 4089][Wall Clock 191.232196152s] Trained 120 records in 0.040276291 seconds. Throughput is 2979.4202 records/second. Loss is 0.2299671. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005501760563380281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10800/60000][Iteration 4090][Wall Clock 191.272784226s] Trained 120 records in 0.040588074 seconds. Throughput is 2956.5334 records/second. Loss is 0.3327915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005501155242600946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 10920/60000][Iteration 4091][Wall Clock 191.313051259s] Trained 120 records in 0.040267033 seconds. Throughput is 2980.1055 records/second. Loss is 0.29312518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005500550055005501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 11040/60000][Iteration 4092][Wall Clock 191.356931955s] Trained 120 records in 0.043880696 seconds. Throughput is 2734.6877 records/second. Loss is 0.22594506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005499945000549994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 11160/60000][Iteration 4093][Wall Clock 191.396896535s] Trained 120 records in 0.03996458 seconds. Throughput is 3002.659 records/second. Loss is 0.26569957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005499340079190497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 11280/60000][Iteration 4094][Wall Clock 191.436760564s] Trained 120 records in 0.039864029 seconds. Throughput is 3010.2327 records/second. Loss is 0.2947966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005498735290883097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 11400/60000][Iteration 4095][Wall Clock 191.476701254s] Trained 120 records in 0.03994069 seconds. Throughput is 3004.4548 records/second. Loss is 0.20505184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005498130635583902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 11520/60000][Iteration 4096][Wall Clock 191.517359209s] Trained 120 records in 0.040657955 seconds. Throughput is 2951.452 records/second. Loss is 0.24301879. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005497526113249039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:17 INFO  DistriOptimizer$:406 - [Epoch 9 11640/60000][Iteration 4097][Wall Clock 191.557331733s] Trained 120 records in 0.039972524 seconds. Throughput is 3002.062 records/second. Loss is 0.33805567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005496921723834653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 11760/60000][Iteration 4098][Wall Clock 191.597403299s] Trained 120 records in 0.040071566 seconds. Throughput is 2994.642 records/second. Loss is 0.19088557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005496317467296912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 11880/60000][Iteration 4099][Wall Clock 191.646252202s] Trained 120 records in 0.048848903 seconds. Throughput is 2456.5547 records/second. Loss is 0.2637091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005495713343591999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12000/60000][Iteration 4100][Wall Clock 191.691423361s] Trained 120 records in 0.045171159 seconds. Throughput is 2656.5623 records/second. Loss is 0.30050144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005495109352676118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12120/60000][Iteration 4101][Wall Clock 191.732097522s] Trained 120 records in 0.040674161 seconds. Throughput is 2950.276 records/second. Loss is 0.16957492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005494505494505494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12240/60000][Iteration 4102][Wall Clock 191.773543227s] Trained 120 records in 0.041445705 seconds. Throughput is 2895.3542 records/second. Loss is 0.30425626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00549390176903637. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12360/60000][Iteration 4103][Wall Clock 191.813691927s] Trained 120 records in 0.0401487 seconds. Throughput is 2988.8887 records/second. Loss is 0.31718817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005493298176225006. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12480/60000][Iteration 4104][Wall Clock 191.853716566s] Trained 120 records in 0.040024639 seconds. Throughput is 2998.1533 records/second. Loss is 0.36585915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054926947160276835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12600/60000][Iteration 4105][Wall Clock 191.894492841s] Trained 120 records in 0.040776275 seconds. Throughput is 2942.8877 records/second. Loss is 0.2425664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005492091388400702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12720/60000][Iteration 4106][Wall Clock 191.935005396s] Trained 120 records in 0.040512555 seconds. Throughput is 2962.0447 records/second. Loss is 0.19021375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005491488193300384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12840/60000][Iteration 4107][Wall Clock 191.975647172s] Trained 120 records in 0.040641776 seconds. Throughput is 2952.6267 records/second. Loss is 0.21352024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005490885130683066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 12960/60000][Iteration 4108][Wall Clock 192.016336871s] Trained 120 records in 0.040689699 seconds. Throughput is 2949.1494 records/second. Loss is 0.36411867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054902822005051055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13080/60000][Iteration 4109][Wall Clock 192.058115738s] Trained 120 records in 0.041778867 seconds. Throughput is 2872.2656 records/second. Loss is 0.24895705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005489679402722881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13200/60000][Iteration 4110][Wall Clock 192.10107764s] Trained 120 records in 0.042961902 seconds. Throughput is 2793.1724 records/second. Loss is 0.25235233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054890767372927874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13320/60000][Iteration 4111][Wall Clock 192.165101585s] Trained 120 records in 0.064023945 seconds. Throughput is 1874.2988 records/second. Loss is 0.18892339. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00548847420417124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13440/60000][Iteration 4112][Wall Clock 192.206464739s] Trained 120 records in 0.041363154 seconds. Throughput is 2901.1328 records/second. Loss is 0.22484352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005487871803314674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13560/60000][Iteration 4113][Wall Clock 192.246841968s] Trained 120 records in 0.040377229 seconds. Throughput is 2971.9722 records/second. Loss is 0.3419544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005487269534679543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13680/60000][Iteration 4114][Wall Clock 192.28735242s] Trained 120 records in 0.040510452 seconds. Throughput is 2962.1985 records/second. Loss is 0.25926003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054866673982223195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13800/60000][Iteration 4115][Wall Clock 192.327695395s] Trained 120 records in 0.040342975 seconds. Throughput is 2974.4956 records/second. Loss is 0.401635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054860653938994955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 13920/60000][Iteration 4116][Wall Clock 192.367976768s] Trained 120 records in 0.040281373 seconds. Throughput is 2979.0444 records/second. Loss is 0.243325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005485463521667581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 14040/60000][Iteration 4117][Wall Clock 192.408300443s] Trained 120 records in 0.040323675 seconds. Throughput is 2975.9192 records/second. Loss is 0.31713396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005484861781483107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 14160/60000][Iteration 4118][Wall Clock 192.448625041s] Trained 120 records in 0.040324598 seconds. Throughput is 2975.851 records/second. Loss is 0.16112511. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005484260173302622. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 14280/60000][Iteration 4119][Wall Clock 192.489327239s] Trained 120 records in 0.040702198 seconds. Throughput is 2948.2437 records/second. Loss is 0.16546161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005483658697082694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 14400/60000][Iteration 4120][Wall Clock 192.53035098s] Trained 120 records in 0.041023741 seconds. Throughput is 2925.1353 records/second. Loss is 0.19863269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00548305735277991. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:18 INFO  DistriOptimizer$:406 - [Epoch 9 14520/60000][Iteration 4121][Wall Clock 192.570814377s] Trained 120 records in 0.040463397 seconds. Throughput is 2965.6433 records/second. Loss is 0.29334888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005482456140350877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 14640/60000][Iteration 4122][Wall Clock 192.611135493s] Trained 120 records in 0.040321116 seconds. Throughput is 2976.1082 records/second. Loss is 0.2748156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00548185505975222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 14760/60000][Iteration 4123][Wall Clock 192.65059806s] Trained 120 records in 0.039462567 seconds. Throughput is 3040.8564 records/second. Loss is 0.19225116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005481254110940584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 14880/60000][Iteration 4124][Wall Clock 192.690595127s] Trained 120 records in 0.039997067 seconds. Throughput is 3000.22 records/second. Loss is 0.18123156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00548065329387263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15000/60000][Iteration 4125][Wall Clock 192.731144895s] Trained 120 records in 0.040549768 seconds. Throughput is 2959.3267 records/second. Loss is 0.21343753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054800526085050415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15120/60000][Iteration 4126][Wall Clock 192.786897602s] Trained 120 records in 0.055752707 seconds. Throughput is 2152.3618 records/second. Loss is 0.21235517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00547945205479452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15240/60000][Iteration 4127][Wall Clock 192.828747755s] Trained 120 records in 0.041850153 seconds. Throughput is 2867.373 records/second. Loss is 0.20628598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005478851632697786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15360/60000][Iteration 4128][Wall Clock 192.869715078s] Trained 120 records in 0.040967323 seconds. Throughput is 2929.1638 records/second. Loss is 0.36976564. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005478251342171578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15480/60000][Iteration 4129][Wall Clock 192.914302555s] Trained 120 records in 0.044587477 seconds. Throughput is 2691.3386 records/second. Loss is 0.21491621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005477651183172655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15600/60000][Iteration 4130][Wall Clock 192.954648441s] Trained 120 records in 0.040345886 seconds. Throughput is 2974.281 records/second. Loss is 0.28398806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005477051155657794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15720/60000][Iteration 4131][Wall Clock 192.995010496s] Trained 120 records in 0.040362055 seconds. Throughput is 2973.0894 records/second. Loss is 0.23549037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00547645125958379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15840/60000][Iteration 4132][Wall Clock 193.035938512s] Trained 120 records in 0.040928016 seconds. Throughput is 2931.9768 records/second. Loss is 0.16981004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005475851494907458. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 15960/60000][Iteration 4133][Wall Clock 193.077100322s] Trained 120 records in 0.04116181 seconds. Throughput is 2915.3237 records/second. Loss is 0.2191975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005475251861585633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16080/60000][Iteration 4134][Wall Clock 193.117898095s] Trained 120 records in 0.040797773 seconds. Throughput is 2941.337 records/second. Loss is 0.18814759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005474652359575167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16200/60000][Iteration 4135][Wall Clock 193.159371997s] Trained 120 records in 0.041473902 seconds. Throughput is 2893.3857 records/second. Loss is 0.2882346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005474052988832932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16320/60000][Iteration 4136][Wall Clock 193.219711166s] Trained 120 records in 0.060339169 seconds. Throughput is 1988.7579 records/second. Loss is 0.24774282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005473453749315818. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16440/60000][Iteration 4137][Wall Clock 193.265623056s] Trained 120 records in 0.04591189 seconds. Throughput is 2613.7021 records/second. Loss is 0.30988437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005472854640980736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16560/60000][Iteration 4138][Wall Clock 193.306760528s] Trained 120 records in 0.041137472 seconds. Throughput is 2917.0486 records/second. Loss is 0.3025604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005472255663784612. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16680/60000][Iteration 4139][Wall Clock 193.347251317s] Trained 120 records in 0.040490789 seconds. Throughput is 2963.6372 records/second. Loss is 0.21381035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005471656817684395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16800/60000][Iteration 4140][Wall Clock 193.388160749s] Trained 120 records in 0.040909432 seconds. Throughput is 2933.3088 records/second. Loss is 0.14526066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00547105810263705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 16920/60000][Iteration 4141][Wall Clock 193.4292428s] Trained 120 records in 0.041082051 seconds. Throughput is 2920.9836 records/second. Loss is 0.21197677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005470459518599562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 17040/60000][Iteration 4142][Wall Clock 193.47149439s] Trained 120 records in 0.04225159 seconds. Throughput is 2840.1296 records/second. Loss is 0.16746794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005469861065528936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 17160/60000][Iteration 4143][Wall Clock 193.513409546s] Trained 120 records in 0.041915156 seconds. Throughput is 2862.9263 records/second. Loss is 0.24497642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054692627433821925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:19 INFO  DistriOptimizer$:406 - [Epoch 9 17280/60000][Iteration 4144][Wall Clock 193.554604661s] Trained 120 records in 0.041195115 seconds. Throughput is 2912.9668 records/second. Loss is 0.26245397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005468664552116373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 17400/60000][Iteration 4145][Wall Clock 193.59640595s] Trained 120 records in 0.041801289 seconds. Throughput is 2870.7249 records/second. Loss is 0.27382106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005468066491688539. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 17520/60000][Iteration 4146][Wall Clock 193.638230994s] Trained 120 records in 0.041825044 seconds. Throughput is 2869.0942 records/second. Loss is 0.21854036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005467468562055768. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 17640/60000][Iteration 4147][Wall Clock 193.680445945s] Trained 120 records in 0.042214951 seconds. Throughput is 2842.5947 records/second. Loss is 0.24248348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005466870763175158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 17760/60000][Iteration 4148][Wall Clock 193.725948149s] Trained 120 records in 0.045502204 seconds. Throughput is 2637.2349 records/second. Loss is 0.28054544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005466273095003826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 17880/60000][Iteration 4149][Wall Clock 193.767820334s] Trained 120 records in 0.041872185 seconds. Throughput is 2865.8643 records/second. Loss is 0.19549158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005465675557498907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18000/60000][Iteration 4150][Wall Clock 193.808812757s] Trained 120 records in 0.040992423 seconds. Throughput is 2927.37 records/second. Loss is 0.3066386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005465078150617554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18120/60000][Iteration 4151][Wall Clock 193.85007667s] Trained 120 records in 0.041263913 seconds. Throughput is 2908.11 records/second. Loss is 0.19542173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00546448087431694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18240/60000][Iteration 4152][Wall Clock 193.900180355s] Trained 120 records in 0.050103685 seconds. Throughput is 2395.0334 records/second. Loss is 0.23863886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005463883728554256. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18360/60000][Iteration 4153][Wall Clock 193.949878497s] Trained 120 records in 0.049698142 seconds. Throughput is 2414.5771 records/second. Loss is 0.20743684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005463286713286713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18480/60000][Iteration 4154][Wall Clock 193.994570484s] Trained 120 records in 0.044691987 seconds. Throughput is 2685.0452 records/second. Loss is 0.22404194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005462689828471539. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18600/60000][Iteration 4155][Wall Clock 194.03558012s] Trained 120 records in 0.041009636 seconds. Throughput is 2926.1416 records/second. Loss is 0.24655984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005462093074065982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18720/60000][Iteration 4156][Wall Clock 194.076896377s] Trained 120 records in 0.041316257 seconds. Throughput is 2904.4258 records/second. Loss is 0.2690177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005461496450027308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18840/60000][Iteration 4157][Wall Clock 194.118005837s] Trained 120 records in 0.04110946 seconds. Throughput is 2919.0361 records/second. Loss is 0.17053336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005460899956312801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 18960/60000][Iteration 4158][Wall Clock 194.159034737s] Trained 120 records in 0.0410289 seconds. Throughput is 2924.7678 records/second. Loss is 0.16862008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005460303592879764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19080/60000][Iteration 4159][Wall Clock 194.199838907s] Trained 120 records in 0.04080417 seconds. Throughput is 2940.876 records/second. Loss is 0.27780095. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005459707359685521. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19200/60000][Iteration 4160][Wall Clock 194.241958277s] Trained 120 records in 0.04211937 seconds. Throughput is 2849.0457 records/second. Loss is 0.27201793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005459111256687411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19320/60000][Iteration 4161][Wall Clock 194.290411414s] Trained 120 records in 0.048453137 seconds. Throughput is 2476.6199 records/second. Loss is 0.13029319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054585152838427945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19440/60000][Iteration 4162][Wall Clock 194.335302119s] Trained 120 records in 0.044890705 seconds. Throughput is 2673.1592 records/second. Loss is 0.27603096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005457919441109049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19560/60000][Iteration 4163][Wall Clock 194.376250416s] Trained 120 records in 0.040948297 seconds. Throughput is 2930.5247 records/second. Loss is 0.20285879. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005457323728443571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19680/60000][Iteration 4164][Wall Clock 194.417614259s] Trained 120 records in 0.041363843 seconds. Throughput is 2901.0845 records/second. Loss is 0.24835993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005456728145803776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19800/60000][Iteration 4165][Wall Clock 194.45942399s] Trained 120 records in 0.041809731 seconds. Throughput is 2870.1453 records/second. Loss is 0.13901186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005456132693147098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 19920/60000][Iteration 4166][Wall Clock 194.503922596s] Trained 120 records in 0.044498606 seconds. Throughput is 2696.7136 records/second. Loss is 0.31821364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005455537370430987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:20 INFO  DistriOptimizer$:406 - [Epoch 9 20040/60000][Iteration 4167][Wall Clock 194.544995369s] Trained 120 records in 0.041072773 seconds. Throughput is 2921.6433 records/second. Loss is 0.2667607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054549421776129165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 20160/60000][Iteration 4168][Wall Clock 194.585884779s] Trained 120 records in 0.04088941 seconds. Throughput is 2934.7454 records/second. Loss is 0.27867633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005454347114650376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 20280/60000][Iteration 4169][Wall Clock 194.626523338s] Trained 120 records in 0.040638559 seconds. Throughput is 2952.8606 records/second. Loss is 0.25838858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005453752181500873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 20400/60000][Iteration 4170][Wall Clock 194.668025088s] Trained 120 records in 0.04150175 seconds. Throughput is 2891.4443 records/second. Loss is 0.22809418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005453157378121932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 20520/60000][Iteration 4171][Wall Clock 194.708686954s] Trained 120 records in 0.040661866 seconds. Throughput is 2951.168 records/second. Loss is 0.2554484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054525627044711015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 20640/60000][Iteration 4172][Wall Clock 194.74905169s] Trained 120 records in 0.040364736 seconds. Throughput is 2972.892 records/second. Loss is 0.15679614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054519681605059425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 20760/60000][Iteration 4173][Wall Clock 194.789806631s] Trained 120 records in 0.040754941 seconds. Throughput is 2944.4282 records/second. Loss is 0.27694818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005451373746184038. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 20880/60000][Iteration 4174][Wall Clock 194.832373351s] Trained 120 records in 0.04256672 seconds. Throughput is 2819.1038 records/second. Loss is 0.2733308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054507794614629896. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21000/60000][Iteration 4175][Wall Clock 194.873269912s] Trained 120 records in 0.040896561 seconds. Throughput is 2934.232 records/second. Loss is 0.23613065. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054501853063004145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21120/60000][Iteration 4176][Wall Clock 194.91387755s] Trained 120 records in 0.040607638 seconds. Throughput is 2955.1091 records/second. Loss is 0.18455252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005449591280653951. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21240/60000][Iteration 4177][Wall Clock 194.954229033s] Trained 120 records in 0.040351483 seconds. Throughput is 2973.8684 records/second. Loss is 0.13653132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054489973844812556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21360/60000][Iteration 4178][Wall Clock 194.994686321s] Trained 120 records in 0.040457288 seconds. Throughput is 2966.0908 records/second. Loss is 0.30908167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054484036177400025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21480/60000][Iteration 4179][Wall Clock 195.043928444s] Trained 120 records in 0.049242123 seconds. Throughput is 2436.938 records/second. Loss is 0.19096485. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005447809980387884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21600/60000][Iteration 4180][Wall Clock 195.090158928s] Trained 120 records in 0.046230484 seconds. Throughput is 2595.69 records/second. Loss is 0.25622934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005447216472382613. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21720/60000][Iteration 4181][Wall Clock 195.13375567s] Trained 120 records in 0.043596742 seconds. Throughput is 2752.4993 records/second. Loss is 0.25812012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054466230936819175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21840/60000][Iteration 4182][Wall Clock 195.174678268s] Trained 120 records in 0.040922598 seconds. Throughput is 2932.3652 records/second. Loss is 0.274416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005446029844243546. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 21960/60000][Iteration 4183][Wall Clock 195.215650941s] Trained 120 records in 0.040972673 seconds. Throughput is 2928.7815 records/second. Loss is 0.16097285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054454367240252665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22080/60000][Iteration 4184][Wall Clock 195.257362274s] Trained 120 records in 0.041711333 seconds. Throughput is 2876.9158 records/second. Loss is 0.2722054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005444843732984863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22200/60000][Iteration 4185][Wall Clock 195.304356926s] Trained 120 records in 0.046994652 seconds. Throughput is 2553.482 records/second. Loss is 0.22640556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00544425087108014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22320/60000][Iteration 4186][Wall Clock 195.347815168s] Trained 120 records in 0.043458242 seconds. Throughput is 2761.2715 records/second. Loss is 0.16305259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005443658138268916. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22440/60000][Iteration 4187][Wall Clock 195.388872956s] Trained 120 records in 0.041057788 seconds. Throughput is 2922.7097 records/second. Loss is 0.2478151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054430655345090355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22560/60000][Iteration 4188][Wall Clock 195.440786023s] Trained 120 records in 0.051913067 seconds. Throughput is 2311.5566 records/second. Loss is 0.2720918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005442473059758354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22680/60000][Iteration 4189][Wall Clock 195.482674902s] Trained 120 records in 0.041888879 seconds. Throughput is 2864.7222 records/second. Loss is 0.23780656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00544188071397475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22800/60000][Iteration 4190][Wall Clock 195.524649358s] Trained 120 records in 0.041974456 seconds. Throughput is 2858.8816 records/second. Loss is 0.26875007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005441288497116117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:21 INFO  DistriOptimizer$:406 - [Epoch 9 22920/60000][Iteration 4191][Wall Clock 195.566387346s] Trained 120 records in 0.041737988 seconds. Throughput is 2875.0786 records/second. Loss is 0.27237847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00544069640914037. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23040/60000][Iteration 4192][Wall Clock 195.607472935s] Trained 120 records in 0.041085589 seconds. Throughput is 2920.7322 records/second. Loss is 0.26151538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00544010445000544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23160/60000][Iteration 4193][Wall Clock 195.64880996s] Trained 120 records in 0.041337025 seconds. Throughput is 2902.9666 records/second. Loss is 0.22654076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005439512619669277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23280/60000][Iteration 4194][Wall Clock 195.690004434s] Trained 120 records in 0.041194474 seconds. Throughput is 2913.0122 records/second. Loss is 0.2390685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005438920918089851. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23400/60000][Iteration 4195][Wall Clock 195.730920445s] Trained 120 records in 0.040916011 seconds. Throughput is 2932.8372 records/second. Loss is 0.23501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005438329345225147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23520/60000][Iteration 4196][Wall Clock 195.772268777s] Trained 120 records in 0.041348332 seconds. Throughput is 2902.1729 records/second. Loss is 0.2160606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005437737901033171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23640/60000][Iteration 4197][Wall Clock 195.813221133s] Trained 120 records in 0.040952356 seconds. Throughput is 2930.2344 records/second. Loss is 0.3074594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005437146585471945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23760/60000][Iteration 4198][Wall Clock 195.854380119s] Trained 120 records in 0.041158986 seconds. Throughput is 2915.5237 records/second. Loss is 0.23056287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005436555398499511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 23880/60000][Iteration 4199][Wall Clock 195.89545031s] Trained 120 records in 0.041070191 seconds. Throughput is 2921.8274 records/second. Loss is 0.25259465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00543596434007393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24000/60000][Iteration 4200][Wall Clock 195.936526838s] Trained 120 records in 0.041076528 seconds. Throughput is 2921.3762 records/second. Loss is 0.2700849. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005435373410153278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24120/60000][Iteration 4201][Wall Clock 195.977714852s] Trained 120 records in 0.041188014 seconds. Throughput is 2913.469 records/second. Loss is 0.25961927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005434782608695652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24240/60000][Iteration 4202][Wall Clock 196.019200127s] Trained 120 records in 0.041485275 seconds. Throughput is 2892.5925 records/second. Loss is 0.19825979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005434191935659167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24360/60000][Iteration 4203][Wall Clock 196.061270294s] Trained 120 records in 0.042070167 seconds. Throughput is 2852.3777 records/second. Loss is 0.2627737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005433601391001956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24480/60000][Iteration 4204][Wall Clock 196.106438759s] Trained 120 records in 0.045168465 seconds. Throughput is 2656.721 records/second. Loss is 0.28343216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005433010974682169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24600/60000][Iteration 4205][Wall Clock 196.147797922s] Trained 120 records in 0.041359163 seconds. Throughput is 2901.4126 records/second. Loss is 0.19171491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005432420686657975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24720/60000][Iteration 4206][Wall Clock 196.203818311s] Trained 120 records in 0.056020389 seconds. Throughput is 2142.0771 records/second. Loss is 0.26276952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005431830526887561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24840/60000][Iteration 4207][Wall Clock 196.249359254s] Trained 120 records in 0.045540943 seconds. Throughput is 2634.9915 records/second. Loss is 0.22625948. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005431240495329133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 24960/60000][Iteration 4208][Wall Clock 196.290872383s] Trained 120 records in 0.041513129 seconds. Throughput is 2890.6516 records/second. Loss is 0.31704158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005430650591940914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 25080/60000][Iteration 4209][Wall Clock 196.333214559s] Trained 120 records in 0.042342176 seconds. Throughput is 2834.0537 records/second. Loss is 0.27385283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005430060816681147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 25200/60000][Iteration 4210][Wall Clock 196.375713927s] Trained 120 records in 0.042499368 seconds. Throughput is 2823.5715 records/second. Loss is 0.18313155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00542947116950809. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 25320/60000][Iteration 4211][Wall Clock 196.417276403s] Trained 120 records in 0.041562476 seconds. Throughput is 2887.2197 records/second. Loss is 0.20733579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054288816503800215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 25440/60000][Iteration 4212][Wall Clock 196.459695498s] Trained 120 records in 0.042419095 seconds. Throughput is 2828.9148 records/second. Loss is 0.20536843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005428292259255238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 25560/60000][Iteration 4213][Wall Clock 196.501033988s] Trained 120 records in 0.04133849 seconds. Throughput is 2902.8638 records/second. Loss is 0.25135177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005427702996092054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:22 INFO  DistriOptimizer$:406 - [Epoch 9 25680/60000][Iteration 4214][Wall Clock 196.549042294s] Trained 120 records in 0.048008306 seconds. Throughput is 2499.5674 records/second. Loss is 0.13195731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005427113860848801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 25800/60000][Iteration 4215][Wall Clock 196.592837775s] Trained 120 records in 0.043795481 seconds. Throughput is 2740.0088 records/second. Loss is 0.29702014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005426524853483829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 25920/60000][Iteration 4216][Wall Clock 196.633854465s] Trained 120 records in 0.04101669 seconds. Throughput is 2925.6382 records/second. Loss is 0.2831207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005425935973955507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26040/60000][Iteration 4217][Wall Clock 196.674565919s] Trained 120 records in 0.040711454 seconds. Throughput is 2947.5732 records/second. Loss is 0.30870458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005425347222222223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26160/60000][Iteration 4218][Wall Clock 196.715042304s] Trained 120 records in 0.040476385 seconds. Throughput is 2964.6917 records/second. Loss is 0.3165409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005424758598242378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26280/60000][Iteration 4219][Wall Clock 196.755591245s] Trained 120 records in 0.040548941 seconds. Throughput is 2959.387 records/second. Loss is 0.26635048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005424170101974398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26400/60000][Iteration 4220][Wall Clock 196.795988953s] Trained 120 records in 0.040397708 seconds. Throughput is 2970.4656 records/second. Loss is 0.253862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005423581733376722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26520/60000][Iteration 4221][Wall Clock 196.837482367s] Trained 120 records in 0.041493414 seconds. Throughput is 2892.0251 records/second. Loss is 0.2936796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005422993492407809. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26640/60000][Iteration 4222][Wall Clock 196.878542126s] Trained 120 records in 0.041059759 seconds. Throughput is 2922.5696 records/second. Loss is 0.22195247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005422405379026136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26760/60000][Iteration 4223][Wall Clock 196.922925928s] Trained 120 records in 0.044383802 seconds. Throughput is 2703.6892 records/second. Loss is 0.2589859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005421817393190197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 26880/60000][Iteration 4224][Wall Clock 196.964123349s] Trained 120 records in 0.041197421 seconds. Throughput is 2912.8037 records/second. Loss is 0.1630605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005421229534858506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27000/60000][Iteration 4225][Wall Clock 197.004863694s] Trained 120 records in 0.040740345 seconds. Throughput is 2945.4832 records/second. Loss is 0.21822357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005420641803989592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27120/60000][Iteration 4226][Wall Clock 197.046397561s] Trained 120 records in 0.041533867 seconds. Throughput is 2889.2083 records/second. Loss is 0.22071323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054200542005420045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27240/60000][Iteration 4227][Wall Clock 197.08739748s] Trained 120 records in 0.040999919 seconds. Throughput is 2926.835 records/second. Loss is 0.19059992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005419466724474312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27360/60000][Iteration 4228][Wall Clock 197.127806677s] Trained 120 records in 0.040409197 seconds. Throughput is 2969.621 records/second. Loss is 0.28599817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005418879375745095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27480/60000][Iteration 4229][Wall Clock 197.16841966s] Trained 120 records in 0.040612983 seconds. Throughput is 2954.72 records/second. Loss is 0.19260523. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00541829215431296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27600/60000][Iteration 4230][Wall Clock 197.208395748s] Trained 120 records in 0.039976088 seconds. Throughput is 3001.7947 records/second. Loss is 0.30021706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005417705060136526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27720/60000][Iteration 4231][Wall Clock 197.249128529s] Trained 120 records in 0.040732781 seconds. Throughput is 2946.03 records/second. Loss is 0.15018012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005417118093174431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27840/60000][Iteration 4232][Wall Clock 197.29781539s] Trained 120 records in 0.048686861 seconds. Throughput is 2464.7307 records/second. Loss is 0.25474605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005416531253385332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 27960/60000][Iteration 4233][Wall Clock 197.347474703s] Trained 120 records in 0.049659313 seconds. Throughput is 2416.4653 records/second. Loss is 0.32204083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005415944540727903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 28080/60000][Iteration 4234][Wall Clock 197.390349672s] Trained 120 records in 0.042874969 seconds. Throughput is 2798.8357 records/second. Loss is 0.3920994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005415357955160836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 28200/60000][Iteration 4235][Wall Clock 197.432857845s] Trained 120 records in 0.042508173 seconds. Throughput is 2822.9866 records/second. Loss is 0.1329365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005414771496642842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 28320/60000][Iteration 4236][Wall Clock 197.475752632s] Trained 120 records in 0.042894787 seconds. Throughput is 2797.5427 records/second. Loss is 0.19827275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005414185165132647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 28440/60000][Iteration 4237][Wall Clock 197.515970183s] Trained 120 records in 0.040217551 seconds. Throughput is 2983.7717 records/second. Loss is 0.21901892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005413598960589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:23 INFO  DistriOptimizer$:406 - [Epoch 9 28560/60000][Iteration 4238][Wall Clock 197.556416847s] Trained 120 records in 0.040446664 seconds. Throughput is 2966.87 records/second. Loss is 0.25182286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005413012882970662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 28680/60000][Iteration 4239][Wall Clock 197.596584684s] Trained 120 records in 0.040167837 seconds. Throughput is 2987.4648 records/second. Loss is 0.26903173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005412426932236415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 28800/60000][Iteration 4240][Wall Clock 197.643320665s] Trained 120 records in 0.046735981 seconds. Throughput is 2567.615 records/second. Loss is 0.20034002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005411841108345059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 28920/60000][Iteration 4241][Wall Clock 197.691077338s] Trained 120 records in 0.047756673 seconds. Throughput is 2512.7378 records/second. Loss is 0.23873146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005411255411255411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29040/60000][Iteration 4242][Wall Clock 197.731489757s] Trained 120 records in 0.040412419 seconds. Throughput is 2969.3843 records/second. Loss is 0.25292093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005410669840926307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29160/60000][Iteration 4243][Wall Clock 197.771041173s] Trained 120 records in 0.039551416 seconds. Throughput is 3034.0254 records/second. Loss is 0.23523745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005410084397316598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29280/60000][Iteration 4244][Wall Clock 197.810422987s] Trained 120 records in 0.039381814 seconds. Throughput is 3047.0918 records/second. Loss is 0.27905533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005409499080385157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29400/60000][Iteration 4245][Wall Clock 197.8498405s] Trained 120 records in 0.039417513 seconds. Throughput is 3044.332 records/second. Loss is 0.31625572. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054089138900908695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29520/60000][Iteration 4246][Wall Clock 197.889594169s] Trained 120 records in 0.039753669 seconds. Throughput is 3018.5894 records/second. Loss is 0.22930756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005408328826392644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29640/60000][Iteration 4247][Wall Clock 197.929017374s] Trained 120 records in 0.039423205 seconds. Throughput is 3043.8926 records/second. Loss is 0.15222426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005407743889249405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29760/60000][Iteration 4248][Wall Clock 197.969096865s] Trained 120 records in 0.040079491 seconds. Throughput is 2994.05 records/second. Loss is 0.20630814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005407159078620093. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 29880/60000][Iteration 4249][Wall Clock 198.00914425s] Trained 120 records in 0.040047385 seconds. Throughput is 2996.4504 records/second. Loss is 0.15327626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005406574394463667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30000/60000][Iteration 4250][Wall Clock 198.049255143s] Trained 120 records in 0.040110893 seconds. Throughput is 2991.706 records/second. Loss is 0.22559182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005405989836739107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30120/60000][Iteration 4251][Wall Clock 198.090394522s] Trained 120 records in 0.041139379 seconds. Throughput is 2916.9133 records/second. Loss is 0.1646321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005405405405405405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30240/60000][Iteration 4252][Wall Clock 198.132056493s] Trained 120 records in 0.041661971 seconds. Throughput is 2880.3247 records/second. Loss is 0.31811607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005404821100421576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30360/60000][Iteration 4253][Wall Clock 198.174308064s] Trained 120 records in 0.042251571 seconds. Throughput is 2840.131 records/second. Loss is 0.21049671. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005404236921746649. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30480/60000][Iteration 4254][Wall Clock 198.215454614s] Trained 120 records in 0.04114655 seconds. Throughput is 2916.4048 records/second. Loss is 0.2842568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005403652869339673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30600/60000][Iteration 4255][Wall Clock 198.256193048s] Trained 120 records in 0.040738434 seconds. Throughput is 2945.6213 records/second. Loss is 0.25614992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005403068943159715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30720/60000][Iteration 4256][Wall Clock 198.29646562s] Trained 120 records in 0.040272572 seconds. Throughput is 2979.6956 records/second. Loss is 0.27305716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005402485143165856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30840/60000][Iteration 4257][Wall Clock 198.33696808s] Trained 120 records in 0.04050246 seconds. Throughput is 2962.7832 records/second. Loss is 0.19231415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0054019014693172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 30960/60000][Iteration 4258][Wall Clock 198.38623381s] Trained 120 records in 0.04926573 seconds. Throughput is 2435.7703 records/second. Loss is 0.25105605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005401317921572864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 31080/60000][Iteration 4259][Wall Clock 198.436796679s] Trained 120 records in 0.050562869 seconds. Throughput is 2373.283 records/second. Loss is 0.34459513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005400734499891985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 31200/60000][Iteration 4260][Wall Clock 198.486597531s] Trained 120 records in 0.049800852 seconds. Throughput is 2409.5974 records/second. Loss is 0.25340736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005400151204233719. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:24 INFO  DistriOptimizer$:406 - [Epoch 9 31320/60000][Iteration 4261][Wall Clock 198.528322253s] Trained 120 records in 0.041724722 seconds. Throughput is 2875.9927 records/second. Loss is 0.15850884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005399568034557235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 31440/60000][Iteration 4262][Wall Clock 198.568302042s] Trained 120 records in 0.039979789 seconds. Throughput is 3001.5166 records/second. Loss is 0.2348503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005398984990821726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 31560/60000][Iteration 4263][Wall Clock 198.609207823s] Trained 120 records in 0.040905781 seconds. Throughput is 2933.5708 records/second. Loss is 0.29037136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005398402072986396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 31680/60000][Iteration 4264][Wall Clock 198.64938696s] Trained 120 records in 0.040179137 seconds. Throughput is 2986.6245 records/second. Loss is 0.3345028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005397819281010472. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 31800/60000][Iteration 4265][Wall Clock 198.68954152s] Trained 120 records in 0.04015456 seconds. Throughput is 2988.4526 records/second. Loss is 0.23327163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005397236614853195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 31920/60000][Iteration 4266][Wall Clock 198.737372686s] Trained 120 records in 0.047831166 seconds. Throughput is 2508.8245 records/second. Loss is 0.23321745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005396654074473825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32040/60000][Iteration 4267][Wall Clock 198.783580399s] Trained 120 records in 0.046207713 seconds. Throughput is 2596.969 records/second. Loss is 0.2431818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005396071659831642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32160/60000][Iteration 4268][Wall Clock 198.823931355s] Trained 120 records in 0.040350956 seconds. Throughput is 2973.9072 records/second. Loss is 0.2087105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005395489370885939. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32280/60000][Iteration 4269][Wall Clock 198.866349025s] Trained 120 records in 0.04241767 seconds. Throughput is 2829.0095 records/second. Loss is 0.13255683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005394907207596029. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32400/60000][Iteration 4270][Wall Clock 198.907821405s] Trained 120 records in 0.04147238 seconds. Throughput is 2893.4922 records/second. Loss is 0.30341026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005394325169921243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32520/60000][Iteration 4271][Wall Clock 198.950043534s] Trained 120 records in 0.042222129 seconds. Throughput is 2842.1116 records/second. Loss is 0.3003288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005393743257820927. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32640/60000][Iteration 4272][Wall Clock 198.991368566s] Trained 120 records in 0.041325032 seconds. Throughput is 2903.8088 records/second. Loss is 0.18919238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005393161471254449. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32760/60000][Iteration 4273][Wall Clock 199.031988145s] Trained 120 records in 0.040619579 seconds. Throughput is 2954.2405 records/second. Loss is 0.25537124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005392579810181191. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 32880/60000][Iteration 4274][Wall Clock 199.072502329s] Trained 120 records in 0.040514184 seconds. Throughput is 2961.9258 records/second. Loss is 0.24355118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053919982745605525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33000/60000][Iteration 4275][Wall Clock 199.113873539s] Trained 120 records in 0.04137121 seconds. Throughput is 2900.5676 records/second. Loss is 0.21628173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053914168643519516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33120/60000][Iteration 4276][Wall Clock 199.154908683s] Trained 120 records in 0.041035144 seconds. Throughput is 2924.3225 records/second. Loss is 0.12737302. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005390835579514825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33240/60000][Iteration 4277][Wall Clock 199.195807657s] Trained 120 records in 0.040898974 seconds. Throughput is 2934.0588 records/second. Loss is 0.18607382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005390254420008625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33360/60000][Iteration 4278][Wall Clock 199.235976853s] Trained 120 records in 0.040169196 seconds. Throughput is 2987.3638 records/second. Loss is 0.29065883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053896733857928215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33480/60000][Iteration 4279][Wall Clock 199.279769196s] Trained 120 records in 0.043792343 seconds. Throughput is 2740.205 records/second. Loss is 0.2959818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053890924768269025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33600/60000][Iteration 4280][Wall Clock 199.319474725s] Trained 120 records in 0.039705529 seconds. Throughput is 3022.249 records/second. Loss is 0.28264776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005388511693070374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33720/60000][Iteration 4281][Wall Clock 199.358970808s] Trained 120 records in 0.039496083 seconds. Throughput is 3038.276 records/second. Loss is 0.32137033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005387931034482758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33840/60000][Iteration 4282][Wall Clock 199.399121194s] Trained 120 records in 0.040150386 seconds. Throughput is 2988.7634 records/second. Loss is 0.27057812. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005387350501023597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 33960/60000][Iteration 4283][Wall Clock 199.440302242s] Trained 120 records in 0.041181048 seconds. Throughput is 2913.962 records/second. Loss is 0.18670873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053867700926524455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 34080/60000][Iteration 4284][Wall Clock 199.489387004s] Trained 120 records in 0.049084762 seconds. Throughput is 2444.7507 records/second. Loss is 0.22391425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00538618980932888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:25 INFO  DistriOptimizer$:406 - [Epoch 9 34200/60000][Iteration 4285][Wall Clock 199.542125441s] Trained 120 records in 0.052738437 seconds. Throughput is 2275.3804 records/second. Loss is 0.18865523. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005385609651012494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 34320/60000][Iteration 4286][Wall Clock 199.590013179s] Trained 120 records in 0.047887738 seconds. Throughput is 2505.8606 records/second. Loss is 0.18097003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005385029617662897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 34440/60000][Iteration 4287][Wall Clock 199.629998792s] Trained 120 records in 0.039985613 seconds. Throughput is 3001.0796 records/second. Loss is 0.23161072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005384449709239715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 34560/60000][Iteration 4288][Wall Clock 199.670241906s] Trained 120 records in 0.040243114 seconds. Throughput is 2981.8765 records/second. Loss is 0.26850453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005383869925702595. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 34680/60000][Iteration 4289][Wall Clock 199.710978867s] Trained 120 records in 0.040736961 seconds. Throughput is 2945.7278 records/second. Loss is 0.12535506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005383290267011197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 34800/60000][Iteration 4290][Wall Clock 199.752847369s] Trained 120 records in 0.041868502 seconds. Throughput is 2866.1165 records/second. Loss is 0.24929717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005382710733125202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 34920/60000][Iteration 4291][Wall Clock 199.793435156s] Trained 120 records in 0.040587787 seconds. Throughput is 2956.5544 records/second. Loss is 0.22378546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005382131324004305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35040/60000][Iteration 4292][Wall Clock 199.833674639s] Trained 120 records in 0.040239483 seconds. Throughput is 2982.1458 records/second. Loss is 0.339712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005381552039608223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35160/60000][Iteration 4293][Wall Clock 199.884012365s] Trained 120 records in 0.050337726 seconds. Throughput is 2383.898 records/second. Loss is 0.22149402. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005380972879896685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35280/60000][Iteration 4294][Wall Clock 199.924369064s] Trained 120 records in 0.040356699 seconds. Throughput is 2973.484 records/second. Loss is 0.23841316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053803938448294415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35400/60000][Iteration 4295][Wall Clock 199.965437059s] Trained 120 records in 0.041067995 seconds. Throughput is 2921.9834 records/second. Loss is 0.25869626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005379814934366258. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35520/60000][Iteration 4296][Wall Clock 200.006682584s] Trained 120 records in 0.041245525 seconds. Throughput is 2909.4067 records/second. Loss is 0.13668092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053792361484669175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35640/60000][Iteration 4297][Wall Clock 200.050609238s] Trained 120 records in 0.043926654 seconds. Throughput is 2731.8267 records/second. Loss is 0.31328028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005378657487091223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35760/60000][Iteration 4298][Wall Clock 200.090730569s] Trained 120 records in 0.040121331 seconds. Throughput is 2990.9277 records/second. Loss is 0.2768369. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053780789501989895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 35880/60000][Iteration 4299][Wall Clock 200.132130252s] Trained 120 records in 0.041399683 seconds. Throughput is 2898.5728 records/second. Loss is 0.2403367. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005377500537750054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36000/60000][Iteration 4300][Wall Clock 200.173871612s] Trained 120 records in 0.04174136 seconds. Throughput is 2874.8464 records/second. Loss is 0.2579732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053769222497042695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36120/60000][Iteration 4301][Wall Clock 200.21483672s] Trained 120 records in 0.040965108 seconds. Throughput is 2929.3223 records/second. Loss is 0.2014575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005376344086021506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36240/60000][Iteration 4302][Wall Clock 200.255182582s] Trained 120 records in 0.040345862 seconds. Throughput is 2974.2827 records/second. Loss is 0.21112032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005375766046661649. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36360/60000][Iteration 4303][Wall Clock 200.294901658s] Trained 120 records in 0.039719076 seconds. Throughput is 3021.2185 records/second. Loss is 0.21757554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053751881315846056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36480/60000][Iteration 4304][Wall Clock 200.334995776s] Trained 120 records in 0.040094118 seconds. Throughput is 2992.9578 records/second. Loss is 0.18875204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005374610340750295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36600/60000][Iteration 4305][Wall Clock 200.375058964s] Trained 120 records in 0.040063188 seconds. Throughput is 2995.2683 records/second. Loss is 0.2197776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005374032674118658. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36720/60000][Iteration 4306][Wall Clock 200.416246964s] Trained 120 records in 0.041188 seconds. Throughput is 2913.4697 records/second. Loss is 0.28442267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053734551316496505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36840/60000][Iteration 4307][Wall Clock 200.457749131s] Trained 120 records in 0.041502167 seconds. Throughput is 2891.4153 records/second. Loss is 0.4218146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053728777133032445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 36960/60000][Iteration 4308][Wall Clock 200.499014763s] Trained 120 records in 0.041265632 seconds. Throughput is 2907.9888 records/second. Loss is 0.33691266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053723004190394325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:26 INFO  DistriOptimizer$:406 - [Epoch 9 37080/60000][Iteration 4309][Wall Clock 200.539571422s] Trained 120 records in 0.040556659 seconds. Throughput is 2958.8237 records/second. Loss is 0.25943998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053717232488182205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 37200/60000][Iteration 4310][Wall Clock 200.593733821s] Trained 120 records in 0.054162399 seconds. Throughput is 2215.5593 records/second. Loss is 0.26152864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005371146202599634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 37320/60000][Iteration 4311][Wall Clock 200.642236415s] Trained 120 records in 0.048502594 seconds. Throughput is 2474.0945 records/second. Loss is 0.26444677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053705692803437165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 37440/60000][Iteration 4312][Wall Clock 200.6830111s] Trained 120 records in 0.040774685 seconds. Throughput is 2943.0024 records/second. Loss is 0.21404184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005369992482010525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 37560/60000][Iteration 4313][Wall Clock 200.723297788s] Trained 120 records in 0.040286688 seconds. Throughput is 2978.6516 records/second. Loss is 0.21223512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053694158075601375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 37680/60000][Iteration 4314][Wall Clock 200.763373954s] Trained 120 records in 0.040076166 seconds. Throughput is 2994.2983 records/second. Loss is 0.20395857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005368839256952647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 37800/60000][Iteration 4315][Wall Clock 200.803779986s] Trained 120 records in 0.040406032 seconds. Throughput is 2969.8535 records/second. Loss is 0.23902121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005368262830148164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 37920/60000][Iteration 4316][Wall Clock 200.847174484s] Trained 120 records in 0.043394498 seconds. Throughput is 2765.3274 records/second. Loss is 0.20517708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005367686527106817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38040/60000][Iteration 4317][Wall Clock 200.887275278s] Trained 120 records in 0.040100794 seconds. Throughput is 2992.4595 records/second. Loss is 0.2806143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053671103477887505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38160/60000][Iteration 4318][Wall Clock 200.927546285s] Trained 120 records in 0.040271007 seconds. Throughput is 2979.8113 records/second. Loss is 0.15459585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005366534292154127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38280/60000][Iteration 4319][Wall Clock 200.973114658s] Trained 120 records in 0.045568373 seconds. Throughput is 2633.4055 records/second. Loss is 0.19276838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053659583601631256. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38400/60000][Iteration 4320][Wall Clock 201.019786643s] Trained 120 records in 0.046671985 seconds. Throughput is 2571.1355 records/second. Loss is 0.28081954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005365382551775942. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38520/60000][Iteration 4321][Wall Clock 201.061064888s] Trained 120 records in 0.041278245 seconds. Throughput is 2907.1 records/second. Loss is 0.17298304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053648068669527905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38640/60000][Iteration 4322][Wall Clock 201.102463657s] Trained 120 records in 0.041398769 seconds. Throughput is 2898.637 records/second. Loss is 0.29831. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053642313056538994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38760/60000][Iteration 4323][Wall Clock 201.143800898s] Trained 120 records in 0.041337241 seconds. Throughput is 2902.9514 records/second. Loss is 0.12897389. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005363655867839519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 38880/60000][Iteration 4324][Wall Clock 201.184537272s] Trained 120 records in 0.040736374 seconds. Throughput is 2945.7703 records/second. Loss is 0.25398985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005363080553469913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39000/60000][Iteration 4325][Wall Clock 201.226667131s] Trained 120 records in 0.042129859 seconds. Throughput is 2848.3362 records/second. Loss is 0.29367578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005362505362505363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39120/60000][Iteration 4326][Wall Clock 201.269185625s] Trained 120 records in 0.042518494 seconds. Throughput is 2822.3013 records/second. Loss is 0.27586704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005361930294906166. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39240/60000][Iteration 4327][Wall Clock 201.31099982s] Trained 120 records in 0.041814195 seconds. Throughput is 2869.8386 records/second. Loss is 0.2147303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005361355350632639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39360/60000][Iteration 4328][Wall Clock 201.351434091s] Trained 120 records in 0.040434271 seconds. Throughput is 2967.7795 records/second. Loss is 0.24482612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005360780529645116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39480/60000][Iteration 4329][Wall Clock 201.392957906s] Trained 120 records in 0.041523815 seconds. Throughput is 2889.908 records/second. Loss is 0.20862953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005360205831903945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39600/60000][Iteration 4330][Wall Clock 201.434834777s] Trained 120 records in 0.041876871 seconds. Throughput is 2865.5437 records/second. Loss is 0.1488655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005359631257369493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39720/60000][Iteration 4331][Wall Clock 201.476024055s] Trained 120 records in 0.041189278 seconds. Throughput is 2913.3794 records/second. Loss is 0.19101268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053590568060021436. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:27 INFO  DistriOptimizer$:406 - [Epoch 9 39840/60000][Iteration 4332][Wall Clock 201.516772218s] Trained 120 records in 0.040748163 seconds. Throughput is 2944.918 records/second. Loss is 0.24050502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005358482477762298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 39960/60000][Iteration 4333][Wall Clock 201.557402287s] Trained 120 records in 0.040630069 seconds. Throughput is 2953.4775 records/second. Loss is 0.19405045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005357908272610373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40080/60000][Iteration 4334][Wall Clock 201.599238159s] Trained 120 records in 0.041835872 seconds. Throughput is 2868.3518 records/second. Loss is 0.19488607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005357334190506804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40200/60000][Iteration 4335][Wall Clock 201.651979032s] Trained 120 records in 0.052740873 seconds. Throughput is 2275.2751 records/second. Loss is 0.26545256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005356760231412042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40320/60000][Iteration 4336][Wall Clock 201.701133764s] Trained 120 records in 0.049154732 seconds. Throughput is 2441.2705 records/second. Loss is 0.19749616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005356186395286556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40440/60000][Iteration 4337][Wall Clock 201.742213527s] Trained 120 records in 0.041079763 seconds. Throughput is 2921.1462 records/second. Loss is 0.24461664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005355612682090832. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40560/60000][Iteration 4338][Wall Clock 201.784886255s] Trained 120 records in 0.042672728 seconds. Throughput is 2812.1006 records/second. Loss is 0.21238418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00535503909178537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40680/60000][Iteration 4339][Wall Clock 201.824784348s] Trained 120 records in 0.039898093 seconds. Throughput is 3007.6626 records/second. Loss is 0.24232498. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005354465624330692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40800/60000][Iteration 4340][Wall Clock 201.864289639s] Trained 120 records in 0.039505291 seconds. Throughput is 3037.5676 records/second. Loss is 0.3134012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005353892279687333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 40920/60000][Iteration 4341][Wall Clock 201.90395965s] Trained 120 records in 0.039670011 seconds. Throughput is 3024.955 records/second. Loss is 0.3163602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005353319057815846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41040/60000][Iteration 4342][Wall Clock 201.944551941s] Trained 120 records in 0.040592291 seconds. Throughput is 2956.2263 records/second. Loss is 0.11885472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005352745958676801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41160/60000][Iteration 4343][Wall Clock 201.9865721s] Trained 120 records in 0.042020159 seconds. Throughput is 2855.772 records/second. Loss is 0.18252535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005352172982230786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41280/60000][Iteration 4344][Wall Clock 202.028471395s] Trained 120 records in 0.041899295 seconds. Throughput is 2864.01 records/second. Loss is 0.28740346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005351600128438403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41400/60000][Iteration 4345][Wall Clock 202.07044846s] Trained 120 records in 0.041977065 seconds. Throughput is 2858.7039 records/second. Loss is 0.15163131. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005351027397260274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41520/60000][Iteration 4346][Wall Clock 202.120311352s] Trained 120 records in 0.049862892 seconds. Throughput is 2406.5994 records/second. Loss is 0.25008097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005350454788657036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41640/60000][Iteration 4347][Wall Clock 202.166141263s] Trained 120 records in 0.045829911 seconds. Throughput is 2618.3774 records/second. Loss is 0.3572447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005349882302589343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41760/60000][Iteration 4348][Wall Clock 202.20735378s] Trained 120 records in 0.041212517 seconds. Throughput is 2911.7366 records/second. Loss is 0.29931837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005349309939017866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 41880/60000][Iteration 4349][Wall Clock 202.249333241s] Trained 120 records in 0.041979461 seconds. Throughput is 2858.5408 records/second. Loss is 0.30823988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005348737697903294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 42000/60000][Iteration 4350][Wall Clock 202.290060489s] Trained 120 records in 0.040727248 seconds. Throughput is 2946.4304 records/second. Loss is 0.2851892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053481655792063315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 42120/60000][Iteration 4351][Wall Clock 202.331473905s] Trained 120 records in 0.041413416 seconds. Throughput is 2897.6118 records/second. Loss is 0.20596616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053475935828877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 42240/60000][Iteration 4352][Wall Clock 202.372733793s] Trained 120 records in 0.041259888 seconds. Throughput is 2908.3938 records/second. Loss is 0.23375784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005347021708908138. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 42360/60000][Iteration 4353][Wall Clock 202.418596904s] Trained 120 records in 0.045863111 seconds. Throughput is 2616.482 records/second. Loss is 0.24556418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053464499572284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 42480/60000][Iteration 4354][Wall Clock 202.461790442s] Trained 120 records in 0.043193538 seconds. Throughput is 2778.1934 records/second. Loss is 0.20833874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005345878327809259. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:28 INFO  DistriOptimizer$:406 - [Epoch 9 42600/60000][Iteration 4355][Wall Clock 202.504828181s] Trained 120 records in 0.043037739 seconds. Throughput is 2788.2505 records/second. Loss is 0.38333893. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005345306820611503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 42720/60000][Iteration 4356][Wall Clock 202.547517665s] Trained 120 records in 0.042689484 seconds. Throughput is 2810.9968 records/second. Loss is 0.22679871. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005344735435595938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 42840/60000][Iteration 4357][Wall Clock 202.590486886s] Trained 120 records in 0.042969221 seconds. Throughput is 2792.6968 records/second. Loss is 0.3280217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005344164172723386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 42960/60000][Iteration 4358][Wall Clock 202.632986238s] Trained 120 records in 0.042499352 seconds. Throughput is 2823.5725 records/second. Loss is 0.2202156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005343593031954687. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43080/60000][Iteration 4359][Wall Clock 202.675937914s] Trained 120 records in 0.042951676 seconds. Throughput is 2793.8374 records/second. Loss is 0.26920182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005343022013250695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43200/60000][Iteration 4360][Wall Clock 202.729387719s] Trained 120 records in 0.053449805 seconds. Throughput is 2245.097 records/second. Loss is 0.2437114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005342451116572284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43320/60000][Iteration 4361][Wall Clock 202.789090188s] Trained 120 records in 0.059702469 seconds. Throughput is 2009.9672 records/second. Loss is 0.26860112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005341880341880342. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43440/60000][Iteration 4362][Wall Clock 202.832432569s] Trained 120 records in 0.043342381 seconds. Throughput is 2768.6526 records/second. Loss is 0.25856146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005341309689135776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43560/60000][Iteration 4363][Wall Clock 202.875669749s] Trained 120 records in 0.04323718 seconds. Throughput is 2775.3892 records/second. Loss is 0.31637335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005340739158299509. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43680/60000][Iteration 4364][Wall Clock 202.91853185s] Trained 120 records in 0.042862101 seconds. Throughput is 2799.676 records/second. Loss is 0.22598423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005340168749332479. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43800/60000][Iteration 4365][Wall Clock 202.961224094s] Trained 120 records in 0.042692244 seconds. Throughput is 2810.815 records/second. Loss is 0.15475325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005339598462195643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 43920/60000][Iteration 4366][Wall Clock 203.004192197s] Trained 120 records in 0.042968103 seconds. Throughput is 2792.7693 records/second. Loss is 0.26617208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005339028296849973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44040/60000][Iteration 4367][Wall Clock 203.046955412s] Trained 120 records in 0.042763215 seconds. Throughput is 2806.1501 records/second. Loss is 0.15319207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005338458253256459. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44160/60000][Iteration 4368][Wall Clock 203.089673954s] Trained 120 records in 0.042718542 seconds. Throughput is 2809.0847 records/second. Loss is 0.20318136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005337888331376107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44280/60000][Iteration 4369][Wall Clock 203.132513059s] Trained 120 records in 0.042839105 seconds. Throughput is 2801.179 records/second. Loss is 0.28613117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00533731853116994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44400/60000][Iteration 4370][Wall Clock 203.175863418s] Trained 120 records in 0.043350359 seconds. Throughput is 2768.1433 records/second. Loss is 0.26763457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005336748852598996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44520/60000][Iteration 4371][Wall Clock 203.218296774s] Trained 120 records in 0.042433356 seconds. Throughput is 2827.964 records/second. Loss is 0.20971094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005336179295624333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44640/60000][Iteration 4372][Wall Clock 203.264183853s] Trained 120 records in 0.045887079 seconds. Throughput is 2615.1152 records/second. Loss is 0.2791787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005335609860207022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44760/60000][Iteration 4373][Wall Clock 203.317913706s] Trained 120 records in 0.053729853 seconds. Throughput is 2233.3953 records/second. Loss is 0.19085214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005335040546308152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 44880/60000][Iteration 4374][Wall Clock 203.362926372s] Trained 120 records in 0.045012666 seconds. Throughput is 2665.9163 records/second. Loss is 0.25032058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005334471353888829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 45000/60000][Iteration 4375][Wall Clock 203.405859654s] Trained 120 records in 0.042933282 seconds. Throughput is 2795.0344 records/second. Loss is 0.18263361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005333902282910177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 45120/60000][Iteration 4376][Wall Clock 203.449141495s] Trained 120 records in 0.043281841 seconds. Throughput is 2772.5251 records/second. Loss is 0.20979252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005333333333333333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:29 INFO  DistriOptimizer$:406 - [Epoch 9 45240/60000][Iteration 4377][Wall Clock 203.492330283s] Trained 120 records in 0.043188788 seconds. Throughput is 2778.4988 records/second. Loss is 0.4272448. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005332764505119454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 45360/60000][Iteration 4378][Wall Clock 203.53431203s] Trained 120 records in 0.041981747 seconds. Throughput is 2858.3853 records/second. Loss is 0.38451472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005332195798229711. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 45480/60000][Iteration 4379][Wall Clock 203.576680375s] Trained 120 records in 0.042368345 seconds. Throughput is 2832.3032 records/second. Loss is 0.30091867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053316272126252935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 45600/60000][Iteration 4380][Wall Clock 203.619210621s] Trained 120 records in 0.042530246 seconds. Throughput is 2821.5215 records/second. Loss is 0.24861951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005331058748267406. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 45720/60000][Iteration 4381][Wall Clock 203.661684369s] Trained 120 records in 0.042473748 seconds. Throughput is 2825.2747 records/second. Loss is 0.29250214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053304904051172716. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 45840/60000][Iteration 4382][Wall Clock 203.704224048s] Trained 120 records in 0.042539679 seconds. Throughput is 2820.8958 records/second. Loss is 0.18912789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005329922183136126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 45960/60000][Iteration 4383][Wall Clock 203.745970903s] Trained 120 records in 0.041746855 seconds. Throughput is 2874.468 records/second. Loss is 0.33972964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005329354082285227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46080/60000][Iteration 4384][Wall Clock 203.788537622s] Trained 120 records in 0.042566719 seconds. Throughput is 2819.1038 records/second. Loss is 0.21671942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005328786102525845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46200/60000][Iteration 4385][Wall Clock 203.831918659s] Trained 120 records in 0.043381037 seconds. Throughput is 2766.1858 records/second. Loss is 0.20324372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005328218243819267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46320/60000][Iteration 4386][Wall Clock 203.890029949s] Trained 120 records in 0.05811129 seconds. Throughput is 2065.0032 records/second. Loss is 0.15487652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005327650506126798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46440/60000][Iteration 4387][Wall Clock 203.934960685s] Trained 120 records in 0.044930736 seconds. Throughput is 2670.7773 records/second. Loss is 0.19579133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005327082889409759. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46560/60000][Iteration 4388][Wall Clock 203.977430968s] Trained 120 records in 0.042470283 seconds. Throughput is 2825.5051 records/second. Loss is 0.27298743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005326515393629487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46680/60000][Iteration 4389][Wall Clock 204.020339157s] Trained 120 records in 0.042908189 seconds. Throughput is 2796.669 records/second. Loss is 0.18018134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005325948018747337. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46800/60000][Iteration 4390][Wall Clock 204.06256534s] Trained 120 records in 0.042226183 seconds. Throughput is 2841.8386 records/second. Loss is 0.31909883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005325380764724678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 46920/60000][Iteration 4391][Wall Clock 204.108272939s] Trained 120 records in 0.045707599 seconds. Throughput is 2625.384 records/second. Loss is 0.19719648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005324813631522897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47040/60000][Iteration 4392][Wall Clock 204.150355638s] Trained 120 records in 0.042082699 seconds. Throughput is 2851.5283 records/second. Loss is 0.19989242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053242466191033965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47160/60000][Iteration 4393][Wall Clock 204.192618665s] Trained 120 records in 0.042263027 seconds. Throughput is 2839.361 records/second. Loss is 0.29293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005323679727427598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47280/60000][Iteration 4394][Wall Clock 204.234604522s] Trained 120 records in 0.041985857 seconds. Throughput is 2858.1052 records/second. Loss is 0.24703862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005323112956456936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47400/60000][Iteration 4395][Wall Clock 204.276401127s] Trained 120 records in 0.041796605 seconds. Throughput is 2871.0466 records/second. Loss is 0.20496161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053225463061528635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47520/60000][Iteration 4396][Wall Clock 204.318581817s] Trained 120 records in 0.04218069 seconds. Throughput is 2844.9036 records/second. Loss is 0.26503447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005321979776476849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47640/60000][Iteration 4397][Wall Clock 204.361149018s] Trained 120 records in 0.042567201 seconds. Throughput is 2819.0718 records/second. Loss is 0.21658655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005321413367390379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47760/60000][Iteration 4398][Wall Clock 204.403567551s] Trained 120 records in 0.042418533 seconds. Throughput is 2828.9521 records/second. Loss is 0.25190207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005320847078854954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 47880/60000][Iteration 4399][Wall Clock 204.453867319s] Trained 120 records in 0.050299768 seconds. Throughput is 2385.697 records/second. Loss is 0.32634553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005320280910832092. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:30 INFO  DistriOptimizer$:406 - [Epoch 9 48000/60000][Iteration 4400][Wall Clock 204.503413872s] Trained 120 records in 0.049546553 seconds. Throughput is 2421.9646 records/second. Loss is 0.30981505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005319714863283328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48120/60000][Iteration 4401][Wall Clock 204.546640095s] Trained 120 records in 0.043226223 seconds. Throughput is 2776.0925 records/second. Loss is 0.29466727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053191489361702135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48240/60000][Iteration 4402][Wall Clock 204.588938961s] Trained 120 records in 0.042298866 seconds. Throughput is 2836.9556 records/second. Loss is 0.22347824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005318583129454314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48360/60000][Iteration 4403][Wall Clock 204.631460871s] Trained 120 records in 0.04252191 seconds. Throughput is 2822.0747 records/second. Loss is 0.24031934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005318017443097213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48480/60000][Iteration 4404][Wall Clock 204.674159784s] Trained 120 records in 0.042698913 seconds. Throughput is 2810.376 records/second. Loss is 0.24642523. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005317451877060513. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48600/60000][Iteration 4405][Wall Clock 204.716567002s] Trained 120 records in 0.042407218 seconds. Throughput is 2829.707 records/second. Loss is 0.27734482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005316886431305828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48720/60000][Iteration 4406][Wall Clock 204.7583093s] Trained 120 records in 0.041742298 seconds. Throughput is 2874.7817 records/second. Loss is 0.3243228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00531632110579479. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48840/60000][Iteration 4407][Wall Clock 204.800184262s] Trained 120 records in 0.041874962 seconds. Throughput is 2865.674 records/second. Loss is 0.23683636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005315755900489049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 48960/60000][Iteration 4408][Wall Clock 204.842986402s] Trained 120 records in 0.04280214 seconds. Throughput is 2803.5981 records/second. Loss is 0.25270167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005315190815350271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49080/60000][Iteration 4409][Wall Clock 204.885002198s] Trained 120 records in 0.042015796 seconds. Throughput is 2856.0688 records/second. Loss is 0.25906298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005314625850340136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49200/60000][Iteration 4410][Wall Clock 204.933000989s] Trained 120 records in 0.047998791 seconds. Throughput is 2500.063 records/second. Loss is 0.31969622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005314061005420342. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49320/60000][Iteration 4411][Wall Clock 204.98307743s] Trained 120 records in 0.050076441 seconds. Throughput is 2396.3364 records/second. Loss is 0.15518491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005313496280552604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49440/60000][Iteration 4412][Wall Clock 205.028399135s] Trained 120 records in 0.045321705 seconds. Throughput is 2647.7378 records/second. Loss is 0.22054532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005312931675698651. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49560/60000][Iteration 4413][Wall Clock 205.072205108s] Trained 120 records in 0.043805973 seconds. Throughput is 2739.3525 records/second. Loss is 0.20705476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053123671908202295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49680/60000][Iteration 4414][Wall Clock 205.115124951s] Trained 120 records in 0.042919843 seconds. Throughput is 2795.9094 records/second. Loss is 0.2920244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005311802825879103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49800/60000][Iteration 4415][Wall Clock 205.157310972s] Trained 120 records in 0.042186021 seconds. Throughput is 2844.5442 records/second. Loss is 0.22894564. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053112385808370514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 49920/60000][Iteration 4416][Wall Clock 205.199777111s] Trained 120 records in 0.042466139 seconds. Throughput is 2825.781 records/second. Loss is 0.18057562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053106744556558685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 50040/60000][Iteration 4417][Wall Clock 205.243152849s] Trained 120 records in 0.043375738 seconds. Throughput is 2766.5234 records/second. Loss is 0.23330553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005310110450297366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 50160/60000][Iteration 4418][Wall Clock 205.285982839s] Trained 120 records in 0.04282999 seconds. Throughput is 2801.7751 records/second. Loss is 0.17066568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005309546564723373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 50280/60000][Iteration 4419][Wall Clock 205.328163856s] Trained 120 records in 0.042181017 seconds. Throughput is 2844.8816 records/second. Loss is 0.26493746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005308982798895732. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 50400/60000][Iteration 4420][Wall Clock 205.37076435s] Trained 120 records in 0.042600494 seconds. Throughput is 2816.8687 records/second. Loss is 0.19801672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005308419152776304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 50520/60000][Iteration 4421][Wall Clock 205.413690805s] Trained 120 records in 0.042926455 seconds. Throughput is 2795.4788 records/second. Loss is 0.17865564. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0053078556263269645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 50640/60000][Iteration 4422][Wall Clock 205.45661152s] Trained 120 records in 0.042920715 seconds. Throughput is 2795.8528 records/second. Loss is 0.25455987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005307292219509606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:31 INFO  DistriOptimizer$:406 - [Epoch 9 50760/60000][Iteration 4423][Wall Clock 205.498922965s] Trained 120 records in 0.042311445 seconds. Throughput is 2836.112 records/second. Loss is 0.32719764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005306728932286139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 50880/60000][Iteration 4424][Wall Clock 205.540845196s] Trained 120 records in 0.041922231 seconds. Throughput is 2862.443 records/second. Loss is 0.2288393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005306165764618486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51000/60000][Iteration 4425][Wall Clock 205.582538862s] Trained 120 records in 0.041693666 seconds. Throughput is 2878.135 records/second. Loss is 0.21838357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005305602716468591. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51120/60000][Iteration 4426][Wall Clock 205.636555269s] Trained 120 records in 0.054016407 seconds. Throughput is 2221.547 records/second. Loss is 0.22698706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005305039787798408. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51240/60000][Iteration 4427][Wall Clock 205.692225829s] Trained 120 records in 0.05567056 seconds. Throughput is 2155.5378 records/second. Loss is 0.16009527. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005304476978569912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51360/60000][Iteration 4428][Wall Clock 205.73877767s] Trained 120 records in 0.046551841 seconds. Throughput is 2577.7712 records/second. Loss is 0.23746164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005303914288745094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51480/60000][Iteration 4429][Wall Clock 205.78181717s] Trained 120 records in 0.0430395 seconds. Throughput is 2788.1365 records/second. Loss is 0.30741605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005303351718285956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51600/60000][Iteration 4430][Wall Clock 205.824167426s] Trained 120 records in 0.042350256 seconds. Throughput is 2833.513 records/second. Loss is 0.2660694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005302789267154523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51720/60000][Iteration 4431][Wall Clock 205.866723862s] Trained 120 records in 0.042556436 seconds. Throughput is 2819.7852 records/second. Loss is 0.20218273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005302226935312831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51840/60000][Iteration 4432][Wall Clock 205.909162609s] Trained 120 records in 0.042438747 seconds. Throughput is 2827.6047 records/second. Loss is 0.29907772. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005301664722722935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 51960/60000][Iteration 4433][Wall Clock 205.951533475s] Trained 120 records in 0.042370866 seconds. Throughput is 2832.1345 records/second. Loss is 0.23562178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005301102629346904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52080/60000][Iteration 4434][Wall Clock 205.994617019s] Trained 120 records in 0.043083544 seconds. Throughput is 2785.2861 records/second. Loss is 0.13771488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005300540655146825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52200/60000][Iteration 4435][Wall Clock 206.038808206s] Trained 120 records in 0.044191187 seconds. Throughput is 2715.4736 records/second. Loss is 0.18401265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052999788000848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52320/60000][Iteration 4436][Wall Clock 206.087342815s] Trained 120 records in 0.048534609 seconds. Throughput is 2472.4624 records/second. Loss is 0.24924745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005299417064122946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52440/60000][Iteration 4437][Wall Clock 206.132004272s] Trained 120 records in 0.044661457 seconds. Throughput is 2686.8804 records/second. Loss is 0.34716648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052988554472234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52560/60000][Iteration 4438][Wall Clock 206.175631809s] Trained 120 records in 0.043627537 seconds. Throughput is 2750.5564 records/second. Loss is 0.28048247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00529829394934831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52680/60000][Iteration 4439][Wall Clock 206.219113241s] Trained 120 records in 0.043481432 seconds. Throughput is 2759.7988 records/second. Loss is 0.2901521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005297732570459844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52800/60000][Iteration 4440][Wall Clock 206.26234801s] Trained 120 records in 0.043234769 seconds. Throughput is 2775.544 records/second. Loss is 0.17058083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005297171310520182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 52920/60000][Iteration 4441][Wall Clock 206.306246815s] Trained 120 records in 0.043898805 seconds. Throughput is 2733.5596 records/second. Loss is 0.2713793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005296610169491526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 53040/60000][Iteration 4442][Wall Clock 206.349986065s] Trained 120 records in 0.04373925 seconds. Throughput is 2743.5312 records/second. Loss is 0.28139788. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052960491473360875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 53160/60000][Iteration 4443][Wall Clock 206.393365074s] Trained 120 records in 0.043379009 seconds. Throughput is 2766.315 records/second. Loss is 0.1349472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005295488244016098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 53280/60000][Iteration 4444][Wall Clock 206.437064209s] Trained 120 records in 0.043699135 seconds. Throughput is 2746.0498 records/second. Loss is 0.25286418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005294927459493805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:32 INFO  DistriOptimizer$:406 - [Epoch 9 53400/60000][Iteration 4445][Wall Clock 206.481154466s] Trained 120 records in 0.044090257 seconds. Throughput is 2721.6897 records/second. Loss is 0.22785501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052943667937314694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 53520/60000][Iteration 4446][Wall Clock 206.524739986s] Trained 120 records in 0.04358552 seconds. Throughput is 2753.208 records/second. Loss is 0.12142567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005293806246691371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 53640/60000][Iteration 4447][Wall Clock 206.571130133s] Trained 120 records in 0.046390147 seconds. Throughput is 2586.7563 records/second. Loss is 0.22949862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005293245818335804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 53760/60000][Iteration 4448][Wall Clock 206.613147859s] Trained 120 records in 0.042017726 seconds. Throughput is 2855.9377 records/second. Loss is 0.24670841. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005292685508627077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 53880/60000][Iteration 4449][Wall Clock 206.655638303s] Trained 120 records in 0.042490444 seconds. Throughput is 2824.1643 records/second. Loss is 0.23934205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005292125317527519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54000/60000][Iteration 4450][Wall Clock 206.698484558s] Trained 120 records in 0.042846255 seconds. Throughput is 2800.7114 records/second. Loss is 0.3116617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00529156524499947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54120/60000][Iteration 4451][Wall Clock 206.741803951s] Trained 120 records in 0.043319393 seconds. Throughput is 2770.1218 records/second. Loss is 0.19961332. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005291005291005291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54240/60000][Iteration 4452][Wall Clock 206.784529898s] Trained 120 records in 0.042725947 seconds. Throughput is 2808.598 records/second. Loss is 0.2516573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005290445455507354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54360/60000][Iteration 4453][Wall Clock 206.839532975s] Trained 120 records in 0.055003077 seconds. Throughput is 2181.696 records/second. Loss is 0.22502245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005289885738468049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54480/60000][Iteration 4454][Wall Clock 206.885161522s] Trained 120 records in 0.045628547 seconds. Throughput is 2629.9324 records/second. Loss is 0.14410113. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005289326139849783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54600/60000][Iteration 4455][Wall Clock 206.928293773s] Trained 120 records in 0.043132251 seconds. Throughput is 2782.141 records/second. Loss is 0.2323083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052887666596149775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54720/60000][Iteration 4456][Wall Clock 206.97113494s] Trained 120 records in 0.042841167 seconds. Throughput is 2801.0442 records/second. Loss is 0.21096067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005288207297726071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54840/60000][Iteration 4457][Wall Clock 207.014405312s] Trained 120 records in 0.043270372 seconds. Throughput is 2773.2603 records/second. Loss is 0.1784798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005287648054145516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 54960/60000][Iteration 4458][Wall Clock 207.058145759s] Trained 120 records in 0.043740447 seconds. Throughput is 2743.456 records/second. Loss is 0.24762262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005287088928835783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55080/60000][Iteration 4459][Wall Clock 207.10127416s] Trained 120 records in 0.043128401 seconds. Throughput is 2782.3892 records/second. Loss is 0.11463056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005286529921759357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55200/60000][Iteration 4460][Wall Clock 207.147967014s] Trained 120 records in 0.046692854 seconds. Throughput is 2569.9863 records/second. Loss is 0.2595824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00528597103287874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55320/60000][Iteration 4461][Wall Clock 207.209531361s] Trained 120 records in 0.061564347 seconds. Throughput is 1949.18 records/second. Loss is 0.26930854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005285412262156448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55440/60000][Iteration 4462][Wall Clock 207.255412238s] Trained 120 records in 0.045880877 seconds. Throughput is 2615.4688 records/second. Loss is 0.21291064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005284853609555016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55560/60000][Iteration 4463][Wall Clock 207.298269181s] Trained 120 records in 0.042856943 seconds. Throughput is 2800.0132 records/second. Loss is 0.23309256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00528429507503699. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55680/60000][Iteration 4464][Wall Clock 207.341288483s] Trained 120 records in 0.043019302 seconds. Throughput is 2789.4456 records/second. Loss is 0.28741273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005283736658564937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55800/60000][Iteration 4465][Wall Clock 207.384271938s] Trained 120 records in 0.042983455 seconds. Throughput is 2791.772 records/second. Loss is 0.31023502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005283178360101437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 55920/60000][Iteration 4466][Wall Clock 207.43149354s] Trained 120 records in 0.047221602 seconds. Throughput is 2541.21 records/second. Loss is 0.29834735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005282620179609086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:33 INFO  DistriOptimizer$:406 - [Epoch 9 56040/60000][Iteration 4467][Wall Clock 207.474337545s] Trained 120 records in 0.042844005 seconds. Throughput is 2800.8586 records/second. Loss is 0.21282628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005282062117050497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 56160/60000][Iteration 4468][Wall Clock 207.517737472s] Trained 120 records in 0.043399927 seconds. Throughput is 2764.9817 records/second. Loss is 0.33653527. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005281504172388296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 56280/60000][Iteration 4469][Wall Clock 207.560373234s] Trained 120 records in 0.042635762 seconds. Throughput is 2814.5388 records/second. Loss is 0.28294036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005280946345585128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 56400/60000][Iteration 4470][Wall Clock 207.602834448s] Trained 120 records in 0.042461214 seconds. Throughput is 2826.1086 records/second. Loss is 0.22183503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005280388636603654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 56520/60000][Iteration 4471][Wall Clock 207.645567751s] Trained 120 records in 0.042733303 seconds. Throughput is 2808.1143 records/second. Loss is 0.2428592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005279831045406547. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 56640/60000][Iteration 4472][Wall Clock 207.688224444s] Trained 120 records in 0.042656693 seconds. Throughput is 2813.1575 records/second. Loss is 0.23977545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005279273571956499. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 56760/60000][Iteration 4473][Wall Clock 207.73080587s] Trained 120 records in 0.042581426 seconds. Throughput is 2818.1301 records/second. Loss is 0.23674032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005278716216216216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 56880/60000][Iteration 4474][Wall Clock 207.772896089s] Trained 120 records in 0.042090219 seconds. Throughput is 2851.0188 records/second. Loss is 0.20393494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052781589781484214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57000/60000][Iteration 4475][Wall Clock 207.814135104s] Trained 120 records in 0.041239015 seconds. Throughput is 2909.8657 records/second. Loss is 0.18156627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005277601857715854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57120/60000][Iteration 4476][Wall Clock 207.855896221s] Trained 120 records in 0.041761117 seconds. Throughput is 2873.4866 records/second. Loss is 0.29845408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005277044854881266. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57240/60000][Iteration 4477][Wall Clock 207.898620876s] Trained 120 records in 0.042724655 seconds. Throughput is 2808.6829 records/second. Loss is 0.15079314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00527648796960743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57360/60000][Iteration 4478][Wall Clock 207.941474444s] Trained 120 records in 0.042853568 seconds. Throughput is 2800.2336 records/second. Loss is 0.15141669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052759312018571276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57480/60000][Iteration 4479][Wall Clock 207.984190576s] Trained 120 records in 0.042716132 seconds. Throughput is 2809.2432 records/second. Loss is 0.25552335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005275374551593164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57600/60000][Iteration 4480][Wall Clock 208.041301011s] Trained 120 records in 0.057110435 seconds. Throughput is 2101.1921 records/second. Loss is 0.15922423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005274818018778353. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57720/60000][Iteration 4481][Wall Clock 208.090941201s] Trained 120 records in 0.04964019 seconds. Throughput is 2417.396 records/second. Loss is 0.23645276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005274261603375528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57840/60000][Iteration 4482][Wall Clock 208.134642921s] Trained 120 records in 0.04370172 seconds. Throughput is 2745.8875 records/second. Loss is 0.22434263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005273705305347537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 57960/60000][Iteration 4483][Wall Clock 208.177812337s] Trained 120 records in 0.043169416 seconds. Throughput is 2779.7456 records/second. Loss is 0.19725731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005273149124657245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 58080/60000][Iteration 4484][Wall Clock 208.225136197s] Trained 120 records in 0.04732386 seconds. Throughput is 2535.7188 records/second. Loss is 0.20931183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005272593061267531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 58200/60000][Iteration 4485][Wall Clock 208.270660928s] Trained 120 records in 0.045524731 seconds. Throughput is 2635.93 records/second. Loss is 0.13079062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005272037115141291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 58320/60000][Iteration 4486][Wall Clock 208.314981574s] Trained 120 records in 0.044320646 seconds. Throughput is 2707.5417 records/second. Loss is 0.22815071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005271481286241434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 58440/60000][Iteration 4487][Wall Clock 208.35742211s] Trained 120 records in 0.042440536 seconds. Throughput is 2827.4854 records/second. Loss is 0.23260921. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005270925574530887. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 58560/60000][Iteration 4488][Wall Clock 208.409012808s] Trained 120 records in 0.051590698 seconds. Throughput is 2326.0007 records/second. Loss is 0.1969032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005270369979972594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 58680/60000][Iteration 4489][Wall Clock 208.455982815s] Trained 120 records in 0.046970007 seconds. Throughput is 2554.8218 records/second. Loss is 0.16928643. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052698145025295105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:34 INFO  DistriOptimizer$:406 - [Epoch 9 58800/60000][Iteration 4490][Wall Clock 208.498860082s] Trained 120 records in 0.042877267 seconds. Throughput is 2798.6858 records/second. Loss is 0.13100322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005269259142164611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 58920/60000][Iteration 4491][Wall Clock 208.541747312s] Trained 120 records in 0.04288723 seconds. Throughput is 2798.0356 records/second. Loss is 0.2524329. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005268703898840885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59040/60000][Iteration 4492][Wall Clock 208.584115224s] Trained 120 records in 0.042367912 seconds. Throughput is 2832.332 records/second. Loss is 0.24256842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005268148772521336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59160/60000][Iteration 4493][Wall Clock 208.626205037s] Trained 120 records in 0.042089813 seconds. Throughput is 2851.0461 records/second. Loss is 0.26761216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005267593763168985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59280/60000][Iteration 4494][Wall Clock 208.668139571s] Trained 120 records in 0.041934534 seconds. Throughput is 2861.6033 records/second. Loss is 0.15303202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005267038870746866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59400/60000][Iteration 4495][Wall Clock 208.710788049s] Trained 120 records in 0.042648478 seconds. Throughput is 2813.6995 records/second. Loss is 0.28271338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005266484095218032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59520/60000][Iteration 4496][Wall Clock 208.752596626s] Trained 120 records in 0.041808577 seconds. Throughput is 2870.2246 records/second. Loss is 0.20006755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052659294365455505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59640/60000][Iteration 4497][Wall Clock 208.794489041s] Trained 120 records in 0.041892415 seconds. Throughput is 2864.4802 records/second. Loss is 0.30461922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005265374894692502. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59760/60000][Iteration 4498][Wall Clock 208.836484033s] Trained 120 records in 0.041994992 seconds. Throughput is 2857.4836 records/second. Loss is 0.25988105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005264820469621986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 59880/60000][Iteration 4499][Wall Clock 208.878201014s] Trained 120 records in 0.041716981 seconds. Throughput is 2876.5264 records/second. Loss is 0.26138714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052642661612971155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:406 - [Epoch 9 60000/60000][Iteration 4500][Wall Clock 208.919990013s] Trained 120 records in 0.041788999 seconds. Throughput is 2871.569 records/second. Loss is 0.32683244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005263711969681019. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:35 INFO  DistriOptimizer$:451 - [Epoch 9 60000/60000][Iteration 4500][Wall Clock 208.919990013s] Epoch finished. Wall clock time is 209727.071002 ms
2019-10-23 15:56:35 INFO  DistriOptimizer$:111 - [Epoch 9 60000/60000][Iteration 4500][Wall Clock 208.919990013s] Validate model...
2019-10-23 15:56:36 INFO  DistriOptimizer$:177 - [Epoch 9 60000/60000][Iteration 4500][Wall Clock 208.919990013s] validate model throughput is 14826.283 records/second
2019-10-23 15:56:36 INFO  DistriOptimizer$:180 - [Epoch 9 60000/60000][Iteration 4500][Wall Clock 208.919990013s] Top1Accuracy is Accuracy(correct: 9406, count: 10000, accuracy: 0.9406)
2019-10-23 15:56:36 INFO  DistriOptimizer$:220 - [Wall Clock 209.727071002s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:56:36 INFO  DistriOptimizer$:225 - [Wall Clock 209.727071002s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 120/60000][Iteration 4501][Wall Clock 209.775680285s] Trained 120 records in 0.048609283 seconds. Throughput is 2468.6643 records/second. Loss is 0.17739105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005263157894736843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 240/60000][Iteration 4502][Wall Clock 209.82137744s] Trained 120 records in 0.045697155 seconds. Throughput is 2625.984 records/second. Loss is 0.14684841. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005262603936427745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 360/60000][Iteration 4503][Wall Clock 209.863582212s] Trained 120 records in 0.042204772 seconds. Throughput is 2843.2805 records/second. Loss is 0.21229382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005262050094716902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 480/60000][Iteration 4504][Wall Clock 209.905906715s] Trained 120 records in 0.042324503 seconds. Throughput is 2835.237 records/second. Loss is 0.19072925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005261496369567505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 600/60000][Iteration 4505][Wall Clock 209.957558499s] Trained 120 records in 0.051651784 seconds. Throughput is 2323.25 records/second. Loss is 0.24526195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005260942760942761. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 720/60000][Iteration 4506][Wall Clock 210.004911229s] Trained 120 records in 0.04735273 seconds. Throughput is 2534.1726 records/second. Loss is 0.1840196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052603892688058915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 840/60000][Iteration 4507][Wall Clock 210.051182436s] Trained 120 records in 0.046271207 seconds. Throughput is 2593.4053 records/second. Loss is 0.21020673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005259835893120135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 960/60000][Iteration 4508][Wall Clock 210.095136862s] Trained 120 records in 0.043954426 seconds. Throughput is 2730.1006 records/second. Loss is 0.24429291. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005259282633848742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1080/60000][Iteration 4509][Wall Clock 210.1382346s] Trained 120 records in 0.043097738 seconds. Throughput is 2784.369 records/second. Loss is 0.27978137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005258729490954985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1200/60000][Iteration 4510][Wall Clock 210.180089121s] Trained 120 records in 0.041854521 seconds. Throughput is 2867.074 records/second. Loss is 0.21444961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005258176464402145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1320/60000][Iteration 4511][Wall Clock 210.222202927s] Trained 120 records in 0.042113806 seconds. Throughput is 2849.4219 records/second. Loss is 0.1055289. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005257623554153522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1440/60000][Iteration 4512][Wall Clock 210.265613749s] Trained 120 records in 0.043410822 seconds. Throughput is 2764.2876 records/second. Loss is 0.28587627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005257070760172432. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1560/60000][Iteration 4513][Wall Clock 210.3174026s] Trained 120 records in 0.051788851 seconds. Throughput is 2317.101 records/second. Loss is 0.18587068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052565180824222036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1680/60000][Iteration 4514][Wall Clock 210.364038346s] Trained 120 records in 0.046635746 seconds. Throughput is 2573.1335 records/second. Loss is 0.20170072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005255965520866183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1800/60000][Iteration 4515][Wall Clock 210.406745931s] Trained 120 records in 0.042707585 seconds. Throughput is 2809.8054 records/second. Loss is 0.17846721. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052554130754677315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 1920/60000][Iteration 4516][Wall Clock 210.449949287s] Trained 120 records in 0.043203356 seconds. Throughput is 2777.562 records/second. Loss is 0.23033972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005254860746190226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 2040/60000][Iteration 4517][Wall Clock 210.494720161s] Trained 120 records in 0.044770874 seconds. Throughput is 2680.314 records/second. Loss is 0.4344558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005254308532997058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 2160/60000][Iteration 4518][Wall Clock 210.537958106s] Trained 120 records in 0.043237945 seconds. Throughput is 2775.34 records/second. Loss is 0.25965974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005253756435851634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:36 INFO  DistriOptimizer$:406 - [Epoch 10 2280/60000][Iteration 4519][Wall Clock 210.580646854s] Trained 120 records in 0.042688748 seconds. Throughput is 2811.0452 records/second. Loss is 0.14291817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052532044547173775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 2400/60000][Iteration 4520][Wall Clock 210.627559204s] Trained 120 records in 0.04691235 seconds. Throughput is 2557.962 records/second. Loss is 0.2318326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005252652589557727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 2520/60000][Iteration 4521][Wall Clock 210.671062949s] Trained 120 records in 0.043503745 seconds. Throughput is 2758.383 records/second. Loss is 0.18092473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005252100840336135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 2640/60000][Iteration 4522][Wall Clock 210.713342433s] Trained 120 records in 0.042279484 seconds. Throughput is 2838.2559 records/second. Loss is 0.25343457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00525154920701607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 2760/60000][Iteration 4523][Wall Clock 210.756180276s] Trained 120 records in 0.042837843 seconds. Throughput is 2801.2615 records/second. Loss is 0.23338659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005250997689561016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 2880/60000][Iteration 4524][Wall Clock 210.799678482s] Trained 120 records in 0.043498206 seconds. Throughput is 2758.7344 records/second. Loss is 0.19059277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005250446287934475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3000/60000][Iteration 4525][Wall Clock 210.84145433s] Trained 120 records in 0.041775848 seconds. Throughput is 2872.4731 records/second. Loss is 0.21499379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005249895002099958. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3120/60000][Iteration 4526][Wall Clock 210.883005044s] Trained 120 records in 0.041550714 seconds. Throughput is 2888.0369 records/second. Loss is 0.33394367. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005249343832020997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3240/60000][Iteration 4527][Wall Clock 210.925760636s] Trained 120 records in 0.042755592 seconds. Throughput is 2806.6504 records/second. Loss is 0.22656867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005248792777661138. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3360/60000][Iteration 4528][Wall Clock 210.968575892s] Trained 120 records in 0.042815256 seconds. Throughput is 2802.7393 records/second. Loss is 0.17316145. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00524824183898394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3480/60000][Iteration 4529][Wall Clock 211.010957143s] Trained 120 records in 0.042381251 seconds. Throughput is 2831.441 records/second. Loss is 0.25668013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00524769101595298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3600/60000][Iteration 4530][Wall Clock 211.053542999s] Trained 120 records in 0.042585856 seconds. Throughput is 2817.837 records/second. Loss is 0.26711234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00524714030853185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3720/60000][Iteration 4531][Wall Clock 211.097015222s] Trained 120 records in 0.043472223 seconds. Throughput is 2760.3833 records/second. Loss is 0.19687323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005246589716684155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3840/60000][Iteration 4532][Wall Clock 211.154437366s] Trained 120 records in 0.057422144 seconds. Throughput is 2089.7861 records/second. Loss is 0.18795504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005246039240373518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 3960/60000][Iteration 4533][Wall Clock 211.202532448s] Trained 120 records in 0.048095082 seconds. Throughput is 2495.0576 records/second. Loss is 0.10761416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005245488879563575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4080/60000][Iteration 4534][Wall Clock 211.246650959s] Trained 120 records in 0.044118511 seconds. Throughput is 2719.9465 records/second. Loss is 0.13379289. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052449386342179796. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4200/60000][Iteration 4535][Wall Clock 211.288965091s] Trained 120 records in 0.042314132 seconds. Throughput is 2835.9321 records/second. Loss is 0.24355356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005244388504300398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4320/60000][Iteration 4536][Wall Clock 211.331478481s] Trained 120 records in 0.04251339 seconds. Throughput is 2822.6401 records/second. Loss is 0.2284715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005243838489774515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4440/60000][Iteration 4537][Wall Clock 211.373875024s] Trained 120 records in 0.042396543 seconds. Throughput is 2830.4194 records/second. Loss is 0.16766141. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005243288590604027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4560/60000][Iteration 4538][Wall Clock 211.416557715s] Trained 120 records in 0.042682691 seconds. Throughput is 2811.444 records/second. Loss is 0.25303277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005242738806752648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4680/60000][Iteration 4539][Wall Clock 211.462583522s] Trained 120 records in 0.046025807 seconds. Throughput is 2607.2332 records/second. Loss is 0.2964219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005242189138184106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4800/60000][Iteration 4540][Wall Clock 211.513385821s] Trained 120 records in 0.050802299 seconds. Throughput is 2362.098 records/second. Loss is 0.24139895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005241639584862145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:37 INFO  DistriOptimizer$:406 - [Epoch 10 4920/60000][Iteration 4541][Wall Clock 211.560816065s] Trained 120 records in 0.047430244 seconds. Throughput is 2530.0312 records/second. Loss is 0.13097486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005241090146750524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5040/60000][Iteration 4542][Wall Clock 211.603792081s] Trained 120 records in 0.042976016 seconds. Throughput is 2792.2551 records/second. Loss is 0.22005652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005240540823813018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5160/60000][Iteration 4543][Wall Clock 211.646912455s] Trained 120 records in 0.043120374 seconds. Throughput is 2782.9072 records/second. Loss is 0.21996711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005239991616013414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5280/60000][Iteration 4544][Wall Clock 211.689854502s] Trained 120 records in 0.042942047 seconds. Throughput is 2794.4639 records/second. Loss is 0.23926353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005239442523315519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5400/60000][Iteration 4545][Wall Clock 211.732266013s] Trained 120 records in 0.042411511 seconds. Throughput is 2829.4207 records/second. Loss is 0.2296358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005238893545683152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5520/60000][Iteration 4546][Wall Clock 211.775067469s] Trained 120 records in 0.042801456 seconds. Throughput is 2803.643 records/second. Loss is 0.2738434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005238344683080147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5640/60000][Iteration 4547][Wall Clock 211.817713808s] Trained 120 records in 0.042646339 seconds. Throughput is 2813.8408 records/second. Loss is 0.21791475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005237795935470354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5760/60000][Iteration 4548][Wall Clock 211.860031545s] Trained 120 records in 0.042317737 seconds. Throughput is 2835.6904 records/second. Loss is 0.2537479. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005237247302817639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 5880/60000][Iteration 4549][Wall Clock 211.902719443s] Trained 120 records in 0.042687898 seconds. Throughput is 2811.1013 records/second. Loss is 0.31846783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005236698785085881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6000/60000][Iteration 4550][Wall Clock 211.945849125s] Trained 120 records in 0.043129682 seconds. Throughput is 2782.3066 records/second. Loss is 0.26650134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005236150382238978. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6120/60000][Iteration 4551][Wall Clock 211.988233238s] Trained 120 records in 0.042384113 seconds. Throughput is 2831.2495 records/second. Loss is 0.16427301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005235602094240837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6240/60000][Iteration 4552][Wall Clock 212.030893012s] Trained 120 records in 0.042659774 seconds. Throughput is 2812.9543 records/second. Loss is 0.19437322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005235053921055386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6360/60000][Iteration 4553][Wall Clock 212.074063686s] Trained 120 records in 0.043170674 seconds. Throughput is 2779.6646 records/second. Loss is 0.23158592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005234505862646566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6480/60000][Iteration 4554][Wall Clock 212.117170675s] Trained 120 records in 0.043106989 seconds. Throughput is 2783.7715 records/second. Loss is 0.27631792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005233957918978331. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6600/60000][Iteration 4555][Wall Clock 212.159872099s] Trained 120 records in 0.042701424 seconds. Throughput is 2810.2107 records/second. Loss is 0.19804455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005233410090014654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6720/60000][Iteration 4556][Wall Clock 212.203457232s] Trained 120 records in 0.043585133 seconds. Throughput is 2753.2324 records/second. Loss is 0.27084324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052328623757195184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6840/60000][Iteration 4557][Wall Clock 212.252830332s] Trained 120 records in 0.0493731 seconds. Throughput is 2430.4731 records/second. Loss is 0.20177661. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005232314776056928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 6960/60000][Iteration 4558][Wall Clock 212.315689582s] Trained 120 records in 0.06285925 seconds. Throughput is 1909.0269 records/second. Loss is 0.24331911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005231767290990897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 7080/60000][Iteration 4559][Wall Clock 212.367443712s] Trained 120 records in 0.05175413 seconds. Throughput is 2318.6555 records/second. Loss is 0.2599149. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052312199204854574. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 7200/60000][Iteration 4560][Wall Clock 212.410983227s] Trained 120 records in 0.043539515 seconds. Throughput is 2756.117 records/second. Loss is 0.25850213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005230672664504656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 7320/60000][Iteration 4561][Wall Clock 212.454732348s] Trained 120 records in 0.043749121 seconds. Throughput is 2742.9124 records/second. Loss is 0.19815002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005230125523012553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 7440/60000][Iteration 4562][Wall Clock 212.498437712s] Trained 120 records in 0.043705364 seconds. Throughput is 2745.6584 records/second. Loss is 0.21051346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005229578495973225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:38 INFO  DistriOptimizer$:406 - [Epoch 10 7560/60000][Iteration 4563][Wall Clock 212.543478329s] Trained 120 records in 0.045040617 seconds. Throughput is 2664.2617 records/second. Loss is 0.32134044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005229031583350764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 7680/60000][Iteration 4564][Wall Clock 212.587572959s] Trained 120 records in 0.04409463 seconds. Throughput is 2721.42 records/second. Loss is 0.26949957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005228484785109276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 7800/60000][Iteration 4565][Wall Clock 212.630417496s] Trained 120 records in 0.042844537 seconds. Throughput is 2800.8237 records/second. Loss is 0.24708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052279381012128815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 7920/60000][Iteration 4566][Wall Clock 212.671689097s] Trained 120 records in 0.041271601 seconds. Throughput is 2907.5684 records/second. Loss is 0.2439122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005227391531625719. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8040/60000][Iteration 4567][Wall Clock 212.725755724s] Trained 120 records in 0.054066627 seconds. Throughput is 2219.4836 records/second. Loss is 0.20328684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052268450763119385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8160/60000][Iteration 4568][Wall Clock 212.766720553s] Trained 120 records in 0.040964829 seconds. Throughput is 2929.342 records/second. Loss is 0.25668463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005226298735235706. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8280/60000][Iteration 4569][Wall Clock 212.80764538s] Trained 120 records in 0.040924827 seconds. Throughput is 2932.2053 records/second. Loss is 0.2316834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005225752508361204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8400/60000][Iteration 4570][Wall Clock 212.848752702s] Trained 120 records in 0.041107322 seconds. Throughput is 2919.188 records/second. Loss is 0.19297324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005225206395652628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8520/60000][Iteration 4571][Wall Clock 212.890186131s] Trained 120 records in 0.041433429 seconds. Throughput is 2896.2122 records/second. Loss is 0.18178298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00522466039707419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8640/60000][Iteration 4572][Wall Clock 212.930899782s] Trained 120 records in 0.040713651 seconds. Throughput is 2947.4146 records/second. Loss is 0.15689293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052241145125901155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8760/60000][Iteration 4573][Wall Clock 212.97110159s] Trained 120 records in 0.040201808 seconds. Throughput is 2984.9402 records/second. Loss is 0.2223689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005223568742164647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 8880/60000][Iteration 4574][Wall Clock 213.012457711s] Trained 120 records in 0.041356121 seconds. Throughput is 2901.6262 records/second. Loss is 0.16417052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005223023085762039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9000/60000][Iteration 4575][Wall Clock 213.053391168s] Trained 120 records in 0.040933457 seconds. Throughput is 2931.5874 records/second. Loss is 0.30320868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005222477543346564. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9120/60000][Iteration 4576][Wall Clock 213.097519517s] Trained 120 records in 0.044128349 seconds. Throughput is 2719.3406 records/second. Loss is 0.17928286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005221932114882507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9240/60000][Iteration 4577][Wall Clock 213.137963866s] Trained 120 records in 0.040444349 seconds. Throughput is 2967.04 records/second. Loss is 0.21853402. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052213868003341685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9360/60000][Iteration 4578][Wall Clock 213.178350253s] Trained 120 records in 0.040386387 seconds. Throughput is 2971.2983 records/second. Loss is 0.22173889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005220841599665866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9480/60000][Iteration 4579][Wall Clock 213.218406816s] Trained 120 records in 0.040056563 seconds. Throughput is 2995.7637 records/second. Loss is 0.3062028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00522029651284193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9600/60000][Iteration 4580][Wall Clock 213.258460403s] Trained 120 records in 0.040053587 seconds. Throughput is 2995.9863 records/second. Loss is 0.2300821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005219751539826704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9720/60000][Iteration 4581][Wall Clock 213.298660673s] Trained 120 records in 0.04020027 seconds. Throughput is 2985.0544 records/second. Loss is 0.24820322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005219206680584551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9840/60000][Iteration 4582][Wall Clock 213.338648261s] Trained 120 records in 0.039987588 seconds. Throughput is 3000.9314 records/second. Loss is 0.24942389. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005218661935079846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 9960/60000][Iteration 4583][Wall Clock 213.384887046s] Trained 120 records in 0.046238785 seconds. Throughput is 2595.2239 records/second. Loss is 0.29910988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005218117303276978. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 10080/60000][Iteration 4584][Wall Clock 213.433151818s] Trained 120 records in 0.048264772 seconds. Throughput is 2486.2854 records/second. Loss is 0.27303228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005217572785140352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 10200/60000][Iteration 4585][Wall Clock 213.474321957s] Trained 120 records in 0.041170139 seconds. Throughput is 2914.734 records/second. Loss is 0.31134033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005217028380634391. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 10320/60000][Iteration 4586][Wall Clock 213.515607273s] Trained 120 records in 0.041285316 seconds. Throughput is 2906.6023 records/second. Loss is 0.19782116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005216484089723527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:39 INFO  DistriOptimizer$:406 - [Epoch 10 10440/60000][Iteration 4587][Wall Clock 213.556731056s] Trained 120 records in 0.041123783 seconds. Throughput is 2918.0195 records/second. Loss is 0.2849286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005215939912372209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 10560/60000][Iteration 4588][Wall Clock 213.596888736s] Trained 120 records in 0.04015768 seconds. Throughput is 2988.2205 records/second. Loss is 0.344326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005215395848544905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 10680/60000][Iteration 4589][Wall Clock 213.636982492s] Trained 120 records in 0.040093756 seconds. Throughput is 2992.9846 records/second. Loss is 0.30172306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005214851898206091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 10800/60000][Iteration 4590][Wall Clock 213.677050347s] Trained 120 records in 0.040067855 seconds. Throughput is 2994.9194 records/second. Loss is 0.21260427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005214308061320262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 10920/60000][Iteration 4591][Wall Clock 213.716688872s] Trained 120 records in 0.039638525 seconds. Throughput is 3027.3577 records/second. Loss is 0.23412827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005213764337851929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11040/60000][Iteration 4592][Wall Clock 213.757302794s] Trained 120 records in 0.040613922 seconds. Throughput is 2954.6519 records/second. Loss is 0.3088337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005213220727765614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11160/60000][Iteration 4593][Wall Clock 213.80361103s] Trained 120 records in 0.046308236 seconds. Throughput is 2591.3318 records/second. Loss is 0.27173316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052126772310258545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11280/60000][Iteration 4594][Wall Clock 213.848188824s] Trained 120 records in 0.044577794 seconds. Throughput is 2691.9233 records/second. Loss is 0.21276738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005212133847597206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11400/60000][Iteration 4595][Wall Clock 213.891931796s] Trained 120 records in 0.043742972 seconds. Throughput is 2743.2979 records/second. Loss is 0.22630116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005211590577444236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11520/60000][Iteration 4596][Wall Clock 213.932016638s] Trained 120 records in 0.040084842 seconds. Throughput is 2993.6504 records/second. Loss is 0.23588173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005211047420531527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11640/60000][Iteration 4597][Wall Clock 213.97205274s] Trained 120 records in 0.040036102 seconds. Throughput is 2997.295 records/second. Loss is 0.2738942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005210504376823677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11760/60000][Iteration 4598][Wall Clock 214.012546646s] Trained 120 records in 0.040493906 seconds. Throughput is 2963.409 records/second. Loss is 0.3196711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005209961446285298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 11880/60000][Iteration 4599][Wall Clock 214.053018638s] Trained 120 records in 0.040471992 seconds. Throughput is 2965.0134 records/second. Loss is 0.34088627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005209418628881017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12000/60000][Iteration 4600][Wall Clock 214.093571833s] Trained 120 records in 0.040553195 seconds. Throughput is 2959.0764 records/second. Loss is 0.16072969. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005208875924575477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12120/60000][Iteration 4601][Wall Clock 214.13483012s] Trained 120 records in 0.041258287 seconds. Throughput is 2908.5066 records/second. Loss is 0.2143577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005208333333333334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12240/60000][Iteration 4602][Wall Clock 214.176270212s] Trained 120 records in 0.041440092 seconds. Throughput is 2895.7466 records/second. Loss is 0.18433826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005207790855119259. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12360/60000][Iteration 4603][Wall Clock 214.217260159s] Trained 120 records in 0.040989947 seconds. Throughput is 2927.547 records/second. Loss is 0.21265702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052072484898979384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12480/60000][Iteration 4604][Wall Clock 214.25739273s] Trained 120 records in 0.040132571 seconds. Throughput is 2990.09 records/second. Loss is 0.23103423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005206706237634072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12600/60000][Iteration 4605][Wall Clock 214.297395495s] Trained 120 records in 0.040002765 seconds. Throughput is 2999.7927 records/second. Loss is 0.26183546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005206164098292378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12720/60000][Iteration 4606][Wall Clock 214.338502027s] Trained 120 records in 0.041106532 seconds. Throughput is 2919.244 records/second. Loss is 0.13525827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0052056220718375845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12840/60000][Iteration 4607][Wall Clock 214.379907441s] Trained 120 records in 0.041405414 seconds. Throughput is 2898.1719 records/second. Loss is 0.31143343. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005205080158234437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 12960/60000][Iteration 4608][Wall Clock 214.427566567s] Trained 120 records in 0.047659126 seconds. Throughput is 2517.8809 records/second. Loss is 0.22352356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005204538357447695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 13080/60000][Iteration 4609][Wall Clock 214.476436847s] Trained 120 records in 0.04887028 seconds. Throughput is 2455.48 records/second. Loss is 0.21372625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005203996669442131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 13200/60000][Iteration 4610][Wall Clock 214.517615507s] Trained 120 records in 0.04117866 seconds. Throughput is 2914.1309 records/second. Loss is 0.17052196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005203455094182537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:40 INFO  DistriOptimizer$:406 - [Epoch 10 13320/60000][Iteration 4611][Wall Clock 214.558364332s] Trained 120 records in 0.040748825 seconds. Throughput is 2944.8704 records/second. Loss is 0.16160314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005202913631633715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 13440/60000][Iteration 4612][Wall Clock 214.599162025s] Trained 120 records in 0.040797693 seconds. Throughput is 2941.3428 records/second. Loss is 0.17023662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005202372281760482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 13560/60000][Iteration 4613][Wall Clock 214.639732103s] Trained 120 records in 0.040570078 seconds. Throughput is 2957.845 records/second. Loss is 0.22334233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005201831044527674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 13680/60000][Iteration 4614][Wall Clock 214.683585118s] Trained 120 records in 0.043853015 seconds. Throughput is 2736.4138 records/second. Loss is 0.16029449. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005201289919900135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 13800/60000][Iteration 4615][Wall Clock 214.72428801s] Trained 120 records in 0.040702892 seconds. Throughput is 2948.1936 records/second. Loss is 0.20598838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00520074890784273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 13920/60000][Iteration 4616][Wall Clock 214.764895611s] Trained 120 records in 0.040607601 seconds. Throughput is 2955.1118 records/second. Loss is 0.21881059. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005200208008320333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14040/60000][Iteration 4617][Wall Clock 214.805283942s] Trained 120 records in 0.040388331 seconds. Throughput is 2971.1553 records/second. Loss is 0.22390811. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005199667221297837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14160/60000][Iteration 4618][Wall Clock 214.845979882s] Trained 120 records in 0.04069594 seconds. Throughput is 2948.6973 records/second. Loss is 0.22351088. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005199126546740148. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14280/60000][Iteration 4619][Wall Clock 214.886791796s] Trained 120 records in 0.040811914 seconds. Throughput is 2940.3179 records/second. Loss is 0.16623506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051985859846121855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14400/60000][Iteration 4620][Wall Clock 214.935174281s] Trained 120 records in 0.048382485 seconds. Throughput is 2480.2366 records/second. Loss is 0.31679326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005198045534878886. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14520/60000][Iteration 4621][Wall Clock 214.982353991s] Trained 120 records in 0.04717971 seconds. Throughput is 2543.4663 records/second. Loss is 0.22183983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005197505197505198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14640/60000][Iteration 4622][Wall Clock 215.023998119s] Trained 120 records in 0.041644128 seconds. Throughput is 2881.5588 records/second. Loss is 0.12791373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005196964972456086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14760/60000][Iteration 4623][Wall Clock 215.064976256s] Trained 120 records in 0.040978137 seconds. Throughput is 2928.3909 records/second. Loss is 0.2197067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005196424859696529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 14880/60000][Iteration 4624][Wall Clock 215.106224987s] Trained 120 records in 0.041248731 seconds. Throughput is 2909.1804 records/second. Loss is 0.20641495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051958848591915205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15000/60000][Iteration 4625][Wall Clock 215.147127405s] Trained 120 records in 0.040902418 seconds. Throughput is 2933.812 records/second. Loss is 0.18739194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005195344970906068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15120/60000][Iteration 4626][Wall Clock 215.189158115s] Trained 120 records in 0.04203071 seconds. Throughput is 2855.0552 records/second. Loss is 0.2030271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005194805194805195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15240/60000][Iteration 4627][Wall Clock 215.230233618s] Trained 120 records in 0.041075503 seconds. Throughput is 2921.4495 records/second. Loss is 0.22687565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005194265530853937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15360/60000][Iteration 4628][Wall Clock 215.270947002s] Trained 120 records in 0.040713384 seconds. Throughput is 2947.4336 records/second. Loss is 0.11242283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005193725979017347. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15480/60000][Iteration 4629][Wall Clock 215.315480495s] Trained 120 records in 0.044533493 seconds. Throughput is 2694.601 records/second. Loss is 0.2690174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00519318653926049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15600/60000][Iteration 4630][Wall Clock 215.356723011s] Trained 120 records in 0.041242516 seconds. Throughput is 2909.6187 records/second. Loss is 0.19722652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005192647211548447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15720/60000][Iteration 4631][Wall Clock 215.397309778s] Trained 120 records in 0.040586767 seconds. Throughput is 2956.6287 records/second. Loss is 0.19489701. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005192107995846313. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15840/60000][Iteration 4632][Wall Clock 215.4401236s] Trained 120 records in 0.042813822 seconds. Throughput is 2802.833 records/second. Loss is 0.18819705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051915688921191985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 15960/60000][Iteration 4633][Wall Clock 215.497865426s] Trained 120 records in 0.057741826 seconds. Throughput is 2078.2163 records/second. Loss is 0.13409439. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005191029900332226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:41 INFO  DistriOptimizer$:406 - [Epoch 10 16080/60000][Iteration 4634][Wall Clock 215.54651332s] Trained 120 records in 0.048647894 seconds. Throughput is 2466.7048 records/second. Loss is 0.3190947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005190491020450535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 16200/60000][Iteration 4635][Wall Clock 215.58713829s] Trained 120 records in 0.04062497 seconds. Throughput is 2953.8484 records/second. Loss is 0.20741114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005189952252439277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 16320/60000][Iteration 4636][Wall Clock 215.62731287s] Trained 120 records in 0.04017458 seconds. Throughput is 2986.9634 records/second. Loss is 0.19580434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005189413596263622. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 16440/60000][Iteration 4637][Wall Clock 215.667783503s] Trained 120 records in 0.040470633 seconds. Throughput is 2965.113 records/second. Loss is 0.22888105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00518887505188875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 16560/60000][Iteration 4638][Wall Clock 215.707288915s] Trained 120 records in 0.039505412 seconds. Throughput is 3037.5586 records/second. Loss is 0.2514214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005188336619279859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 16680/60000][Iteration 4639][Wall Clock 215.747382573s] Trained 120 records in 0.040093658 seconds. Throughput is 2992.9922 records/second. Loss is 0.16659543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005187798298402158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 16800/60000][Iteration 4640][Wall Clock 215.787739008s] Trained 120 records in 0.040356435 seconds. Throughput is 2973.5034 records/second. Loss is 0.19507335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005187260089220874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 16920/60000][Iteration 4641][Wall Clock 215.82714208s] Trained 120 records in 0.039403072 seconds. Throughput is 3045.4478 records/second. Loss is 0.3624941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051867219917012455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17040/60000][Iteration 4642][Wall Clock 215.866774027s] Trained 120 records in 0.039631947 seconds. Throughput is 3027.8604 records/second. Loss is 0.20007817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005186184005808526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17160/60000][Iteration 4643][Wall Clock 215.906931773s] Trained 120 records in 0.040157746 seconds. Throughput is 2988.2156 records/second. Loss is 0.2515473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005185646131507986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17280/60000][Iteration 4644][Wall Clock 215.947278988s] Trained 120 records in 0.040347215 seconds. Throughput is 2974.183 records/second. Loss is 0.17095722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005185108368764907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17400/60000][Iteration 4645][Wall Clock 215.987735651s] Trained 120 records in 0.040456663 seconds. Throughput is 2966.1367 records/second. Loss is 0.3007169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051845707175445874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17520/60000][Iteration 4646][Wall Clock 216.028475695s] Trained 120 records in 0.040740044 seconds. Throughput is 2945.505 records/second. Loss is 0.2845526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005184033177812338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17640/60000][Iteration 4647][Wall Clock 216.083094217s] Trained 120 records in 0.054618522 seconds. Throughput is 2197.057 records/second. Loss is 0.17096679. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005183495749533485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17760/60000][Iteration 4648][Wall Clock 216.12743263s] Trained 120 records in 0.044338413 seconds. Throughput is 2706.4568 records/second. Loss is 0.25240433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00518295843267337. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 17880/60000][Iteration 4649][Wall Clock 216.167645906s] Trained 120 records in 0.040213276 seconds. Throughput is 2984.089 records/second. Loss is 0.28158882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005182421227197346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18000/60000][Iteration 4650][Wall Clock 216.208866908s] Trained 120 records in 0.041221002 seconds. Throughput is 2911.1375 records/second. Loss is 0.2718982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005181884133070784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18120/60000][Iteration 4651][Wall Clock 216.252495119s] Trained 120 records in 0.043628211 seconds. Throughput is 2750.514 records/second. Loss is 0.1722407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005181347150259067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18240/60000][Iteration 4652][Wall Clock 216.294041839s] Trained 120 records in 0.04154672 seconds. Throughput is 2888.3147 records/second. Loss is 0.22230254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005180810278727592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18360/60000][Iteration 4653][Wall Clock 216.335525889s] Trained 120 records in 0.04148405 seconds. Throughput is 2892.678 records/second. Loss is 0.18496798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005180273518441774. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18480/60000][Iteration 4654][Wall Clock 216.37770112s] Trained 120 records in 0.042175231 seconds. Throughput is 2845.272 records/second. Loss is 0.26343256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005179736869367036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18600/60000][Iteration 4655][Wall Clock 216.419244507s] Trained 120 records in 0.041543387 seconds. Throughput is 2888.5464 records/second. Loss is 0.15431659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005179200331468821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18720/60000][Iteration 4656][Wall Clock 216.460974645s] Trained 120 records in 0.041730138 seconds. Throughput is 2875.6194 records/second. Loss is 0.2022615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005178663904712584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18840/60000][Iteration 4657][Wall Clock 216.501922631s] Trained 120 records in 0.040947986 seconds. Throughput is 2930.547 records/second. Loss is 0.27628842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051781275890637945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:42 INFO  DistriOptimizer$:406 - [Epoch 10 18960/60000][Iteration 4658][Wall Clock 216.543577886s] Trained 120 records in 0.041655255 seconds. Throughput is 2880.789 records/second. Loss is 0.21476725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005177591384487936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19080/60000][Iteration 4659][Wall Clock 216.600030981s] Trained 120 records in 0.056453095 seconds. Throughput is 2125.6584 records/second. Loss is 0.2610568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051770552909505075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19200/60000][Iteration 4660][Wall Clock 216.642335272s] Trained 120 records in 0.042304291 seconds. Throughput is 2836.5916 records/second. Loss is 0.28271613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00517651930841702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19320/60000][Iteration 4661][Wall Clock 216.682761643s] Trained 120 records in 0.040426371 seconds. Throughput is 2968.3596 records/second. Loss is 0.19189507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005175983436853002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19440/60000][Iteration 4662][Wall Clock 216.723047789s] Trained 120 records in 0.040286146 seconds. Throughput is 2978.6914 records/second. Loss is 0.18819155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005175447676223994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19560/60000][Iteration 4663][Wall Clock 216.763340222s] Trained 120 records in 0.040292433 seconds. Throughput is 2978.2266 records/second. Loss is 0.27811536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00517491202649555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19680/60000][Iteration 4664][Wall Clock 216.803860142s] Trained 120 records in 0.04051992 seconds. Throughput is 2961.5063 records/second. Loss is 0.23639533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00517437648763324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19800/60000][Iteration 4665][Wall Clock 216.844193238s] Trained 120 records in 0.040333096 seconds. Throughput is 2975.224 records/second. Loss is 0.20694545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051738410596026485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 19920/60000][Iteration 4666][Wall Clock 216.884936518s] Trained 120 records in 0.04074328 seconds. Throughput is 2945.271 records/second. Loss is 0.15929295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005173305742369374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20040/60000][Iteration 4667][Wall Clock 216.925930122s] Trained 120 records in 0.040993604 seconds. Throughput is 2927.286 records/second. Loss is 0.2542208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051727705358990276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20160/60000][Iteration 4668][Wall Clock 216.966812632s] Trained 120 records in 0.04088251 seconds. Throughput is 2935.2405 records/second. Loss is 0.28467742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005172235440157236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20280/60000][Iteration 4669][Wall Clock 217.007627552s] Trained 120 records in 0.04081492 seconds. Throughput is 2940.1013 records/second. Loss is 0.1573334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00517170045510964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20400/60000][Iteration 4670][Wall Clock 217.051766798s] Trained 120 records in 0.044139246 seconds. Throughput is 2718.669 records/second. Loss is 0.1893271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005171165580721894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20520/60000][Iteration 4671][Wall Clock 217.092912023s] Trained 120 records in 0.041145225 seconds. Throughput is 2916.4988 records/second. Loss is 0.17213239. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005170630816959669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20640/60000][Iteration 4672][Wall Clock 217.134059789s] Trained 120 records in 0.041147766 seconds. Throughput is 2916.3188 records/second. Loss is 0.28119722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005170096163788647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20760/60000][Iteration 4673][Wall Clock 217.185599186s] Trained 120 records in 0.051539397 seconds. Throughput is 2328.316 records/second. Loss is 0.21595179. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005169561621174525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 20880/60000][Iteration 4674][Wall Clock 217.234187109s] Trained 120 records in 0.048587923 seconds. Throughput is 2469.7495 records/second. Loss is 0.27163675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051690271890830145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21000/60000][Iteration 4675][Wall Clock 217.275359314s] Trained 120 records in 0.041172205 seconds. Throughput is 2914.5876 records/second. Loss is 0.22007014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051684928674798425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21120/60000][Iteration 4676][Wall Clock 217.316478329s] Trained 120 records in 0.041119015 seconds. Throughput is 2918.3577 records/second. Loss is 0.2765351. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00516795865633075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21240/60000][Iteration 4677][Wall Clock 217.357581726s] Trained 120 records in 0.041103397 seconds. Throughput is 2919.4668 records/second. Loss is 0.18086393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005167424555601488. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21360/60000][Iteration 4678][Wall Clock 217.39833851s] Trained 120 records in 0.040756784 seconds. Throughput is 2944.2952 records/second. Loss is 0.26553908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005166890565257828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21480/60000][Iteration 4679][Wall Clock 217.438933571s] Trained 120 records in 0.040595061 seconds. Throughput is 2956.0247 records/second. Loss is 0.18198468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051663566852655505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21600/60000][Iteration 4680][Wall Clock 217.479598666s] Trained 120 records in 0.040665095 seconds. Throughput is 2950.9338 records/second. Loss is 0.1827213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005165822915590454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21720/60000][Iteration 4681][Wall Clock 217.520163946s] Trained 120 records in 0.04056528 seconds. Throughput is 2958.1948 records/second. Loss is 0.20199557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005165289256198347. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:43 INFO  DistriOptimizer$:406 - [Epoch 10 21840/60000][Iteration 4682][Wall Clock 217.561405486s] Trained 120 records in 0.04124154 seconds. Throughput is 2909.6875 records/second. Loss is 0.16177277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005164755707055057. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 21960/60000][Iteration 4683][Wall Clock 217.602901534s] Trained 120 records in 0.041496048 seconds. Throughput is 2891.8416 records/second. Loss is 0.27455872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005164222268126421. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22080/60000][Iteration 4684][Wall Clock 217.650098782s] Trained 120 records in 0.047197248 seconds. Throughput is 2542.521 records/second. Loss is 0.21389748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005163688939378292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22200/60000][Iteration 4685][Wall Clock 217.694589038s] Trained 120 records in 0.044490256 seconds. Throughput is 2697.22 records/second. Loss is 0.15006842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005163155720776538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22320/60000][Iteration 4686][Wall Clock 217.734767104s] Trained 120 records in 0.040178066 seconds. Throughput is 2986.7043 records/second. Loss is 0.20344003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005162622612287042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22440/60000][Iteration 4687][Wall Clock 217.775502426s] Trained 120 records in 0.040735322 seconds. Throughput is 2945.8462 records/second. Loss is 0.23591945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005162089613875697. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22560/60000][Iteration 4688][Wall Clock 217.819056444s] Trained 120 records in 0.043554018 seconds. Throughput is 2755.1992 records/second. Loss is 0.32941687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005161556725508413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22680/60000][Iteration 4689][Wall Clock 217.858955566s] Trained 120 records in 0.039899122 seconds. Throughput is 3007.585 records/second. Loss is 0.2689811. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005161023947151114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22800/60000][Iteration 4690][Wall Clock 217.899757495s] Trained 120 records in 0.040801929 seconds. Throughput is 2941.0376 records/second. Loss is 0.28619644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005160491278769739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 22920/60000][Iteration 4691][Wall Clock 217.939959322s] Trained 120 records in 0.040201827 seconds. Throughput is 2984.939 records/second. Loss is 0.27296218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005159958720330237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23040/60000][Iteration 4692][Wall Clock 217.980424129s] Trained 120 records in 0.040464807 seconds. Throughput is 2965.5398 records/second. Loss is 0.18702479. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005159426271798576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23160/60000][Iteration 4693][Wall Clock 218.020734549s] Trained 120 records in 0.04031042 seconds. Throughput is 2976.8977 records/second. Loss is 0.24611595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005158893933140734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23280/60000][Iteration 4694][Wall Clock 218.061870833s] Trained 120 records in 0.041136284 seconds. Throughput is 2917.1328 records/second. Loss is 0.22310573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005158361704322707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23400/60000][Iteration 4695][Wall Clock 218.10403369s] Trained 120 records in 0.042162857 seconds. Throughput is 2846.107 records/second. Loss is 0.17618057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051578295853105015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23520/60000][Iteration 4696][Wall Clock 218.146750235s] Trained 120 records in 0.042716545 seconds. Throughput is 2809.216 records/second. Loss is 0.19162397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005157297576070139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23640/60000][Iteration 4697][Wall Clock 218.188878835s] Trained 120 records in 0.0421286 seconds. Throughput is 2848.4211 records/second. Loss is 0.4374436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005156765676567657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23760/60000][Iteration 4698][Wall Clock 218.229298398s] Trained 120 records in 0.040419563 seconds. Throughput is 2968.8594 records/second. Loss is 0.2638042. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005156233886769104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 23880/60000][Iteration 4699][Wall Clock 218.26970366s] Trained 120 records in 0.040405262 seconds. Throughput is 2969.9102 records/second. Loss is 0.28095385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005155702206640545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 24000/60000][Iteration 4700][Wall Clock 218.322510726s] Trained 120 records in 0.052807066 seconds. Throughput is 2272.423 records/second. Loss is 0.25737497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005155170636148057. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 24120/60000][Iteration 4701][Wall Clock 218.365990027s] Trained 120 records in 0.043479301 seconds. Throughput is 2759.934 records/second. Loss is 0.2865887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005154639175257732. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 24240/60000][Iteration 4702][Wall Clock 218.4063001s] Trained 120 records in 0.040310073 seconds. Throughput is 2976.9233 records/second. Loss is 0.2026843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005154107823935677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 24360/60000][Iteration 4703][Wall Clock 218.446210204s] Trained 120 records in 0.039910104 seconds. Throughput is 3006.7573 records/second. Loss is 0.27768597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005153576582148011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 24480/60000][Iteration 4704][Wall Clock 218.486484335s] Trained 120 records in 0.040274131 seconds. Throughput is 2979.58 records/second. Loss is 0.11826372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005153045449860868. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:44 INFO  DistriOptimizer$:406 - [Epoch 10 24600/60000][Iteration 4705][Wall Clock 218.526095536s] Trained 120 records in 0.039611201 seconds. Throughput is 3029.446 records/second. Loss is 0.17569381. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005152514427040396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 24720/60000][Iteration 4706][Wall Clock 218.566461458s] Trained 120 records in 0.040365922 seconds. Throughput is 2972.8044 records/second. Loss is 0.2114432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005151983513652756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 24840/60000][Iteration 4707][Wall Clock 218.610163865s] Trained 120 records in 0.043702407 seconds. Throughput is 2745.844 records/second. Loss is 0.17163886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005151452709664125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 24960/60000][Iteration 4708][Wall Clock 218.650984017s] Trained 120 records in 0.040820152 seconds. Throughput is 2939.7246 records/second. Loss is 0.21533397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005150922015040692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25080/60000][Iteration 4709][Wall Clock 218.699394089s] Trained 120 records in 0.048410072 seconds. Throughput is 2478.823 records/second. Loss is 0.32333067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005150391429748661. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25200/60000][Iteration 4710][Wall Clock 218.743593116s] Trained 120 records in 0.044199027 seconds. Throughput is 2714.992 records/second. Loss is 0.18958086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005149860953754248. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25320/60000][Iteration 4711][Wall Clock 218.784350504s] Trained 120 records in 0.040757388 seconds. Throughput is 2944.2515 records/second. Loss is 0.2101154. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005149330587023686. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25440/60000][Iteration 4712][Wall Clock 218.825420225s] Trained 120 records in 0.041069721 seconds. Throughput is 2921.8606 records/second. Loss is 0.21193044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005148800329523221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25560/60000][Iteration 4713][Wall Clock 218.865955993s] Trained 120 records in 0.040535768 seconds. Throughput is 2960.3486 records/second. Loss is 0.20095648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00514827018121911. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25680/60000][Iteration 4714][Wall Clock 218.90665152s] Trained 120 records in 0.040695527 seconds. Throughput is 2948.727 records/second. Loss is 0.21521707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005147740142077628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25800/60000][Iteration 4715][Wall Clock 218.947248113s] Trained 120 records in 0.040596593 seconds. Throughput is 2955.913 records/second. Loss is 0.1750969. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005147210212065061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 25920/60000][Iteration 4716][Wall Clock 218.98766009s] Trained 120 records in 0.040411977 seconds. Throughput is 2969.4167 records/second. Loss is 0.21791649. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051466803911477095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26040/60000][Iteration 4717][Wall Clock 219.028131402s] Trained 120 records in 0.040471312 seconds. Throughput is 2965.0632 records/second. Loss is 0.31441984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00514615067929189. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26160/60000][Iteration 4718][Wall Clock 219.069354056s] Trained 120 records in 0.041222654 seconds. Throughput is 2911.0208 records/second. Loss is 0.16310452. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005145621076463929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26280/60000][Iteration 4719][Wall Clock 219.109855542s] Trained 120 records in 0.040501486 seconds. Throughput is 2962.8542 records/second. Loss is 0.18533498. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005145091582630171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26400/60000][Iteration 4720][Wall Clock 219.150129645s] Trained 120 records in 0.040274103 seconds. Throughput is 2979.5823 records/second. Loss is 0.24627425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051445621977569715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26520/60000][Iteration 4721][Wall Clock 219.189939618s] Trained 120 records in 0.039809973 seconds. Throughput is 3014.32 records/second. Loss is 0.18313797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051440329218107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26640/60000][Iteration 4722][Wall Clock 219.229804157s] Trained 120 records in 0.039864539 seconds. Throughput is 3010.194 records/second. Loss is 0.16941331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005143503754757741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26760/60000][Iteration 4723][Wall Clock 219.270388603s] Trained 120 records in 0.040584446 seconds. Throughput is 2956.7979 records/second. Loss is 0.16110532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005142974696564493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 26880/60000][Iteration 4724][Wall Clock 219.311056558s] Trained 120 records in 0.040667955 seconds. Throughput is 2950.7263 records/second. Loss is 0.19051808. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005142445747197367. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 27000/60000][Iteration 4725][Wall Clock 219.35070726s] Trained 120 records in 0.039650702 seconds. Throughput is 3026.4282 records/second. Loss is 0.29320416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005141916906622789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 27120/60000][Iteration 4726][Wall Clock 219.402090102s] Trained 120 records in 0.051382842 seconds. Throughput is 2335.41 records/second. Loss is 0.33492672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005141388174807198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 27240/60000][Iteration 4727][Wall Clock 219.453559077s] Trained 120 records in 0.051468975 seconds. Throughput is 2331.5017 records/second. Loss is 0.12503876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005140859551717047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 27360/60000][Iteration 4728][Wall Clock 219.498763314s] Trained 120 records in 0.045204237 seconds. Throughput is 2654.6184 records/second. Loss is 0.17455277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005140331037318803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:45 INFO  DistriOptimizer$:406 - [Epoch 10 27480/60000][Iteration 4729][Wall Clock 219.539944857s] Trained 120 records in 0.041181543 seconds. Throughput is 2913.9268 records/second. Loss is 0.24284236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005139802631578948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 27600/60000][Iteration 4730][Wall Clock 219.581307215s] Trained 120 records in 0.041362358 seconds. Throughput is 2901.1887 records/second. Loss is 0.24740349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005139274334463973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 27720/60000][Iteration 4731][Wall Clock 219.621895644s] Trained 120 records in 0.040588429 seconds. Throughput is 2956.5078 records/second. Loss is 0.20978521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051387461459403904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 27840/60000][Iteration 4732][Wall Clock 219.662736716s] Trained 120 records in 0.040841072 seconds. Throughput is 2938.2185 records/second. Loss is 0.18473807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051382180659747196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 27960/60000][Iteration 4733][Wall Clock 219.704413369s] Trained 120 records in 0.041676653 seconds. Throughput is 2879.31 records/second. Loss is 0.19793914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005137690094533498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28080/60000][Iteration 4734][Wall Clock 219.74633973s] Trained 120 records in 0.041926361 seconds. Throughput is 2862.1611 records/second. Loss is 0.21155074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005137162231583273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28200/60000][Iteration 4735][Wall Clock 219.798282019s] Trained 120 records in 0.051942289 seconds. Throughput is 2310.2563 records/second. Loss is 0.19459294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00513663447709061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28320/60000][Iteration 4736][Wall Clock 219.839458123s] Trained 120 records in 0.041176104 seconds. Throughput is 2914.3118 records/second. Loss is 0.20626643. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005136106831022085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28440/60000][Iteration 4737][Wall Clock 219.879390382s] Trained 120 records in 0.039932259 seconds. Throughput is 3005.0894 records/second. Loss is 0.28118867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005135579293344289. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28560/60000][Iteration 4738][Wall Clock 219.91971286s] Trained 120 records in 0.040322478 seconds. Throughput is 2976.0076 records/second. Loss is 0.3115581. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005135051864023826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28680/60000][Iteration 4739][Wall Clock 219.959682104s] Trained 120 records in 0.039969244 seconds. Throughput is 3002.3086 records/second. Loss is 0.26248834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051345245430273155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28800/60000][Iteration 4740][Wall Clock 220.000470104s] Trained 120 records in 0.040788 seconds. Throughput is 2942.042 records/second. Loss is 0.18969704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005133997330321389. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 28920/60000][Iteration 4741][Wall Clock 220.041753289s] Trained 120 records in 0.041283185 seconds. Throughput is 2906.7524 records/second. Loss is 0.15721874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051334702258726906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29040/60000][Iteration 4742][Wall Clock 220.082890922s] Trained 120 records in 0.041137633 seconds. Throughput is 2917.037 records/second. Loss is 0.33039093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005132943229647881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29160/60000][Iteration 4743][Wall Clock 220.123856891s] Trained 120 records in 0.040965969 seconds. Throughput is 2929.2605 records/second. Loss is 0.27959517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005132416341613632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29280/60000][Iteration 4744][Wall Clock 220.168416686s] Trained 120 records in 0.044559795 seconds. Throughput is 2693.0105 records/second. Loss is 0.2193285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005131889561736632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29400/60000][Iteration 4745][Wall Clock 220.208611751s] Trained 120 records in 0.040195065 seconds. Throughput is 2985.441 records/second. Loss is 0.19638446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051313628899835794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29520/60000][Iteration 4746][Wall Clock 220.249151669s] Trained 120 records in 0.040539918 seconds. Throughput is 2960.0457 records/second. Loss is 0.28018036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00513083632632119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29640/60000][Iteration 4747][Wall Clock 220.290191792s] Trained 120 records in 0.041040123 seconds. Throughput is 2923.9678 records/second. Loss is 0.21626191. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005130309870716191. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29760/60000][Iteration 4748][Wall Clock 220.331858381s] Trained 120 records in 0.041666589 seconds. Throughput is 2880.0054 records/second. Loss is 0.28470424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005129783523135324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 29880/60000][Iteration 4749][Wall Clock 220.373075051s] Trained 120 records in 0.04121667 seconds. Throughput is 2911.4434 records/second. Loss is 0.17204067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051292572835453425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 30000/60000][Iteration 4750][Wall Clock 220.415877986s] Trained 120 records in 0.042802935 seconds. Throughput is 2803.5461 records/second. Loss is 0.18431887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005128731151913016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 30120/60000][Iteration 4751][Wall Clock 220.457326023s] Trained 120 records in 0.041448037 seconds. Throughput is 2895.1914 records/second. Loss is 0.31470463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005128205128205128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:46 INFO  DistriOptimizer$:406 - [Epoch 10 30240/60000][Iteration 4752][Wall Clock 220.498811474s] Trained 120 records in 0.041485451 seconds. Throughput is 2892.5803 records/second. Loss is 0.19786805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005127679212388473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 30360/60000][Iteration 4753][Wall Clock 220.548219818s] Trained 120 records in 0.049408344 seconds. Throughput is 2428.7397 records/second. Loss is 0.23802043. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00512715340442986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 30480/60000][Iteration 4754][Wall Clock 220.598495946s] Trained 120 records in 0.050276128 seconds. Throughput is 2386.8186 records/second. Loss is 0.20773195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051266277042961135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 30600/60000][Iteration 4755][Wall Clock 220.640546794s] Trained 120 records in 0.042050848 seconds. Throughput is 2853.688 records/second. Loss is 0.26692826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00512610211195407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 30720/60000][Iteration 4756][Wall Clock 220.68145763s] Trained 120 records in 0.040910836 seconds. Throughput is 2933.2083 records/second. Loss is 0.2073651. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005125576627370579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 30840/60000][Iteration 4757][Wall Clock 220.723277296s] Trained 120 records in 0.041819666 seconds. Throughput is 2869.4634 records/second. Loss is 0.23888366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005125051250512505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 30960/60000][Iteration 4758][Wall Clock 220.765732458s] Trained 120 records in 0.042455162 seconds. Throughput is 2826.5115 records/second. Loss is 0.24519028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005124525981346726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31080/60000][Iteration 4759][Wall Clock 220.808135246s] Trained 120 records in 0.042402788 seconds. Throughput is 2830.0024 records/second. Loss is 0.18468256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005124000819840132. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31200/60000][Iteration 4760][Wall Clock 220.848481123s] Trained 120 records in 0.040345877 seconds. Throughput is 2974.2815 records/second. Loss is 0.23246816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005123475765959627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31320/60000][Iteration 4761][Wall Clock 220.898115153s] Trained 120 records in 0.04963403 seconds. Throughput is 2417.6963 records/second. Loss is 0.18439023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005122950819672132. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31440/60000][Iteration 4762][Wall Clock 220.940960059s] Trained 120 records in 0.042844906 seconds. Throughput is 2800.7996 records/second. Loss is 0.17744058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051224259809445755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31560/60000][Iteration 4763][Wall Clock 220.985339844s] Trained 120 records in 0.044379785 seconds. Throughput is 2703.9338 records/second. Loss is 0.2770373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005121901249743905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31680/60000][Iteration 4764][Wall Clock 221.026222007s] Trained 120 records in 0.040882163 seconds. Throughput is 2935.2654 records/second. Loss is 0.13327621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005121376626037079. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31800/60000][Iteration 4765][Wall Clock 221.067247577s] Trained 120 records in 0.04102557 seconds. Throughput is 2925.005 records/second. Loss is 0.25803334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005120852109791069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 31920/60000][Iteration 4766][Wall Clock 221.108235559s] Trained 120 records in 0.040987982 seconds. Throughput is 2927.6873 records/second. Loss is 0.17640263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005120327700972862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32040/60000][Iteration 4767][Wall Clock 221.149019184s] Trained 120 records in 0.040783625 seconds. Throughput is 2942.3574 records/second. Loss is 0.1547925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005119803399549457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32160/60000][Iteration 4768][Wall Clock 221.189379736s] Trained 120 records in 0.040360552 seconds. Throughput is 2973.2002 records/second. Loss is 0.19107372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005119279205487867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32280/60000][Iteration 4769][Wall Clock 221.229843822s] Trained 120 records in 0.040464086 seconds. Throughput is 2965.5928 records/second. Loss is 0.22800516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005118755118755119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32400/60000][Iteration 4770][Wall Clock 221.269974929s] Trained 120 records in 0.040131107 seconds. Throughput is 2990.1992 records/second. Loss is 0.21136467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005118231139318251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32520/60000][Iteration 4771][Wall Clock 221.310126657s] Trained 120 records in 0.040151728 seconds. Throughput is 2988.6636 records/second. Loss is 0.32131225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005117707267144319. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32640/60000][Iteration 4772][Wall Clock 221.350133057s] Trained 120 records in 0.0400064 seconds. Throughput is 2999.52 records/second. Loss is 0.21249978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005117183502200389. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32760/60000][Iteration 4773][Wall Clock 221.390407754s] Trained 120 records in 0.040274697 seconds. Throughput is 2979.538 records/second. Loss is 0.31550774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00511665984445354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 32880/60000][Iteration 4774][Wall Clock 221.43083414s] Trained 120 records in 0.040426386 seconds. Throughput is 2968.3584 records/second. Loss is 0.25631344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005116136293870869. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 33000/60000][Iteration 4775][Wall Clock 221.470677853s] Trained 120 records in 0.039843713 seconds. Throughput is 3011.7676 records/second. Loss is 0.21441929. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00511561285041948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:47 INFO  DistriOptimizer$:406 - [Epoch 10 33120/60000][Iteration 4776][Wall Clock 221.511231001s] Trained 120 records in 0.040553148 seconds. Throughput is 2959.0798 records/second. Loss is 0.22395737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005115089514066496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 33240/60000][Iteration 4777][Wall Clock 221.551684775s] Trained 120 records in 0.040453774 seconds. Throughput is 2966.3489 records/second. Loss is 0.17711382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005114566284779051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 33360/60000][Iteration 4778][Wall Clock 221.592451416s] Trained 120 records in 0.040766641 seconds. Throughput is 2943.5833 records/second. Loss is 0.11836003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005114043162524291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 33480/60000][Iteration 4779][Wall Clock 221.632926744s] Trained 120 records in 0.040475328 seconds. Throughput is 2964.769 records/second. Loss is 0.27303302. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005113520147269381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 33600/60000][Iteration 4780][Wall Clock 221.683342154s] Trained 120 records in 0.05041541 seconds. Throughput is 2380.2246 records/second. Loss is 0.27397627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005112997238981491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 33720/60000][Iteration 4781][Wall Clock 221.729273886s] Trained 120 records in 0.045931732 seconds. Throughput is 2612.573 records/second. Loss is 0.18171738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005112474437627812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 33840/60000][Iteration 4782][Wall Clock 221.773961038s] Trained 120 records in 0.044687152 seconds. Throughput is 2685.3357 records/second. Loss is 0.3207467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051119517431755445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 33960/60000][Iteration 4783][Wall Clock 221.815211447s] Trained 120 records in 0.041250409 seconds. Throughput is 2909.0623 records/second. Loss is 0.15020794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005111429155591904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34080/60000][Iteration 4784][Wall Clock 221.856296424s] Trained 120 records in 0.041084977 seconds. Throughput is 2920.7756 records/second. Loss is 0.20680065. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005110906674844117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34200/60000][Iteration 4785][Wall Clock 221.897749189s] Trained 120 records in 0.041452765 seconds. Throughput is 2894.861 records/second. Loss is 0.109656364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005110384300899428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34320/60000][Iteration 4786][Wall Clock 221.938588018s] Trained 120 records in 0.040838829 seconds. Throughput is 2938.38 records/second. Loss is 0.18378107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005109862033725089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34440/60000][Iteration 4787][Wall Clock 221.979627072s] Trained 120 records in 0.041039054 seconds. Throughput is 2924.044 records/second. Loss is 0.18026559. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005109339873288371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34560/60000][Iteration 4788][Wall Clock 222.028550461s] Trained 120 records in 0.048923389 seconds. Throughput is 2452.8147 records/second. Loss is 0.23159885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051088178195565544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34680/60000][Iteration 4789][Wall Clock 222.072058992s] Trained 120 records in 0.043508531 seconds. Throughput is 2758.0798 records/second. Loss is 0.2067825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051082958724969355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34800/60000][Iteration 4790][Wall Clock 222.112862088s] Trained 120 records in 0.040803096 seconds. Throughput is 2940.9531 records/second. Loss is 0.22194144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00510777403207682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 34920/60000][Iteration 4791][Wall Clock 222.152851921s] Trained 120 records in 0.039989833 seconds. Throughput is 3000.7627 records/second. Loss is 0.14076576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005107252298263534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35040/60000][Iteration 4792][Wall Clock 222.193194489s] Trained 120 records in 0.040342568 seconds. Throughput is 2974.5254 records/second. Loss is 0.21096562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00510673067102441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35160/60000][Iteration 4793][Wall Clock 222.234046901s] Trained 120 records in 0.040852412 seconds. Throughput is 2937.403 records/second. Loss is 0.24485561. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051062091503267975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35280/60000][Iteration 4794][Wall Clock 222.27433215s] Trained 120 records in 0.040285249 seconds. Throughput is 2978.7578 records/second. Loss is 0.2726533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005105687736138058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35400/60000][Iteration 4795][Wall Clock 222.314328769s] Trained 120 records in 0.039996619 seconds. Throughput is 3000.2534 records/second. Loss is 0.2648965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005105166428425566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35520/60000][Iteration 4796][Wall Clock 222.355750022s] Trained 120 records in 0.041421253 seconds. Throughput is 2897.0635 records/second. Loss is 0.2231792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005104645227156712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35640/60000][Iteration 4797][Wall Clock 222.396975034s] Trained 120 records in 0.041225012 seconds. Throughput is 2910.8542 records/second. Loss is 0.22703364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005104124132298897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35760/60000][Iteration 4798][Wall Clock 222.438568092s] Trained 120 records in 0.041593058 seconds. Throughput is 2885.097 records/second. Loss is 0.24753062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005103603143819537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 35880/60000][Iteration 4799][Wall Clock 222.479203273s] Trained 120 records in 0.040635181 seconds. Throughput is 2953.1062 records/second. Loss is 0.19134213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005103082261686058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:48 INFO  DistriOptimizer$:406 - [Epoch 10 36000/60000][Iteration 4800][Wall Clock 222.519416103s] Trained 120 records in 0.04021283 seconds. Throughput is 2984.1223 records/second. Loss is 0.23844592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005102561485865905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36120/60000][Iteration 4801][Wall Clock 222.563563255s] Trained 120 records in 0.044147152 seconds. Throughput is 2718.1821 records/second. Loss is 0.21998814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005102040816326531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36240/60000][Iteration 4802][Wall Clock 222.604573475s] Trained 120 records in 0.04101022 seconds. Throughput is 2926.0999 records/second. Loss is 0.1576717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005101520253035405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36360/60000][Iteration 4803][Wall Clock 222.64500897s] Trained 120 records in 0.040435495 seconds. Throughput is 2967.6895 records/second. Loss is 0.25712064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005100999795960008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36480/60000][Iteration 4804][Wall Clock 222.685736271s] Trained 120 records in 0.040727301 seconds. Throughput is 2946.4265 records/second. Loss is 0.24272124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0051004794450678365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36600/60000][Iteration 4805][Wall Clock 222.72611696s] Trained 120 records in 0.040380689 seconds. Throughput is 2971.7173 records/second. Loss is 0.20392251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005099959200326397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36720/60000][Iteration 4806][Wall Clock 222.774492456s] Trained 120 records in 0.048375496 seconds. Throughput is 2480.5947 records/second. Loss is 0.21985584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005099439061703213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36840/60000][Iteration 4807][Wall Clock 222.823344753s] Trained 120 records in 0.048852297 seconds. Throughput is 2456.384 records/second. Loss is 0.20152807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005098919029165817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 36960/60000][Iteration 4808][Wall Clock 222.868867483s] Trained 120 records in 0.04552273 seconds. Throughput is 2636.0457 records/second. Loss is 0.17787538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005098399102681758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37080/60000][Iteration 4809][Wall Clock 222.910200299s] Trained 120 records in 0.041332816 seconds. Throughput is 2903.2622 records/second. Loss is 0.17873703. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005097879282218597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37200/60000][Iteration 4810][Wall Clock 222.950343204s] Trained 120 records in 0.040142905 seconds. Throughput is 2989.3203 records/second. Loss is 0.2562359. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005097359567743908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37320/60000][Iteration 4811][Wall Clock 222.990718831s] Trained 120 records in 0.040375627 seconds. Throughput is 2972.09 records/second. Loss is 0.17480744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00509683995922528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37440/60000][Iteration 4812][Wall Clock 223.031714313s] Trained 120 records in 0.040995482 seconds. Throughput is 2927.1519 records/second. Loss is 0.19783553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005096320456630312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37560/60000][Iteration 4813][Wall Clock 223.071776505s] Trained 120 records in 0.040062192 seconds. Throughput is 2995.3428 records/second. Loss is 0.18921515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005095801059926621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37680/60000][Iteration 4814][Wall Clock 223.11943154s] Trained 120 records in 0.047655035 seconds. Throughput is 2518.097 records/second. Loss is 0.18720588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00509528176908183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37800/60000][Iteration 4815][Wall Clock 223.164062236s] Trained 120 records in 0.044630696 seconds. Throughput is 2688.7324 records/second. Loss is 0.19687648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005094762584063582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 37920/60000][Iteration 4816][Wall Clock 223.204223626s] Trained 120 records in 0.04016139 seconds. Throughput is 2987.9443 records/second. Loss is 0.31248888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005094243504839531. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38040/60000][Iteration 4817][Wall Clock 223.244126693s] Trained 120 records in 0.039903067 seconds. Throughput is 3007.2876 records/second. Loss is 0.26483068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005093724531377343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38160/60000][Iteration 4818][Wall Clock 223.284492409s] Trained 120 records in 0.040365716 seconds. Throughput is 2972.8198 records/second. Loss is 0.20461169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005093205663644698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38280/60000][Iteration 4819][Wall Clock 223.327959226s] Trained 120 records in 0.043466817 seconds. Throughput is 2760.7266 records/second. Loss is 0.17354694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005092686901609289. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38400/60000][Iteration 4820][Wall Clock 223.368930753s] Trained 120 records in 0.040971527 seconds. Throughput is 2928.863 records/second. Loss is 0.30190966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050921682452388225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38520/60000][Iteration 4821][Wall Clock 223.409614039s] Trained 120 records in 0.040683286 seconds. Throughput is 2949.6143 records/second. Loss is 0.20830281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050916496945010185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38640/60000][Iteration 4822][Wall Clock 223.450811665s] Trained 120 records in 0.041197626 seconds. Throughput is 2912.789 records/second. Loss is 0.16668399. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005091131249363609. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38760/60000][Iteration 4823][Wall Clock 223.491520317s] Trained 120 records in 0.040708652 seconds. Throughput is 2947.7761 records/second. Loss is 0.23953125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005090612909794339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:49 INFO  DistriOptimizer$:406 - [Epoch 10 38880/60000][Iteration 4824][Wall Clock 223.531998987s] Trained 120 records in 0.04047867 seconds. Throughput is 2964.5244 records/second. Loss is 0.28888357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00509009467576097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39000/60000][Iteration 4825][Wall Clock 223.572148585s] Trained 120 records in 0.040149598 seconds. Throughput is 2988.8218 records/second. Loss is 0.17060825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005089576547231271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39120/60000][Iteration 4826][Wall Clock 223.612215922s] Trained 120 records in 0.040067337 seconds. Throughput is 2994.9583 records/second. Loss is 0.18135993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050890585241730275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39240/60000][Iteration 4827][Wall Clock 223.65242366s] Trained 120 records in 0.040207738 seconds. Throughput is 2984.5002 records/second. Loss is 0.2785911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00508854060655404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39360/60000][Iteration 4828][Wall Clock 223.693200786s] Trained 120 records in 0.040777126 seconds. Throughput is 2942.8264 records/second. Loss is 0.3204824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005088022794342118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39480/60000][Iteration 4829][Wall Clock 223.733300665s] Trained 120 records in 0.040099879 seconds. Throughput is 2992.5278 records/second. Loss is 0.30004737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005087505087505087. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39600/60000][Iteration 4830][Wall Clock 223.772922811s] Trained 120 records in 0.039622146 seconds. Throughput is 3028.6094 records/second. Loss is 0.3187164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005086987486010785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39720/60000][Iteration 4831][Wall Clock 223.812831638s] Trained 120 records in 0.039908827 seconds. Throughput is 3006.8538 records/second. Loss is 0.21955055. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050864699898270594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39840/60000][Iteration 4832][Wall Clock 223.861051836s] Trained 120 records in 0.048220198 seconds. Throughput is 2488.5837 records/second. Loss is 0.18785912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005085952598921778. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 39960/60000][Iteration 4833][Wall Clock 223.911101784s] Trained 120 records in 0.050049948 seconds. Throughput is 2397.6047 records/second. Loss is 0.35294268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005085435313262815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40080/60000][Iteration 4834][Wall Clock 223.95801879s] Trained 120 records in 0.046917006 seconds. Throughput is 2557.708 records/second. Loss is 0.17446207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005084918132818061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40200/60000][Iteration 4835][Wall Clock 223.998910686s] Trained 120 records in 0.040891896 seconds. Throughput is 2934.5667 records/second. Loss is 0.2153026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00508440105755542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40320/60000][Iteration 4836][Wall Clock 224.039719462s] Trained 120 records in 0.040808776 seconds. Throughput is 2940.5442 records/second. Loss is 0.23570248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005083884087442806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40440/60000][Iteration 4837][Wall Clock 224.080501474s] Trained 120 records in 0.040782012 seconds. Throughput is 2942.4736 records/second. Loss is 0.20459102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005083367222448149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40560/60000][Iteration 4838][Wall Clock 224.124045449s] Trained 120 records in 0.043543975 seconds. Throughput is 2755.8347 records/second. Loss is 0.29880887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005082850462539392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40680/60000][Iteration 4839][Wall Clock 224.163443867s] Trained 120 records in 0.039398418 seconds. Throughput is 3045.8076 records/second. Loss is 0.28533044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005082333807684488. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40800/60000][Iteration 4840][Wall Clock 224.202772786s] Trained 120 records in 0.039328919 seconds. Throughput is 3051.19 records/second. Loss is 0.27622262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050818172578514075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 40920/60000][Iteration 4841][Wall Clock 224.252654s] Trained 120 records in 0.049881214 seconds. Throughput is 2405.7153 records/second. Loss is 0.23307677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00508130081300813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 41040/60000][Iteration 4842][Wall Clock 224.292702426s] Trained 120 records in 0.040048426 seconds. Throughput is 2996.3726 records/second. Loss is 0.20647256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00508078447312265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 41160/60000][Iteration 4843][Wall Clock 224.332839286s] Trained 120 records in 0.04013686 seconds. Throughput is 2989.7705 records/second. Loss is 0.2248568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005080268238162975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 41280/60000][Iteration 4844][Wall Clock 224.373657142s] Trained 120 records in 0.040817856 seconds. Throughput is 2939.89 records/second. Loss is 0.23978819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005079752108097125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 41400/60000][Iteration 4845][Wall Clock 224.41405344s] Trained 120 records in 0.040396298 seconds. Throughput is 2970.569 records/second. Loss is 0.23423281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005079236082893133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 41520/60000][Iteration 4846][Wall Clock 224.454676355s] Trained 120 records in 0.040622915 seconds. Throughput is 2953.9978 records/second. Loss is 0.26969147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005078720162519045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:50 INFO  DistriOptimizer$:406 - [Epoch 10 41640/60000][Iteration 4847][Wall Clock 224.495090929s] Trained 120 records in 0.040414574 seconds. Throughput is 2969.2258 records/second. Loss is 0.35100648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005078204346942921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 41760/60000][Iteration 4848][Wall Clock 224.535620208s] Trained 120 records in 0.040529279 seconds. Throughput is 2960.8225 records/second. Loss is 0.33579236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050776886361328325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 41880/60000][Iteration 4849][Wall Clock 224.576260787s] Trained 120 records in 0.040640579 seconds. Throughput is 2952.7139 records/second. Loss is 0.2715994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005077173030056864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42000/60000][Iteration 4850][Wall Clock 224.617347205s] Trained 120 records in 0.041086418 seconds. Throughput is 2920.6733 records/second. Loss is 0.17897558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050766575286831156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42120/60000][Iteration 4851][Wall Clock 224.657710961s] Trained 120 records in 0.040363756 seconds. Throughput is 2972.964 records/second. Loss is 0.225004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005076142131979695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42240/60000][Iteration 4852][Wall Clock 224.698012384s] Trained 120 records in 0.040301423 seconds. Throughput is 2977.5623 records/second. Loss is 0.19319966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050756268399147295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42360/60000][Iteration 4853][Wall Clock 224.738335587s] Trained 120 records in 0.040323203 seconds. Throughput is 2975.954 records/second. Loss is 0.30768645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005075111652456354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42480/60000][Iteration 4854][Wall Clock 224.778606226s] Trained 120 records in 0.040270639 seconds. Throughput is 2979.8386 records/second. Loss is 0.20723014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005074596569572719. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42600/60000][Iteration 4855][Wall Clock 224.819276524s] Trained 120 records in 0.040670298 seconds. Throughput is 2950.5562 records/second. Loss is 0.17946123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005074081591231987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42720/60000][Iteration 4856][Wall Clock 224.860326156s] Trained 120 records in 0.041049632 seconds. Throughput is 2923.2905 records/second. Loss is 0.15930818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050735667174023336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42840/60000][Iteration 4857][Wall Clock 224.904966386s] Trained 120 records in 0.04464023 seconds. Throughput is 2688.1582 records/second. Loss is 0.1791442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005073051948051948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 42960/60000][Iteration 4858][Wall Clock 224.962496253s] Trained 120 records in 0.057529867 seconds. Throughput is 2085.873 records/second. Loss is 0.36810204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005072537283149031. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43080/60000][Iteration 4859][Wall Clock 225.008561868s] Trained 120 records in 0.046065615 seconds. Throughput is 2604.98 records/second. Loss is 0.22825111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005072022722661797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43200/60000][Iteration 4860][Wall Clock 225.050100335s] Trained 120 records in 0.041538467 seconds. Throughput is 2888.8887 records/second. Loss is 0.2767087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005071508266558475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43320/60000][Iteration 4861][Wall Clock 225.091391758s] Trained 120 records in 0.041291423 seconds. Throughput is 2906.1726 records/second. Loss is 0.16082318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005070993914807302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43440/60000][Iteration 4862][Wall Clock 225.132053034s] Trained 120 records in 0.040661276 seconds. Throughput is 2951.211 records/second. Loss is 0.17016293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005070479667376534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43560/60000][Iteration 4863][Wall Clock 225.172568022s] Trained 120 records in 0.040514988 seconds. Throughput is 2961.867 records/second. Loss is 0.18928127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050699655242344354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43680/60000][Iteration 4864][Wall Clock 225.213586604s] Trained 120 records in 0.041018582 seconds. Throughput is 2925.5034 records/second. Loss is 0.2055447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005069451485349286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43800/60000][Iteration 4865][Wall Clock 225.25502947s] Trained 120 records in 0.041442866 seconds. Throughput is 2895.5525 records/second. Loss is 0.34709623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005068937550689376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 43920/60000][Iteration 4866][Wall Clock 225.29603661s] Trained 120 records in 0.04100714 seconds. Throughput is 2926.3198 records/second. Loss is 0.2690046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00506842372022301. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 44040/60000][Iteration 4867][Wall Clock 225.343829756s] Trained 120 records in 0.047793146 seconds. Throughput is 2510.8203 records/second. Loss is 0.21101624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005067909993918508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 44160/60000][Iteration 4868][Wall Clock 225.391202856s] Trained 120 records in 0.0473731 seconds. Throughput is 2533.083 records/second. Loss is 0.1792342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005067396371744198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 44280/60000][Iteration 4869][Wall Clock 225.432939796s] Trained 120 records in 0.04173694 seconds. Throughput is 2875.151 records/second. Loss is 0.12523031. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005066882853668423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 44400/60000][Iteration 4870][Wall Clock 225.474050842s] Trained 120 records in 0.041111046 seconds. Throughput is 2918.9236 records/second. Loss is 0.16924998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00506636943965954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:51 INFO  DistriOptimizer$:406 - [Epoch 10 44520/60000][Iteration 4871][Wall Clock 225.515514895s] Trained 120 records in 0.041464053 seconds. Throughput is 2894.073 records/second. Loss is 0.20758702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005065856129685916. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 44640/60000][Iteration 4872][Wall Clock 225.558355915s] Trained 120 records in 0.04284102 seconds. Throughput is 2801.0537 records/second. Loss is 0.24498278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005065342923715935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 44760/60000][Iteration 4873][Wall Clock 225.601547013s] Trained 120 records in 0.043191098 seconds. Throughput is 2778.3503 records/second. Loss is 0.23773387. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00506482982171799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 44880/60000][Iteration 4874][Wall Clock 225.643174111s] Trained 120 records in 0.041627098 seconds. Throughput is 2882.7375 records/second. Loss is 0.24180838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005064316823660488. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45000/60000][Iteration 4875][Wall Clock 225.688078895s] Trained 120 records in 0.044904784 seconds. Throughput is 2672.321 records/second. Loss is 0.25278002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005063803929511849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45120/60000][Iteration 4876][Wall Clock 225.72999958s] Trained 120 records in 0.041920685 seconds. Throughput is 2862.5486 records/second. Loss is 0.2156901. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005063291139240506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45240/60000][Iteration 4877][Wall Clock 225.770900911s] Trained 120 records in 0.040901331 seconds. Throughput is 2933.89 records/second. Loss is 0.2233939. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005062778452814905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45360/60000][Iteration 4878][Wall Clock 225.811763541s] Trained 120 records in 0.04086263 seconds. Throughput is 2936.6685 records/second. Loss is 0.20969895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005062265870203503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45480/60000][Iteration 4879][Wall Clock 225.852242554s] Trained 120 records in 0.040479013 seconds. Throughput is 2964.4993 records/second. Loss is 0.19292101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005061753391374772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45600/60000][Iteration 4880][Wall Clock 225.892901391s] Trained 120 records in 0.040658837 seconds. Throughput is 2951.388 records/second. Loss is 0.2611019. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005061241016297196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45720/60000][Iteration 4881][Wall Clock 225.933825596s] Trained 120 records in 0.040924205 seconds. Throughput is 2932.25 records/second. Loss is 0.19512679. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005060728744939271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45840/60000][Iteration 4882][Wall Clock 225.975025792s] Trained 120 records in 0.041200196 seconds. Throughput is 2912.6077 records/second. Loss is 0.2097888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050602165772695076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 45960/60000][Iteration 4883][Wall Clock 226.026312222s] Trained 120 records in 0.05128643 seconds. Throughput is 2339.8003 records/second. Loss is 0.3221595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005059704513256426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46080/60000][Iteration 4884][Wall Clock 226.077329478s] Trained 120 records in 0.051017256 seconds. Throughput is 2352.1455 records/second. Loss is 0.22263664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005059192552868562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46200/60000][Iteration 4885][Wall Clock 226.118274046s] Trained 120 records in 0.040944568 seconds. Throughput is 2930.7917 records/second. Loss is 0.20527013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005058680696074464. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46320/60000][Iteration 4886][Wall Clock 226.158954464s] Trained 120 records in 0.040680418 seconds. Throughput is 2949.822 records/second. Loss is 0.119371384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005058168942842691. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46440/60000][Iteration 4887][Wall Clock 226.199594759s] Trained 120 records in 0.040640295 seconds. Throughput is 2952.7346 records/second. Loss is 0.20427515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050576572931418165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46560/60000][Iteration 4888][Wall Clock 226.240670364s] Trained 120 records in 0.041075605 seconds. Throughput is 2921.442 records/second. Loss is 0.21677642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005057145746940427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46680/60000][Iteration 4889][Wall Clock 226.28165824s] Trained 120 records in 0.040987876 seconds. Throughput is 2927.695 records/second. Loss is 0.18219826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050566343042071195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46800/60000][Iteration 4890][Wall Clock 226.323241939s] Trained 120 records in 0.041583699 seconds. Throughput is 2885.7463 records/second. Loss is 0.23663074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005056122964910507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 46920/60000][Iteration 4891][Wall Clock 226.364915336s] Trained 120 records in 0.041673397 seconds. Throughput is 2879.535 records/second. Loss is 0.2748345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005055611729019211. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 47040/60000][Iteration 4892][Wall Clock 226.405769605s] Trained 120 records in 0.040854269 seconds. Throughput is 2937.2695 records/second. Loss is 0.17120288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00505510059650187. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 47160/60000][Iteration 4893][Wall Clock 226.446544609s] Trained 120 records in 0.040775004 seconds. Throughput is 2942.9795 records/second. Loss is 0.17190224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005054589567327133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:52 INFO  DistriOptimizer$:406 - [Epoch 10 47280/60000][Iteration 4894][Wall Clock 226.502629982s] Trained 120 records in 0.056085373 seconds. Throughput is 2139.5952 records/second. Loss is 0.1915601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005054078641463661. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 47400/60000][Iteration 4895][Wall Clock 226.544500893s] Trained 120 records in 0.041870911 seconds. Throughput is 2865.9514 records/second. Loss is 0.17719331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005053567818880129. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 47520/60000][Iteration 4896][Wall Clock 226.586502784s] Trained 120 records in 0.042001891 seconds. Throughput is 2857.0142 records/second. Loss is 0.12680197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005053057099545225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 47640/60000][Iteration 4897][Wall Clock 226.627978939s] Trained 120 records in 0.041476155 seconds. Throughput is 2893.2285 records/second. Loss is 0.19891234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050525464834276475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 47760/60000][Iteration 4898][Wall Clock 226.669393794s] Trained 120 records in 0.041414855 seconds. Throughput is 2897.5112 records/second. Loss is 0.15045711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050520359704961096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 47880/60000][Iteration 4899][Wall Clock 226.710124036s] Trained 120 records in 0.040730242 seconds. Throughput is 2946.2139 records/second. Loss is 0.24466436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005051525560719338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48000/60000][Iteration 4900][Wall Clock 226.750552721s] Trained 120 records in 0.040428685 seconds. Throughput is 2968.1897 records/second. Loss is 0.32269195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050510152540660675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48120/60000][Iteration 4901][Wall Clock 226.791080616s] Trained 120 records in 0.040527895 seconds. Throughput is 2960.9236 records/second. Loss is 0.20896217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005050505050505051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48240/60000][Iteration 4902][Wall Clock 226.831187852s] Trained 120 records in 0.040107236 seconds. Throughput is 2991.9788 records/second. Loss is 0.1142077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00504999495000505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48360/60000][Iteration 4903][Wall Clock 226.871762329s] Trained 120 records in 0.040574477 seconds. Throughput is 2957.5244 records/second. Loss is 0.18021831. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005049484952534842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48480/60000][Iteration 4904][Wall Clock 226.912142115s] Trained 120 records in 0.040379786 seconds. Throughput is 2971.784 records/second. Loss is 0.19560169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005048975058063214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48600/60000][Iteration 4905][Wall Clock 226.952872909s] Trained 120 records in 0.040730794 seconds. Throughput is 2946.1738 records/second. Loss is 0.21464808. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005048465266558966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48720/60000][Iteration 4906][Wall Clock 226.993761491s] Trained 120 records in 0.040888582 seconds. Throughput is 2934.8047 records/second. Loss is 0.19640324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005047955577990914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48840/60000][Iteration 4907][Wall Clock 227.03548253s] Trained 120 records in 0.041721039 seconds. Throughput is 2876.2468 records/second. Loss is 0.23258749. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005047445992327882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 48960/60000][Iteration 4908][Wall Clock 227.083732849s] Trained 120 records in 0.048250319 seconds. Throughput is 2487.0303 records/second. Loss is 0.3033125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00504693650953871. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49080/60000][Iteration 4909][Wall Clock 227.13273224s] Trained 120 records in 0.048999391 seconds. Throughput is 2449.01 records/second. Loss is 0.1551103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005046427129592248. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49200/60000][Iteration 4910][Wall Clock 227.173937681s] Trained 120 records in 0.041205441 seconds. Throughput is 2912.2368 records/second. Loss is 0.2528558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005045917852457362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49320/60000][Iteration 4911][Wall Clock 227.214672605s] Trained 120 records in 0.040734924 seconds. Throughput is 2945.875 records/second. Loss is 0.2403573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005045408678102926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49440/60000][Iteration 4912][Wall Clock 227.255408731s] Trained 120 records in 0.040736126 seconds. Throughput is 2945.788 records/second. Loss is 0.2499049. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050448996064978305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49560/60000][Iteration 4913][Wall Clock 227.299881378s] Trained 120 records in 0.044472647 seconds. Throughput is 2698.2878 records/second. Loss is 0.2178209. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005044390637610976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49680/60000][Iteration 4914][Wall Clock 227.340966134s] Trained 120 records in 0.041084756 seconds. Throughput is 2920.7915 records/second. Loss is 0.16144483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005043881771411278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49800/60000][Iteration 4915][Wall Clock 227.382095257s] Trained 120 records in 0.041129123 seconds. Throughput is 2917.6406 records/second. Loss is 0.17449802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005043373007867662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 49920/60000][Iteration 4916][Wall Clock 227.423113331s] Trained 120 records in 0.041018074 seconds. Throughput is 2925.5398 records/second. Loss is 0.29491475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005042864346949067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 50040/60000][Iteration 4917][Wall Clock 227.464506899s] Trained 120 records in 0.041393568 seconds. Throughput is 2899.0012 records/second. Loss is 0.19939998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005042355788624445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:53 INFO  DistriOptimizer$:406 - [Epoch 10 50160/60000][Iteration 4918][Wall Clock 227.505847458s] Trained 120 records in 0.041340559 seconds. Throughput is 2902.7183 records/second. Loss is 0.17577995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005041847332862761. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 50280/60000][Iteration 4919][Wall Clock 227.546680812s] Trained 120 records in 0.040833354 seconds. Throughput is 2938.774 records/second. Loss is 0.19242898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00504133897963299. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 50400/60000][Iteration 4920][Wall Clock 227.594990933s] Trained 120 records in 0.048310121 seconds. Throughput is 2483.9517 records/second. Loss is 0.17790793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005040830728904123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 50520/60000][Iteration 4921][Wall Clock 227.643040492s] Trained 120 records in 0.048049559 seconds. Throughput is 2497.4216 records/second. Loss is 0.18108825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005040322580645161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 50640/60000][Iteration 4922][Wall Clock 227.684009682s] Trained 120 records in 0.04096919 seconds. Throughput is 2929.0303 records/second. Loss is 0.26642737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005039814534825118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 50760/60000][Iteration 4923][Wall Clock 227.724511549s] Trained 120 records in 0.040501867 seconds. Throughput is 2962.8264 records/second. Loss is 0.22837284. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005039306591413022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 50880/60000][Iteration 4924][Wall Clock 227.765104945s] Trained 120 records in 0.040593396 seconds. Throughput is 2956.1458 records/second. Loss is 0.2342981. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050387987503779106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51000/60000][Iteration 4925][Wall Clock 227.805184148s] Trained 120 records in 0.040079203 seconds. Throughput is 2994.0715 records/second. Loss is 0.16990271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005038291011688835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51120/60000][Iteration 4926][Wall Clock 227.845499976s] Trained 120 records in 0.040315828 seconds. Throughput is 2976.4983 records/second. Loss is 0.24682543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005037783375314861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51240/60000][Iteration 4927][Wall Clock 227.886021823s] Trained 120 records in 0.040521847 seconds. Throughput is 2961.3657 records/second. Loss is 0.15578516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005037275841225065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51360/60000][Iteration 4928][Wall Clock 227.926032214s] Trained 120 records in 0.040010391 seconds. Throughput is 2999.2207 records/second. Loss is 0.1918478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005036768409388537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51480/60000][Iteration 4929][Wall Clock 227.966752856s] Trained 120 records in 0.040720642 seconds. Throughput is 2946.9084 records/second. Loss is 0.21590446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005036261079774376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51600/60000][Iteration 4930][Wall Clock 228.00813339s] Trained 120 records in 0.041380534 seconds. Throughput is 2899.914 records/second. Loss is 0.36049134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050357538523516975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51720/60000][Iteration 4931][Wall Clock 228.053186693s] Trained 120 records in 0.045053303 seconds. Throughput is 2663.5117 records/second. Loss is 0.21661845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005035246727089627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51840/60000][Iteration 4932][Wall Clock 228.095846347s] Trained 120 records in 0.042659654 seconds. Throughput is 2812.9622 records/second. Loss is 0.27625865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005034739703957305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 51960/60000][Iteration 4933][Wall Clock 228.145575145s] Trained 120 records in 0.049728798 seconds. Throughput is 2413.0886 records/second. Loss is 0.20770083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050342327829238824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52080/60000][Iteration 4934][Wall Clock 228.197151691s] Trained 120 records in 0.051576546 seconds. Throughput is 2326.639 records/second. Loss is 0.3143595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005033725963958522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52200/60000][Iteration 4935][Wall Clock 228.238142015s] Trained 120 records in 0.040990324 seconds. Throughput is 2927.5203 records/second. Loss is 0.21697555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005033219247030401. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52320/60000][Iteration 4936][Wall Clock 228.278848692s] Trained 120 records in 0.040706677 seconds. Throughput is 2947.9194 records/second. Loss is 0.24488913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050327126321087065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52440/60000][Iteration 4937][Wall Clock 228.31862455s] Trained 120 records in 0.039775858 seconds. Throughput is 3016.9053 records/second. Loss is 0.3018719. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005032206119162641. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52560/60000][Iteration 4938][Wall Clock 228.358242754s] Trained 120 records in 0.039618204 seconds. Throughput is 3028.9106 records/second. Loss is 0.23320341. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005031699708161417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52680/60000][Iteration 4939][Wall Clock 228.397794073s] Trained 120 records in 0.039551319 seconds. Throughput is 3034.033 records/second. Loss is 0.13083492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00503119339907426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52800/60000][Iteration 4940][Wall Clock 228.437549617s] Trained 120 records in 0.039755544 seconds. Throughput is 3018.4468 records/second. Loss is 0.32992285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005030687191870409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:54 INFO  DistriOptimizer$:406 - [Epoch 10 52920/60000][Iteration 4941][Wall Clock 228.477540174s] Trained 120 records in 0.039990557 seconds. Throughput is 3000.7085 records/second. Loss is 0.24378045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005030181086519115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53040/60000][Iteration 4942][Wall Clock 228.517643048s] Trained 120 records in 0.040102874 seconds. Throughput is 2992.3042 records/second. Loss is 0.19645864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005029675082989639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53160/60000][Iteration 4943][Wall Clock 228.557565495s] Trained 120 records in 0.039922447 seconds. Throughput is 3005.828 records/second. Loss is 0.20339678. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005029169181251258. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53280/60000][Iteration 4944][Wall Clock 228.597880157s] Trained 120 records in 0.040314662 seconds. Throughput is 2976.5845 records/second. Loss is 0.22221057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005028663381273258. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53400/60000][Iteration 4945][Wall Clock 228.638356442s] Trained 120 records in 0.040476285 seconds. Throughput is 2964.699 records/second. Loss is 0.11382655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00502815768302494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53520/60000][Iteration 4946][Wall Clock 228.678765325s] Trained 120 records in 0.040408883 seconds. Throughput is 2969.644 records/second. Loss is 0.23737155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005027652086475615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53640/60000][Iteration 4947][Wall Clock 228.72886752s] Trained 120 records in 0.050102195 seconds. Throughput is 2395.1045 records/second. Loss is 0.18326691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005027146591594611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53760/60000][Iteration 4948][Wall Clock 228.776509515s] Trained 120 records in 0.047641995 seconds. Throughput is 2518.7861 records/second. Loss is 0.32410255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005026641198351262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 53880/60000][Iteration 4949][Wall Clock 228.816562225s] Trained 120 records in 0.04005271 seconds. Throughput is 2996.052 records/second. Loss is 0.29394856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005026135906714918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54000/60000][Iteration 4950][Wall Clock 228.859575669s] Trained 120 records in 0.043013444 seconds. Throughput is 2789.8254 records/second. Loss is 0.20277993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00502563071665494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54120/60000][Iteration 4951][Wall Clock 228.89946084s] Trained 120 records in 0.039885171 seconds. Throughput is 3008.637 records/second. Loss is 0.24078624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005025125628140703. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54240/60000][Iteration 4952][Wall Clock 228.940732624s] Trained 120 records in 0.041271784 seconds. Throughput is 2907.5554 records/second. Loss is 0.15144433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005024620641141593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54360/60000][Iteration 4953][Wall Clock 228.982429246s] Trained 120 records in 0.041696622 seconds. Throughput is 2877.931 records/second. Loss is 0.22696833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00502411575562701. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54480/60000][Iteration 4954][Wall Clock 229.024851098s] Trained 120 records in 0.042421852 seconds. Throughput is 2828.731 records/second. Loss is 0.1683148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005023610971566362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54600/60000][Iteration 4955][Wall Clock 229.066567834s] Trained 120 records in 0.041716736 seconds. Throughput is 2876.5435 records/second. Loss is 0.1961811. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005023106288929074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54720/60000][Iteration 4956][Wall Clock 229.107555982s] Trained 120 records in 0.040988148 seconds. Throughput is 2927.6755 records/second. Loss is 0.20963955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005022601707684581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54840/60000][Iteration 4957][Wall Clock 229.148085903s] Trained 120 records in 0.040529921 seconds. Throughput is 2960.7756 records/second. Loss is 0.19432785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050220972278023305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 54960/60000][Iteration 4958][Wall Clock 229.190185527s] Trained 120 records in 0.042099624 seconds. Throughput is 2850.3816 records/second. Loss is 0.23502527. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005021592849251783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 55080/60000][Iteration 4959][Wall Clock 229.24383252s] Trained 120 records in 0.053646993 seconds. Throughput is 2236.845 records/second. Loss is 0.22615756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00502108857200241. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 55200/60000][Iteration 4960][Wall Clock 229.285547681s] Trained 120 records in 0.041715161 seconds. Throughput is 2876.652 records/second. Loss is 0.15819198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005020584396023697. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 55320/60000][Iteration 4961][Wall Clock 229.325640321s] Trained 120 records in 0.04009264 seconds. Throughput is 2993.068 records/second. Loss is 0.25075328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050200803212851405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 55440/60000][Iteration 4962][Wall Clock 229.365891252s] Trained 120 records in 0.040250931 seconds. Throughput is 2981.2976 records/second. Loss is 0.19167039. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050195763477562496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 55560/60000][Iteration 4963][Wall Clock 229.406257052s] Trained 120 records in 0.0403658 seconds. Throughput is 2972.8137 records/second. Loss is 0.24600616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005019072475406545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 55680/60000][Iteration 4964][Wall Clock 229.446892243s] Trained 120 records in 0.040635191 seconds. Throughput is 2953.1055 records/second. Loss is 0.14540344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005018568704205561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:55 INFO  DistriOptimizer$:406 - [Epoch 10 55800/60000][Iteration 4965][Wall Clock 229.487262892s] Trained 120 records in 0.040370649 seconds. Throughput is 2972.4565 records/second. Loss is 0.122445785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005018065034122843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 55920/60000][Iteration 4966][Wall Clock 229.528109227s] Trained 120 records in 0.040846335 seconds. Throughput is 2937.8398 records/second. Loss is 0.19129308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050175614651279486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56040/60000][Iteration 4967][Wall Clock 229.568515271s] Trained 120 records in 0.040406044 seconds. Throughput is 2969.8528 records/second. Loss is 0.30595228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050170579971904475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56160/60000][Iteration 4968][Wall Clock 229.61012408s] Trained 120 records in 0.041608809 seconds. Throughput is 2884.0046 records/second. Loss is 0.18326923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005016554630279924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56280/60000][Iteration 4969][Wall Clock 229.655379051s] Trained 120 records in 0.045254971 seconds. Throughput is 2651.6423 records/second. Loss is 0.12952855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005016051364365971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56400/60000][Iteration 4970][Wall Clock 229.696510796s] Trained 120 records in 0.041131745 seconds. Throughput is 2917.4546 records/second. Loss is 0.14590016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005015548199418196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56520/60000][Iteration 4971][Wall Clock 229.736851953s] Trained 120 records in 0.040341157 seconds. Throughput is 2974.6296 records/second. Loss is 0.17138936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050150451354062184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56640/60000][Iteration 4972][Wall Clock 229.776520834s] Trained 120 records in 0.039668881 seconds. Throughput is 3025.0413 records/second. Loss is 0.3202317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005014542172299669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56760/60000][Iteration 4973][Wall Clock 229.816723424s] Trained 120 records in 0.04020259 seconds. Throughput is 2984.882 records/second. Loss is 0.30782682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00501403931006819. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 56880/60000][Iteration 4974][Wall Clock 229.872019031s] Trained 120 records in 0.055295607 seconds. Throughput is 2170.1543 records/second. Loss is 0.18888836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050135365486814396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57000/60000][Iteration 4975][Wall Clock 229.915726325s] Trained 120 records in 0.043707294 seconds. Throughput is 2745.5374 records/second. Loss is 0.26117653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005013033888109084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57120/60000][Iteration 4976][Wall Clock 229.958974769s] Trained 120 records in 0.043248444 seconds. Throughput is 2774.6663 records/second. Loss is 0.25964794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005012531328320802. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57240/60000][Iteration 4977][Wall Clock 230.001410103s] Trained 120 records in 0.042435334 seconds. Throughput is 2827.8323 records/second. Loss is 0.2817187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005012028869286287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57360/60000][Iteration 4978][Wall Clock 230.042354323s] Trained 120 records in 0.04094422 seconds. Throughput is 2930.8167 records/second. Loss is 0.1881504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005011526510975243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57480/60000][Iteration 4979][Wall Clock 230.083012668s] Trained 120 records in 0.040658345 seconds. Throughput is 2951.4238 records/second. Loss is 0.15498158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050110242533573865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57600/60000][Iteration 4980][Wall Clock 230.123048435s] Trained 120 records in 0.040035767 seconds. Throughput is 2997.32 records/second. Loss is 0.23565702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005010522096402445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57720/60000][Iteration 4981][Wall Clock 230.163083809s] Trained 120 records in 0.040035374 seconds. Throughput is 2997.3494 records/second. Loss is 0.24798484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00501002004008016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57840/60000][Iteration 4982][Wall Clock 230.204659031s] Trained 120 records in 0.041575222 seconds. Throughput is 2886.3345 records/second. Loss is 0.20024729. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050095180843602845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 57960/60000][Iteration 4983][Wall Clock 230.24796515s] Trained 120 records in 0.043306119 seconds. Throughput is 2770.971 records/second. Loss is 0.16496222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005009016229212583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 58080/60000][Iteration 4984][Wall Clock 230.305770423s] Trained 120 records in 0.057805273 seconds. Throughput is 2075.935 records/second. Loss is 0.15938427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005008514474606832. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 58200/60000][Iteration 4985][Wall Clock 230.350971612s] Trained 120 records in 0.045201189 seconds. Throughput is 2654.7974 records/second. Loss is 0.22443058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005008012820512821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 58320/60000][Iteration 4986][Wall Clock 230.393978663s] Trained 120 records in 0.043007051 seconds. Throughput is 2790.2402 records/second. Loss is 0.32900944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005007511266900351. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 58440/60000][Iteration 4987][Wall Clock 230.438459137s] Trained 120 records in 0.044480474 seconds. Throughput is 2697.813 records/second. Loss is 0.2979608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005007009813739235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:56 INFO  DistriOptimizer$:406 - [Epoch 10 58560/60000][Iteration 4988][Wall Clock 230.479537131s] Trained 120 records in 0.041077994 seconds. Throughput is 2921.2722 records/second. Loss is 0.30145878. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005006508460999299. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 58680/60000][Iteration 4989][Wall Clock 230.520933552s] Trained 120 records in 0.041396421 seconds. Throughput is 2898.8013 records/second. Loss is 0.18857092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005006007208650381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 58800/60000][Iteration 4990][Wall Clock 230.561365307s] Trained 120 records in 0.040431755 seconds. Throughput is 2967.964 records/second. Loss is 0.19121245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005005506056662328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 58920/60000][Iteration 4991][Wall Clock 230.601528503s] Trained 120 records in 0.040163196 seconds. Throughput is 2987.81 records/second. Loss is 0.19459076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005005005005005005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59040/60000][Iteration 4992][Wall Clock 230.641739802s] Trained 120 records in 0.040211299 seconds. Throughput is 2984.2358 records/second. Loss is 0.19875693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005004504053648283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59160/60000][Iteration 4993][Wall Clock 230.681745099s] Trained 120 records in 0.040005297 seconds. Throughput is 2999.6028 records/second. Loss is 0.17288692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050040032025620495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59280/60000][Iteration 4994][Wall Clock 230.721935242s] Trained 120 records in 0.040190143 seconds. Throughput is 2985.807 records/second. Loss is 0.2926882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005003502451716201. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59400/60000][Iteration 4995][Wall Clock 230.762840351s] Trained 120 records in 0.040905109 seconds. Throughput is 2933.6187 records/second. Loss is 0.24316843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005003001801080648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59520/60000][Iteration 4996][Wall Clock 230.802860561s] Trained 120 records in 0.04002021 seconds. Throughput is 2998.485 records/second. Loss is 0.27257437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0050025012506253125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59640/60000][Iteration 4997][Wall Clock 230.842844505s] Trained 120 records in 0.039983944 seconds. Throughput is 3001.2048 records/second. Loss is 0.20016263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005002000800320128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59760/60000][Iteration 4998][Wall Clock 230.88357743s] Trained 120 records in 0.040732925 seconds. Throughput is 2946.0198 records/second. Loss is 0.31514475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00500150045013504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 59880/60000][Iteration 4999][Wall Clock 230.924375475s] Trained 120 records in 0.040798045 seconds. Throughput is 2941.3174 records/second. Loss is 0.24887854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005001000200040008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:406 - [Epoch 10 60000/60000][Iteration 5000][Wall Clock 230.965581439s] Trained 120 records in 0.041205964 seconds. Throughput is 2912.1997 records/second. Loss is 0.26648682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005000500050005001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:57 INFO  DistriOptimizer$:451 - [Epoch 10 60000/60000][Iteration 5000][Wall Clock 230.965581439s] Epoch finished. Wall clock time is 231780.0568 ms
2019-10-23 15:56:57 INFO  DistriOptimizer$:111 - [Epoch 10 60000/60000][Iteration 5000][Wall Clock 230.965581439s] Validate model...
2019-10-23 15:56:58 INFO  DistriOptimizer$:177 - [Epoch 10 60000/60000][Iteration 5000][Wall Clock 230.965581439s] validate model throughput is 14471.723 records/second
2019-10-23 15:56:58 INFO  DistriOptimizer$:180 - [Epoch 10 60000/60000][Iteration 5000][Wall Clock 230.965581439s] Top1Accuracy is Accuracy(correct: 9437, count: 10000, accuracy: 0.9437)
2019-10-23 15:56:58 INFO  DistriOptimizer$:220 - [Wall Clock 231.7800568s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:56:58 INFO  DistriOptimizer$:225 - [Wall Clock 231.7800568s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 120/60000][Iteration 5001][Wall Clock 231.826808794s] Trained 120 records in 0.046751994 seconds. Throughput is 2566.7354 records/second. Loss is 0.22582613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 240/60000][Iteration 5002][Wall Clock 231.867973635s] Trained 120 records in 0.041164841 seconds. Throughput is 2915.109 records/second. Loss is 0.27753958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004999500049995001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 360/60000][Iteration 5003][Wall Clock 231.908650891s] Trained 120 records in 0.040677256 seconds. Throughput is 2950.0515 records/second. Loss is 0.15144855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004999000199960009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 480/60000][Iteration 5004][Wall Clock 231.952628016s] Trained 120 records in 0.043977125 seconds. Throughput is 2728.6912 records/second. Loss is 0.27640048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00499850044986504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 600/60000][Iteration 5005][Wall Clock 231.99318061s] Trained 120 records in 0.040552594 seconds. Throughput is 2959.12 records/second. Loss is 0.26679757. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004998000799680128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 720/60000][Iteration 5006][Wall Clock 232.041871227s] Trained 120 records in 0.048690617 seconds. Throughput is 2464.5405 records/second. Loss is 0.16619927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004997501249375312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 840/60000][Iteration 5007][Wall Clock 232.09170206s] Trained 120 records in 0.049830833 seconds. Throughput is 2408.1477 records/second. Loss is 0.16827917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049970017989206484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 960/60000][Iteration 5008][Wall Clock 232.14860832s] Trained 120 records in 0.05690626 seconds. Throughput is 2108.731 records/second. Loss is 0.19934638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004996502448286199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1080/60000][Iteration 5009][Wall Clock 232.192639648s] Trained 120 records in 0.044031328 seconds. Throughput is 2725.3323 records/second. Loss is 0.16994795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004996003197442047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1200/60000][Iteration 5010][Wall Clock 232.233535302s] Trained 120 records in 0.040895654 seconds. Throughput is 2934.297 records/second. Loss is 0.22667211. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004995504046358277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1320/60000][Iteration 5011][Wall Clock 232.274143294s] Trained 120 records in 0.040607992 seconds. Throughput is 2955.0833 records/second. Loss is 0.23893401. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004995004995004996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1440/60000][Iteration 5012][Wall Clock 232.314852683s] Trained 120 records in 0.040709389 seconds. Throughput is 2947.7231 records/second. Loss is 0.27567565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004994506043352312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1560/60000][Iteration 5013][Wall Clock 232.355640519s] Trained 120 records in 0.040787836 seconds. Throughput is 2942.0537 records/second. Loss is 0.21069294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004994007191370356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1680/60000][Iteration 5014][Wall Clock 232.396049664s] Trained 120 records in 0.040409145 seconds. Throughput is 2969.625 records/second. Loss is 0.14341076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049935084390292615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1800/60000][Iteration 5015][Wall Clock 232.437646932s] Trained 120 records in 0.041597268 seconds. Throughput is 2884.8047 records/second. Loss is 0.27867615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004993009786299181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 1920/60000][Iteration 5016][Wall Clock 232.478620923s] Trained 120 records in 0.040973991 seconds. Throughput is 2928.687 records/second. Loss is 0.22330675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004992511233150274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 2040/60000][Iteration 5017][Wall Clock 232.520322962s] Trained 120 records in 0.041702039 seconds. Throughput is 2877.5571 records/second. Loss is 0.24396771. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049920127795527154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:58 INFO  DistriOptimizer$:406 - [Epoch 11 2160/60000][Iteration 5018][Wall Clock 232.5610534s] Trained 120 records in 0.040730438 seconds. Throughput is 2946.1995 records/second. Loss is 0.23696057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004991514425476689. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 2280/60000][Iteration 5019][Wall Clock 232.60239351s] Trained 120 records in 0.04134011 seconds. Throughput is 2902.75 records/second. Loss is 0.14294332. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004991016170892394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 2400/60000][Iteration 5020][Wall Clock 232.643104204s] Trained 120 records in 0.040710694 seconds. Throughput is 2947.6284 records/second. Loss is 0.28008708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004990518015770037. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 2520/60000][Iteration 5021][Wall Clock 232.685210389s] Trained 120 records in 0.042106185 seconds. Throughput is 2849.9375 records/second. Loss is 0.16099316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00499001996007984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 2640/60000][Iteration 5022][Wall Clock 232.727225153s] Trained 120 records in 0.042014764 seconds. Throughput is 2856.139 records/second. Loss is 0.24987422. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004989522003792037. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 2760/60000][Iteration 5023][Wall Clock 232.771892912s] Trained 120 records in 0.044667759 seconds. Throughput is 2686.5015 records/second. Loss is 0.1976727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004989024146876871. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 2880/60000][Iteration 5024][Wall Clock 232.814207496s] Trained 120 records in 0.042314584 seconds. Throughput is 2835.9016 records/second. Loss is 0.1798001. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049885263893046. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3000/60000][Iteration 5025][Wall Clock 232.85610773s] Trained 120 records in 0.041900234 seconds. Throughput is 2863.946 records/second. Loss is 0.2462621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00498802873104549. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3120/60000][Iteration 5026][Wall Clock 232.910088182s] Trained 120 records in 0.053980452 seconds. Throughput is 2223.027 records/second. Loss is 0.19959576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004987531172069826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3240/60000][Iteration 5027][Wall Clock 232.954122168s] Trained 120 records in 0.044033986 seconds. Throughput is 2725.1677 records/second. Loss is 0.1890846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004987033712347895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3360/60000][Iteration 5028][Wall Clock 232.996119446s] Trained 120 records in 0.041997278 seconds. Throughput is 2857.3281 records/second. Loss is 0.16537406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049865363518500055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3480/60000][Iteration 5029][Wall Clock 233.037689891s] Trained 120 records in 0.041570445 seconds. Throughput is 2886.6663 records/second. Loss is 0.1918462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004986039090546469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3600/60000][Iteration 5030][Wall Clock 233.078929683s] Trained 120 records in 0.041239792 seconds. Throughput is 2909.811 records/second. Loss is 0.294952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004985541928407619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3720/60000][Iteration 5031][Wall Clock 233.122705307s] Trained 120 records in 0.043775624 seconds. Throughput is 2741.2515 records/second. Loss is 0.13982616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004985044865403788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3840/60000][Iteration 5032][Wall Clock 233.168157242s] Trained 120 records in 0.045451935 seconds. Throughput is 2640.1516 records/second. Loss is 0.14642037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049845479015053346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 3960/60000][Iteration 5033][Wall Clock 233.211334976s] Trained 120 records in 0.043177734 seconds. Throughput is 2779.2102 records/second. Loss is 0.20092615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004984051036682615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4080/60000][Iteration 5034][Wall Clock 233.260143442s] Trained 120 records in 0.048808466 seconds. Throughput is 2458.5898 records/second. Loss is 0.2616158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004983554270906011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4200/60000][Iteration 5035][Wall Clock 233.306943573s] Trained 120 records in 0.046800131 seconds. Throughput is 2564.0952 records/second. Loss is 0.19185738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004983057604145903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4320/60000][Iteration 5036][Wall Clock 233.347833103s] Trained 120 records in 0.04088953 seconds. Throughput is 2934.7366 records/second. Loss is 0.19420616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004982561036372696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4440/60000][Iteration 5037][Wall Clock 233.388167457s] Trained 120 records in 0.040334354 seconds. Throughput is 2975.1313 records/second. Loss is 0.23598982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004982064567556795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4560/60000][Iteration 5038][Wall Clock 233.428598433s] Trained 120 records in 0.040430976 seconds. Throughput is 2968.0215 records/second. Loss is 0.19793333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004981568197668626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4680/60000][Iteration 5039][Wall Clock 233.469148083s] Trained 120 records in 0.04054965 seconds. Throughput is 2959.335 records/second. Loss is 0.29772708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004981071926678621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4800/60000][Iteration 5040][Wall Clock 233.509493974s] Trained 120 records in 0.040345891 seconds. Throughput is 2974.2805 records/second. Loss is 0.2585753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004980575754557227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:56:59 INFO  DistriOptimizer$:406 - [Epoch 11 4920/60000][Iteration 5041][Wall Clock 233.550188269s] Trained 120 records in 0.040694295 seconds. Throughput is 2948.8162 records/second. Loss is 0.20258777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049800796812749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5040/60000][Iteration 5042][Wall Clock 233.594035615s] Trained 120 records in 0.043847346 seconds. Throughput is 2736.7678 records/second. Loss is 0.24454421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004979583706802112. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5160/60000][Iteration 5043][Wall Clock 233.634799428s] Trained 120 records in 0.040763813 seconds. Throughput is 2943.7874 records/second. Loss is 0.26111284. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004979087831109341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5280/60000][Iteration 5044][Wall Clock 233.675483018s] Trained 120 records in 0.04068359 seconds. Throughput is 2949.5923 records/second. Loss is 0.21135047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004978592054167082. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5400/60000][Iteration 5045][Wall Clock 233.716370033s] Trained 120 records in 0.040887015 seconds. Throughput is 2934.917 records/second. Loss is 0.13849096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004978096375945838. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5520/60000][Iteration 5046][Wall Clock 233.757585805s] Trained 120 records in 0.041215772 seconds. Throughput is 2911.5066 records/second. Loss is 0.17406997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004977600796416127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5640/60000][Iteration 5047][Wall Clock 233.798671438s] Trained 120 records in 0.041085633 seconds. Throughput is 2920.729 records/second. Loss is 0.110545985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004977105315548477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5760/60000][Iteration 5048][Wall Clock 233.840713238s] Trained 120 records in 0.0420418 seconds. Throughput is 2854.302 records/second. Loss is 0.1832326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049766099333134264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 5880/60000][Iteration 5049][Wall Clock 233.881124942s] Trained 120 records in 0.040411704 seconds. Throughput is 2969.4368 records/second. Loss is 0.2125379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004976114649681529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6000/60000][Iteration 5050][Wall Clock 233.921709959s] Trained 120 records in 0.040585017 seconds. Throughput is 2956.756 records/second. Loss is 0.3045406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004975619464623345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6120/60000][Iteration 5051][Wall Clock 233.96313581s] Trained 120 records in 0.041425851 seconds. Throughput is 2896.742 records/second. Loss is 0.23969673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049751243781094535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6240/60000][Iteration 5052][Wall Clock 234.012615604s] Trained 120 records in 0.049479794 seconds. Throughput is 2425.2324 records/second. Loss is 0.15959507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049746293901104365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6360/60000][Iteration 5053][Wall Clock 234.059897391s] Trained 120 records in 0.047281787 seconds. Throughput is 2537.975 records/second. Loss is 0.21729526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004974134500596897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6480/60000][Iteration 5054][Wall Clock 234.1041851s] Trained 120 records in 0.044287709 seconds. Throughput is 2709.5554 records/second. Loss is 0.2610738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00497363970953944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6600/60000][Iteration 5055][Wall Clock 234.144931856s] Trained 120 records in 0.040746756 seconds. Throughput is 2945.0198 records/second. Loss is 0.22874157. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004973145016908693. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6720/60000][Iteration 5056][Wall Clock 234.187050608s] Trained 120 records in 0.042118752 seconds. Throughput is 2849.0874 records/second. Loss is 0.19429718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004972650422675286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6840/60000][Iteration 5057][Wall Clock 234.235911697s] Trained 120 records in 0.048861089 seconds. Throughput is 2455.942 records/second. Loss is 0.16936737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004972155926809865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 6960/60000][Iteration 5058][Wall Clock 234.27821866s] Trained 120 records in 0.042306963 seconds. Throughput is 2836.4126 records/second. Loss is 0.2569911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004971661529283087. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 7080/60000][Iteration 5059][Wall Clock 234.319981499s] Trained 120 records in 0.041762839 seconds. Throughput is 2873.368 records/second. Loss is 0.21139985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00497116723006562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 7200/60000][Iteration 5060][Wall Clock 234.361038732s] Trained 120 records in 0.041057233 seconds. Throughput is 2922.7493 records/second. Loss is 0.24760936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004970673029128144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 7320/60000][Iteration 5061][Wall Clock 234.413942721s] Trained 120 records in 0.052903989 seconds. Throughput is 2268.26 records/second. Loss is 0.2975737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004970178926441352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 7440/60000][Iteration 5062][Wall Clock 234.454390175s] Trained 120 records in 0.040447454 seconds. Throughput is 2966.8123 records/second. Loss is 0.2852378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004969684921975947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 7560/60000][Iteration 5063][Wall Clock 234.494847893s] Trained 120 records in 0.040457718 seconds. Throughput is 2966.0596 records/second. Loss is 0.23240238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004969191015702644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:00 INFO  DistriOptimizer$:406 - [Epoch 11 7680/60000][Iteration 5064][Wall Clock 234.53511403s] Trained 120 records in 0.040266137 seconds. Throughput is 2980.1716 records/second. Loss is 0.28533345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004968697207592169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 7800/60000][Iteration 5065][Wall Clock 234.575848799s] Trained 120 records in 0.040734769 seconds. Throughput is 2945.8865 records/second. Loss is 0.21347947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049682034976152615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 7920/60000][Iteration 5066][Wall Clock 234.616766697s] Trained 120 records in 0.040917898 seconds. Throughput is 2932.702 records/second. Loss is 0.2145682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004967709885742673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8040/60000][Iteration 5067][Wall Clock 234.658238001s] Trained 120 records in 0.041471304 seconds. Throughput is 2893.5671 records/second. Loss is 0.19100708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004967216371945161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8160/60000][Iteration 5068][Wall Clock 234.699057759s] Trained 120 records in 0.040819758 seconds. Throughput is 2939.753 records/second. Loss is 0.2543826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004966722956193504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8280/60000][Iteration 5069][Wall Clock 234.739721974s] Trained 120 records in 0.040664215 seconds. Throughput is 2950.9976 records/second. Loss is 0.29417226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004966229638458481. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8400/60000][Iteration 5070][Wall Clock 234.780407963s] Trained 120 records in 0.040685989 seconds. Throughput is 2949.4182 records/second. Loss is 0.19835256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004965736418710895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8520/60000][Iteration 5071][Wall Clock 234.821780414s] Trained 120 records in 0.041372451 seconds. Throughput is 2900.4807 records/second. Loss is 0.19008444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004965243296921548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8640/60000][Iteration 5072][Wall Clock 234.8632463s] Trained 120 records in 0.041465886 seconds. Throughput is 2893.945 records/second. Loss is 0.14098682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004964750273061266. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8760/60000][Iteration 5073][Wall Clock 234.904347513s] Trained 120 records in 0.041101213 seconds. Throughput is 2919.6218 records/second. Loss is 0.15955652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004964257347100873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 8880/60000][Iteration 5074][Wall Clock 234.945262527s] Trained 120 records in 0.040915014 seconds. Throughput is 2932.9087 records/second. Loss is 0.17176838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004963764519011219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9000/60000][Iteration 5075][Wall Clock 234.986002993s] Trained 120 records in 0.040740466 seconds. Throughput is 2945.4744 records/second. Loss is 0.20285542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004963271788763152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9120/60000][Iteration 5076][Wall Clock 235.026888364s] Trained 120 records in 0.040885371 seconds. Throughput is 2935.0352 records/second. Loss is 0.2727242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004962779156327543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9240/60000][Iteration 5077][Wall Clock 235.068682204s] Trained 120 records in 0.04179384 seconds. Throughput is 2871.2366 records/second. Loss is 0.15441251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049622866216752675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9360/60000][Iteration 5078][Wall Clock 235.109771399s] Trained 120 records in 0.041089195 seconds. Throughput is 2920.4758 records/second. Loss is 0.20167646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049617941847772155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9480/60000][Iteration 5079][Wall Clock 235.160326318s] Trained 120 records in 0.050554919 seconds. Throughput is 2373.6562 records/second. Loss is 0.26134488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004961301845604287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9600/60000][Iteration 5080][Wall Clock 235.210552285s] Trained 120 records in 0.050225967 seconds. Throughput is 2389.2024 records/second. Loss is 0.22140147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004960809604127394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9720/60000][Iteration 5081][Wall Clock 235.256473642s] Trained 120 records in 0.045921357 seconds. Throughput is 2613.1633 records/second. Loss is 0.16583912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00496031746031746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9840/60000][Iteration 5082][Wall Clock 235.297662434s] Trained 120 records in 0.041188792 seconds. Throughput is 2913.414 records/second. Loss is 0.20115109. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004959825414145422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 9960/60000][Iteration 5083][Wall Clock 235.338265554s] Trained 120 records in 0.04060312 seconds. Throughput is 2955.438 records/second. Loss is 0.21751161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004959333465582226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 10080/60000][Iteration 5084][Wall Clock 235.378365374s] Trained 120 records in 0.04009982 seconds. Throughput is 2992.5322 records/second. Loss is 0.1961269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00495884161459883. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 10200/60000][Iteration 5085][Wall Clock 235.419323248s] Trained 120 records in 0.040957874 seconds. Throughput is 2929.8394 records/second. Loss is 0.16077802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004958349861166204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 10320/60000][Iteration 5086][Wall Clock 235.461321001s] Trained 120 records in 0.041997753 seconds. Throughput is 2857.2957 records/second. Loss is 0.3075272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004957858205255329. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 10440/60000][Iteration 5087][Wall Clock 235.508222695s] Trained 120 records in 0.046901694 seconds. Throughput is 2558.543 records/second. Loss is 0.22004862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049573666468372005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:01 INFO  DistriOptimizer$:406 - [Epoch 11 10560/60000][Iteration 5088][Wall Clock 235.551715383s] Trained 120 records in 0.043492688 seconds. Throughput is 2759.0845 records/second. Loss is 0.2431003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004956875185882819. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 10680/60000][Iteration 5089][Wall Clock 235.592196876s] Trained 120 records in 0.040481493 seconds. Throughput is 2964.3176 records/second. Loss is 0.2164466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004956383822363204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 10800/60000][Iteration 5090][Wall Clock 235.632984498s] Trained 120 records in 0.040787622 seconds. Throughput is 2942.069 records/second. Loss is 0.1474557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00495589255624938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 10920/60000][Iteration 5091][Wall Clock 235.673859283s] Trained 120 records in 0.040874785 seconds. Throughput is 2935.7952 records/second. Loss is 0.22635822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004955401387512389. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11040/60000][Iteration 5092][Wall Clock 235.714035127s] Trained 120 records in 0.040175844 seconds. Throughput is 2986.8694 records/second. Loss is 0.20098573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004954910316123278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11160/60000][Iteration 5093][Wall Clock 235.755099541s] Trained 120 records in 0.041064414 seconds. Throughput is 2922.238 records/second. Loss is 0.21536928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004954419342053112. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11280/60000][Iteration 5094][Wall Clock 235.795990559s] Trained 120 records in 0.040891018 seconds. Throughput is 2934.63 records/second. Loss is 0.24708174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049539284652729615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11400/60000][Iteration 5095][Wall Clock 235.836520237s] Trained 120 records in 0.040529678 seconds. Throughput is 2960.7932 records/second. Loss is 0.16962245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004953437685753913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11520/60000][Iteration 5096][Wall Clock 235.876769989s] Trained 120 records in 0.040249752 seconds. Throughput is 2981.3848 records/second. Loss is 0.1861783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004952947003467063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11640/60000][Iteration 5097][Wall Clock 235.917242713s] Trained 120 records in 0.040472724 seconds. Throughput is 2964.96 records/second. Loss is 0.24663869. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004952456418383518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11760/60000][Iteration 5098][Wall Clock 235.961103186s] Trained 120 records in 0.043860473 seconds. Throughput is 2735.9487 records/second. Loss is 0.2522914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004951965930474398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 11880/60000][Iteration 5099][Wall Clock 236.001740476s] Trained 120 records in 0.04063729 seconds. Throughput is 2952.953 records/second. Loss is 0.2663124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004951475539710834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12000/60000][Iteration 5100][Wall Clock 236.042658631s] Trained 120 records in 0.040918155 seconds. Throughput is 2932.6833 records/second. Loss is 0.22171836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004950985246063967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12120/60000][Iteration 5101][Wall Clock 236.083429352s] Trained 120 records in 0.040770721 seconds. Throughput is 2943.2886 records/second. Loss is 0.22103904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049504950495049506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12240/60000][Iteration 5102][Wall Clock 236.124466532s] Trained 120 records in 0.04103718 seconds. Throughput is 2924.1775 records/second. Loss is 0.2499518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00495000495000495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12360/60000][Iteration 5103][Wall Clock 236.165521283s] Trained 120 records in 0.041054751 seconds. Throughput is 2922.926 records/second. Loss is 0.16803962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004949514947535142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12480/60000][Iteration 5104][Wall Clock 236.206660037s] Trained 120 records in 0.041138754 seconds. Throughput is 2916.9575 records/second. Loss is 0.17451878. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004949025042066713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12600/60000][Iteration 5105][Wall Clock 236.248085987s] Trained 120 records in 0.04142595 seconds. Throughput is 2896.7349 records/second. Loss is 0.14960568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004948535233570862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12720/60000][Iteration 5106][Wall Clock 236.302833285s] Trained 120 records in 0.054747298 seconds. Throughput is 2191.889 records/second. Loss is 0.2388963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004948045522018803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12840/60000][Iteration 5107][Wall Clock 236.349815039s] Trained 120 records in 0.046981754 seconds. Throughput is 2554.1829 records/second. Loss is 0.18952514. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004947555907381752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 12960/60000][Iteration 5108][Wall Clock 236.391903337s] Trained 120 records in 0.042088298 seconds. Throughput is 2851.149 records/second. Loss is 0.28148234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004947066389630949. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 13080/60000][Iteration 5109][Wall Clock 236.433011503s] Trained 120 records in 0.041108166 seconds. Throughput is 2919.1282 records/second. Loss is 0.16047321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004946576968737633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 13200/60000][Iteration 5110][Wall Clock 236.474725636s] Trained 120 records in 0.041714133 seconds. Throughput is 2876.723 records/second. Loss is 0.113941364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004946087644673064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 13320/60000][Iteration 5111][Wall Clock 236.51598455s] Trained 120 records in 0.041258914 seconds. Throughput is 2908.4624 records/second. Loss is 0.23539566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004945598417408506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:02 INFO  DistriOptimizer$:406 - [Epoch 11 13440/60000][Iteration 5112][Wall Clock 236.557728533s] Trained 120 records in 0.041743983 seconds. Throughput is 2874.6658 records/second. Loss is 0.23324722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004945109286915241. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 13560/60000][Iteration 5113][Wall Clock 236.599879485s] Trained 120 records in 0.042150952 seconds. Throughput is 2846.911 records/second. Loss is 0.24054122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004944620253164556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 13680/60000][Iteration 5114][Wall Clock 236.652237834s] Trained 120 records in 0.052358349 seconds. Throughput is 2291.8982 records/second. Loss is 0.3399226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004944131316127757. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 13800/60000][Iteration 5115][Wall Clock 236.693905946s] Trained 120 records in 0.041668112 seconds. Throughput is 2879.9 records/second. Loss is 0.355662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004943642475776152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 13920/60000][Iteration 5116][Wall Clock 236.73529256s] Trained 120 records in 0.041386614 seconds. Throughput is 2899.488 records/second. Loss is 0.17292728. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004943153732081067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14040/60000][Iteration 5117][Wall Clock 236.780671311s] Trained 120 records in 0.045378751 seconds. Throughput is 2644.4094 records/second. Loss is 0.25137717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049426650850138395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14160/60000][Iteration 5118][Wall Clock 236.821247272s] Trained 120 records in 0.040575961 seconds. Throughput is 2957.416 records/second. Loss is 0.26185268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004942176534545814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14280/60000][Iteration 5119][Wall Clock 236.862144267s] Trained 120 records in 0.040896995 seconds. Throughput is 2934.2007 records/second. Loss is 0.18224353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00494168808064835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14400/60000][Iteration 5120][Wall Clock 236.90339401s] Trained 120 records in 0.041249743 seconds. Throughput is 2909.109 records/second. Loss is 0.18670689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004941199723292816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14520/60000][Iteration 5121][Wall Clock 236.944748378s] Trained 120 records in 0.041354368 seconds. Throughput is 2901.749 records/second. Loss is 0.2253994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004940711462450593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14640/60000][Iteration 5122][Wall Clock 236.986119115s] Trained 120 records in 0.041370737 seconds. Throughput is 2900.6008 records/second. Loss is 0.1724452. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004940223298093074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14760/60000][Iteration 5123][Wall Clock 237.026578334s] Trained 120 records in 0.040459219 seconds. Throughput is 2965.9495 records/second. Loss is 0.2324129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049397352301916615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 14880/60000][Iteration 5124][Wall Clock 237.067938754s] Trained 120 records in 0.04136042 seconds. Throughput is 2901.3245 records/second. Loss is 0.21724622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004939247258717772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15000/60000][Iteration 5125][Wall Clock 237.109570194s] Trained 120 records in 0.04163144 seconds. Throughput is 2882.4368 records/second. Loss is 0.18737428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004938759383642829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15120/60000][Iteration 5126][Wall Clock 237.150855395s] Trained 120 records in 0.041285201 seconds. Throughput is 2906.6104 records/second. Loss is 0.21956491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004938271604938271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15240/60000][Iteration 5127][Wall Clock 237.192267419s] Trained 120 records in 0.041412024 seconds. Throughput is 2897.709 records/second. Loss is 0.12262206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004937783922575548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15360/60000][Iteration 5128][Wall Clock 237.232806844s] Trained 120 records in 0.040539425 seconds. Throughput is 2960.0815 records/second. Loss is 0.18559286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004937296336526118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15480/60000][Iteration 5129][Wall Clock 237.273620572s] Trained 120 records in 0.040813728 seconds. Throughput is 2940.187 records/second. Loss is 0.15402752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049368088467614535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15600/60000][Iteration 5130][Wall Clock 237.313908338s] Trained 120 records in 0.040287766 seconds. Throughput is 2978.5718 records/second. Loss is 0.24253593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004936321453253035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15720/60000][Iteration 5131][Wall Clock 237.36296102s] Trained 120 records in 0.049052682 seconds. Throughput is 2446.3494 records/second. Loss is 0.14160751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00493583415597236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15840/60000][Iteration 5132][Wall Clock 237.413816577s] Trained 120 records in 0.050855557 seconds. Throughput is 2359.624 records/second. Loss is 0.3356942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004935346954890929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 15960/60000][Iteration 5133][Wall Clock 237.456645029s] Trained 120 records in 0.042828452 seconds. Throughput is 2801.8757 records/second. Loss is 0.18586425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004934859849980261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 16080/60000][Iteration 5134][Wall Clock 237.497960904s] Trained 120 records in 0.041315875 seconds. Throughput is 2904.4526 records/second. Loss is 0.23024203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004934372841211882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:03 INFO  DistriOptimizer$:406 - [Epoch 11 16200/60000][Iteration 5135][Wall Clock 237.542627656s] Trained 120 records in 0.044666752 seconds. Throughput is 2686.562 records/second. Loss is 0.33045545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049338859285573316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 16320/60000][Iteration 5136][Wall Clock 237.584103878s] Trained 120 records in 0.041476222 seconds. Throughput is 2893.2239 records/second. Loss is 0.22820784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00493339911198816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 16440/60000][Iteration 5137][Wall Clock 237.625303314s] Trained 120 records in 0.041199436 seconds. Throughput is 2912.6614 records/second. Loss is 0.24595867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004932912391475927. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 16560/60000][Iteration 5138][Wall Clock 237.666261084s] Trained 120 records in 0.04095777 seconds. Throughput is 2929.847 records/second. Loss is 0.26354057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049324257669922066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 16680/60000][Iteration 5139][Wall Clock 237.706573786s] Trained 120 records in 0.040312702 seconds. Throughput is 2976.7292 records/second. Loss is 0.24947889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004931939238508582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 16800/60000][Iteration 5140][Wall Clock 237.753052605s] Trained 120 records in 0.046478819 seconds. Throughput is 2581.8213 records/second. Loss is 0.26356083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004931452805996646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 16920/60000][Iteration 5141][Wall Clock 237.797743332s] Trained 120 records in 0.044690727 seconds. Throughput is 2685.1206 records/second. Loss is 0.21389614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004930966469428008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17040/60000][Iteration 5142][Wall Clock 237.838455434s] Trained 120 records in 0.040712102 seconds. Throughput is 2947.5264 records/second. Loss is 0.14820077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004930480228774283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17160/60000][Iteration 5143][Wall Clock 237.879623276s] Trained 120 records in 0.041167842 seconds. Throughput is 2914.8967 records/second. Loss is 0.17086132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004929994084007099. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17280/60000][Iteration 5144][Wall Clock 237.92094494s] Trained 120 records in 0.041321664 seconds. Throughput is 2904.0457 records/second. Loss is 0.21260545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004929508035098097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17400/60000][Iteration 5145][Wall Clock 237.962337416s] Trained 120 records in 0.041392476 seconds. Throughput is 2899.0776 records/second. Loss is 0.22102833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004929022082018926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17520/60000][Iteration 5146][Wall Clock 238.003490095s] Trained 120 records in 0.041152679 seconds. Throughput is 2915.9707 records/second. Loss is 0.10115121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004928536224741252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17640/60000][Iteration 5147][Wall Clock 238.044554947s] Trained 120 records in 0.041064852 seconds. Throughput is 2922.207 records/second. Loss is 0.16224311. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004928050463236743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17760/60000][Iteration 5148][Wall Clock 238.086217862s] Trained 120 records in 0.041662915 seconds. Throughput is 2880.2593 records/second. Loss is 0.20184875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004927564797477088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 17880/60000][Iteration 5149][Wall Clock 238.127313112s] Trained 120 records in 0.04109525 seconds. Throughput is 2920.0457 records/second. Loss is 0.25797912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004927079227433976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18000/60000][Iteration 5150][Wall Clock 238.168394493s] Trained 120 records in 0.041081381 seconds. Throughput is 2921.0312 records/second. Loss is 0.22209482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004926593753079122. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18120/60000][Iteration 5151][Wall Clock 238.209568272s] Trained 120 records in 0.041173779 seconds. Throughput is 2914.4763 records/second. Loss is 0.23225905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004926108374384236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18240/60000][Iteration 5152][Wall Clock 238.251575517s] Trained 120 records in 0.042007245 seconds. Throughput is 2856.6501 records/second. Loss is 0.21310173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004925623091321053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18360/60000][Iteration 5153][Wall Clock 238.292899268s] Trained 120 records in 0.041323751 seconds. Throughput is 2903.899 records/second. Loss is 0.1635408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004925137903861307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18480/60000][Iteration 5154][Wall Clock 238.336593449s] Trained 120 records in 0.043694181 seconds. Throughput is 2746.3613 records/second. Loss is 0.234095. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049246528119767565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18600/60000][Iteration 5155][Wall Clock 238.377085199s] Trained 120 records in 0.04049175 seconds. Throughput is 2963.5667 records/second. Loss is 0.2448662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004924167815639157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18720/60000][Iteration 5156][Wall Clock 238.428301042s] Trained 120 records in 0.051215843 seconds. Throughput is 2343.025 records/second. Loss is 0.28380713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004923682914820285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18840/60000][Iteration 5157][Wall Clock 238.478846171s] Trained 120 records in 0.050545129 seconds. Throughput is 2374.116 records/second. Loss is 0.18653646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004923198109491926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:04 INFO  DistriOptimizer$:406 - [Epoch 11 18960/60000][Iteration 5158][Wall Clock 238.519939024s] Trained 120 records in 0.041092853 seconds. Throughput is 2920.2158 records/second. Loss is 0.27675217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004922713399625874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19080/60000][Iteration 5159][Wall Clock 238.5610152s] Trained 120 records in 0.041076176 seconds. Throughput is 2921.4014 records/second. Loss is 0.14180218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004922228785193936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19200/60000][Iteration 5160][Wall Clock 238.604309829s] Trained 120 records in 0.043294629 seconds. Throughput is 2771.7065 records/second. Loss is 0.22660767. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00492174426616793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19320/60000][Iteration 5161][Wall Clock 238.648100368s] Trained 120 records in 0.043790539 seconds. Throughput is 2740.318 records/second. Loss is 0.14123999. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004921259842519685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19440/60000][Iteration 5162][Wall Clock 238.69176435s] Trained 120 records in 0.043663982 seconds. Throughput is 2748.2605 records/second. Loss is 0.23891488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004920775514221041. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19560/60000][Iteration 5163][Wall Clock 238.735588493s] Trained 120 records in 0.043824143 seconds. Throughput is 2738.2166 records/second. Loss is 0.11826431. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00492029128124385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19680/60000][Iteration 5164][Wall Clock 238.777427206s] Trained 120 records in 0.041838713 seconds. Throughput is 2868.157 records/second. Loss is 0.32929724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004919807143559973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19800/60000][Iteration 5165][Wall Clock 238.818877672s] Trained 120 records in 0.041450466 seconds. Throughput is 2895.0217 records/second. Loss is 0.31835315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049193231011412835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 19920/60000][Iteration 5166][Wall Clock 238.859968454s] Trained 120 records in 0.041090782 seconds. Throughput is 2920.363 records/second. Loss is 0.22100224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004918839153959665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20040/60000][Iteration 5167][Wall Clock 238.907030577s] Trained 120 records in 0.047062123 seconds. Throughput is 2549.8213 records/second. Loss is 0.15632372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004918355301987016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20160/60000][Iteration 5168][Wall Clock 238.954479802s] Trained 120 records in 0.047449225 seconds. Throughput is 2529.0193 records/second. Loss is 0.15235463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004917871545195239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20280/60000][Iteration 5169][Wall Clock 238.995709762s] Trained 120 records in 0.04122996 seconds. Throughput is 2910.505 records/second. Loss is 0.18607329. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049173878835562556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20400/60000][Iteration 5170][Wall Clock 239.036616608s] Trained 120 records in 0.040906846 seconds. Throughput is 2933.4944 records/second. Loss is 0.2924722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00491690431704199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20520/60000][Iteration 5171][Wall Clock 239.078296881s] Trained 120 records in 0.041680273 seconds. Throughput is 2879.0598 records/second. Loss is 0.30874425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004916420845624386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20640/60000][Iteration 5172][Wall Clock 239.119123009s] Trained 120 records in 0.040826128 seconds. Throughput is 2939.2942 records/second. Loss is 0.22242616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004915937469275391. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20760/60000][Iteration 5173][Wall Clock 239.16352353s] Trained 120 records in 0.044400521 seconds. Throughput is 2702.671 records/second. Loss is 0.20156403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004915454187966969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 20880/60000][Iteration 5174][Wall Clock 239.204702856s] Trained 120 records in 0.041179326 seconds. Throughput is 2914.0837 records/second. Loss is 0.21781822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00491497100167109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 21000/60000][Iteration 5175][Wall Clock 239.246081096s] Trained 120 records in 0.04137824 seconds. Throughput is 2900.075 records/second. Loss is 0.27251893. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004914487910359741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 21120/60000][Iteration 5176][Wall Clock 239.287354357s] Trained 120 records in 0.041273261 seconds. Throughput is 2907.4512 records/second. Loss is 0.20473142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004914004914004914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 21240/60000][Iteration 5177][Wall Clock 239.328069556s] Trained 120 records in 0.040715199 seconds. Throughput is 2947.3022 records/second. Loss is 0.28540128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004913522012578616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 21360/60000][Iteration 5178][Wall Clock 239.368359233s] Trained 120 records in 0.040289677 seconds. Throughput is 2978.4304 records/second. Loss is 0.20843874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004913039206052864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 21480/60000][Iteration 5179][Wall Clock 239.409323762s] Trained 120 records in 0.040964529 seconds. Throughput is 2929.3635 records/second. Loss is 0.14365362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049125564943996855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 21600/60000][Iteration 5180][Wall Clock 239.449810142s] Trained 120 records in 0.04048638 seconds. Throughput is 2963.9597 records/second. Loss is 0.20631064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004912073877591119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:05 INFO  DistriOptimizer$:406 - [Epoch 11 21720/60000][Iteration 5181][Wall Clock 239.498133049s] Trained 120 records in 0.048322907 seconds. Throughput is 2483.2942 records/second. Loss is 0.3115106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004911591355599214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 21840/60000][Iteration 5182][Wall Clock 239.54824959s] Trained 120 records in 0.050116541 seconds. Throughput is 2394.419 records/second. Loss is 0.16125673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004911108928396032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 21960/60000][Iteration 5183][Wall Clock 239.591096385s] Trained 120 records in 0.042846795 seconds. Throughput is 2800.6763 records/second. Loss is 0.30520526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004910626595953644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22080/60000][Iteration 5184][Wall Clock 239.631116037s] Trained 120 records in 0.040019652 seconds. Throughput is 2998.5266 records/second. Loss is 0.30036965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004910144358244132. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22200/60000][Iteration 5185][Wall Clock 239.672208016s] Trained 120 records in 0.041091979 seconds. Throughput is 2920.278 records/second. Loss is 0.24946146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004909662215239592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22320/60000][Iteration 5186][Wall Clock 239.713098232s] Trained 120 records in 0.040890216 seconds. Throughput is 2934.6873 records/second. Loss is 0.22775024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004909180166912126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22440/60000][Iteration 5187][Wall Clock 239.754330136s] Trained 120 records in 0.041231904 seconds. Throughput is 2910.3677 records/second. Loss is 0.22745524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004908698213233849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22560/60000][Iteration 5188][Wall Clock 239.794897906s] Trained 120 records in 0.04056777 seconds. Throughput is 2958.0132 records/second. Loss is 0.27404773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004908216354176893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22680/60000][Iteration 5189][Wall Clock 239.834874605s] Trained 120 records in 0.039976699 seconds. Throughput is 3001.7488 records/second. Loss is 0.32764247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004907734589713388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22800/60000][Iteration 5190][Wall Clock 239.874865397s] Trained 120 records in 0.039990792 seconds. Throughput is 3000.691 records/second. Loss is 0.26133502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004907252919815488. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 22920/60000][Iteration 5191][Wall Clock 239.917431002s] Trained 120 records in 0.042565605 seconds. Throughput is 2819.1775 records/second. Loss is 0.1701061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004906771344455348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23040/60000][Iteration 5192][Wall Clock 239.957971317s] Trained 120 records in 0.040540315 seconds. Throughput is 2960.0164 records/second. Loss is 0.15117072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004906289863605143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23160/60000][Iteration 5193][Wall Clock 239.999008638s] Trained 120 records in 0.041037321 seconds. Throughput is 2924.1675 records/second. Loss is 0.3125118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004905808477237048. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23280/60000][Iteration 5194][Wall Clock 240.048404729s] Trained 120 records in 0.049396091 seconds. Throughput is 2429.342 records/second. Loss is 0.20912439. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004905327185323262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23400/60000][Iteration 5195][Wall Clock 240.093560982s] Trained 120 records in 0.045156253 seconds. Throughput is 2657.4395 records/second. Loss is 0.20185846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004904845987835982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23520/60000][Iteration 5196][Wall Clock 240.135171031s] Trained 120 records in 0.041610049 seconds. Throughput is 2883.919 records/second. Loss is 0.2026133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004904364884747425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23640/60000][Iteration 5197][Wall Clock 240.178359563s] Trained 120 records in 0.043188532 seconds. Throughput is 2778.5154 records/second. Loss is 0.23145482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004903883876029815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23760/60000][Iteration 5198][Wall Clock 240.219698603s] Trained 120 records in 0.04133904 seconds. Throughput is 2902.825 records/second. Loss is 0.16309746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004903402961655388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 23880/60000][Iteration 5199][Wall Clock 240.260303693s] Trained 120 records in 0.04060509 seconds. Throughput is 2955.2944 records/second. Loss is 0.25090984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004902922141596391. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 24000/60000][Iteration 5200][Wall Clock 240.301125572s] Trained 120 records in 0.040821879 seconds. Throughput is 2939.6 records/second. Loss is 0.16017729. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0049024414158250805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 24120/60000][Iteration 5201][Wall Clock 240.341738233s] Trained 120 records in 0.040612661 seconds. Throughput is 2954.7437 records/second. Loss is 0.18713208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004901960784313725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 24240/60000][Iteration 5202][Wall Clock 240.38201982s] Trained 120 records in 0.040281587 seconds. Throughput is 2979.0286 records/second. Loss is 0.21085022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004901480247034604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 24360/60000][Iteration 5203][Wall Clock 240.423013838s] Trained 120 records in 0.040994018 seconds. Throughput is 2927.2563 records/second. Loss is 0.22639383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004900999803960008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 24480/60000][Iteration 5204][Wall Clock 240.464542645s] Trained 120 records in 0.041528807 seconds. Throughput is 2889.5605 records/second. Loss is 0.22360188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004900519455062237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:06 INFO  DistriOptimizer$:406 - [Epoch 11 24600/60000][Iteration 5205][Wall Clock 240.505775813s] Trained 120 records in 0.041233168 seconds. Throughput is 2910.2786 records/second. Loss is 0.14988072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004900039200313603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 24720/60000][Iteration 5206][Wall Clock 240.548325577s] Trained 120 records in 0.042549764 seconds. Throughput is 2820.2273 records/second. Loss is 0.21461459. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004899559039686427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 24840/60000][Iteration 5207][Wall Clock 240.598422335s] Trained 120 records in 0.050096758 seconds. Throughput is 2395.3645 records/second. Loss is 0.17408785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004899078973153047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 24960/60000][Iteration 5208][Wall Clock 240.643452151s] Trained 120 records in 0.045029816 seconds. Throughput is 2664.9011 records/second. Loss is 0.24422923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004898599000685803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25080/60000][Iteration 5209][Wall Clock 240.684760823s] Trained 120 records in 0.041308672 seconds. Throughput is 2904.959 records/second. Loss is 0.2422563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004898119122257054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25200/60000][Iteration 5210][Wall Clock 240.729204779s] Trained 120 records in 0.044443956 seconds. Throughput is 2700.0295 records/second. Loss is 0.21792646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004897639337839161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25320/60000][Iteration 5211][Wall Clock 240.770155736s] Trained 120 records in 0.040950957 seconds. Throughput is 2930.3345 records/second. Loss is 0.13205853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004897159647404506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25440/60000][Iteration 5212][Wall Clock 240.810622211s] Trained 120 records in 0.040466475 seconds. Throughput is 2965.4175 records/second. Loss is 0.18761674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004896680050925472. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25560/60000][Iteration 5213][Wall Clock 240.850902298s] Trained 120 records in 0.040280087 seconds. Throughput is 2979.1394 records/second. Loss is 0.22154637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004896200548374462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25680/60000][Iteration 5214][Wall Clock 240.89114572s] Trained 120 records in 0.040243422 seconds. Throughput is 2981.8538 records/second. Loss is 0.29690662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004895721139723881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25800/60000][Iteration 5215][Wall Clock 240.931747079s] Trained 120 records in 0.040601359 seconds. Throughput is 2955.5662 records/second. Loss is 0.17336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004895241824946153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 25920/60000][Iteration 5216][Wall Clock 240.972413884s] Trained 120 records in 0.040666805 seconds. Throughput is 2950.8098 records/second. Loss is 0.21486036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004894762604013705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26040/60000][Iteration 5217][Wall Clock 241.012516236s] Trained 120 records in 0.040102352 seconds. Throughput is 2992.3433 records/second. Loss is 0.3018348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004894283476898981. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26160/60000][Iteration 5218][Wall Clock 241.053994477s] Trained 120 records in 0.041478241 seconds. Throughput is 2893.083 records/second. Loss is 0.18716322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004893804443574435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26280/60000][Iteration 5219][Wall Clock 241.095314966s] Trained 120 records in 0.041320489 seconds. Throughput is 2904.1284 records/second. Loss is 0.28217414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004893325504012527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26400/60000][Iteration 5220][Wall Clock 241.136664641s] Trained 120 records in 0.041349675 seconds. Throughput is 2902.0784 records/second. Loss is 0.18412156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004892846658185733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26520/60000][Iteration 5221][Wall Clock 241.192350082s] Trained 120 records in 0.055685441 seconds. Throughput is 2154.962 records/second. Loss is 0.26017657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004892367906066536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26640/60000][Iteration 5222][Wall Clock 241.236041161s] Trained 120 records in 0.043691079 seconds. Throughput is 2746.5562 records/second. Loss is 0.2672253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004891889247627434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26760/60000][Iteration 5223][Wall Clock 241.277052462s] Trained 120 records in 0.041011301 seconds. Throughput is 2926.023 records/second. Loss is 0.25672653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004891410682840931. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 26880/60000][Iteration 5224][Wall Clock 241.318076978s] Trained 120 records in 0.041024516 seconds. Throughput is 2925.08 records/second. Loss is 0.18620962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004890932211679546. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 27000/60000][Iteration 5225][Wall Clock 241.358967706s] Trained 120 records in 0.040890728 seconds. Throughput is 2934.6506 records/second. Loss is 0.3106383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004890453834115806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 27120/60000][Iteration 5226][Wall Clock 241.399565045s] Trained 120 records in 0.040597339 seconds. Throughput is 2955.859 records/second. Loss is 0.16971129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004889975550122249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 27240/60000][Iteration 5227][Wall Clock 241.440157001s] Trained 120 records in 0.040591956 seconds. Throughput is 2956.2507 records/second. Loss is 0.18044318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004889497359671425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 27360/60000][Iteration 5228][Wall Clock 241.48191244s] Trained 120 records in 0.041755439 seconds. Throughput is 2873.8772 records/second. Loss is 0.12049609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004889019262735895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:07 INFO  DistriOptimizer$:406 - [Epoch 11 27480/60000][Iteration 5229][Wall Clock 241.52732493s] Trained 120 records in 0.04541249 seconds. Throughput is 2642.4448 records/second. Loss is 0.19799641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004888541259288228. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 27600/60000][Iteration 5230][Wall Clock 241.568376207s] Trained 120 records in 0.041051277 seconds. Throughput is 2923.1733 records/second. Loss is 0.14255852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004888063349301007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 27720/60000][Iteration 5231][Wall Clock 241.610140963s] Trained 120 records in 0.041764756 seconds. Throughput is 2873.236 records/second. Loss is 0.24935168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004887585532746822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 27840/60000][Iteration 5232][Wall Clock 241.657387468s] Trained 120 records in 0.047246505 seconds. Throughput is 2539.8704 records/second. Loss is 0.23634733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004887107809598281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 27960/60000][Iteration 5233][Wall Clock 241.701529709s] Trained 120 records in 0.044142241 seconds. Throughput is 2718.4844 records/second. Loss is 0.21328004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048866301798279905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28080/60000][Iteration 5234][Wall Clock 241.742954735s] Trained 120 records in 0.041425026 seconds. Throughput is 2896.7996 records/second. Loss is 0.23925085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004886152643408581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28200/60000][Iteration 5235][Wall Clock 241.783837803s] Trained 120 records in 0.040883068 seconds. Throughput is 2935.2004 records/second. Loss is 0.20923163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004885675200312683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28320/60000][Iteration 5236][Wall Clock 241.824372154s] Trained 120 records in 0.040534351 seconds. Throughput is 2960.452 records/second. Loss is 0.26898548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004885197850512946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28440/60000][Iteration 5237][Wall Clock 241.86499193s] Trained 120 records in 0.040619776 seconds. Throughput is 2954.226 records/second. Loss is 0.1745256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004884720593982024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28560/60000][Iteration 5238][Wall Clock 241.905703961s] Trained 120 records in 0.040712031 seconds. Throughput is 2947.5315 records/second. Loss is 0.16038081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004884243430692586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28680/60000][Iteration 5239][Wall Clock 241.946527585s] Trained 120 records in 0.040823624 seconds. Throughput is 2939.4746 records/second. Loss is 0.26401454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004883766360617308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28800/60000][Iteration 5240][Wall Clock 241.986877928s] Trained 120 records in 0.040350343 seconds. Throughput is 2973.9524 records/second. Loss is 0.2577129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00488328938372888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 28920/60000][Iteration 5241][Wall Clock 242.027937983s] Trained 120 records in 0.041060055 seconds. Throughput is 2922.5483 records/second. Loss is 0.29359916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048828125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29040/60000][Iteration 5242][Wall Clock 242.068769514s] Trained 120 records in 0.040831531 seconds. Throughput is 2938.905 records/second. Loss is 0.19593363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004882335709403379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29160/60000][Iteration 5243][Wall Clock 242.109350403s] Trained 120 records in 0.040580889 seconds. Throughput is 2957.0571 records/second. Loss is 0.16743916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004881859011911736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29280/60000][Iteration 5244][Wall Clock 242.150019169s] Trained 120 records in 0.040668766 seconds. Throughput is 2950.6672 records/second. Loss is 0.15596776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004881382407497804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29400/60000][Iteration 5245][Wall Clock 242.189954121s] Trained 120 records in 0.039934952 seconds. Throughput is 3004.8865 records/second. Loss is 0.16789027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004880905896134323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29520/60000][Iteration 5246][Wall Clock 242.23010908s] Trained 120 records in 0.040154959 seconds. Throughput is 2988.4229 records/second. Loss is 0.25558275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004880429477794045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29640/60000][Iteration 5247][Wall Clock 242.270506613s] Trained 120 records in 0.040397533 seconds. Throughput is 2970.4785 records/second. Loss is 0.2229421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004879953152449737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29760/60000][Iteration 5248][Wall Clock 242.325929873s] Trained 120 records in 0.05542326 seconds. Throughput is 2165.156 records/second. Loss is 0.21056621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004879476920074168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 29880/60000][Iteration 5249][Wall Clock 242.368985876s] Trained 120 records in 0.043056003 seconds. Throughput is 2787.0679 records/second. Loss is 0.18740228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004879000780640125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 30000/60000][Iteration 5250][Wall Clock 242.409927155s] Trained 120 records in 0.040941279 seconds. Throughput is 2931.027 records/second. Loss is 0.13920097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004878524734120401. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 30120/60000][Iteration 5251][Wall Clock 242.450558871s] Trained 120 records in 0.040631716 seconds. Throughput is 2953.358 records/second. Loss is 0.11295945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004878048780487806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 30240/60000][Iteration 5252][Wall Clock 242.491184135s] Trained 120 records in 0.040625264 seconds. Throughput is 2953.8271 records/second. Loss is 0.1804457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00487757291971515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:08 INFO  DistriOptimizer$:406 - [Epoch 11 30360/60000][Iteration 5253][Wall Clock 242.532108651s] Trained 120 records in 0.040924516 seconds. Throughput is 2932.2278 records/second. Loss is 0.23200591. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004877097151775264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 30480/60000][Iteration 5254][Wall Clock 242.573073242s] Trained 120 records in 0.040964591 seconds. Throughput is 2929.3591 records/second. Loss is 0.29758978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004876621476640983. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 30600/60000][Iteration 5255][Wall Clock 242.614002371s] Trained 120 records in 0.040929129 seconds. Throughput is 2931.8975 records/second. Loss is 0.20083202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004876145894285157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 30720/60000][Iteration 5256][Wall Clock 242.656524262s] Trained 120 records in 0.042521891 seconds. Throughput is 2822.076 records/second. Loss is 0.25308782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048756704046806435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 30840/60000][Iteration 5257][Wall Clock 242.70549048s] Trained 120 records in 0.048966218 seconds. Throughput is 2450.6692 records/second. Loss is 0.1689008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004875195007800312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 30960/60000][Iteration 5258][Wall Clock 242.74931518s] Trained 120 records in 0.0438247 seconds. Throughput is 2738.182 records/second. Loss is 0.17944618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004874719703617042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31080/60000][Iteration 5259][Wall Clock 242.790943052s] Trained 120 records in 0.041627872 seconds. Throughput is 2882.6838 records/second. Loss is 0.1732565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004874244492103724. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31200/60000][Iteration 5260][Wall Clock 242.83144484s] Trained 120 records in 0.040501788 seconds. Throughput is 2962.832 records/second. Loss is 0.2083829. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048737693732332586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31320/60000][Iteration 5261][Wall Clock 242.871671053s] Trained 120 records in 0.040226213 seconds. Throughput is 2983.1294 records/second. Loss is 0.18173575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004873294346978557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31440/60000][Iteration 5262][Wall Clock 242.912277573s] Trained 120 records in 0.04060652 seconds. Throughput is 2955.1904 records/second. Loss is 0.12523961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004872819413312543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31560/60000][Iteration 5263][Wall Clock 242.953677162s] Trained 120 records in 0.041399589 seconds. Throughput is 2898.5793 records/second. Loss is 0.19266964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004872344572208147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31680/60000][Iteration 5264][Wall Clock 242.994702502s] Trained 120 records in 0.04102534 seconds. Throughput is 2925.0215 records/second. Loss is 0.16993204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004871869823638313. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31800/60000][Iteration 5265][Wall Clock 243.03617727s] Trained 120 records in 0.041474768 seconds. Throughput is 2893.3254 records/second. Loss is 0.23924072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004871395167575994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 31920/60000][Iteration 5266][Wall Clock 243.080568241s] Trained 120 records in 0.044390971 seconds. Throughput is 2703.2524 records/second. Loss is 0.24221739. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004870920603994155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32040/60000][Iteration 5267][Wall Clock 243.121759759s] Trained 120 records in 0.041191518 seconds. Throughput is 2913.2212 records/second. Loss is 0.24747671. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00487044613286577. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32160/60000][Iteration 5268][Wall Clock 243.162325299s] Trained 120 records in 0.04056554 seconds. Throughput is 2958.1758 records/second. Loss is 0.21824966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004869971754163826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32280/60000][Iteration 5269][Wall Clock 243.203202329s] Trained 120 records in 0.04087703 seconds. Throughput is 2935.634 records/second. Loss is 0.19571593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004869497467861316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32400/60000][Iteration 5270][Wall Clock 243.243369599s] Trained 120 records in 0.04016727 seconds. Throughput is 2987.507 records/second. Loss is 0.1660131. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00486902327393125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32520/60000][Iteration 5271][Wall Clock 243.28318924s] Trained 120 records in 0.039819641 seconds. Throughput is 3013.5884 records/second. Loss is 0.21387216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00486854917234664. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32640/60000][Iteration 5272][Wall Clock 243.32291043s] Trained 120 records in 0.03972119 seconds. Throughput is 3021.0574 records/second. Loss is 0.18288833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004868075163080518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32760/60000][Iteration 5273][Wall Clock 243.362916526s] Trained 120 records in 0.040006096 seconds. Throughput is 2999.5427 records/second. Loss is 0.1886686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004867601246105919. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 32880/60000][Iteration 5274][Wall Clock 243.410016719s] Trained 120 records in 0.047100193 seconds. Throughput is 2547.7603 records/second. Loss is 0.16160539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004867127421395893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 33000/60000][Iteration 5275][Wall Clock 243.456712838s] Trained 120 records in 0.046696119 seconds. Throughput is 2569.8066 records/second. Loss is 0.16209605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004866653688923496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:09 INFO  DistriOptimizer$:406 - [Epoch 11 33120/60000][Iteration 5276][Wall Clock 243.50011069s] Trained 120 records in 0.043397852 seconds. Throughput is 2765.1138 records/second. Loss is 0.1346458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004866180048661801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 33240/60000][Iteration 5277][Wall Clock 243.54031315s] Trained 120 records in 0.04020246 seconds. Throughput is 2984.8918 records/second. Loss is 0.18275525. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004865706500583884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 33360/60000][Iteration 5278][Wall Clock 243.580329257s] Trained 120 records in 0.040016107 seconds. Throughput is 2998.7925 records/second. Loss is 0.20717518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048652330446628395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 33480/60000][Iteration 5279][Wall Clock 243.620556574s] Trained 120 records in 0.040227317 seconds. Throughput is 2983.0476 records/second. Loss is 0.1775463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004864759680871765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 33600/60000][Iteration 5280][Wall Clock 243.661369232s] Trained 120 records in 0.040812658 seconds. Throughput is 2940.2644 records/second. Loss is 0.1852622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004864286409183773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 33720/60000][Iteration 5281][Wall Clock 243.703521188s] Trained 120 records in 0.042151956 seconds. Throughput is 2846.8428 records/second. Loss is 0.31058198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048638132295719845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 33840/60000][Iteration 5282][Wall Clock 243.752912757s] Trained 120 records in 0.049391569 seconds. Throughput is 2429.5645 records/second. Loss is 0.14737955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048633401420095325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 33960/60000][Iteration 5283][Wall Clock 243.79875602s] Trained 120 records in 0.045843263 seconds. Throughput is 2617.6147 records/second. Loss is 0.19541317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004862867146469559. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34080/60000][Iteration 5284][Wall Clock 243.840733521s] Trained 120 records in 0.041977501 seconds. Throughput is 2858.674 records/second. Loss is 0.24081822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004862394242925216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34200/60000][Iteration 5285][Wall Clock 243.884721267s] Trained 120 records in 0.043987746 seconds. Throughput is 2728.0325 records/second. Loss is 0.22715852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048619214313496695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34320/60000][Iteration 5286][Wall Clock 243.925279103s] Trained 120 records in 0.040557836 seconds. Throughput is 2958.7378 records/second. Loss is 0.28350314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048614487117160906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34440/60000][Iteration 5287][Wall Clock 243.965458744s] Trained 120 records in 0.040179641 seconds. Throughput is 2986.5872 records/second. Loss is 0.109554596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004860976083997667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34560/60000][Iteration 5288][Wall Clock 244.00588754s] Trained 120 records in 0.040428796 seconds. Throughput is 2968.1814 records/second. Loss is 0.19576995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00486050354816759. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34680/60000][Iteration 5289][Wall Clock 244.046540814s] Trained 120 records in 0.040653274 seconds. Throughput is 2951.7917 records/second. Loss is 0.20681559. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004860031104199068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34800/60000][Iteration 5290][Wall Clock 244.087012084s] Trained 120 records in 0.04047127 seconds. Throughput is 2965.0662 records/second. Loss is 0.1790136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004859558752065312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 34920/60000][Iteration 5291][Wall Clock 244.127560016s] Trained 120 records in 0.040547932 seconds. Throughput is 2959.4602 records/second. Loss is 0.19904324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004859086491739554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35040/60000][Iteration 5292][Wall Clock 244.16808275s] Trained 120 records in 0.040522734 seconds. Throughput is 2961.3005 records/second. Loss is 0.23219074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004858614323195024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35160/60000][Iteration 5293][Wall Clock 244.208975086s] Trained 120 records in 0.040892336 seconds. Throughput is 2934.5352 records/second. Loss is 0.29397428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004858142246404976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35280/60000][Iteration 5294][Wall Clock 244.249510095s] Trained 120 records in 0.040535009 seconds. Throughput is 2960.4038 records/second. Loss is 0.19068308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00485767026134266. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35400/60000][Iteration 5295][Wall Clock 244.289727008s] Trained 120 records in 0.040216913 seconds. Throughput is 2983.8193 records/second. Loss is 0.1549027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048571983679813495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35520/60000][Iteration 5296][Wall Clock 244.329842553s] Trained 120 records in 0.040115545 seconds. Throughput is 2991.359 records/second. Loss is 0.17359073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048567265662943174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35640/60000][Iteration 5297][Wall Clock 244.370324796s] Trained 120 records in 0.040482243 seconds. Throughput is 2964.2627 records/second. Loss is 0.21463893. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004856254856254856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35760/60000][Iteration 5298][Wall Clock 244.410794562s] Trained 120 records in 0.040469766 seconds. Throughput is 2965.1765 records/second. Loss is 0.22197558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004855783237836263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 35880/60000][Iteration 5299][Wall Clock 244.450834189s] Trained 120 records in 0.040039627 seconds. Throughput is 2997.0308 records/second. Loss is 0.22458191. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004855311711011847. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:10 INFO  DistriOptimizer$:406 - [Epoch 11 36000/60000][Iteration 5300][Wall Clock 244.491160198s] Trained 120 records in 0.040326009 seconds. Throughput is 2975.7468 records/second. Loss is 0.14516954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004854840275754928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36120/60000][Iteration 5301][Wall Clock 244.539350243s] Trained 120 records in 0.048190045 seconds. Throughput is 2490.1409 records/second. Loss is 0.16130081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048543689320388345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36240/60000][Iteration 5302][Wall Clock 244.586857491s] Trained 120 records in 0.047507248 seconds. Throughput is 2525.9304 records/second. Loss is 0.20534714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004853897679836909. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36360/60000][Iteration 5303][Wall Clock 244.632032999s] Trained 120 records in 0.045175508 seconds. Throughput is 2656.3066 records/second. Loss is 0.21132974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048534265191225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36480/60000][Iteration 5304][Wall Clock 244.672632633s] Trained 120 records in 0.040599634 seconds. Throughput is 2955.6917 records/second. Loss is 0.19500881. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00485295544986897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36600/60000][Iteration 5305][Wall Clock 244.713148774s] Trained 120 records in 0.040516141 seconds. Throughput is 2961.7825 records/second. Loss is 0.26624778. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00485248447204969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36720/60000][Iteration 5306][Wall Clock 244.754317986s] Trained 120 records in 0.041169212 seconds. Throughput is 2914.7996 records/second. Loss is 0.20974426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00485201358563804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36840/60000][Iteration 5307][Wall Clock 244.797911432s] Trained 120 records in 0.043593446 seconds. Throughput is 2752.7073 records/second. Loss is 0.20133585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004851542790607412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 36960/60000][Iteration 5308][Wall Clock 244.838604795s] Trained 120 records in 0.040693363 seconds. Throughput is 2948.884 records/second. Loss is 0.16872838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004851072086931212. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37080/60000][Iteration 5309][Wall Clock 244.885402002s] Trained 120 records in 0.046797207 seconds. Throughput is 2564.2556 records/second. Loss is 0.192665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004850601474582847. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37200/60000][Iteration 5310][Wall Clock 244.928966656s] Trained 120 records in 0.043564654 seconds. Throughput is 2754.5266 records/second. Loss is 0.17097211. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004850130953535746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37320/60000][Iteration 5311][Wall Clock 244.969794285s] Trained 120 records in 0.040827629 seconds. Throughput is 2939.1863 records/second. Loss is 0.32599112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004849660523763336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37440/60000][Iteration 5312][Wall Clock 245.010039332s] Trained 120 records in 0.040245047 seconds. Throughput is 2981.7332 records/second. Loss is 0.1866684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004849190185239066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37560/60000][Iteration 5313][Wall Clock 245.050583764s] Trained 120 records in 0.040544432 seconds. Throughput is 2959.7158 records/second. Loss is 0.22750838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004848719937936384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37680/60000][Iteration 5314][Wall Clock 245.091622318s] Trained 120 records in 0.041038554 seconds. Throughput is 2924.0796 records/second. Loss is 0.167167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00484824978182876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37800/60000][Iteration 5315][Wall Clock 245.132106054s] Trained 120 records in 0.040483736 seconds. Throughput is 2964.1533 records/second. Loss is 0.23356317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004847779716889664. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 37920/60000][Iteration 5316][Wall Clock 245.171904264s] Trained 120 records in 0.03979821 seconds. Throughput is 3015.211 records/second. Loss is 0.19412085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004847309743092584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38040/60000][Iteration 5317][Wall Clock 245.212212856s] Trained 120 records in 0.040308592 seconds. Throughput is 2977.033 records/second. Loss is 0.20509794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004846839860411012. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38160/60000][Iteration 5318][Wall Clock 245.253046147s] Trained 120 records in 0.040833291 seconds. Throughput is 2938.7786 records/second. Loss is 0.17206153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004846370068818454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38280/60000][Iteration 5319][Wall Clock 245.293693561s] Trained 120 records in 0.040647414 seconds. Throughput is 2952.2173 records/second. Loss is 0.21745779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004845900368288428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38400/60000][Iteration 5320][Wall Clock 245.334747497s] Trained 120 records in 0.041053936 seconds. Throughput is 2922.9841 records/second. Loss is 0.14823274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048454307587944565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38520/60000][Iteration 5321][Wall Clock 245.375322558s] Trained 120 records in 0.040575061 seconds. Throughput is 2957.4817 records/second. Loss is 0.23525669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048449612403100775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38640/60000][Iteration 5322][Wall Clock 245.417131588s] Trained 120 records in 0.04180903 seconds. Throughput is 2870.1934 records/second. Loss is 0.15052421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004844491812808836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38760/60000][Iteration 5323][Wall Clock 245.461908119s] Trained 120 records in 0.044776531 seconds. Throughput is 2679.9753 records/second. Loss is 0.18821448. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00484402247626429. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:11 INFO  DistriOptimizer$:406 - [Epoch 11 38880/60000][Iteration 5324][Wall Clock 245.503331042s] Trained 120 records in 0.041422923 seconds. Throughput is 2896.9468 records/second. Loss is 0.23227838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004843553230650005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39000/60000][Iteration 5325][Wall Clock 245.544324178s] Trained 120 records in 0.040993136 seconds. Throughput is 2927.3193 records/second. Loss is 0.17570812. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048430840759395586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39120/60000][Iteration 5326][Wall Clock 245.586838271s] Trained 120 records in 0.042514093 seconds. Throughput is 2822.5935 records/second. Loss is 0.26811486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004842615012106538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39240/60000][Iteration 5327][Wall Clock 245.628272761s] Trained 120 records in 0.04143449 seconds. Throughput is 2896.138 records/second. Loss is 0.16507258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00484214603912454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39360/60000][Iteration 5328][Wall Clock 245.687750968s] Trained 120 records in 0.059478207 seconds. Throughput is 2017.5457 records/second. Loss is 0.20809521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004841677156967173. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39480/60000][Iteration 5329][Wall Clock 245.738078516s] Trained 120 records in 0.050327548 seconds. Throughput is 2384.3801 records/second. Loss is 0.2464992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048412083656080565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39600/60000][Iteration 5330][Wall Clock 245.781795405s] Trained 120 records in 0.043716889 seconds. Throughput is 2744.9346 records/second. Loss is 0.2174933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004840739665020815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39720/60000][Iteration 5331][Wall Clock 245.824226882s] Trained 120 records in 0.042431477 seconds. Throughput is 2828.089 records/second. Loss is 0.2092101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004840271055179091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39840/60000][Iteration 5332][Wall Clock 245.867143286s] Trained 120 records in 0.042916404 seconds. Throughput is 2796.1338 records/second. Loss is 0.14177828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004839802536056528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 39960/60000][Iteration 5333][Wall Clock 245.907838791s] Trained 120 records in 0.040695505 seconds. Throughput is 2948.7288 records/second. Loss is 0.1715898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004839334107626791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40080/60000][Iteration 5334][Wall Clock 245.961009039s] Trained 120 records in 0.053170248 seconds. Throughput is 2256.9011 records/second. Loss is 0.2755375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004838865769863544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40200/60000][Iteration 5335][Wall Clock 246.003263817s] Trained 120 records in 0.042254778 seconds. Throughput is 2839.9155 records/second. Loss is 0.1734119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004838397522740469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40320/60000][Iteration 5336][Wall Clock 246.052686457s] Trained 120 records in 0.04942264 seconds. Throughput is 2428.037 records/second. Loss is 0.19197589. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004837929366231253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40440/60000][Iteration 5337][Wall Clock 246.095964004s] Trained 120 records in 0.043277547 seconds. Throughput is 2772.8005 records/second. Loss is 0.18152152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004837461300309597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40560/60000][Iteration 5338][Wall Clock 246.136994591s] Trained 120 records in 0.041030587 seconds. Throughput is 2924.6475 records/second. Loss is 0.2007615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004836993324949211. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40680/60000][Iteration 5339][Wall Clock 246.178091083s] Trained 120 records in 0.041096492 seconds. Throughput is 2919.957 records/second. Loss is 0.23349327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048365254401238145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40800/60000][Iteration 5340][Wall Clock 246.219782523s] Trained 120 records in 0.04169144 seconds. Throughput is 2878.2886 records/second. Loss is 0.21868798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004836057645807138. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 40920/60000][Iteration 5341][Wall Clock 246.264991608s] Trained 120 records in 0.045209085 seconds. Throughput is 2654.3337 records/second. Loss is 0.19889168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004835589941972921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 41040/60000][Iteration 5342][Wall Clock 246.306546167s] Trained 120 records in 0.041554559 seconds. Throughput is 2887.7698 records/second. Loss is 0.20717593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004835122328594913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 41160/60000][Iteration 5343][Wall Clock 246.348242054s] Trained 120 records in 0.041695887 seconds. Throughput is 2877.982 records/second. Loss is 0.23174635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004834654805646877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 41280/60000][Iteration 5344][Wall Clock 246.389239505s] Trained 120 records in 0.040997451 seconds. Throughput is 2927.0115 records/second. Loss is 0.23780364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004834187373102581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 41400/60000][Iteration 5345][Wall Clock 246.430423891s] Trained 120 records in 0.041184386 seconds. Throughput is 2913.7258 records/second. Loss is 0.18326524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004833720030935808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 41520/60000][Iteration 5346][Wall Clock 246.47109394s] Trained 120 records in 0.040670049 seconds. Throughput is 2950.5742 records/second. Loss is 0.18484816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004833252779120348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:12 INFO  DistriOptimizer$:406 - [Epoch 11 41640/60000][Iteration 5347][Wall Clock 246.511751329s] Trained 120 records in 0.040657389 seconds. Throughput is 2951.493 records/second. Loss is 0.18751517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004832785617630001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 41760/60000][Iteration 5348][Wall Clock 246.552710147s] Trained 120 records in 0.040958818 seconds. Throughput is 2929.772 records/second. Loss is 0.18027239. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004832318546438581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 41880/60000][Iteration 5349][Wall Clock 246.593550538s] Trained 120 records in 0.040840391 seconds. Throughput is 2938.2676 records/second. Loss is 0.27301887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004831851565519907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42000/60000][Iteration 5350][Wall Clock 246.63504509s] Trained 120 records in 0.041494552 seconds. Throughput is 2891.9458 records/second. Loss is 0.22049472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048313846748478115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42120/60000][Iteration 5351][Wall Clock 246.676717362s] Trained 120 records in 0.041672272 seconds. Throughput is 2879.6128 records/second. Loss is 0.19961374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004830917874396135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42240/60000][Iteration 5352][Wall Clock 246.717647597s] Trained 120 records in 0.040930235 seconds. Throughput is 2931.818 records/second. Loss is 0.24382909. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004830451164138731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42360/60000][Iteration 5353][Wall Clock 246.758334545s] Trained 120 records in 0.040686948 seconds. Throughput is 2949.3489 records/second. Loss is 0.26544887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004829984544049459. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42480/60000][Iteration 5354][Wall Clock 246.80869874s] Trained 120 records in 0.050364195 seconds. Throughput is 2382.645 records/second. Loss is 0.2063755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004829518014102193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42600/60000][Iteration 5355][Wall Clock 246.855232605s] Trained 120 records in 0.046533865 seconds. Throughput is 2578.767 records/second. Loss is 0.2553873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004829051574270813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42720/60000][Iteration 5356][Wall Clock 246.899661757s] Trained 120 records in 0.044429152 seconds. Throughput is 2700.9292 records/second. Loss is 0.14818026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004828585224529214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42840/60000][Iteration 5357][Wall Clock 246.943358575s] Trained 120 records in 0.043696818 seconds. Throughput is 2746.1956 records/second. Loss is 0.20144916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004828118964851294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 42960/60000][Iteration 5358][Wall Clock 246.984790956s] Trained 120 records in 0.041432381 seconds. Throughput is 2896.2854 records/second. Loss is 0.18489577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004827652795210968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43080/60000][Iteration 5359][Wall Clock 247.02602902s] Trained 120 records in 0.041238064 seconds. Throughput is 2909.9329 records/second. Loss is 0.22786517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048271867155821584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43200/60000][Iteration 5360][Wall Clock 247.06967823s] Trained 120 records in 0.04364921 seconds. Throughput is 2749.1907 records/second. Loss is 0.24410127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004826720725938797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43320/60000][Iteration 5361][Wall Clock 247.110509477s] Trained 120 records in 0.040831247 seconds. Throughput is 2938.9258 records/second. Loss is 0.17537576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004826254826254826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43440/60000][Iteration 5362][Wall Clock 247.158316412s] Trained 120 records in 0.047806935 seconds. Throughput is 2510.0962 records/second. Loss is 0.15845476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004825789016504199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43560/60000][Iteration 5363][Wall Clock 247.20503949s] Trained 120 records in 0.046723078 seconds. Throughput is 2568.324 records/second. Loss is 0.20863818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004825323296660877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43680/60000][Iteration 5364][Wall Clock 247.244862188s] Trained 120 records in 0.039822698 seconds. Throughput is 3013.357 records/second. Loss is 0.2131049. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048248576666988325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43800/60000][Iteration 5365][Wall Clock 247.286104617s] Trained 120 records in 0.041242429 seconds. Throughput is 2909.625 records/second. Loss is 0.12808529. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00482439212659205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 43920/60000][Iteration 5366][Wall Clock 247.326575056s] Trained 120 records in 0.040470439 seconds. Throughput is 2965.1272 records/second. Loss is 0.2080336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00482392667631452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 44040/60000][Iteration 5367][Wall Clock 247.367236254s] Trained 120 records in 0.040661198 seconds. Throughput is 2951.2166 records/second. Loss is 0.15036443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004823461315840247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 44160/60000][Iteration 5368][Wall Clock 247.408823225s] Trained 120 records in 0.041586971 seconds. Throughput is 2885.519 records/second. Loss is 0.09190205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004822996045143242. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 44280/60000][Iteration 5369][Wall Clock 247.451383376s] Trained 120 records in 0.042560151 seconds. Throughput is 2819.5388 records/second. Loss is 0.24574009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048225308641975315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:13 INFO  DistriOptimizer$:406 - [Epoch 11 44400/60000][Iteration 5370][Wall Clock 247.492973705s] Trained 120 records in 0.041590329 seconds. Throughput is 2885.2861 records/second. Loss is 0.29938278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004822065772977143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 44520/60000][Iteration 5371][Wall Clock 247.534098992s] Trained 120 records in 0.041125287 seconds. Throughput is 2917.9128 records/second. Loss is 0.16802493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048216007714561235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 44640/60000][Iteration 5372][Wall Clock 247.574397109s] Trained 120 records in 0.040298117 seconds. Throughput is 2977.8066 records/second. Loss is 0.18657665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004821135859608523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 44760/60000][Iteration 5373][Wall Clock 247.615808518s] Trained 120 records in 0.041411409 seconds. Throughput is 2897.7522 records/second. Loss is 0.28349924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004820671037408407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 44880/60000][Iteration 5374][Wall Clock 247.656709772s] Trained 120 records in 0.040901254 seconds. Throughput is 2933.8953 records/second. Loss is 0.20810089. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004820206304829846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45000/60000][Iteration 5375][Wall Clock 247.697954314s] Trained 120 records in 0.041244542 seconds. Throughput is 2909.476 records/second. Loss is 0.23033865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004819741661846926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45120/60000][Iteration 5376][Wall Clock 247.741513864s] Trained 120 records in 0.04355955 seconds. Throughput is 2754.8494 records/second. Loss is 0.19178466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048192771084337345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45240/60000][Iteration 5377][Wall Clock 247.786792035s] Trained 120 records in 0.045278171 seconds. Throughput is 2650.284 records/second. Loss is 0.24444537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004818812644564379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45360/60000][Iteration 5378][Wall Clock 247.827759107s] Trained 120 records in 0.040967072 seconds. Throughput is 2929.1816 records/second. Loss is 0.1659812. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004818348270212971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45480/60000][Iteration 5379][Wall Clock 247.871605169s] Trained 120 records in 0.043846062 seconds. Throughput is 2736.8477 records/second. Loss is 0.20126632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004817883985353632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45600/60000][Iteration 5380][Wall Clock 247.911978787s] Trained 120 records in 0.040373618 seconds. Throughput is 2972.2378 records/second. Loss is 0.19875804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004817419789960497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45720/60000][Iteration 5381][Wall Clock 247.969633465s] Trained 120 records in 0.057654678 seconds. Throughput is 2081.3574 records/second. Loss is 0.23344924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004816955684007707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45840/60000][Iteration 5382][Wall Clock 248.015748284s] Trained 120 records in 0.046114819 seconds. Throughput is 2602.2004 records/second. Loss is 0.21445353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004816491667469416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 45960/60000][Iteration 5383][Wall Clock 248.057762079s] Trained 120 records in 0.042013795 seconds. Throughput is 2856.2048 records/second. Loss is 0.2426672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004816027740319784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46080/60000][Iteration 5384][Wall Clock 248.100194158s] Trained 120 records in 0.042432079 seconds. Throughput is 2828.049 records/second. Loss is 0.15573761. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004815563902532987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46200/60000][Iteration 5385][Wall Clock 248.142093432s] Trained 120 records in 0.041899274 seconds. Throughput is 2864.0115 records/second. Loss is 0.28495914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0048151001540832055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46320/60000][Iteration 5386][Wall Clock 248.183639823s] Trained 120 records in 0.041546391 seconds. Throughput is 2888.3376 records/second. Loss is 0.27477202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004814636494944632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46440/60000][Iteration 5387][Wall Clock 248.224747945s] Trained 120 records in 0.041108122 seconds. Throughput is 2919.1313 records/second. Loss is 0.19617319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004814172925091468. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46560/60000][Iteration 5388][Wall Clock 248.265844664s] Trained 120 records in 0.041096719 seconds. Throughput is 2919.941 records/second. Loss is 0.21565166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00481370944449793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46680/60000][Iteration 5389][Wall Clock 248.315511132s] Trained 120 records in 0.049666468 seconds. Throughput is 2416.117 records/second. Loss is 0.2195917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004813246053138235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46800/60000][Iteration 5390][Wall Clock 248.359925229s] Trained 120 records in 0.044414097 seconds. Throughput is 2701.845 records/second. Loss is 0.13096474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004812782750986621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 46920/60000][Iteration 5391][Wall Clock 248.400762359s] Trained 120 records in 0.04083713 seconds. Throughput is 2938.5022 records/second. Loss is 0.10266054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004812319538017324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 47040/60000][Iteration 5392][Wall Clock 248.441453086s] Trained 120 records in 0.040690727 seconds. Throughput is 2949.0747 records/second. Loss is 0.19064885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004811856414204601. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:14 INFO  DistriOptimizer$:406 - [Epoch 11 47160/60000][Iteration 5393][Wall Clock 248.483289197s] Trained 120 records in 0.041836111 seconds. Throughput is 2868.3352 records/second. Loss is 0.1980093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004811393379522709. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 47280/60000][Iteration 5394][Wall Clock 248.525232384s] Trained 120 records in 0.041943187 seconds. Throughput is 2861.0127 records/second. Loss is 0.1680129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004810930433945926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 47400/60000][Iteration 5395][Wall Clock 248.566716685s] Trained 120 records in 0.041484301 seconds. Throughput is 2892.6606 records/second. Loss is 0.18319279. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004810467577448528. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 47520/60000][Iteration 5396][Wall Clock 248.608317776s] Trained 120 records in 0.041601091 seconds. Throughput is 2884.5398 records/second. Loss is 0.14341646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00481000481000481. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 47640/60000][Iteration 5397][Wall Clock 248.652355062s] Trained 120 records in 0.044037286 seconds. Throughput is 2724.9636 records/second. Loss is 0.21367598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004809542131589072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 47760/60000][Iteration 5398][Wall Clock 248.693745232s] Trained 120 records in 0.04139017 seconds. Throughput is 2899.2393 records/second. Loss is 0.18372437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004809079542175627. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 47880/60000][Iteration 5399][Wall Clock 248.734752672s] Trained 120 records in 0.04100744 seconds. Throughput is 2926.298 records/second. Loss is 0.19533764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004808617041738796. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48000/60000][Iteration 5400][Wall Clock 248.775799349s] Trained 120 records in 0.041046677 seconds. Throughput is 2923.501 records/second. Loss is 0.1682512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004808154630252909. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48120/60000][Iteration 5401][Wall Clock 248.816682844s] Trained 120 records in 0.040883495 seconds. Throughput is 2935.1697 records/second. Loss is 0.120818265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004807692307692308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48240/60000][Iteration 5402][Wall Clock 248.857541572s] Trained 120 records in 0.040858728 seconds. Throughput is 2936.949 records/second. Loss is 0.19377227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004807230074031343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48360/60000][Iteration 5403][Wall Clock 248.898239342s] Trained 120 records in 0.04069777 seconds. Throughput is 2948.5647 records/second. Loss is 0.20019208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004806767929244376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48480/60000][Iteration 5404][Wall Clock 248.938905969s] Trained 120 records in 0.040666627 seconds. Throughput is 2950.8225 records/second. Loss is 0.25356886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004806305873305777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48600/60000][Iteration 5405][Wall Clock 248.979203075s] Trained 120 records in 0.040297106 seconds. Throughput is 2977.8813 records/second. Loss is 0.16559245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004805843906189927. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48720/60000][Iteration 5406][Wall Clock 249.022913708s] Trained 120 records in 0.043710633 seconds. Throughput is 2745.3274 records/second. Loss is 0.23332578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004805382027871216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48840/60000][Iteration 5407][Wall Clock 249.073151666s] Trained 120 records in 0.050237958 seconds. Throughput is 2388.632 records/second. Loss is 0.22374988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004804920238324044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 48960/60000][Iteration 5408][Wall Clock 249.11622402s] Trained 120 records in 0.043072354 seconds. Throughput is 2786.0098 records/second. Loss is 0.2922998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004804458537522821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49080/60000][Iteration 5409][Wall Clock 249.156430253s] Trained 120 records in 0.040206233 seconds. Throughput is 2984.612 records/second. Loss is 0.21751174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004803996925441968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49200/60000][Iteration 5410][Wall Clock 249.196638206s] Trained 120 records in 0.040207953 seconds. Throughput is 2984.4841 records/second. Loss is 0.24853833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004803535402055912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49320/60000][Iteration 5411][Wall Clock 249.236964391s] Trained 120 records in 0.040326185 seconds. Throughput is 2975.734 records/second. Loss is 0.28015593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004803073967339097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49440/60000][Iteration 5412][Wall Clock 249.277582701s] Trained 120 records in 0.04061831 seconds. Throughput is 2954.3325 records/second. Loss is 0.29861566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004802612621265968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49560/60000][Iteration 5413][Wall Clock 249.318715475s] Trained 120 records in 0.041132774 seconds. Throughput is 2917.3816 records/second. Loss is 0.13991608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004802151363810988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49680/60000][Iteration 5414][Wall Clock 249.358938592s] Trained 120 records in 0.040223117 seconds. Throughput is 2983.359 records/second. Loss is 0.1942398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004801690194948621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49800/60000][Iteration 5415][Wall Clock 249.40480093s] Trained 120 records in 0.045862338 seconds. Throughput is 2616.526 records/second. Loss is 0.17618127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004801229114653352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 49920/60000][Iteration 5416][Wall Clock 249.454355512s] Trained 120 records in 0.049554582 seconds. Throughput is 2421.5723 records/second. Loss is 0.2526563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004800768122899664. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:15 INFO  DistriOptimizer$:406 - [Epoch 11 50040/60000][Iteration 5417][Wall Clock 249.494379823s] Trained 120 records in 0.040024311 seconds. Throughput is 2998.1777 records/second. Loss is 0.23365633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004800307219662058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 50160/60000][Iteration 5418][Wall Clock 249.535339135s] Trained 120 records in 0.040959312 seconds. Throughput is 2929.7366 records/second. Loss is 0.23034877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047998464049150424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 50280/60000][Iteration 5419][Wall Clock 249.575859856s] Trained 120 records in 0.040520721 seconds. Throughput is 2961.4478 records/second. Loss is 0.16317491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004799385678633135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 50400/60000][Iteration 5420][Wall Clock 249.616018207s] Trained 120 records in 0.040158351 seconds. Throughput is 2988.1707 records/second. Loss is 0.19406192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004798925040790863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 50520/60000][Iteration 5421][Wall Clock 249.656197539s] Trained 120 records in 0.040179332 seconds. Throughput is 2986.61 records/second. Loss is 0.19810733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047984644913627635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 50640/60000][Iteration 5422][Wall Clock 249.695860952s] Trained 120 records in 0.039663413 seconds. Throughput is 3025.4583 records/second. Loss is 0.23789676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004798004030323385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 50760/60000][Iteration 5423][Wall Clock 249.736414371s] Trained 120 records in 0.040553419 seconds. Throughput is 2959.0598 records/second. Loss is 0.21862008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004797543657647284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 50880/60000][Iteration 5424][Wall Clock 249.77621764s] Trained 120 records in 0.039803269 seconds. Throughput is 3014.8276 records/second. Loss is 0.22843234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004797083373309028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51000/60000][Iteration 5425][Wall Clock 249.816437183s] Trained 120 records in 0.040219543 seconds. Throughput is 2983.6243 records/second. Loss is 0.21399085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004796623177283193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51120/60000][Iteration 5426][Wall Clock 249.856301065s] Trained 120 records in 0.039863882 seconds. Throughput is 3010.244 records/second. Loss is 0.29750395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004796163069544365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51240/60000][Iteration 5427][Wall Clock 249.896864916s] Trained 120 records in 0.040563851 seconds. Throughput is 2958.299 records/second. Loss is 0.20490047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00479570305006714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51360/60000][Iteration 5428][Wall Clock 249.93766379s] Trained 120 records in 0.040798874 seconds. Throughput is 2941.2578 records/second. Loss is 0.26558682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047952431188261245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51480/60000][Iteration 5429][Wall Clock 249.978254484s] Trained 120 records in 0.040590694 seconds. Throughput is 2956.3428 records/second. Loss is 0.20295165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004794783275795933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51600/60000][Iteration 5430][Wall Clock 250.018078123s] Trained 120 records in 0.039823639 seconds. Throughput is 3013.2856 records/second. Loss is 0.24023081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004794323520951194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51720/60000][Iteration 5431][Wall Clock 250.070538009s] Trained 120 records in 0.052459886 seconds. Throughput is 2287.4622 records/second. Loss is 0.18938732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004793863854266538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51840/60000][Iteration 5432][Wall Clock 250.119426976s] Trained 120 records in 0.048888967 seconds. Throughput is 2454.5415 records/second. Loss is 0.21039352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004793404275716615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 51960/60000][Iteration 5433][Wall Clock 250.160999547s] Trained 120 records in 0.041572571 seconds. Throughput is 2886.5186 records/second. Loss is 0.21315874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004792944785276073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52080/60000][Iteration 5434][Wall Clock 250.205333166s] Trained 120 records in 0.044333619 seconds. Throughput is 2706.7495 records/second. Loss is 0.15607508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004792485382919582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52200/60000][Iteration 5435][Wall Clock 250.245797516s] Trained 120 records in 0.04046435 seconds. Throughput is 2965.5735 records/second. Loss is 0.19387941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004792026068621813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52320/60000][Iteration 5436][Wall Clock 250.285820621s] Trained 120 records in 0.040023105 seconds. Throughput is 2998.2683 records/second. Loss is 0.2288672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004791566842357452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52440/60000][Iteration 5437][Wall Clock 250.32556052s] Trained 120 records in 0.039739899 seconds. Throughput is 3019.6353 records/second. Loss is 0.2093847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004791107704101188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52560/60000][Iteration 5438][Wall Clock 250.365973003s] Trained 120 records in 0.040412483 seconds. Throughput is 2969.3796 records/second. Loss is 0.16599417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004790648653827728. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52680/60000][Iteration 5439][Wall Clock 250.407977458s] Trained 120 records in 0.042004455 seconds. Throughput is 2856.8398 records/second. Loss is 0.21840554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004790189691511784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52800/60000][Iteration 5440][Wall Clock 250.450560993s] Trained 120 records in 0.042583535 seconds. Throughput is 2817.9905 records/second. Loss is 0.15985005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004789730817128077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:16 INFO  DistriOptimizer$:406 - [Epoch 11 52920/60000][Iteration 5441][Wall Clock 250.491468634s] Trained 120 records in 0.040907641 seconds. Throughput is 2933.4373 records/second. Loss is 0.2021136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004789272030651341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53040/60000][Iteration 5442][Wall Clock 250.541583814s] Trained 120 records in 0.05011518 seconds. Throughput is 2394.4841 records/second. Loss is 0.13167407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004788813332056317. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53160/60000][Iteration 5443][Wall Clock 250.585564415s] Trained 120 records in 0.043980601 seconds. Throughput is 2728.4756 records/second. Loss is 0.1813747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004788354721317755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53280/60000][Iteration 5444][Wall Clock 250.626736901s] Trained 120 records in 0.041172486 seconds. Throughput is 2914.5679 records/second. Loss is 0.19010454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004787896198410418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53400/60000][Iteration 5445][Wall Clock 250.667895869s] Trained 120 records in 0.041158968 seconds. Throughput is 2915.5251 records/second. Loss is 0.24650578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004787437763309077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53520/60000][Iteration 5446][Wall Clock 250.708619773s] Trained 120 records in 0.040723904 seconds. Throughput is 2946.672 records/second. Loss is 0.11793276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004786979415988511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53640/60000][Iteration 5447][Wall Clock 250.749196211s] Trained 120 records in 0.040576438 seconds. Throughput is 2957.3813 records/second. Loss is 0.18677734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047865211564235115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53760/60000][Iteration 5448][Wall Clock 250.790549355s] Trained 120 records in 0.041353144 seconds. Throughput is 2901.835 records/second. Loss is 0.2648492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004786062984588876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 53880/60000][Iteration 5449][Wall Clock 250.831860408s] Trained 120 records in 0.041311053 seconds. Throughput is 2904.7917 records/second. Loss is 0.20179442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047856049004594186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54000/60000][Iteration 5450][Wall Clock 250.87362884s] Trained 120 records in 0.041768432 seconds. Throughput is 2872.9832 records/second. Loss is 0.2364173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047851469040099525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54120/60000][Iteration 5451][Wall Clock 250.914791329s] Trained 120 records in 0.041162489 seconds. Throughput is 2915.2754 records/second. Loss is 0.2959998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004784688995215312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54240/60000][Iteration 5452][Wall Clock 250.95580439s] Trained 120 records in 0.041013061 seconds. Throughput is 2925.8972 records/second. Loss is 0.324603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00478423117405033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54360/60000][Iteration 5453][Wall Clock 251.000587654s] Trained 120 records in 0.044783264 seconds. Throughput is 2679.5725 records/second. Loss is 0.1449604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004783773440489859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54480/60000][Iteration 5454][Wall Clock 251.041576926s] Trained 120 records in 0.040989272 seconds. Throughput is 2927.5952 records/second. Loss is 0.17943376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004783315794508753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54600/60000][Iteration 5455][Wall Clock 251.082284354s] Trained 120 records in 0.040707428 seconds. Throughput is 2947.865 records/second. Loss is 0.20918582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004782858236081883. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54720/60000][Iteration 5456][Wall Clock 251.13005736s] Trained 120 records in 0.047773006 seconds. Throughput is 2511.8787 records/second. Loss is 0.13607405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004782400765184122. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54840/60000][Iteration 5457][Wall Clock 251.180191557s] Trained 120 records in 0.050134197 seconds. Throughput is 2393.5757 records/second. Loss is 0.13739124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00478194338179036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 54960/60000][Iteration 5458][Wall Clock 251.222610189s] Trained 120 records in 0.042418632 seconds. Throughput is 2828.9456 records/second. Loss is 0.22919759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00478148608587549. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 55080/60000][Iteration 5459][Wall Clock 251.263175358s] Trained 120 records in 0.040565169 seconds. Throughput is 2958.203 records/second. Loss is 0.32288936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004781028877414419. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 55200/60000][Iteration 5460][Wall Clock 251.303271801s] Trained 120 records in 0.040096443 seconds. Throughput is 2992.7842 records/second. Loss is 0.2908624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004780571756382063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 55320/60000][Iteration 5461][Wall Clock 251.34306294s] Trained 120 records in 0.039791139 seconds. Throughput is 3015.7466 records/second. Loss is 0.23217374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004780114722753346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 55440/60000][Iteration 5462][Wall Clock 251.383577802s] Trained 120 records in 0.040514862 seconds. Throughput is 2961.8762 records/second. Loss is 0.3100905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047796577765032025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 55560/60000][Iteration 5463][Wall Clock 251.423974283s] Trained 120 records in 0.040396481 seconds. Throughput is 2970.5557 records/second. Loss is 0.19332989. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004779200917606577. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:17 INFO  DistriOptimizer$:406 - [Epoch 11 55680/60000][Iteration 5464][Wall Clock 251.463934592s] Trained 120 records in 0.039960309 seconds. Throughput is 3002.9797 records/second. Loss is 0.19198376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047787441460384215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 55800/60000][Iteration 5465][Wall Clock 251.5037602s] Trained 120 records in 0.039825608 seconds. Throughput is 3013.1367 records/second. Loss is 0.23195241. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047782874617737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 55920/60000][Iteration 5466][Wall Clock 251.543914516s] Trained 120 records in 0.040154316 seconds. Throughput is 2988.4707 records/second. Loss is 0.27503243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004777830864787387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56040/60000][Iteration 5467][Wall Clock 251.583755717s] Trained 120 records in 0.039841201 seconds. Throughput is 3011.9573 records/second. Loss is 0.1811926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004777374355054462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56160/60000][Iteration 5468][Wall Clock 251.630457973s] Trained 120 records in 0.046702256 seconds. Throughput is 2569.469 records/second. Loss is 0.20710267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004776917932549919. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56280/60000][Iteration 5469][Wall Clock 251.678675353s] Trained 120 records in 0.04821738 seconds. Throughput is 2488.7292 records/second. Loss is 0.3292729. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047764615972487575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56400/60000][Iteration 5470][Wall Clock 251.719308597s] Trained 120 records in 0.040633244 seconds. Throughput is 2953.247 records/second. Loss is 0.27099168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004776005349125991. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56520/60000][Iteration 5471][Wall Clock 251.760270124s] Trained 120 records in 0.040961527 seconds. Throughput is 2929.5784 records/second. Loss is 0.24153863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004775549188156637. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56640/60000][Iteration 5472][Wall Clock 251.804413159s] Trained 120 records in 0.044143035 seconds. Throughput is 2718.4355 records/second. Loss is 0.19424286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00477509311431573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56760/60000][Iteration 5473][Wall Clock 251.845141294s] Trained 120 records in 0.040728135 seconds. Throughput is 2946.3662 records/second. Loss is 0.24594131. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004774637127578304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 56880/60000][Iteration 5474][Wall Clock 251.885740421s] Trained 120 records in 0.040599127 seconds. Throughput is 2955.7285 records/second. Loss is 0.16201667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004774181227919412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57000/60000][Iteration 5475][Wall Clock 251.926345635s] Trained 120 records in 0.040605214 seconds. Throughput is 2955.2856 records/second. Loss is 0.1302593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004773725415314111. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57120/60000][Iteration 5476][Wall Clock 251.966568673s] Trained 120 records in 0.040223038 seconds. Throughput is 2983.3647 records/second. Loss is 0.26077667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004773269689737471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57240/60000][Iteration 5477][Wall Clock 252.006943368s] Trained 120 records in 0.040374695 seconds. Throughput is 2972.1587 records/second. Loss is 0.19916053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004772814051164567. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57360/60000][Iteration 5478][Wall Clock 252.047943013s] Trained 120 records in 0.040999645 seconds. Throughput is 2926.8547 records/second. Loss is 0.25157538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004772358499570487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57480/60000][Iteration 5479][Wall Clock 252.087789594s] Trained 120 records in 0.039846581 seconds. Throughput is 3011.5508 records/second. Loss is 0.17567678. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00477190303493033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57600/60000][Iteration 5480][Wall Clock 252.128021577s] Trained 120 records in 0.040231983 seconds. Throughput is 2982.7014 records/second. Loss is 0.1577856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047714476572192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57720/60000][Iteration 5481][Wall Clock 252.169334647s] Trained 120 records in 0.04131307 seconds. Throughput is 2904.6497 records/second. Loss is 0.30372334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004770992366412214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57840/60000][Iteration 5482][Wall Clock 252.224424075s] Trained 120 records in 0.055089428 seconds. Throughput is 2178.2764 records/second. Loss is 0.14976197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047705371624844955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 57960/60000][Iteration 5483][Wall Clock 252.271384902s] Trained 120 records in 0.046960827 seconds. Throughput is 2555.3213 records/second. Loss is 0.13687664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004770082045411181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 58080/60000][Iteration 5484][Wall Clock 252.311878549s] Trained 120 records in 0.040493647 seconds. Throughput is 2963.4277 records/second. Loss is 0.22157697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004769627015167414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 58200/60000][Iteration 5485][Wall Clock 252.352491312s] Trained 120 records in 0.040612763 seconds. Throughput is 2954.736 records/second. Loss is 0.2948691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004769172071728348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 58320/60000][Iteration 5486][Wall Clock 252.392758865s] Trained 120 records in 0.040267553 seconds. Throughput is 2980.067 records/second. Loss is 0.19942111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004768717215069147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 58440/60000][Iteration 5487][Wall Clock 252.433913068s] Trained 120 records in 0.041154203 seconds. Throughput is 2915.8625 records/second. Loss is 0.2474065. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004768262445164982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:18 INFO  DistriOptimizer$:406 - [Epoch 11 58560/60000][Iteration 5488][Wall Clock 252.474746256s] Trained 120 records in 0.040833188 seconds. Throughput is 2938.7861 records/second. Loss is 0.19592357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004767807761991036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 58680/60000][Iteration 5489][Wall Clock 252.515334066s] Trained 120 records in 0.04058781 seconds. Throughput is 2956.5527 records/second. Loss is 0.29684067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004767353165522502. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 58800/60000][Iteration 5490][Wall Clock 252.55863232s] Trained 120 records in 0.043298254 seconds. Throughput is 2771.474 records/second. Loss is 0.24401353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004766898655734578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 58920/60000][Iteration 5491][Wall Clock 252.599198989s] Trained 120 records in 0.040566669 seconds. Throughput is 2958.0935 records/second. Loss is 0.25256947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004766444232602479. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59040/60000][Iteration 5492][Wall Clock 252.638885698s] Trained 120 records in 0.039686709 seconds. Throughput is 3023.6824 records/second. Loss is 0.17783767. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00476598989610142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59160/60000][Iteration 5493][Wall Clock 252.679582603s] Trained 120 records in 0.040696905 seconds. Throughput is 2948.6272 records/second. Loss is 0.17561433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004765535646206634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59280/60000][Iteration 5494][Wall Clock 252.720190337s] Trained 120 records in 0.040607734 seconds. Throughput is 2955.102 records/second. Loss is 0.30592474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004765081482893357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59400/60000][Iteration 5495][Wall Clock 252.768355001s] Trained 120 records in 0.048164664 seconds. Throughput is 2491.453 records/second. Loss is 0.21547455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004764627406136841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59520/60000][Iteration 5496][Wall Clock 252.817757722s] Trained 120 records in 0.049402721 seconds. Throughput is 2429.016 records/second. Loss is 0.17360942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047641734159123384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59640/60000][Iteration 5497][Wall Clock 252.858406485s] Trained 120 records in 0.040648763 seconds. Throughput is 2952.1194 records/second. Loss is 0.21810894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004763719512195123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59760/60000][Iteration 5498][Wall Clock 252.899245449s] Trained 120 records in 0.040838964 seconds. Throughput is 2938.3704 records/second. Loss is 0.20594676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004763265694960464. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 59880/60000][Iteration 5499][Wall Clock 252.939561183s] Trained 120 records in 0.040315734 seconds. Throughput is 2976.5056 records/second. Loss is 0.2361782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047628119641836535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:406 - [Epoch 11 60000/60000][Iteration 5500][Wall Clock 252.980735768s] Trained 120 records in 0.041174585 seconds. Throughput is 2914.419 records/second. Loss is 0.16481133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004762358319839985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:19 INFO  DistriOptimizer$:451 - [Epoch 11 60000/60000][Iteration 5500][Wall Clock 252.980735768s] Epoch finished. Wall clock time is 253809.23828 ms
2019-10-23 15:57:19 INFO  DistriOptimizer$:111 - [Epoch 11 60000/60000][Iteration 5500][Wall Clock 252.980735768s] Validate model...
2019-10-23 15:57:20 INFO  DistriOptimizer$:177 - [Epoch 11 60000/60000][Iteration 5500][Wall Clock 252.980735768s] validate model throughput is 15020.977 records/second
2019-10-23 15:57:20 INFO  DistriOptimizer$:180 - [Epoch 11 60000/60000][Iteration 5500][Wall Clock 252.980735768s] Top1Accuracy is Accuracy(correct: 9461, count: 10000, accuracy: 0.9461)
2019-10-23 15:57:20 INFO  DistriOptimizer$:220 - [Wall Clock 253.80923828s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:57:20 INFO  DistriOptimizer$:225 - [Wall Clock 253.80923828s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 120/60000][Iteration 5501][Wall Clock 253.85634497s] Trained 120 records in 0.04710669 seconds. Throughput is 2547.409 records/second. Loss is 0.18489619. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047619047619047615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 240/60000][Iteration 5502][Wall Clock 253.896831113s] Trained 120 records in 0.040486143 seconds. Throughput is 2963.977 records/second. Loss is 0.31363007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047614512903532994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 360/60000][Iteration 5503][Wall Clock 253.938995438s] Trained 120 records in 0.042164325 seconds. Throughput is 2846.0078 records/second. Loss is 0.16772723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004760997905160921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 480/60000][Iteration 5504][Wall Clock 253.983396013s] Trained 120 records in 0.044400575 seconds. Throughput is 2702.6677 records/second. Loss is 0.18286112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004760544606302961. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 600/60000][Iteration 5505][Wall Clock 254.036003547s] Trained 120 records in 0.052607534 seconds. Throughput is 2281.0422 records/second. Loss is 0.17647457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00476009139375476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 720/60000][Iteration 5506][Wall Clock 254.083439924s] Trained 120 records in 0.047436377 seconds. Throughput is 2529.7043 records/second. Loss is 0.14959885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00475963826749167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 840/60000][Iteration 5507][Wall Clock 254.13756447s] Trained 120 records in 0.054124546 seconds. Throughput is 2217.1086 records/second. Loss is 0.16001596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047591852274890545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 960/60000][Iteration 5508][Wall Clock 254.179349073s] Trained 120 records in 0.041784603 seconds. Throughput is 2871.8713 records/second. Loss is 0.30785286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004758732273722281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1080/60000][Iteration 5509][Wall Clock 254.220202779s] Trained 120 records in 0.040853706 seconds. Throughput is 2937.31 records/second. Loss is 0.19419688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004758279406166729. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1200/60000][Iteration 5510][Wall Clock 254.260343246s] Trained 120 records in 0.040140467 seconds. Throughput is 2989.5017 records/second. Loss is 0.13415197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004757826624797793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1320/60000][Iteration 5511][Wall Clock 254.300645647s] Trained 120 records in 0.040302401 seconds. Throughput is 2977.4902 records/second. Loss is 0.15619351. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004757373929590865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1440/60000][Iteration 5512][Wall Clock 254.340963887s] Trained 120 records in 0.04031824 seconds. Throughput is 2976.3203 records/second. Loss is 0.1274908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004756921320521359. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1560/60000][Iteration 5513][Wall Clock 254.381429089s] Trained 120 records in 0.040465202 seconds. Throughput is 2965.511 records/second. Loss is 0.28280753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004756468797564688. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1680/60000][Iteration 5514][Wall Clock 254.422077779s] Trained 120 records in 0.04064869 seconds. Throughput is 2952.1245 records/second. Loss is 0.2597718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004756016360696281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1800/60000][Iteration 5515][Wall Clock 254.462211506s] Trained 120 records in 0.040133727 seconds. Throughput is 2990.004 records/second. Loss is 0.30327266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004755564009891573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 1920/60000][Iteration 5516][Wall Clock 254.502811969s] Trained 120 records in 0.040600463 seconds. Throughput is 2955.6313 records/second. Loss is 0.20806198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047551117451260115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 2040/60000][Iteration 5517][Wall Clock 254.543299571s] Trained 120 records in 0.040487602 seconds. Throughput is 2963.8704 records/second. Loss is 0.16610393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004754659566375047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:20 INFO  DistriOptimizer$:406 - [Epoch 12 2160/60000][Iteration 5518][Wall Clock 254.583875603s] Trained 120 records in 0.040576032 seconds. Throughput is 2957.411 records/second. Loss is 0.26863828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004754207473614149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 2280/60000][Iteration 5519][Wall Clock 254.62468071s] Trained 120 records in 0.040805107 seconds. Throughput is 2940.8083 records/second. Loss is 0.28803843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004753755466818787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 2400/60000][Iteration 5520][Wall Clock 254.665309018s] Trained 120 records in 0.040628308 seconds. Throughput is 2953.6057 records/second. Loss is 0.33612144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004753303545964445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 2520/60000][Iteration 5521][Wall Clock 254.718102422s] Trained 120 records in 0.052793404 seconds. Throughput is 2273.0112 records/second. Loss is 0.38354734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004752851711026616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 2640/60000][Iteration 5522][Wall Clock 254.76133332s] Trained 120 records in 0.043230898 seconds. Throughput is 2775.7925 records/second. Loss is 0.26870707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004752399961980801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 2760/60000][Iteration 5523][Wall Clock 254.802552608s] Trained 120 records in 0.041219288 seconds. Throughput is 2911.2585 records/second. Loss is 0.13480364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004751948298802509. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 2880/60000][Iteration 5524][Wall Clock 254.843241964s] Trained 120 records in 0.040689356 seconds. Throughput is 2949.174 records/second. Loss is 0.20119694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004751496721467262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3000/60000][Iteration 5525][Wall Clock 254.88429958s] Trained 120 records in 0.041057616 seconds. Throughput is 2922.722 records/second. Loss is 0.24199206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00475104522995059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3120/60000][Iteration 5526][Wall Clock 254.929249911s] Trained 120 records in 0.044950331 seconds. Throughput is 2669.6133 records/second. Loss is 0.21505712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004750593824228029. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3240/60000][Iteration 5527][Wall Clock 254.969938564s] Trained 120 records in 0.040688653 seconds. Throughput is 2949.225 records/second. Loss is 0.19493032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004750142504275128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3360/60000][Iteration 5528][Wall Clock 255.011239071s] Trained 120 records in 0.041300507 seconds. Throughput is 2905.5334 records/second. Loss is 0.20390256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004749691270067444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3480/60000][Iteration 5529][Wall Clock 255.061805838s] Trained 120 records in 0.050566767 seconds. Throughput is 2373.1 records/second. Loss is 0.23737448. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004749240121580548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3600/60000][Iteration 5530][Wall Clock 255.110056895s] Trained 120 records in 0.048251057 seconds. Throughput is 2486.9922 records/second. Loss is 0.22125667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004748789058790008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3720/60000][Iteration 5531][Wall Clock 255.158602041s] Trained 120 records in 0.048545146 seconds. Throughput is 2471.9258 records/second. Loss is 0.14628243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004748338081671416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3840/60000][Iteration 5532][Wall Clock 255.19949794s] Trained 120 records in 0.040895899 seconds. Throughput is 2934.2795 records/second. Loss is 0.11914929. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00474788719020036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 3960/60000][Iteration 5533][Wall Clock 255.239785504s] Trained 120 records in 0.040287564 seconds. Throughput is 2978.5864 records/second. Loss is 0.28110284. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00474743638435245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4080/60000][Iteration 5534][Wall Clock 255.280339377s] Trained 120 records in 0.040553873 seconds. Throughput is 2959.027 records/second. Loss is 0.25341603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004746985664103294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4200/60000][Iteration 5535][Wall Clock 255.320353325s] Trained 120 records in 0.040013948 seconds. Throughput is 2998.9543 records/second. Loss is 0.19424203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004746535029428517. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4320/60000][Iteration 5536][Wall Clock 255.360230922s] Trained 120 records in 0.039877597 seconds. Throughput is 3009.2085 records/second. Loss is 0.24380282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004746084480303749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4440/60000][Iteration 5537][Wall Clock 255.400846253s] Trained 120 records in 0.040615331 seconds. Throughput is 2954.5493 records/second. Loss is 0.15743713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004745634016704633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4560/60000][Iteration 5538][Wall Clock 255.441211514s] Trained 120 records in 0.040365261 seconds. Throughput is 2972.8533 records/second. Loss is 0.20125814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004745183638606814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4680/60000][Iteration 5539][Wall Clock 255.481561683s] Trained 120 records in 0.040350169 seconds. Throughput is 2973.9653 records/second. Loss is 0.17271845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004744733345985955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4800/60000][Iteration 5540][Wall Clock 255.522936971s] Trained 120 records in 0.041375288 seconds. Throughput is 2900.282 records/second. Loss is 0.16304749. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004744283138817725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:21 INFO  DistriOptimizer$:406 - [Epoch 12 4920/60000][Iteration 5541][Wall Clock 255.562978416s] Trained 120 records in 0.040041445 seconds. Throughput is 2996.8948 records/second. Loss is 0.1329535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004743833017077799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5040/60000][Iteration 5542][Wall Clock 255.602609627s] Trained 120 records in 0.039631211 seconds. Throughput is 3027.9165 records/second. Loss is 0.27383918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004743382980741865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5160/60000][Iteration 5543][Wall Clock 255.642644359s] Trained 120 records in 0.040034732 seconds. Throughput is 2997.3972 records/second. Loss is 0.08963111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00474293302978562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5280/60000][Iteration 5544][Wall Clock 255.682503598s] Trained 120 records in 0.039859239 seconds. Throughput is 3010.5942 records/second. Loss is 0.19040683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004742483164184767. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5400/60000][Iteration 5545][Wall Clock 255.726517435s] Trained 120 records in 0.044013837 seconds. Throughput is 2726.4155 records/second. Loss is 0.19268931. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004742033383915023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5520/60000][Iteration 5546][Wall Clock 255.766998211s] Trained 120 records in 0.040480776 seconds. Throughput is 2964.3699 records/second. Loss is 0.23609397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00474158368895211. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5640/60000][Iteration 5547][Wall Clock 255.815814177s] Trained 120 records in 0.048815966 seconds. Throughput is 2458.2122 records/second. Loss is 0.14891998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004741134079271762. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5760/60000][Iteration 5548][Wall Clock 255.86305161s] Trained 120 records in 0.047237433 seconds. Throughput is 2540.3582 records/second. Loss is 0.18722416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00474068455484972. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 5880/60000][Iteration 5549][Wall Clock 255.905793112s] Trained 120 records in 0.042741502 seconds. Throughput is 2807.5754 records/second. Loss is 0.1999789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004740235115661736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6000/60000][Iteration 5550][Wall Clock 255.946169837s] Trained 120 records in 0.040376725 seconds. Throughput is 2972.009 records/second. Loss is 0.25325066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004739785761683572. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6120/60000][Iteration 5551][Wall Clock 255.986799505s] Trained 120 records in 0.040629668 seconds. Throughput is 2953.5068 records/second. Loss is 0.19810636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004739336492890995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6240/60000][Iteration 5552][Wall Clock 256.027186767s] Trained 120 records in 0.040387262 seconds. Throughput is 2971.234 records/second. Loss is 0.26943195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004738887309259786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6360/60000][Iteration 5553][Wall Clock 256.067679792s] Trained 120 records in 0.040493025 seconds. Throughput is 2963.4731 records/second. Loss is 0.27066803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047384382107657315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6480/60000][Iteration 5554][Wall Clock 256.108690451s] Trained 120 records in 0.041010659 seconds. Throughput is 2926.0686 records/second. Loss is 0.17986377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00473798919738463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6600/60000][Iteration 5555][Wall Clock 256.150438851s] Trained 120 records in 0.0417484 seconds. Throughput is 2874.3616 records/second. Loss is 0.354487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004737540269092287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6720/60000][Iteration 5556][Wall Clock 256.201238116s] Trained 120 records in 0.050799265 seconds. Throughput is 2362.2388 records/second. Loss is 0.17798452. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047370914258645196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6840/60000][Iteration 5557][Wall Clock 256.241681357s] Trained 120 records in 0.040443241 seconds. Throughput is 2967.121 records/second. Loss is 0.15535077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00473664266767715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 6960/60000][Iteration 5558][Wall Clock 256.282217004s] Trained 120 records in 0.040535647 seconds. Throughput is 2960.3574 records/second. Loss is 0.2522579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004736193994506015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 7080/60000][Iteration 5559][Wall Clock 256.323825825s] Trained 120 records in 0.041608821 seconds. Throughput is 2884.004 records/second. Loss is 0.167034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004735745406326956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 7200/60000][Iteration 5560][Wall Clock 256.36535624s] Trained 120 records in 0.041530415 seconds. Throughput is 2889.4485 records/second. Loss is 0.2399641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004735296903115825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 7320/60000][Iteration 5561][Wall Clock 256.407071293s] Trained 120 records in 0.041715053 seconds. Throughput is 2876.6594 records/second. Loss is 0.16954586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004734848484848485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 7440/60000][Iteration 5562][Wall Clock 256.448508611s] Trained 120 records in 0.041437318 seconds. Throughput is 2895.9404 records/second. Loss is 0.31438634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004734400151500805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 7560/60000][Iteration 5563][Wall Clock 256.489450576s] Trained 120 records in 0.040941965 seconds. Throughput is 2930.978 records/second. Loss is 0.24758466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004733951903048665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 7680/60000][Iteration 5564][Wall Clock 256.533675381s] Trained 120 records in 0.044224805 seconds. Throughput is 2713.4092 records/second. Loss is 0.15856935. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004733503739467954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:22 INFO  DistriOptimizer$:406 - [Epoch 12 7800/60000][Iteration 5565][Wall Clock 256.574077662s] Trained 120 records in 0.040402281 seconds. Throughput is 2970.1292 records/second. Loss is 0.22489594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00473305566073457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 7920/60000][Iteration 5566][Wall Clock 256.615011846s] Trained 120 records in 0.040934184 seconds. Throughput is 2931.5352 records/second. Loss is 0.2978339. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00473260766682442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8040/60000][Iteration 5567][Wall Clock 256.656327036s] Trained 120 records in 0.04131519 seconds. Throughput is 2904.5007 records/second. Loss is 0.19623972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00473215975771342. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8160/60000][Iteration 5568][Wall Clock 256.697306712s] Trained 120 records in 0.040979676 seconds. Throughput is 2928.2808 records/second. Loss is 0.31623957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004731711933377496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8280/60000][Iteration 5569][Wall Clock 256.737305205s] Trained 120 records in 0.039998493 seconds. Throughput is 3000.113 records/second. Loss is 0.22653429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004731264193792582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8400/60000][Iteration 5570][Wall Clock 256.778510346s] Trained 120 records in 0.041205141 seconds. Throughput is 2912.2578 records/second. Loss is 0.25156036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00473081653893462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8520/60000][Iteration 5571][Wall Clock 256.819812017s] Trained 120 records in 0.041301671 seconds. Throughput is 2905.4514 records/second. Loss is 0.20090967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004730368968779565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8640/60000][Iteration 5572][Wall Clock 256.860090461s] Trained 120 records in 0.040278444 seconds. Throughput is 2979.2612 records/second. Loss is 0.19975932. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004729921483303376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8760/60000][Iteration 5573][Wall Clock 256.899955761s] Trained 120 records in 0.0398653 seconds. Throughput is 3010.1367 records/second. Loss is 0.13541815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004729474082482028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 8880/60000][Iteration 5574][Wall Clock 256.950925102s] Trained 120 records in 0.050969341 seconds. Throughput is 2354.3564 records/second. Loss is 0.13903578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004729026766291497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9000/60000][Iteration 5575][Wall Clock 257.000486991s] Trained 120 records in 0.049561889 seconds. Throughput is 2421.2153 records/second. Loss is 0.24836352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004728579534707775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9120/60000][Iteration 5576][Wall Clock 257.043992429s] Trained 120 records in 0.043505438 seconds. Throughput is 2758.276 records/second. Loss is 0.22058874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004728132387706856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9240/60000][Iteration 5577][Wall Clock 257.085907789s] Trained 120 records in 0.04191536 seconds. Throughput is 2862.9124 records/second. Loss is 0.17022234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047276853252647515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9360/60000][Iteration 5578][Wall Clock 257.126752637s] Trained 120 records in 0.040844848 seconds. Throughput is 2937.947 records/second. Loss is 0.10378933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047272383473574734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9480/60000][Iteration 5579][Wall Clock 257.169572628s] Trained 120 records in 0.042819991 seconds. Throughput is 2802.4292 records/second. Loss is 0.22143324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004726791453961051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9600/60000][Iteration 5580][Wall Clock 257.212599731s] Trained 120 records in 0.043027103 seconds. Throughput is 2788.9397 records/second. Loss is 0.16351737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004726344645051517. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9720/60000][Iteration 5581][Wall Clock 257.253664089s] Trained 120 records in 0.041064358 seconds. Throughput is 2922.2422 records/second. Loss is 0.18565682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004725897920604915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9840/60000][Iteration 5582][Wall Clock 257.303634178s] Trained 120 records in 0.049970089 seconds. Throughput is 2401.4365 records/second. Loss is 0.12989682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004725451280597297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 9960/60000][Iteration 5583][Wall Clock 257.347715553s] Trained 120 records in 0.044081375 seconds. Throughput is 2722.238 records/second. Loss is 0.16094443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004725004725004725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 10080/60000][Iteration 5584][Wall Clock 257.388278541s] Trained 120 records in 0.040562988 seconds. Throughput is 2958.362 records/second. Loss is 0.18065757. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004724558253803269. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 10200/60000][Iteration 5585][Wall Clock 257.429008292s] Trained 120 records in 0.040729751 seconds. Throughput is 2946.2493 records/second. Loss is 0.17283821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00472411186696901. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 10320/60000][Iteration 5586][Wall Clock 257.469595385s] Trained 120 records in 0.040587093 seconds. Throughput is 2956.605 records/second. Loss is 0.13379923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004723665564478035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 10440/60000][Iteration 5587][Wall Clock 257.509631567s] Trained 120 records in 0.040036182 seconds. Throughput is 2997.2888 records/second. Loss is 0.21076337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004723219346306443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:23 INFO  DistriOptimizer$:406 - [Epoch 12 10560/60000][Iteration 5588][Wall Clock 257.550301037s] Trained 120 records in 0.04066947 seconds. Throughput is 2950.6162 records/second. Loss is 0.19385523. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004722773212430339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 10680/60000][Iteration 5589][Wall Clock 257.590640667s] Trained 120 records in 0.04033963 seconds. Throughput is 2974.7422 records/second. Loss is 0.2469185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00472232716282584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 10800/60000][Iteration 5590][Wall Clock 257.631306773s] Trained 120 records in 0.040666106 seconds. Throughput is 2950.8604 records/second. Loss is 0.32079524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004721881197469072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 10920/60000][Iteration 5591][Wall Clock 257.671617382s] Trained 120 records in 0.040310609 seconds. Throughput is 2976.8838 records/second. Loss is 0.22782819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004721435316336166. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11040/60000][Iteration 5592][Wall Clock 257.711928982s] Trained 120 records in 0.0403116 seconds. Throughput is 2976.8105 records/second. Loss is 0.22509083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004720989519403267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11160/60000][Iteration 5593][Wall Clock 257.752121945s] Trained 120 records in 0.040192963 seconds. Throughput is 2985.5974 records/second. Loss is 0.26042724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004720543806646525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11280/60000][Iteration 5594][Wall Clock 257.792415134s] Trained 120 records in 0.040293189 seconds. Throughput is 2978.1707 records/second. Loss is 0.21202451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047200981780421035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11400/60000][Iteration 5595][Wall Clock 257.833099789s] Trained 120 records in 0.040684655 seconds. Throughput is 2949.515 records/second. Loss is 0.21335247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004719652633566169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11520/60000][Iteration 5596][Wall Clock 257.87328653s] Trained 120 records in 0.040186741 seconds. Throughput is 2986.0596 records/second. Loss is 0.1802744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004719207173194904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11640/60000][Iteration 5597][Wall Clock 257.914103425s] Trained 120 records in 0.040816895 seconds. Throughput is 2939.959 records/second. Loss is 0.14422184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004718761796904492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11760/60000][Iteration 5598][Wall Clock 257.954668547s] Trained 120 records in 0.040565122 seconds. Throughput is 2958.2063 records/second. Loss is 0.20407441. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004718316504671134. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 11880/60000][Iteration 5599][Wall Clock 257.995119205s] Trained 120 records in 0.040450658 seconds. Throughput is 2966.5771 records/second. Loss is 0.18951064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004717871296471032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12000/60000][Iteration 5600][Wall Clock 258.03619122s] Trained 120 records in 0.041072015 seconds. Throughput is 2921.6975 records/second. Loss is 0.23992811. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004717426172280404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12120/60000][Iteration 5601][Wall Clock 258.093533605s] Trained 120 records in 0.057342385 seconds. Throughput is 2092.6929 records/second. Loss is 0.14299184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047169811320754715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12240/60000][Iteration 5602][Wall Clock 258.137404488s] Trained 120 records in 0.043870883 seconds. Throughput is 2735.2996 records/second. Loss is 0.17663993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004716536175832469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12360/60000][Iteration 5603][Wall Clock 258.179505525s] Trained 120 records in 0.042101037 seconds. Throughput is 2850.2861 records/second. Loss is 0.21551943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047160913035276366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12480/60000][Iteration 5604][Wall Clock 258.221297311s] Trained 120 records in 0.041791786 seconds. Throughput is 2871.3777 records/second. Loss is 0.14418784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004715646515137225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12600/60000][Iteration 5605][Wall Clock 258.271722379s] Trained 120 records in 0.050425068 seconds. Throughput is 2379.7688 records/second. Loss is 0.2182272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004715201810637495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12720/60000][Iteration 5606][Wall Clock 258.3127719s] Trained 120 records in 0.041049521 seconds. Throughput is 2923.2983 records/second. Loss is 0.19864663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004714757190004715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12840/60000][Iteration 5607][Wall Clock 258.353047648s] Trained 120 records in 0.040275748 seconds. Throughput is 2979.4604 records/second. Loss is 0.19496006. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004714312653215162. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 12960/60000][Iteration 5608][Wall Clock 258.393470606s] Trained 120 records in 0.040422958 seconds. Throughput is 2968.61 records/second. Loss is 0.2540611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004713868200245121. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 13080/60000][Iteration 5609][Wall Clock 258.443236776s] Trained 120 records in 0.04976617 seconds. Throughput is 2411.2766 records/second. Loss is 0.112183236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047134238310708905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 13200/60000][Iteration 5610][Wall Clock 258.487338626s] Trained 120 records in 0.04410185 seconds. Throughput is 2720.9744 records/second. Loss is 0.23924015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004712979545668771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 13320/60000][Iteration 5611][Wall Clock 258.528122804s] Trained 120 records in 0.040784178 seconds. Throughput is 2942.3176 records/second. Loss is 0.13513088. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004712535344015081. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:24 INFO  DistriOptimizer$:406 - [Epoch 12 13440/60000][Iteration 5612][Wall Clock 258.568512578s] Trained 120 records in 0.040389774 seconds. Throughput is 2971.049 records/second. Loss is 0.22965078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004712091226086137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 13560/60000][Iteration 5613][Wall Clock 258.609151184s] Trained 120 records in 0.040638606 seconds. Throughput is 2952.8572 records/second. Loss is 0.22227319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004711647191858274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 13680/60000][Iteration 5614][Wall Clock 258.650041041s] Trained 120 records in 0.040889857 seconds. Throughput is 2934.7131 records/second. Loss is 0.25716487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004711203241307829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 13800/60000][Iteration 5615][Wall Clock 258.690611128s] Trained 120 records in 0.040570087 seconds. Throughput is 2957.8442 records/second. Loss is 0.15252803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004710759374411156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 13920/60000][Iteration 5616][Wall Clock 258.730859236s] Trained 120 records in 0.040248108 seconds. Throughput is 2981.5066 records/second. Loss is 0.17926475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004710315591144606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14040/60000][Iteration 5617][Wall Clock 258.771631234s] Trained 120 records in 0.040771998 seconds. Throughput is 2943.1965 records/second. Loss is 0.25831753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004709871891484552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14160/60000][Iteration 5618][Wall Clock 258.812893759s] Trained 120 records in 0.041262525 seconds. Throughput is 2908.2078 records/second. Loss is 0.18557023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004709428275407365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14280/60000][Iteration 5619][Wall Clock 258.85407882s] Trained 120 records in 0.041185061 seconds. Throughput is 2913.6777 records/second. Loss is 0.2050201. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047089847428894325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14400/60000][Iteration 5620][Wall Clock 258.897934069s] Trained 120 records in 0.043855249 seconds. Throughput is 2736.2744 records/second. Loss is 0.21492967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004708541293907147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14520/60000][Iteration 5621][Wall Clock 258.939024773s] Trained 120 records in 0.041090704 seconds. Throughput is 2920.3684 records/second. Loss is 0.16814534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004708097928436911. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14640/60000][Iteration 5622][Wall Clock 258.9800574s] Trained 120 records in 0.041032627 seconds. Throughput is 2924.502 records/second. Loss is 0.18484057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004707654646455136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14760/60000][Iteration 5623][Wall Clock 259.02076231s] Trained 120 records in 0.04070491 seconds. Throughput is 2948.0474 records/second. Loss is 0.2019787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004707211447938241. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 14880/60000][Iteration 5624][Wall Clock 259.061374087s] Trained 120 records in 0.040611777 seconds. Throughput is 2954.8079 records/second. Loss is 0.20238023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004706768332862657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15000/60000][Iteration 5625][Wall Clock 259.102877599s] Trained 120 records in 0.041503512 seconds. Throughput is 2891.3215 records/second. Loss is 0.15516864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00470632530120482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15120/60000][Iteration 5626][Wall Clock 259.143981118s] Trained 120 records in 0.041103519 seconds. Throughput is 2919.458 records/second. Loss is 0.20047727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004705882352941177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15240/60000][Iteration 5627][Wall Clock 259.193512791s] Trained 120 records in 0.049531673 seconds. Throughput is 2422.6924 records/second. Loss is 0.24575838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004705439488048184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15360/60000][Iteration 5628][Wall Clock 259.244432763s] Trained 120 records in 0.050919972 seconds. Throughput is 2356.6392 records/second. Loss is 0.20563918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004704996706502306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15480/60000][Iteration 5629][Wall Clock 259.290633986s] Trained 120 records in 0.046201223 seconds. Throughput is 2597.334 records/second. Loss is 0.1768683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004704554008280014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15600/60000][Iteration 5630][Wall Clock 259.332876662s] Trained 120 records in 0.042242676 seconds. Throughput is 2840.729 records/second. Loss is 0.23006456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004704111393357795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15720/60000][Iteration 5631][Wall Clock 259.373969117s] Trained 120 records in 0.041092455 seconds. Throughput is 2920.2441 records/second. Loss is 0.23037733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004703668861712135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15840/60000][Iteration 5632][Wall Clock 259.424229546s] Trained 120 records in 0.050260429 seconds. Throughput is 2387.5642 records/second. Loss is 0.14639308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004703226413319538. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 15960/60000][Iteration 5633][Wall Clock 259.465647617s] Trained 120 records in 0.041418071 seconds. Throughput is 2897.286 records/second. Loss is 0.21950951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004702784048156508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 16080/60000][Iteration 5634][Wall Clock 259.505645755s] Trained 120 records in 0.039998138 seconds. Throughput is 3000.14 records/second. Loss is 0.12141137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004702341766199568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:25 INFO  DistriOptimizer$:406 - [Epoch 12 16200/60000][Iteration 5635][Wall Clock 259.552182249s] Trained 120 records in 0.046536494 seconds. Throughput is 2578.6213 records/second. Loss is 0.17155293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0047018995674252394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 16320/60000][Iteration 5636][Wall Clock 259.594508231s] Trained 120 records in 0.042325982 seconds. Throughput is 2835.1382 records/second. Loss is 0.14393401. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004701457451810062. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 16440/60000][Iteration 5637][Wall Clock 259.634839909s] Trained 120 records in 0.040331678 seconds. Throughput is 2975.3289 records/second. Loss is 0.19221233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004701015419330575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 16560/60000][Iteration 5638][Wall Clock 259.678861137s] Trained 120 records in 0.044021228 seconds. Throughput is 2725.9578 records/second. Loss is 0.20427102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004700573469963336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 16680/60000][Iteration 5639][Wall Clock 259.719554149s] Trained 120 records in 0.040693012 seconds. Throughput is 2948.9094 records/second. Loss is 0.2762785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004700131603684903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 16800/60000][Iteration 5640][Wall Clock 259.760989412s] Trained 120 records in 0.041435263 seconds. Throughput is 2896.084 records/second. Loss is 0.18900041. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004699689820471848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 16920/60000][Iteration 5641][Wall Clock 259.802983117s] Trained 120 records in 0.041993705 seconds. Throughput is 2857.5713 records/second. Loss is 0.18137185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004699248120300752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17040/60000][Iteration 5642][Wall Clock 259.843905966s] Trained 120 records in 0.040922849 seconds. Throughput is 2932.3472 records/second. Loss is 0.19808766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046988065031482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17160/60000][Iteration 5643][Wall Clock 259.884925872s] Trained 120 records in 0.041019906 seconds. Throughput is 2925.409 records/second. Loss is 0.18912993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004698364968990791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17280/60000][Iteration 5644][Wall Clock 259.925267575s] Trained 120 records in 0.040341703 seconds. Throughput is 2974.5894 records/second. Loss is 0.14960884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00469792351780513. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17400/60000][Iteration 5645][Wall Clock 259.966174614s] Trained 120 records in 0.040907039 seconds. Throughput is 2933.4805 records/second. Loss is 0.17319474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004697482149567831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17520/60000][Iteration 5646][Wall Clock 260.006715016s] Trained 120 records in 0.040540402 seconds. Throughput is 2960.0103 records/second. Loss is 0.1452353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004697040864255519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17640/60000][Iteration 5647][Wall Clock 260.046858744s] Trained 120 records in 0.040143728 seconds. Throughput is 2989.259 records/second. Loss is 0.21763067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004696599661844825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17760/60000][Iteration 5648][Wall Clock 260.087673548s] Trained 120 records in 0.040814804 seconds. Throughput is 2940.1096 records/second. Loss is 0.13181764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004696158542312388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 17880/60000][Iteration 5649][Wall Clock 260.128406023s] Trained 120 records in 0.040732475 seconds. Throughput is 2946.0522 records/second. Loss is 0.18464477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046957175056348615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18000/60000][Iteration 5650][Wall Clock 260.169346612s] Trained 120 records in 0.040940589 seconds. Throughput is 2931.0764 records/second. Loss is 0.18371059. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004695276551788899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18120/60000][Iteration 5651][Wall Clock 260.210255616s] Trained 120 records in 0.040909004 seconds. Throughput is 2933.3396 records/second. Loss is 0.19621083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004694835680751174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18240/60000][Iteration 5652][Wall Clock 260.250248816s] Trained 120 records in 0.0399932 seconds. Throughput is 3000.51 records/second. Loss is 0.22909094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004694394892498357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18360/60000][Iteration 5653][Wall Clock 260.290227725s] Trained 120 records in 0.039978909 seconds. Throughput is 3001.5825 records/second. Loss is 0.21780126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004693954187007136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18480/60000][Iteration 5654][Wall Clock 260.344605205s] Trained 120 records in 0.05437748 seconds. Throughput is 2206.796 records/second. Loss is 0.17657556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046935135642542005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18600/60000][Iteration 5655][Wall Clock 260.389679895s] Trained 120 records in 0.04507469 seconds. Throughput is 2662.2478 records/second. Loss is 0.26072392. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004693073024216257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18720/60000][Iteration 5656][Wall Clock 260.430667909s] Trained 120 records in 0.040988014 seconds. Throughput is 2927.6853 records/second. Loss is 0.2540213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004692632566870014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18840/60000][Iteration 5657][Wall Clock 260.475045561s] Trained 120 records in 0.044377652 seconds. Throughput is 2704.0637 records/second. Loss is 0.21003835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004692192192192193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 18960/60000][Iteration 5658][Wall Clock 260.516705258s] Trained 120 records in 0.041659697 seconds. Throughput is 2880.4817 records/second. Loss is 0.22620322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004691751900159519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:26 INFO  DistriOptimizer$:406 - [Epoch 12 19080/60000][Iteration 5659][Wall Clock 260.558318629s] Trained 120 records in 0.041613371 seconds. Throughput is 2883.6885 records/second. Loss is 0.1285667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046913116907487335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 19200/60000][Iteration 5660][Wall Clock 260.600491482s] Trained 120 records in 0.042172853 seconds. Throughput is 2845.4324 records/second. Loss is 0.2091895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004690871563936579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 19320/60000][Iteration 5661][Wall Clock 260.641815658s] Trained 120 records in 0.041324176 seconds. Throughput is 2903.8691 records/second. Loss is 0.12664865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004690431519699812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 19440/60000][Iteration 5662][Wall Clock 260.690836309s] Trained 120 records in 0.049020651 seconds. Throughput is 2447.9478 records/second. Loss is 0.19849774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004689991558015196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 19560/60000][Iteration 5663][Wall Clock 260.734067125s] Trained 120 records in 0.043230816 seconds. Throughput is 2775.7976 records/second. Loss is 0.18822446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004689551678859501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 19680/60000][Iteration 5664][Wall Clock 260.776019869s] Trained 120 records in 0.041952744 seconds. Throughput is 2860.361 records/second. Loss is 0.19534993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00468911188220951. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 19800/60000][Iteration 5665][Wall Clock 260.816656487s] Trained 120 records in 0.040636618 seconds. Throughput is 2953.0017 records/second. Loss is 0.22415274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046886721680420105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 19920/60000][Iteration 5666][Wall Clock 260.857141195s] Trained 120 records in 0.040484708 seconds. Throughput is 2964.0823 records/second. Loss is 0.20036553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046882325363338025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20040/60000][Iteration 5667][Wall Clock 260.897266989s] Trained 120 records in 0.040125794 seconds. Throughput is 2990.595 records/second. Loss is 0.19737183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004687792987061692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20160/60000][Iteration 5668][Wall Clock 260.937287651s] Trained 120 records in 0.040020662 seconds. Throughput is 2998.4512 records/second. Loss is 0.24142478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004687353520202494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20280/60000][Iteration 5669][Wall Clock 260.977310148s] Trained 120 records in 0.040022497 seconds. Throughput is 2998.3137 records/second. Loss is 0.19554588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004686914135733033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20400/60000][Iteration 5670][Wall Clock 261.017268699s] Trained 120 records in 0.039958551 seconds. Throughput is 3003.1118 records/second. Loss is 0.23916104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004686474833630144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20520/60000][Iteration 5671][Wall Clock 261.057397812s] Trained 120 records in 0.040129113 seconds. Throughput is 2990.3477 records/second. Loss is 0.1371265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004686035613870665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20640/60000][Iteration 5672][Wall Clock 261.097556557s] Trained 120 records in 0.040158745 seconds. Throughput is 2988.141 records/second. Loss is 0.20896944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00468559647643145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20760/60000][Iteration 5673][Wall Clock 261.138017022s] Trained 120 records in 0.040460465 seconds. Throughput is 2965.8582 records/second. Loss is 0.17895803. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004685157421289355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 20880/60000][Iteration 5674][Wall Clock 261.178262203s] Trained 120 records in 0.040245181 seconds. Throughput is 2981.7234 records/second. Loss is 0.118929066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004684718448421251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21000/60000][Iteration 5675][Wall Clock 261.218137492s] Trained 120 records in 0.039875289 seconds. Throughput is 3009.3826 records/second. Loss is 0.23461743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004684279557804009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21120/60000][Iteration 5676][Wall Clock 261.262804402s] Trained 120 records in 0.04466691 seconds. Throughput is 2686.5525 records/second. Loss is 0.21449839. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004683840749414521. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21240/60000][Iteration 5677][Wall Clock 261.304732476s] Trained 120 records in 0.041928074 seconds. Throughput is 2862.0442 records/second. Loss is 0.26730224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004683402023229674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21360/60000][Iteration 5678][Wall Clock 261.345994288s] Trained 120 records in 0.041261812 seconds. Throughput is 2908.2583 records/second. Loss is 0.20679556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004682963379226375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21480/60000][Iteration 5679][Wall Clock 261.390113133s] Trained 120 records in 0.044118845 seconds. Throughput is 2719.9263 records/second. Loss is 0.20920327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004682524817381532. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21600/60000][Iteration 5680][Wall Clock 261.440767279s] Trained 120 records in 0.050654146 seconds. Throughput is 2369.0063 records/second. Loss is 0.19915609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004682086337672067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21720/60000][Iteration 5681][Wall Clock 261.482798625s] Trained 120 records in 0.042031346 seconds. Throughput is 2855.012 records/second. Loss is 0.2550574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046816479400749065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21840/60000][Iteration 5682][Wall Clock 261.52336134s] Trained 120 records in 0.040562715 seconds. Throughput is 2958.3818 records/second. Loss is 0.1711589. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004681209624566988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:27 INFO  DistriOptimizer$:406 - [Epoch 12 21960/60000][Iteration 5683][Wall Clock 261.563288191s] Trained 120 records in 0.039926851 seconds. Throughput is 3005.4963 records/second. Loss is 0.22789948. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004680771391125257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22080/60000][Iteration 5684][Wall Clock 261.603934471s] Trained 120 records in 0.04064628 seconds. Throughput is 2952.2996 records/second. Loss is 0.19961037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004680333239726668. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22200/60000][Iteration 5685][Wall Clock 261.644555297s] Trained 120 records in 0.040620826 seconds. Throughput is 2954.1497 records/second. Loss is 0.3701514. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004679895170348184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22320/60000][Iteration 5686][Wall Clock 261.684368666s] Trained 120 records in 0.039813369 seconds. Throughput is 3014.063 records/second. Loss is 0.17188221. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004679457182966776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22440/60000][Iteration 5687][Wall Clock 261.724355973s] Trained 120 records in 0.039987307 seconds. Throughput is 3000.9524 records/second. Loss is 0.23753555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004679019277559424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22560/60000][Iteration 5688][Wall Clock 261.771353146s] Trained 120 records in 0.046997173 seconds. Throughput is 2553.345 records/second. Loss is 0.18360138. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046785814541031165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22680/60000][Iteration 5689][Wall Clock 261.816224854s] Trained 120 records in 0.044871708 seconds. Throughput is 2674.291 records/second. Loss is 0.14586575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004678143712574851. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22800/60000][Iteration 5690][Wall Clock 261.856818835s] Trained 120 records in 0.040593981 seconds. Throughput is 2956.1033 records/second. Loss is 0.22125323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004677706052951632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 22920/60000][Iteration 5691][Wall Clock 261.897217345s] Trained 120 records in 0.04039851 seconds. Throughput is 2970.4067 records/second. Loss is 0.31829336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004677268475210478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23040/60000][Iteration 5692][Wall Clock 261.937621177s] Trained 120 records in 0.040403832 seconds. Throughput is 2970.0154 records/second. Loss is 0.2237897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046768309793284064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23160/60000][Iteration 5693][Wall Clock 261.978846484s] Trained 120 records in 0.041225307 seconds. Throughput is 2910.8335 records/second. Loss is 0.20408978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004676393565282455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23280/60000][Iteration 5694][Wall Clock 262.023860684s] Trained 120 records in 0.0450142 seconds. Throughput is 2665.8254 records/second. Loss is 0.24018341. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004675956233049658. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23400/60000][Iteration 5695][Wall Clock 262.065891332s] Trained 120 records in 0.042030648 seconds. Throughput is 2855.0596 records/second. Loss is 0.192481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046755189826070695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23520/60000][Iteration 5696][Wall Clock 262.107990201s] Trained 120 records in 0.042098869 seconds. Throughput is 2850.4329 records/second. Loss is 0.15898643. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004675081813931743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23640/60000][Iteration 5697][Wall Clock 262.14907569s] Trained 120 records in 0.041085489 seconds. Throughput is 2920.7393 records/second. Loss is 0.20780213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004674644727000748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23760/60000][Iteration 5698][Wall Clock 262.189102386s] Trained 120 records in 0.040026696 seconds. Throughput is 2997.9993 records/second. Loss is 0.21368004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004674207721791156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 23880/60000][Iteration 5699][Wall Clock 262.230077407s] Trained 120 records in 0.040975021 seconds. Throughput is 2928.6135 records/second. Loss is 0.27277553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004673770798280053. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 24000/60000][Iteration 5700][Wall Clock 262.272345233s] Trained 120 records in 0.042267826 seconds. Throughput is 2839.0388 records/second. Loss is 0.25034288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004673333956444527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 24120/60000][Iteration 5701][Wall Clock 262.313418135s] Trained 120 records in 0.041072902 seconds. Throughput is 2921.6343 records/second. Loss is 0.11639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004672897196261682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 24240/60000][Iteration 5702][Wall Clock 262.35375558s] Trained 120 records in 0.040337445 seconds. Throughput is 2974.9036 records/second. Loss is 0.17226203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004672460517708625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 24360/60000][Iteration 5703][Wall Clock 262.394347469s] Trained 120 records in 0.040591889 seconds. Throughput is 2956.2556 records/second. Loss is 0.20862214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004672023920762474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 24480/60000][Iteration 5704][Wall Clock 262.453377919s] Trained 120 records in 0.05903045 seconds. Throughput is 2032.8491 records/second. Loss is 0.15375246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004671587405400355. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 24600/60000][Iteration 5705][Wall Clock 262.501303097s] Trained 120 records in 0.047925178 seconds. Throughput is 2503.903 records/second. Loss is 0.14783087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004671150971599402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:28 INFO  DistriOptimizer$:406 - [Epoch 12 24720/60000][Iteration 5706][Wall Clock 262.544640713s] Trained 120 records in 0.043337616 seconds. Throughput is 2768.957 records/second. Loss is 0.2748411. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004670714619336758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 24840/60000][Iteration 5707][Wall Clock 262.584731865s] Trained 120 records in 0.040091152 seconds. Throughput is 2993.179 records/second. Loss is 0.1536424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004670278348589576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 24960/60000][Iteration 5708][Wall Clock 262.624536847s] Trained 120 records in 0.039804982 seconds. Throughput is 3014.6982 records/second. Loss is 0.27778134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004669842159335014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25080/60000][Iteration 5709][Wall Clock 262.664486031s] Trained 120 records in 0.039949184 seconds. Throughput is 3003.8162 records/second. Loss is 0.14495035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004669406051550243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25200/60000][Iteration 5710][Wall Clock 262.70432022s] Trained 120 records in 0.039834189 seconds. Throughput is 3012.4875 records/second. Loss is 0.24664195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004668970025212439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25320/60000][Iteration 5711][Wall Clock 262.744445875s] Trained 120 records in 0.040125655 seconds. Throughput is 2990.6055 records/second. Loss is 0.21496601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004668534080298785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25440/60000][Iteration 5712][Wall Clock 262.785291679s] Trained 120 records in 0.040845804 seconds. Throughput is 2937.8782 records/second. Loss is 0.20301804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004668098216786482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25560/60000][Iteration 5713][Wall Clock 262.828859995s] Trained 120 records in 0.043568316 seconds. Throughput is 2754.2952 records/second. Loss is 0.15164635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004667662434652726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25680/60000][Iteration 5714][Wall Clock 262.869205424s] Trained 120 records in 0.040345429 seconds. Throughput is 2974.3145 records/second. Loss is 0.25207558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004667226733874732. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25800/60000][Iteration 5715][Wall Clock 262.917773562s] Trained 120 records in 0.048568138 seconds. Throughput is 2470.7556 records/second. Loss is 0.12210641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004666791114429717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 25920/60000][Iteration 5716][Wall Clock 262.963637234s] Trained 120 records in 0.045863672 seconds. Throughput is 2616.45 records/second. Loss is 0.19829337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004666355576294914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26040/60000][Iteration 5717][Wall Clock 263.004990225s] Trained 120 records in 0.041352991 seconds. Throughput is 2901.8457 records/second. Loss is 0.14502357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004665920119447555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26160/60000][Iteration 5718][Wall Clock 263.045403604s] Trained 120 records in 0.040413379 seconds. Throughput is 2969.3137 records/second. Loss is 0.21032704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004665484743864888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26280/60000][Iteration 5719][Wall Clock 263.086503224s] Trained 120 records in 0.04109962 seconds. Throughput is 2919.735 records/second. Loss is 0.20750093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046650494495241645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26400/60000][Iteration 5720][Wall Clock 263.127842552s] Trained 120 records in 0.041339328 seconds. Throughput is 2902.805 records/second. Loss is 0.15533428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004664614236402649. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26520/60000][Iteration 5721][Wall Clock 263.169497875s] Trained 120 records in 0.041655323 seconds. Throughput is 2880.7842 records/second. Loss is 0.1442657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046641791044776115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26640/60000][Iteration 5722][Wall Clock 263.209791164s] Trained 120 records in 0.040293289 seconds. Throughput is 2978.1636 records/second. Loss is 0.16333061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004663744053726332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26760/60000][Iteration 5723][Wall Clock 263.2499777s] Trained 120 records in 0.040186536 seconds. Throughput is 2986.0747 records/second. Loss is 0.15658619. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004663309084126096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 26880/60000][Iteration 5724][Wall Clock 263.289624129s] Trained 120 records in 0.039646429 seconds. Throughput is 3026.7544 records/second. Loss is 0.15756068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004662874195654201. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 27000/60000][Iteration 5725][Wall Clock 263.329320197s] Trained 120 records in 0.039696068 seconds. Throughput is 3022.9695 records/second. Loss is 0.20016198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004662439388287952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 27120/60000][Iteration 5726][Wall Clock 263.369740984s] Trained 120 records in 0.040420787 seconds. Throughput is 2968.7695 records/second. Loss is 0.15664193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004662004662004662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 27240/60000][Iteration 5727][Wall Clock 263.410019695s] Trained 120 records in 0.040278711 seconds. Throughput is 2979.2415 records/second. Loss is 0.20681407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004661570016781652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 27360/60000][Iteration 5728][Wall Clock 263.45031101s] Trained 120 records in 0.040291315 seconds. Throughput is 2978.3093 records/second. Loss is 0.22028287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004661135452596252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 27480/60000][Iteration 5729][Wall Clock 263.499045328s] Trained 120 records in 0.048734318 seconds. Throughput is 2462.3306 records/second. Loss is 0.13645503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004660700969425802. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:29 INFO  DistriOptimizer$:406 - [Epoch 12 27600/60000][Iteration 5730][Wall Clock 263.550736832s] Trained 120 records in 0.051691504 seconds. Throughput is 2321.4648 records/second. Loss is 0.14553295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004660266567247646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 27720/60000][Iteration 5731][Wall Clock 263.592689856s] Trained 120 records in 0.041953024 seconds. Throughput is 2860.342 records/second. Loss is 0.16775076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004659832246039143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 27840/60000][Iteration 5732][Wall Clock 263.635899935s] Trained 120 records in 0.043210079 seconds. Throughput is 2777.13 records/second. Loss is 0.24143796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004659398005777653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 27960/60000][Iteration 5733][Wall Clock 263.675981092s] Trained 120 records in 0.040081157 seconds. Throughput is 2993.9255 records/second. Loss is 0.17180686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004658963846440552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28080/60000][Iteration 5734][Wall Clock 263.715640954s] Trained 120 records in 0.039659862 seconds. Throughput is 3025.7292 records/second. Loss is 0.28769004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004658529768005217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28200/60000][Iteration 5735][Wall Clock 263.755348947s] Trained 120 records in 0.039707993 seconds. Throughput is 3022.0615 records/second. Loss is 0.1411704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004658095770449041. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28320/60000][Iteration 5736][Wall Clock 263.794851869s] Trained 120 records in 0.039502922 seconds. Throughput is 3037.75 records/second. Loss is 0.21435125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004657661853749417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28440/60000][Iteration 5737][Wall Clock 263.834195687s] Trained 120 records in 0.039343818 seconds. Throughput is 3050.0344 records/second. Loss is 0.16777353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004657228017883756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28560/60000][Iteration 5738][Wall Clock 263.873108947s] Trained 120 records in 0.03891326 seconds. Throughput is 3083.7817 records/second. Loss is 0.13878751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004656794262829468. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28680/60000][Iteration 5739][Wall Clock 263.9125117s] Trained 120 records in 0.039402753 seconds. Throughput is 3045.4724 records/second. Loss is 0.3611677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004656360588563979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28800/60000][Iteration 5740][Wall Clock 263.952279611s] Trained 120 records in 0.039767911 seconds. Throughput is 3017.5083 records/second. Loss is 0.19889301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004655926995064717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 28920/60000][Iteration 5741][Wall Clock 264.000906612s] Trained 120 records in 0.048627001 seconds. Throughput is 2467.765 records/second. Loss is 0.1740595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004655493482309124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29040/60000][Iteration 5742][Wall Clock 264.048734238s] Trained 120 records in 0.047827626 seconds. Throughput is 2509.01 records/second. Loss is 0.1515067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004655060050274648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29160/60000][Iteration 5743][Wall Clock 264.088716431s] Trained 120 records in 0.039982193 seconds. Throughput is 3001.3362 records/second. Loss is 0.20324738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004654626698938745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29280/60000][Iteration 5744][Wall Clock 264.128760538s] Trained 120 records in 0.040044107 seconds. Throughput is 2996.6956 records/second. Loss is 0.14496379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004654193428278879. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29400/60000][Iteration 5745][Wall Clock 264.169801033s] Trained 120 records in 0.041040495 seconds. Throughput is 2923.9414 records/second. Loss is 0.280053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004653760238272524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29520/60000][Iteration 5746][Wall Clock 264.210349234s] Trained 120 records in 0.040548201 seconds. Throughput is 2959.4407 records/second. Loss is 0.34009865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004653327128897162. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29640/60000][Iteration 5747][Wall Clock 264.250806627s] Trained 120 records in 0.040457393 seconds. Throughput is 2966.0833 records/second. Loss is 0.16217245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004652894100130281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29760/60000][Iteration 5748][Wall Clock 264.290571074s] Trained 120 records in 0.039764447 seconds. Throughput is 3017.7712 records/second. Loss is 0.1780507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004652461151949381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 29880/60000][Iteration 5749][Wall Clock 264.331161238s] Trained 120 records in 0.040590164 seconds. Throughput is 2956.3813 records/second. Loss is 0.19742091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004652028284331969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 30000/60000][Iteration 5750][Wall Clock 264.371360256s] Trained 120 records in 0.040199018 seconds. Throughput is 2985.1475 records/second. Loss is 0.28718987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046515954972555585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 30120/60000][Iteration 5751][Wall Clock 264.414793915s] Trained 120 records in 0.043433659 seconds. Throughput is 2762.8342 records/second. Loss is 0.1570972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046511627906976735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 30240/60000][Iteration 5752][Wall Clock 264.455328127s] Trained 120 records in 0.040534212 seconds. Throughput is 2960.4622 records/second. Loss is 0.19154008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004650730164635848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 30360/60000][Iteration 5753][Wall Clock 264.494953454s] Trained 120 records in 0.039625327 seconds. Throughput is 3028.3662 records/second. Loss is 0.17693172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004650297619047618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:30 INFO  DistriOptimizer$:406 - [Epoch 12 30480/60000][Iteration 5754][Wall Clock 264.53595863s] Trained 120 records in 0.041005176 seconds. Throughput is 2926.46 records/second. Loss is 0.2091543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004649865153910537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 30600/60000][Iteration 5755][Wall Clock 264.58777008s] Trained 120 records in 0.05181145 seconds. Throughput is 2316.0903 records/second. Loss is 0.28669852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004649432769202157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 30720/60000][Iteration 5756][Wall Clock 264.630701073s] Trained 120 records in 0.042930993 seconds. Throughput is 2795.1833 records/second. Loss is 0.33781368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004649000464900047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 30840/60000][Iteration 5757][Wall Clock 264.671517946s] Trained 120 records in 0.040816873 seconds. Throughput is 2939.9607 records/second. Loss is 0.19366612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046485682409817776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 30960/60000][Iteration 5758][Wall Clock 264.711974755s] Trained 120 records in 0.040456809 seconds. Throughput is 2966.1262 records/second. Loss is 0.25809243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004648136097424933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31080/60000][Iteration 5759][Wall Clock 264.752689321s] Trained 120 records in 0.040714566 seconds. Throughput is 2947.3481 records/second. Loss is 0.20442446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046477040342071015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31200/60000][Iteration 5760][Wall Clock 264.793232385s] Trained 120 records in 0.040543064 seconds. Throughput is 2959.8157 records/second. Loss is 0.30621102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004647272051305883. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31320/60000][Iteration 5761][Wall Clock 264.833762173s] Trained 120 records in 0.040529788 seconds. Throughput is 2960.7854 records/second. Loss is 0.15541705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004646840148698885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31440/60000][Iteration 5762][Wall Clock 264.873300344s] Trained 120 records in 0.039538171 seconds. Throughput is 3035.0417 records/second. Loss is 0.16026486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004646408326363721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31560/60000][Iteration 5763][Wall Clock 264.913026809s] Trained 120 records in 0.039726465 seconds. Throughput is 3020.6562 records/second. Loss is 0.2739795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004645976584278015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31680/60000][Iteration 5764][Wall Clock 264.953456449s] Trained 120 records in 0.04042964 seconds. Throughput is 2968.1194 records/second. Loss is 0.14488545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046455449224194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31800/60000][Iteration 5765][Wall Clock 264.993865013s] Trained 120 records in 0.040408564 seconds. Throughput is 2969.6675 records/second. Loss is 0.19045135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004645113340765515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 31920/60000][Iteration 5766][Wall Clock 265.035382323s] Trained 120 records in 0.04151731 seconds. Throughput is 2890.3606 records/second. Loss is 0.20915775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004644681839294009. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32040/60000][Iteration 5767][Wall Clock 265.076357252s] Trained 120 records in 0.040974929 seconds. Throughput is 2928.62 records/second. Loss is 0.19987592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004644250417982537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32160/60000][Iteration 5768][Wall Clock 265.13130025s] Trained 120 records in 0.054942998 seconds. Throughput is 2184.0818 records/second. Loss is 0.15993835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004643819076808768. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32280/60000][Iteration 5769][Wall Clock 265.177085005s] Trained 120 records in 0.045784755 seconds. Throughput is 2620.9597 records/second. Loss is 0.17870924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046433878157503715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32400/60000][Iteration 5770][Wall Clock 265.217964928s] Trained 120 records in 0.040879923 seconds. Throughput is 2935.4263 records/second. Loss is 0.21633463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00464295663478503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32520/60000][Iteration 5771][Wall Clock 265.258846807s] Trained 120 records in 0.040881879 seconds. Throughput is 2935.286 records/second. Loss is 0.17893772. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004642525533890437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32640/60000][Iteration 5772][Wall Clock 265.300150876s] Trained 120 records in 0.041304069 seconds. Throughput is 2905.2827 records/second. Loss is 0.17395481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004642094513044285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32760/60000][Iteration 5773][Wall Clock 265.339950693s] Trained 120 records in 0.039799817 seconds. Throughput is 3015.0894 records/second. Loss is 0.18857779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004641663572224285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 32880/60000][Iteration 5774][Wall Clock 265.380441954s] Trained 120 records in 0.040491261 seconds. Throughput is 2963.6025 records/second. Loss is 0.20530215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00464123271140815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 33000/60000][Iteration 5775][Wall Clock 265.421340308s] Trained 120 records in 0.040898354 seconds. Throughput is 2934.1035 records/second. Loss is 0.1265535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004640801930573603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 33120/60000][Iteration 5776][Wall Clock 265.462447787s] Trained 120 records in 0.041107479 seconds. Throughput is 2919.1768 records/second. Loss is 0.25745702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004640371229698376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 33240/60000][Iteration 5777][Wall Clock 265.50257671s] Trained 120 records in 0.040128923 seconds. Throughput is 2990.3618 records/second. Loss is 0.31762996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004639940608760208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:31 INFO  DistriOptimizer$:406 - [Epoch 12 33360/60000][Iteration 5778][Wall Clock 265.542092645s] Trained 120 records in 0.039515935 seconds. Throughput is 3036.7495 records/second. Loss is 0.118178576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004639510067736847. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 33480/60000][Iteration 5779][Wall Clock 265.584065193s] Trained 120 records in 0.041972548 seconds. Throughput is 2859.0115 records/second. Loss is 0.13668796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00463907960660605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 33600/60000][Iteration 5780][Wall Clock 265.632888377s] Trained 120 records in 0.048823184 seconds. Throughput is 2457.8486 records/second. Loss is 0.24165225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004638649225345579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 33720/60000][Iteration 5781][Wall Clock 265.676531628s] Trained 120 records in 0.043643251 seconds. Throughput is 2749.566 records/second. Loss is 0.12790324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00463821892393321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 33840/60000][Iteration 5782][Wall Clock 265.716944685s] Trained 120 records in 0.040413057 seconds. Throughput is 2969.3374 records/second. Loss is 0.12035633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004637788702346721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 33960/60000][Iteration 5783][Wall Clock 265.757316451s] Trained 120 records in 0.040371766 seconds. Throughput is 2972.3745 records/second. Loss is 0.13340889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004637358560563903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34080/60000][Iteration 5784][Wall Clock 265.797064324s] Trained 120 records in 0.039747873 seconds. Throughput is 3019.0295 records/second. Loss is 0.39423096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004636928498562552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34200/60000][Iteration 5785][Wall Clock 265.837186599s] Trained 120 records in 0.040122275 seconds. Throughput is 2990.8574 records/second. Loss is 0.20176117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004636498516320474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34320/60000][Iteration 5786][Wall Clock 265.877296712s] Trained 120 records in 0.040110113 seconds. Throughput is 2991.7644 records/second. Loss is 0.26922894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004636068613815485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34440/60000][Iteration 5787][Wall Clock 265.918134618s] Trained 120 records in 0.040837906 seconds. Throughput is 2938.4465 records/second. Loss is 0.21571608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004635638791025403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34560/60000][Iteration 5788][Wall Clock 265.963319142s] Trained 120 records in 0.045184524 seconds. Throughput is 2655.7766 records/second. Loss is 0.24762993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004635209047928062. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34680/60000][Iteration 5789][Wall Clock 266.005503423s] Trained 120 records in 0.042184281 seconds. Throughput is 2844.6614 records/second. Loss is 0.27900293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004634779384501298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34800/60000][Iteration 5790][Wall Clock 266.047436433s] Trained 120 records in 0.04193301 seconds. Throughput is 2861.7073 records/second. Loss is 0.23523352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004634349800722959. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 34920/60000][Iteration 5791][Wall Clock 266.088763347s] Trained 120 records in 0.041326914 seconds. Throughput is 2903.6768 records/second. Loss is 0.17665513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004633920296570899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35040/60000][Iteration 5792][Wall Clock 266.130039551s] Trained 120 records in 0.041276204 seconds. Throughput is 2907.244 records/second. Loss is 0.17174202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004633490872022982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35160/60000][Iteration 5793][Wall Clock 266.171776984s] Trained 120 records in 0.041737433 seconds. Throughput is 2875.117 records/second. Loss is 0.087243885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046330615270570785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35280/60000][Iteration 5794][Wall Clock 266.220438577s] Trained 120 records in 0.048661593 seconds. Throughput is 2466.0105 records/second. Loss is 0.21407562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004632632261651071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35400/60000][Iteration 5795][Wall Clock 266.268027458s] Trained 120 records in 0.047588881 seconds. Throughput is 2521.5974 records/second. Loss is 0.19959603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046322030757828415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35520/60000][Iteration 5796][Wall Clock 266.311402631s] Trained 120 records in 0.043375173 seconds. Throughput is 2766.5596 records/second. Loss is 0.19476672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004631773969430293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35640/60000][Iteration 5797][Wall Clock 266.353638541s] Trained 120 records in 0.04223591 seconds. Throughput is 2841.184 records/second. Loss is 0.20351458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004631344942571322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35760/60000][Iteration 5798][Wall Clock 266.395731337s] Trained 120 records in 0.042092796 seconds. Throughput is 2850.844 records/second. Loss is 0.15231833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004630915995183848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 35880/60000][Iteration 5799][Wall Clock 266.438052196s] Trained 120 records in 0.042320859 seconds. Throughput is 2835.4812 records/second. Loss is 0.22916739. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004630487127245786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 36000/60000][Iteration 5800][Wall Clock 266.480317831s] Trained 120 records in 0.042265635 seconds. Throughput is 2839.186 records/second. Loss is 0.14303137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004630058338735068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:32 INFO  DistriOptimizer$:406 - [Epoch 12 36120/60000][Iteration 5801][Wall Clock 266.521723243s] Trained 120 records in 0.041405412 seconds. Throughput is 2898.1719 records/second. Loss is 0.19878222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004629629629629629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 36240/60000][Iteration 5802][Wall Clock 266.563701312s] Trained 120 records in 0.041978069 seconds. Throughput is 2858.6355 records/second. Loss is 0.24089584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046292009999074155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 36360/60000][Iteration 5803][Wall Clock 266.6053762s] Trained 120 records in 0.041674888 seconds. Throughput is 2879.4316 records/second. Loss is 0.17615229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00462877244954638. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 36480/60000][Iteration 5804][Wall Clock 266.647438785s] Trained 120 records in 0.042062585 seconds. Throughput is 2852.8918 records/second. Loss is 0.24495307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004628343978524484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 36600/60000][Iteration 5805][Wall Clock 266.699308994s] Trained 120 records in 0.051870209 seconds. Throughput is 2313.4668 records/second. Loss is 0.17453961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004627915586819697. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 36720/60000][Iteration 5806][Wall Clock 266.744772271s] Trained 120 records in 0.045463277 seconds. Throughput is 2639.4932 records/second. Loss is 0.23205577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004627487274409995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 36840/60000][Iteration 5807][Wall Clock 266.791051951s] Trained 120 records in 0.04627968 seconds. Throughput is 2592.9307 records/second. Loss is 0.16336682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004627059041273367. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 36960/60000][Iteration 5808][Wall Clock 266.832619187s] Trained 120 records in 0.041567236 seconds. Throughput is 2886.8892 records/second. Loss is 0.15958227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004626630887387804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37080/60000][Iteration 5809][Wall Clock 266.873838292s] Trained 120 records in 0.041219105 seconds. Throughput is 2911.2715 records/second. Loss is 0.25076875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046262028127313105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37200/60000][Iteration 5810][Wall Clock 266.915586669s] Trained 120 records in 0.041748377 seconds. Throughput is 2874.363 records/second. Loss is 0.18334943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004625774817281894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37320/60000][Iteration 5811][Wall Clock 266.95773703s] Trained 120 records in 0.042150361 seconds. Throughput is 2846.9507 records/second. Loss is 0.22746204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004625346901017576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37440/60000][Iteration 5812][Wall Clock 266.999047693s] Trained 120 records in 0.041310663 seconds. Throughput is 2904.8188 records/second. Loss is 0.1677302. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004624919063916381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37560/60000][Iteration 5813][Wall Clock 267.040584687s] Trained 120 records in 0.041536994 seconds. Throughput is 2888.991 records/second. Loss is 0.14752969. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004624491305956345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37680/60000][Iteration 5814][Wall Clock 267.082395473s] Trained 120 records in 0.041810786 seconds. Throughput is 2870.073 records/second. Loss is 0.18493713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004624063627115508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37800/60000][Iteration 5815][Wall Clock 267.124082011s] Trained 120 records in 0.041686538 seconds. Throughput is 2878.6272 records/second. Loss is 0.20957127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046236360273719255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 37920/60000][Iteration 5816][Wall Clock 267.165871689s] Trained 120 records in 0.041789678 seconds. Throughput is 2871.5225 records/second. Loss is 0.26767266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004623208506703652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38040/60000][Iteration 5817][Wall Clock 267.206820137s] Trained 120 records in 0.040948448 seconds. Throughput is 2930.5142 records/second. Loss is 0.14287376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004622781065088758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38160/60000][Iteration 5818][Wall Clock 267.248347994s] Trained 120 records in 0.041527857 seconds. Throughput is 2889.6267 records/second. Loss is 0.13082662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004622353702505315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38280/60000][Iteration 5819][Wall Clock 267.289977187s] Trained 120 records in 0.041629193 seconds. Throughput is 2882.5925 records/second. Loss is 0.22542877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004621926418931411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38400/60000][Iteration 5820][Wall Clock 267.330925121s] Trained 120 records in 0.040947934 seconds. Throughput is 2930.5508 records/second. Loss is 0.15360144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004621499214345133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38520/60000][Iteration 5821][Wall Clock 267.38022903s] Trained 120 records in 0.049303909 seconds. Throughput is 2433.884 records/second. Loss is 0.19483052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004621072088724584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38640/60000][Iteration 5822][Wall Clock 267.42800553s] Trained 120 records in 0.0477765 seconds. Throughput is 2511.695 records/second. Loss is 0.2090768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00462064504204787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38760/60000][Iteration 5823][Wall Clock 267.472056027s] Trained 120 records in 0.044050497 seconds. Throughput is 2724.1465 records/second. Loss is 0.16590579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004620218074293106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:33 INFO  DistriOptimizer$:406 - [Epoch 12 38880/60000][Iteration 5824][Wall Clock 267.513975686s] Trained 120 records in 0.041919659 seconds. Throughput is 2862.6187 records/second. Loss is 0.21152335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004619791185438418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39000/60000][Iteration 5825][Wall Clock 267.559106982s] Trained 120 records in 0.045131296 seconds. Throughput is 2658.9087 records/second. Loss is 0.17232522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004619364375461937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39120/60000][Iteration 5826][Wall Clock 267.600817573s] Trained 120 records in 0.041710591 seconds. Throughput is 2876.967 records/second. Loss is 0.28153875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004618937644341801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39240/60000][Iteration 5827][Wall Clock 267.642614725s] Trained 120 records in 0.041797152 seconds. Throughput is 2871.0088 records/second. Loss is 0.13002113. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004618510992056161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39360/60000][Iteration 5828][Wall Clock 267.684994931s] Trained 120 records in 0.042380206 seconds. Throughput is 2831.5105 records/second. Loss is 0.2941426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004618084418583172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39480/60000][Iteration 5829][Wall Clock 267.728061557s] Trained 120 records in 0.043066626 seconds. Throughput is 2786.3804 records/second. Loss is 0.13212116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004617657923900997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39600/60000][Iteration 5830][Wall Clock 267.780208371s] Trained 120 records in 0.052146814 seconds. Throughput is 2301.1953 records/second. Loss is 0.23050396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004617231507987811. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39720/60000][Iteration 5831][Wall Clock 267.831862861s] Trained 120 records in 0.05165449 seconds. Throughput is 2323.1282 records/second. Loss is 0.18469253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004616805170821791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39840/60000][Iteration 5832][Wall Clock 267.873806711s] Trained 120 records in 0.04194385 seconds. Throughput is 2860.9675 records/second. Loss is 0.23968515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004616378912381129. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 39960/60000][Iteration 5833][Wall Clock 267.915828192s] Trained 120 records in 0.042021481 seconds. Throughput is 2855.6824 records/second. Loss is 0.14082502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004615952732644017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40080/60000][Iteration 5834][Wall Clock 267.958208692s] Trained 120 records in 0.0423805 seconds. Throughput is 2831.491 records/second. Loss is 0.144186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004615526631588665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40200/60000][Iteration 5835][Wall Clock 268.000516939s] Trained 120 records in 0.042308247 seconds. Throughput is 2836.3264 records/second. Loss is 0.12758617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00461510060919328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40320/60000][Iteration 5836][Wall Clock 268.043302772s] Trained 120 records in 0.042785833 seconds. Throughput is 2804.6665 records/second. Loss is 0.18412568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004614674665436087. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40440/60000][Iteration 5837][Wall Clock 268.085799606s] Trained 120 records in 0.042496834 seconds. Throughput is 2823.7397 records/second. Loss is 0.18833746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004614248800295311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40560/60000][Iteration 5838][Wall Clock 268.128637605s] Trained 120 records in 0.042837999 seconds. Throughput is 2801.2512 records/second. Loss is 0.15508027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004613823013749193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40680/60000][Iteration 5839][Wall Clock 268.171563224s] Trained 120 records in 0.042925619 seconds. Throughput is 2795.5334 records/second. Loss is 0.29856402. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004613397305775973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40800/60000][Iteration 5840][Wall Clock 268.214689149s] Trained 120 records in 0.043125925 seconds. Throughput is 2782.549 records/second. Loss is 0.18105799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004612971676353908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 40920/60000][Iteration 5841][Wall Clock 268.257587396s] Trained 120 records in 0.042898247 seconds. Throughput is 2797.3171 records/second. Loss is 0.1867967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004612546125461255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 41040/60000][Iteration 5842][Wall Clock 268.299734399s] Trained 120 records in 0.042147003 seconds. Throughput is 2847.1775 records/second. Loss is 0.25802368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004612120653076284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 41160/60000][Iteration 5843][Wall Clock 268.34171691s] Trained 120 records in 0.041982511 seconds. Throughput is 2858.3333 records/second. Loss is 0.30280083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004611695259177273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 41280/60000][Iteration 5844][Wall Clock 268.387467337s] Trained 120 records in 0.045750427 seconds. Throughput is 2622.9263 records/second. Loss is 0.25253227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004611269943742506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 41400/60000][Iteration 5845][Wall Clock 268.429534947s] Trained 120 records in 0.04206761 seconds. Throughput is 2852.551 records/second. Loss is 0.23450318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004610844706750277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 41520/60000][Iteration 5846][Wall Clock 268.471174319s] Trained 120 records in 0.041639372 seconds. Throughput is 2881.8877 records/second. Loss is 0.18901855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004610419548178884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:34 INFO  DistriOptimizer$:406 - [Epoch 12 41640/60000][Iteration 5847][Wall Clock 268.512694531s] Trained 120 records in 0.041520212 seconds. Throughput is 2890.1587 records/second. Loss is 0.24673066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004609994468006639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 41760/60000][Iteration 5848][Wall Clock 268.562500251s] Trained 120 records in 0.04980572 seconds. Throughput is 2409.3618 records/second. Loss is 0.13378324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004609569466211856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 41880/60000][Iteration 5849][Wall Clock 268.612750797s] Trained 120 records in 0.050250546 seconds. Throughput is 2388.0337 records/second. Loss is 0.16017334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004609144542772861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42000/60000][Iteration 5850][Wall Clock 268.655989733s] Trained 120 records in 0.043238936 seconds. Throughput is 2775.2764 records/second. Loss is 0.17379297. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004608719697667988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42120/60000][Iteration 5851][Wall Clock 268.697174207s] Trained 120 records in 0.041184474 seconds. Throughput is 2913.7195 records/second. Loss is 0.17867197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004608294930875576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42240/60000][Iteration 5852][Wall Clock 268.738728209s] Trained 120 records in 0.041554002 seconds. Throughput is 2887.8086 records/second. Loss is 0.14346428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004607870242373974. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42360/60000][Iteration 5853][Wall Clock 268.780599012s] Trained 120 records in 0.041870803 seconds. Throughput is 2865.959 records/second. Loss is 0.17079861. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004607445632141541. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42480/60000][Iteration 5854][Wall Clock 268.82320707s] Trained 120 records in 0.042608058 seconds. Throughput is 2816.369 records/second. Loss is 0.15790333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004607021100156638. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42600/60000][Iteration 5855][Wall Clock 268.875644973s] Trained 120 records in 0.052437903 seconds. Throughput is 2288.4211 records/second. Loss is 0.20129615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004606596646397642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42720/60000][Iteration 5856][Wall Clock 268.930052459s] Trained 120 records in 0.054407486 seconds. Throughput is 2205.5789 records/second. Loss is 0.21090268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004606172270842929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42840/60000][Iteration 5857][Wall Clock 268.977419974s] Trained 120 records in 0.047367515 seconds. Throughput is 2533.3818 records/second. Loss is 0.11945534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004605747973470892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 42960/60000][Iteration 5858][Wall Clock 269.020434095s] Trained 120 records in 0.043014121 seconds. Throughput is 2789.7815 records/second. Loss is 0.19115692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004605323754259924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43080/60000][Iteration 5859][Wall Clock 269.063531694s] Trained 120 records in 0.043097599 seconds. Throughput is 2784.3777 records/second. Loss is 0.32728815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004604899613188433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43200/60000][Iteration 5860][Wall Clock 269.105675484s] Trained 120 records in 0.04214379 seconds. Throughput is 2847.3948 records/second. Loss is 0.22432186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046044755502348276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43320/60000][Iteration 5861][Wall Clock 269.148170282s] Trained 120 records in 0.042494798 seconds. Throughput is 2823.8752 records/second. Loss is 0.16914429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004604051565377532. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43440/60000][Iteration 5862][Wall Clock 269.190063601s] Trained 120 records in 0.041893319 seconds. Throughput is 2864.4187 records/second. Loss is 0.27136153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004603627658594973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43560/60000][Iteration 5863][Wall Clock 269.235571731s] Trained 120 records in 0.04550813 seconds. Throughput is 2636.8914 records/second. Loss is 0.24329755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004603203829865586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43680/60000][Iteration 5864][Wall Clock 269.277150034s] Trained 120 records in 0.041578303 seconds. Throughput is 2886.1206 records/second. Loss is 0.25124854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004602780079167817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43800/60000][Iteration 5865][Wall Clock 269.318639357s] Trained 120 records in 0.041489323 seconds. Throughput is 2892.3105 records/second. Loss is 0.14334987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004602356406480118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 43920/60000][Iteration 5866][Wall Clock 269.360592202s] Trained 120 records in 0.041952845 seconds. Throughput is 2860.3542 records/second. Loss is 0.14838184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0046019328117809484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 44040/60000][Iteration 5867][Wall Clock 269.401922898s] Trained 120 records in 0.041330696 seconds. Throughput is 2903.4111 records/second. Loss is 0.21240863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004601509295048776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 44160/60000][Iteration 5868][Wall Clock 269.444172123s] Trained 120 records in 0.042249225 seconds. Throughput is 2840.2888 records/second. Loss is 0.19986328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004601085856262078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 44280/60000][Iteration 5869][Wall Clock 269.485742736s] Trained 120 records in 0.041570613 seconds. Throughput is 2886.6548 records/second. Loss is 0.15250237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004600662495399338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:35 INFO  DistriOptimizer$:406 - [Epoch 12 44400/60000][Iteration 5870][Wall Clock 269.52762013s] Trained 120 records in 0.041877394 seconds. Throughput is 2865.5078 records/second. Loss is 0.20694712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004600239212439047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 44520/60000][Iteration 5871][Wall Clock 269.569552403s] Trained 120 records in 0.041932273 seconds. Throughput is 2861.7576 records/second. Loss is 0.20221116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045998160073597045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 44640/60000][Iteration 5872][Wall Clock 269.611208831s] Trained 120 records in 0.041656428 seconds. Throughput is 2880.708 records/second. Loss is 0.120877214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004599392880139822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 44760/60000][Iteration 5873][Wall Clock 269.652818298s] Trained 120 records in 0.041609467 seconds. Throughput is 2883.9592 records/second. Loss is 0.16662595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00459896983075791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 44880/60000][Iteration 5874][Wall Clock 269.693927591s] Trained 120 records in 0.041109293 seconds. Throughput is 2919.0479 records/second. Loss is 0.19336489. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004598546859192495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45000/60000][Iteration 5875][Wall Clock 269.74901079s] Trained 120 records in 0.055083199 seconds. Throughput is 2178.5227 records/second. Loss is 0.16129002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004598123965422108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45120/60000][Iteration 5876][Wall Clock 269.794960786s] Trained 120 records in 0.045949996 seconds. Throughput is 2611.5344 records/second. Loss is 0.18326263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004597701149425288. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45240/60000][Iteration 5877][Wall Clock 269.836514411s] Trained 120 records in 0.041553625 seconds. Throughput is 2887.8347 records/second. Loss is 0.16087453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004597278411180581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45360/60000][Iteration 5878][Wall Clock 269.878365584s] Trained 120 records in 0.041851173 seconds. Throughput is 2867.303 records/second. Loss is 0.19536604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004596855750666545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45480/60000][Iteration 5879][Wall Clock 269.923286323s] Trained 120 records in 0.044920739 seconds. Throughput is 2671.3718 records/second. Loss is 0.171853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004596433167861739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45600/60000][Iteration 5880][Wall Clock 269.968904236s] Trained 120 records in 0.045617913 seconds. Throughput is 2630.5457 records/second. Loss is 0.22512916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004596010662744739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45720/60000][Iteration 5881][Wall Clock 270.013629352s] Trained 120 records in 0.044725116 seconds. Throughput is 2683.0562 records/second. Loss is 0.15838048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004595588235294118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45840/60000][Iteration 5882][Wall Clock 270.061642592s] Trained 120 records in 0.04801324 seconds. Throughput is 2499.3105 records/second. Loss is 0.18646434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045951658854884656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 45960/60000][Iteration 5883][Wall Clock 270.114176091s] Trained 120 records in 0.052533499 seconds. Throughput is 2284.2568 records/second. Loss is 0.12602817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004594743613306377. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46080/60000][Iteration 5884][Wall Clock 270.161394781s] Trained 120 records in 0.04721869 seconds. Throughput is 2541.3665 records/second. Loss is 0.13147399. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004594321418726454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46200/60000][Iteration 5885][Wall Clock 270.204196832s] Trained 120 records in 0.042802051 seconds. Throughput is 2803.604 records/second. Loss is 0.15510686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004593899301727306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46320/60000][Iteration 5886][Wall Clock 270.247029211s] Trained 120 records in 0.042832379 seconds. Throughput is 2801.619 records/second. Loss is 0.15423903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004593477262287551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46440/60000][Iteration 5887][Wall Clock 270.289181412s] Trained 120 records in 0.042152201 seconds. Throughput is 2846.8264 records/second. Loss is 0.20954186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045930553003858164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46560/60000][Iteration 5888][Wall Clock 270.331592206s] Trained 120 records in 0.042410794 seconds. Throughput is 2829.4683 records/second. Loss is 0.20069961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004592633416000735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46680/60000][Iteration 5889][Wall Clock 270.373934411s] Trained 120 records in 0.042342205 seconds. Throughput is 2834.0518 records/second. Loss is 0.25228623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004592211609110948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46800/60000][Iteration 5890][Wall Clock 270.416426413s] Trained 120 records in 0.042492002 seconds. Throughput is 2824.0608 records/second. Loss is 0.22138652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004591789879695106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 46920/60000][Iteration 5891][Wall Clock 270.458562189s] Trained 120 records in 0.042135776 seconds. Throughput is 2847.9363 records/second. Loss is 0.12945355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004591368227731864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:36 INFO  DistriOptimizer$:406 - [Epoch 12 47040/60000][Iteration 5892][Wall Clock 270.50117619s] Trained 120 records in 0.042614001 seconds. Throughput is 2815.9758 records/second. Loss is 0.22937675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004590946653199889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 47160/60000][Iteration 5893][Wall Clock 270.543090874s] Trained 120 records in 0.041914684 seconds. Throughput is 2862.9585 records/second. Loss is 0.23509355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004590525156077855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 47280/60000][Iteration 5894][Wall Clock 270.585603424s] Trained 120 records in 0.04251255 seconds. Throughput is 2822.6958 records/second. Loss is 0.113104396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004590103736344441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 47400/60000][Iteration 5895][Wall Clock 270.62717599s] Trained 120 records in 0.041572566 seconds. Throughput is 2886.5188 records/second. Loss is 0.26343068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004589682393978337. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 47520/60000][Iteration 5896][Wall Clock 270.668627825s] Trained 120 records in 0.041451835 seconds. Throughput is 2894.9263 records/second. Loss is 0.16029073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004589261128958237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 47640/60000][Iteration 5897][Wall Clock 270.710954571s] Trained 120 records in 0.042326746 seconds. Throughput is 2835.087 records/second. Loss is 0.16062409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004588839941262849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 47760/60000][Iteration 5898][Wall Clock 270.754009396s] Trained 120 records in 0.043054825 seconds. Throughput is 2787.144 records/second. Loss is 0.1973748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004588418830870881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 47880/60000][Iteration 5899][Wall Clock 270.796827116s] Trained 120 records in 0.04281772 seconds. Throughput is 2802.5781 records/second. Loss is 0.16268177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004587997797761058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48000/60000][Iteration 5900][Wall Clock 270.839017154s] Trained 120 records in 0.042190038 seconds. Throughput is 2844.2734 records/second. Loss is 0.18544589. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004587576841912102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48120/60000][Iteration 5901][Wall Clock 270.894263608s] Trained 120 records in 0.055246454 seconds. Throughput is 2172.0852 records/second. Loss is 0.18473782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004587155963302752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48240/60000][Iteration 5902][Wall Clock 270.943985639s] Trained 120 records in 0.049722031 seconds. Throughput is 2413.4172 records/second. Loss is 0.16107008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004586735161911751. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48360/60000][Iteration 5903][Wall Clock 270.98866524s] Trained 120 records in 0.044679601 seconds. Throughput is 2685.7896 records/second. Loss is 0.25429344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00458631443771785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48480/60000][Iteration 5904][Wall Clock 271.032132228s] Trained 120 records in 0.043466988 seconds. Throughput is 2760.7158 records/second. Loss is 0.1769506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045858937906998075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48600/60000][Iteration 5905][Wall Clock 271.074640868s] Trained 120 records in 0.04250864 seconds. Throughput is 2822.9556 records/second. Loss is 0.22519259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045854732208363905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48720/60000][Iteration 5906][Wall Clock 271.115737823s] Trained 120 records in 0.041096955 seconds. Throughput is 2919.9243 records/second. Loss is 0.16615032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004585052728106373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48840/60000][Iteration 5907][Wall Clock 271.156385559s] Trained 120 records in 0.040647736 seconds. Throughput is 2952.1938 records/second. Loss is 0.16337806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045846323124885385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 48960/60000][Iteration 5908][Wall Clock 271.196743151s] Trained 120 records in 0.040357592 seconds. Throughput is 2973.4182 records/second. Loss is 0.095954075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004584211973961676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 49080/60000][Iteration 5909][Wall Clock 271.237230051s] Trained 120 records in 0.0404869 seconds. Throughput is 2963.9219 records/second. Loss is 0.18076271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004583791712504584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 49200/60000][Iteration 5910][Wall Clock 271.287064837s] Trained 120 records in 0.049834786 seconds. Throughput is 2407.9565 records/second. Loss is 0.14962587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004583371528096068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 49320/60000][Iteration 5911][Wall Clock 271.327698811s] Trained 120 records in 0.040633974 seconds. Throughput is 2953.1938 records/second. Loss is 0.20882712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045829514207149395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 49440/60000][Iteration 5912][Wall Clock 271.368216661s] Trained 120 records in 0.04051785 seconds. Throughput is 2961.6575 records/second. Loss is 0.23862197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004582531390340024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 49560/60000][Iteration 5913][Wall Clock 271.408527393s] Trained 120 records in 0.040310732 seconds. Throughput is 2976.8748 records/second. Loss is 0.16987821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004582111436950146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 49680/60000][Iteration 5914][Wall Clock 271.448444674s] Trained 120 records in 0.039917281 seconds. Throughput is 3006.2166 records/second. Loss is 0.35446882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004581691560524146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:37 INFO  DistriOptimizer$:406 - [Epoch 12 49800/60000][Iteration 5915][Wall Clock 271.488196869s] Trained 120 records in 0.039752195 seconds. Throughput is 3018.7012 records/second. Loss is 0.20967533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045812717610408645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 49920/60000][Iteration 5916][Wall Clock 271.528183936s] Trained 120 records in 0.039987067 seconds. Throughput is 3000.9702 records/second. Loss is 0.23890366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004580852038479157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50040/60000][Iteration 5917][Wall Clock 271.569881776s] Trained 120 records in 0.04169784 seconds. Throughput is 2877.847 records/second. Loss is 0.21723747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004580432392817881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50160/60000][Iteration 5918][Wall Clock 271.609871684s] Trained 120 records in 0.039989908 seconds. Throughput is 3000.757 records/second. Loss is 0.2500142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004580012824035908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50280/60000][Iteration 5919][Wall Clock 271.653302281s] Trained 120 records in 0.043430597 seconds. Throughput is 2763.029 records/second. Loss is 0.32363126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045795933321121085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50400/60000][Iteration 5920][Wall Clock 271.693233533s] Trained 120 records in 0.039931252 seconds. Throughput is 3005.165 records/second. Loss is 0.11517768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045791739170253695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50520/60000][Iteration 5921][Wall Clock 271.733586341s] Trained 120 records in 0.040352808 seconds. Throughput is 2973.7708 records/second. Loss is 0.16823997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004578754578754578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50640/60000][Iteration 5922][Wall Clock 271.773715829s] Trained 120 records in 0.040129488 seconds. Throughput is 2990.3198 records/second. Loss is 0.132022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004578335317278638. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50760/60000][Iteration 5923][Wall Clock 271.813298504s] Trained 120 records in 0.039582675 seconds. Throughput is 3031.6294 records/second. Loss is 0.120067805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004577916132576451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 50880/60000][Iteration 5924][Wall Clock 271.853000726s] Trained 120 records in 0.039702222 seconds. Throughput is 3022.501 records/second. Loss is 0.18161263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004577497024626934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51000/60000][Iteration 5925][Wall Clock 271.892875803s] Trained 120 records in 0.039875077 seconds. Throughput is 3009.3987 records/second. Loss is 0.27002856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045770779934090075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51120/60000][Iteration 5926][Wall Clock 271.93290813s] Trained 120 records in 0.040032327 seconds. Throughput is 2997.5774 records/second. Loss is 0.3622523. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004576659038901602. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51240/60000][Iteration 5927][Wall Clock 271.973883239s] Trained 120 records in 0.040975109 seconds. Throughput is 2928.6072 records/second. Loss is 0.21169753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004576240161083654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51360/60000][Iteration 5928][Wall Clock 272.023858989s] Trained 120 records in 0.04997575 seconds. Throughput is 2401.1646 records/second. Loss is 0.30904204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045758213599341084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51480/60000][Iteration 5929][Wall Clock 272.074548181s] Trained 120 records in 0.050689192 seconds. Throughput is 2367.3687 records/second. Loss is 0.1939292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004575402635431918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51600/60000][Iteration 5930][Wall Clock 272.118999761s] Trained 120 records in 0.04445158 seconds. Throughput is 2699.5667 records/second. Loss is 0.13550167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004574983987556043. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51720/60000][Iteration 5931][Wall Clock 272.159861905s] Trained 120 records in 0.040862144 seconds. Throughput is 2936.7036 records/second. Loss is 0.26699495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004574565416285453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51840/60000][Iteration 5932][Wall Clock 272.199703287s] Trained 120 records in 0.039841382 seconds. Throughput is 3011.9436 records/second. Loss is 0.15835628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004574146921599121. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 51960/60000][Iteration 5933][Wall Clock 272.24005728s] Trained 120 records in 0.040353993 seconds. Throughput is 2973.6833 records/second. Loss is 0.22371577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004573728503476034. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 52080/60000][Iteration 5934][Wall Clock 272.280196665s] Trained 120 records in 0.040139385 seconds. Throughput is 2989.5825 records/second. Loss is 0.28369114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004573310161895179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 52200/60000][Iteration 5935][Wall Clock 272.319753994s] Trained 120 records in 0.039557329 seconds. Throughput is 3033.5718 records/second. Loss is 0.17183408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004572891896835559. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 52320/60000][Iteration 5936][Wall Clock 272.365647295s] Trained 120 records in 0.045893301 seconds. Throughput is 2614.7607 records/second. Loss is 0.15877946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004572473708276177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 52440/60000][Iteration 5937][Wall Clock 272.409266577s] Trained 120 records in 0.043619282 seconds. Throughput is 2751.077 records/second. Loss is 0.16521846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00457205559619605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 52560/60000][Iteration 5938][Wall Clock 272.452351304s] Trained 120 records in 0.043084727 seconds. Throughput is 2785.2097 records/second. Loss is 0.31429684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004571637560574197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:38 INFO  DistriOptimizer$:406 - [Epoch 12 52680/60000][Iteration 5939][Wall Clock 272.492223292s] Trained 120 records in 0.039871988 seconds. Throughput is 3009.6318 records/second. Loss is 0.16855426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004571219601389651. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 52800/60000][Iteration 5940][Wall Clock 272.53188956s] Trained 120 records in 0.039666268 seconds. Throughput is 3025.2405 records/second. Loss is 0.23583876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045708017186214455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 52920/60000][Iteration 5941][Wall Clock 272.572074338s] Trained 120 records in 0.040184778 seconds. Throughput is 2986.2053 records/second. Loss is 0.17277074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004570383912248629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53040/60000][Iteration 5942][Wall Clock 272.612660343s] Trained 120 records in 0.040586005 seconds. Throughput is 2956.684 records/second. Loss is 0.14177981. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004569966182250251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53160/60000][Iteration 5943][Wall Clock 272.653571006s] Trained 120 records in 0.040910663 seconds. Throughput is 2933.2207 records/second. Loss is 0.22398968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045695485286053735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53280/60000][Iteration 5944][Wall Clock 272.693981228s] Trained 120 records in 0.040410222 seconds. Throughput is 2969.546 records/second. Loss is 0.20315978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004569130951293064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53400/60000][Iteration 5945][Wall Clock 272.735054799s] Trained 120 records in 0.041073571 seconds. Throughput is 2921.5867 records/second. Loss is 0.14822207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004568713450292397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53520/60000][Iteration 5946][Wall Clock 272.776877388s] Trained 120 records in 0.041822589 seconds. Throughput is 2869.2627 records/second. Loss is 0.22519735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045682960255824575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53640/60000][Iteration 5947][Wall Clock 272.817171989s] Trained 120 records in 0.040294601 seconds. Throughput is 2978.0664 records/second. Loss is 0.2176309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004567878677142335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53760/60000][Iteration 5948][Wall Clock 272.858274303s] Trained 120 records in 0.041102314 seconds. Throughput is 2919.5437 records/second. Loss is 0.20529665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004567461404951128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 53880/60000][Iteration 5949][Wall Clock 272.898855274s] Trained 120 records in 0.040580971 seconds. Throughput is 2957.051 records/second. Loss is 0.17414337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004567044208987943. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54000/60000][Iteration 5950][Wall Clock 272.940145861s] Trained 120 records in 0.041290587 seconds. Throughput is 2906.2312 records/second. Loss is 0.2553209. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004566627089231894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54120/60000][Iteration 5951][Wall Clock 272.981142609s] Trained 120 records in 0.040996748 seconds. Throughput is 2927.0613 records/second. Loss is 0.16901585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004566210045662101. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54240/60000][Iteration 5952][Wall Clock 273.022049466s] Trained 120 records in 0.040906857 seconds. Throughput is 2933.4934 records/second. Loss is 0.2898574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004565793078257694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54360/60000][Iteration 5953][Wall Clock 273.062827261s] Trained 120 records in 0.040777795 seconds. Throughput is 2942.778 records/second. Loss is 0.15441494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004565376186997808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54480/60000][Iteration 5954][Wall Clock 273.109402488s] Trained 120 records in 0.046575227 seconds. Throughput is 2576.477 records/second. Loss is 0.35147458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045649593718615905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54600/60000][Iteration 5955][Wall Clock 273.159007112s] Trained 120 records in 0.049604624 seconds. Throughput is 2419.1294 records/second. Loss is 0.15983231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045645426328281904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54720/60000][Iteration 5956][Wall Clock 273.203253091s] Trained 120 records in 0.044245979 seconds. Throughput is 2712.1108 records/second. Loss is 0.1486609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004564125969876769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54840/60000][Iteration 5957][Wall Clock 273.243963237s] Trained 120 records in 0.040710146 seconds. Throughput is 2947.668 records/second. Loss is 0.16088285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004563709382986491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 54960/60000][Iteration 5958][Wall Clock 273.284259148s] Trained 120 records in 0.040295911 seconds. Throughput is 2977.9697 records/second. Loss is 0.21752913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004563292872136534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 55080/60000][Iteration 5959][Wall Clock 273.324974587s] Trained 120 records in 0.040715439 seconds. Throughput is 2947.2852 records/second. Loss is 0.1456093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004562876437306077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 55200/60000][Iteration 5960][Wall Clock 273.365321637s] Trained 120 records in 0.04034705 seconds. Throughput is 2974.195 records/second. Loss is 0.1436349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004562460078474314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 55320/60000][Iteration 5961][Wall Clock 273.406590129s] Trained 120 records in 0.041268492 seconds. Throughput is 2907.7876 records/second. Loss is 0.23398337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004562043795620438. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 55440/60000][Iteration 5962][Wall Clock 273.449147388s] Trained 120 records in 0.042557259 seconds. Throughput is 2819.7305 records/second. Loss is 0.15679032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004561627588723656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:39 INFO  DistriOptimizer$:406 - [Epoch 12 55560/60000][Iteration 5963][Wall Clock 273.498282012s] Trained 120 records in 0.049134624 seconds. Throughput is 2442.2698 records/second. Loss is 0.16896299. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045612114577631814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 55680/60000][Iteration 5964][Wall Clock 273.54115721s] Trained 120 records in 0.042875198 seconds. Throughput is 2798.821 records/second. Loss is 0.2673687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004560795402718234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 55800/60000][Iteration 5965][Wall Clock 273.581443096s] Trained 120 records in 0.040285886 seconds. Throughput is 2978.7107 records/second. Loss is 0.25049573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004560379423568041. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 55920/60000][Iteration 5966][Wall Clock 273.621988564s] Trained 120 records in 0.040545468 seconds. Throughput is 2959.6404 records/second. Loss is 0.27401686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004559963520291838. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56040/60000][Iteration 5967][Wall Clock 273.662116903s] Trained 120 records in 0.040128339 seconds. Throughput is 2990.4053 records/second. Loss is 0.14258471. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004559547692868867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56160/60000][Iteration 5968][Wall Clock 273.702365589s] Trained 120 records in 0.040248686 seconds. Throughput is 2981.4639 records/second. Loss is 0.11697221. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004559131941278381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56280/60000][Iteration 5969][Wall Clock 273.742343027s] Trained 120 records in 0.039977438 seconds. Throughput is 3001.693 records/second. Loss is 0.17971608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004558716265499635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56400/60000][Iteration 5970][Wall Clock 273.782428473s] Trained 120 records in 0.040085446 seconds. Throughput is 2993.6052 records/second. Loss is 0.24188992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004558300665511898. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56520/60000][Iteration 5971][Wall Clock 273.822176903s] Trained 120 records in 0.03974843 seconds. Throughput is 3018.987 records/second. Loss is 0.23254795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00455788514129444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56640/60000][Iteration 5972][Wall Clock 273.861553909s] Trained 120 records in 0.039377006 seconds. Throughput is 3047.4636 records/second. Loss is 0.18830077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004557469692826542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56760/60000][Iteration 5973][Wall Clock 273.90138513s] Trained 120 records in 0.039831221 seconds. Throughput is 3012.7122 records/second. Loss is 0.17972748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004557054320087496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 56880/60000][Iteration 5974][Wall Clock 273.940919343s] Trained 120 records in 0.039534213 seconds. Throughput is 3035.3457 records/second. Loss is 0.19359893. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004556639023056593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57000/60000][Iteration 5975][Wall Clock 273.984383576s] Trained 120 records in 0.043464233 seconds. Throughput is 2760.8909 records/second. Loss is 0.19930959. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00455622380171314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57120/60000][Iteration 5976][Wall Clock 274.024755657s] Trained 120 records in 0.040372081 seconds. Throughput is 2972.351 records/second. Loss is 0.20227009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004555808656036446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57240/60000][Iteration 5977][Wall Clock 274.065239071s] Trained 120 records in 0.040483414 seconds. Throughput is 2964.1768 records/second. Loss is 0.2273115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004555393586005831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57360/60000][Iteration 5978][Wall Clock 274.105183187s] Trained 120 records in 0.039944116 seconds. Throughput is 3004.1973 records/second. Loss is 0.14505325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004554978591600619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57480/60000][Iteration 5979][Wall Clock 274.154509837s] Trained 120 records in 0.04932665 seconds. Throughput is 2432.762 records/second. Loss is 0.16249633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045545636728001465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57600/60000][Iteration 5980][Wall Clock 274.2031838s] Trained 120 records in 0.048673963 seconds. Throughput is 2465.3838 records/second. Loss is 0.17155267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004554148829583751. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57720/60000][Iteration 5981][Wall Clock 274.244502357s] Trained 120 records in 0.041318557 seconds. Throughput is 2904.264 records/second. Loss is 0.24233563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004553734061930784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57840/60000][Iteration 5982][Wall Clock 274.28494828s] Trained 120 records in 0.040445923 seconds. Throughput is 2966.9246 records/second. Loss is 0.12455217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004553319369820599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 57960/60000][Iteration 5983][Wall Clock 274.325665004s] Trained 120 records in 0.040716724 seconds. Throughput is 2947.1921 records/second. Loss is 0.19866484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004552904753232562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 58080/60000][Iteration 5984][Wall Clock 274.365252024s] Trained 120 records in 0.03958702 seconds. Throughput is 3031.2966 records/second. Loss is 0.23251396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004552490212146044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 58200/60000][Iteration 5985][Wall Clock 274.404613322s] Trained 120 records in 0.039361298 seconds. Throughput is 3048.68 records/second. Loss is 0.18973102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004552075746540422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 58320/60000][Iteration 5986][Wall Clock 274.443802242s] Trained 120 records in 0.03918892 seconds. Throughput is 3062.0898 records/second. Loss is 0.24534552. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004551661356395084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:40 INFO  DistriOptimizer$:406 - [Epoch 12 58440/60000][Iteration 5987][Wall Clock 274.483246214s] Trained 120 records in 0.039443972 seconds. Throughput is 3042.2898 records/second. Loss is 0.25290027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004551247041689423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 58560/60000][Iteration 5988][Wall Clock 274.522948756s] Trained 120 records in 0.039702542 seconds. Throughput is 3022.4766 records/second. Loss is 0.23746487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00455083280240284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 58680/60000][Iteration 5989][Wall Clock 274.563473075s] Trained 120 records in 0.040524319 seconds. Throughput is 2961.1848 records/second. Loss is 0.18589099. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004550418638514743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 58800/60000][Iteration 5990][Wall Clock 274.614978217s] Trained 120 records in 0.051505142 seconds. Throughput is 2329.8645 records/second. Loss is 0.19462997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045500045500045504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 58920/60000][Iteration 5991][Wall Clock 274.65565586s] Trained 120 records in 0.040677643 seconds. Throughput is 2950.0234 records/second. Loss is 0.22613071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004549590536851684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59040/60000][Iteration 5992][Wall Clock 274.696048159s] Trained 120 records in 0.040392299 seconds. Throughput is 2970.8633 records/second. Loss is 0.12713404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004549176599035575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59160/60000][Iteration 5993][Wall Clock 274.73636055s] Trained 120 records in 0.040312391 seconds. Throughput is 2976.7522 records/second. Loss is 0.20814158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004548762736535662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59280/60000][Iteration 5994][Wall Clock 274.780475199s] Trained 120 records in 0.044114649 seconds. Throughput is 2720.1848 records/second. Loss is 0.21387076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004548348949331393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59400/60000][Iteration 5995][Wall Clock 274.821130545s] Trained 120 records in 0.040655346 seconds. Throughput is 2951.6414 records/second. Loss is 0.18273482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004547935237402219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59520/60000][Iteration 5996][Wall Clock 274.861661632s] Trained 120 records in 0.040531087 seconds. Throughput is 2960.6904 records/second. Loss is 0.19462562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004547521600727604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59640/60000][Iteration 5997][Wall Clock 274.901819176s] Trained 120 records in 0.040157544 seconds. Throughput is 2988.2305 records/second. Loss is 0.19682696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004547108039287013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59760/60000][Iteration 5998][Wall Clock 274.941659978s] Trained 120 records in 0.039840802 seconds. Throughput is 3011.9875 records/second. Loss is 0.22904335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045466945530599255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 59880/60000][Iteration 5999][Wall Clock 274.981354679s] Trained 120 records in 0.039694701 seconds. Throughput is 3023.0735 records/second. Loss is 0.16764292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004546281142025823. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:406 - [Epoch 12 60000/60000][Iteration 6000][Wall Clock 275.02152767s] Trained 120 records in 0.040172991 seconds. Throughput is 2987.0815 records/second. Loss is 0.29891345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004545867806164197. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:41 INFO  DistriOptimizer$:451 - [Epoch 12 60000/60000][Iteration 6000][Wall Clock 275.02152767s] Epoch finished. Wall clock time is 275823.757905 ms
2019-10-23 15:57:41 INFO  DistriOptimizer$:111 - [Epoch 12 60000/60000][Iteration 6000][Wall Clock 275.02152767s] Validate model...
2019-10-23 15:57:42 INFO  DistriOptimizer$:177 - [Epoch 12 60000/60000][Iteration 6000][Wall Clock 275.02152767s] validate model throughput is 15085.471 records/second
2019-10-23 15:57:42 INFO  DistriOptimizer$:180 - [Epoch 12 60000/60000][Iteration 6000][Wall Clock 275.02152767s] Top1Accuracy is Accuracy(correct: 9484, count: 10000, accuracy: 0.9484)
2019-10-23 15:57:42 INFO  DistriOptimizer$:220 - [Wall Clock 275.823757905s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:57:42 INFO  DistriOptimizer$:225 - [Wall Clock 275.823757905s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 120/60000][Iteration 6001][Wall Clock 275.869625275s] Trained 120 records in 0.04586737 seconds. Throughput is 2616.239 records/second. Loss is 0.1819872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004545454545454545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 240/60000][Iteration 6002][Wall Clock 275.909256602s] Trained 120 records in 0.039631327 seconds. Throughput is 3027.9077 records/second. Loss is 0.13124849. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004545041359876375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 360/60000][Iteration 6003][Wall Clock 275.958143936s] Trained 120 records in 0.048887334 seconds. Throughput is 2454.6235 records/second. Loss is 0.1786864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004544628249409198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 480/60000][Iteration 6004][Wall Clock 276.011456793s] Trained 120 records in 0.053312857 seconds. Throughput is 2250.8643 records/second. Loss is 0.18654232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004544215214032536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 600/60000][Iteration 6005][Wall Clock 276.051957364s] Trained 120 records in 0.040500571 seconds. Throughput is 2962.9211 records/second. Loss is 0.2442493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045438022537259174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 720/60000][Iteration 6006][Wall Clock 276.091889324s] Trained 120 records in 0.03993196 seconds. Throughput is 3005.1116 records/second. Loss is 0.176523. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004543389368468878. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 840/60000][Iteration 6007][Wall Clock 276.132247939s] Trained 120 records in 0.040358615 seconds. Throughput is 2973.343 records/second. Loss is 0.20982663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004542976558240959. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 960/60000][Iteration 6008][Wall Clock 276.173174236s] Trained 120 records in 0.040926297 seconds. Throughput is 2932.1 records/second. Loss is 0.16904227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004542563823021714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1080/60000][Iteration 6009][Wall Clock 276.214408675s] Trained 120 records in 0.041234439 seconds. Throughput is 2910.189 records/second. Loss is 0.20669547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004542151162790698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1200/60000][Iteration 6010][Wall Clock 276.255111874s] Trained 120 records in 0.040703199 seconds. Throughput is 2948.1711 records/second. Loss is 0.23092057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004541738577527477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1320/60000][Iteration 6011][Wall Clock 276.299013128s] Trained 120 records in 0.043901254 seconds. Throughput is 2733.4072 records/second. Loss is 0.1601952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004541326067211626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1440/60000][Iteration 6012][Wall Clock 276.340435093s] Trained 120 records in 0.041421965 seconds. Throughput is 2897.0137 records/second. Loss is 0.15126444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004540913631822722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1560/60000][Iteration 6013][Wall Clock 276.381727222s] Trained 120 records in 0.041292129 seconds. Throughput is 2906.123 records/second. Loss is 0.17533989. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004540501271340356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1680/60000][Iteration 6014][Wall Clock 276.42326811s] Trained 120 records in 0.041540888 seconds. Throughput is 2888.7202 records/second. Loss is 0.19893599. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00454008898574412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1800/60000][Iteration 6015][Wall Clock 276.473356488s] Trained 120 records in 0.050088378 seconds. Throughput is 2395.7654 records/second. Loss is 0.15196992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045396767750136196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 1920/60000][Iteration 6016][Wall Clock 276.517532671s] Trained 120 records in 0.044176183 seconds. Throughput is 2716.3958 records/second. Loss is 0.1534066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045392646391284605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 2040/60000][Iteration 6017][Wall Clock 276.558616263s] Trained 120 records in 0.041083592 seconds. Throughput is 2920.874 records/second. Loss is 0.25061205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004538852578068265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:42 INFO  DistriOptimizer$:406 - [Epoch 13 2160/60000][Iteration 6018][Wall Clock 276.598705884s] Trained 120 records in 0.040089621 seconds. Throughput is 2993.2935 records/second. Loss is 0.28425997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004538440591812653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 2280/60000][Iteration 6019][Wall Clock 276.640012197s] Trained 120 records in 0.041306313 seconds. Throughput is 2905.125 records/second. Loss is 0.08277818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00453802868034126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 2400/60000][Iteration 6020][Wall Clock 276.680466863s] Trained 120 records in 0.040454666 seconds. Throughput is 2966.2832 records/second. Loss is 0.16755033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004537616843633723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 2520/60000][Iteration 6021][Wall Clock 276.721169116s] Trained 120 records in 0.040702253 seconds. Throughput is 2948.2397 records/second. Loss is 0.21031849. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004537205081669692. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 2640/60000][Iteration 6022][Wall Clock 276.772406629s] Trained 120 records in 0.051237513 seconds. Throughput is 2342.0342 records/second. Loss is 0.1892531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004536793394428818. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 2760/60000][Iteration 6023][Wall Clock 276.813458749s] Trained 120 records in 0.04105212 seconds. Throughput is 2923.1133 records/second. Loss is 0.18770666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004536381781890764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 2880/60000][Iteration 6024][Wall Clock 276.855018535s] Trained 120 records in 0.041559786 seconds. Throughput is 2887.4067 records/second. Loss is 0.118767515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004535970244035199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3000/60000][Iteration 6025][Wall Clock 276.897220459s] Trained 120 records in 0.042201924 seconds. Throughput is 2843.4722 records/second. Loss is 0.18733373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045355587808417995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3120/60000][Iteration 6026][Wall Clock 276.937787072s] Trained 120 records in 0.040566613 seconds. Throughput is 2958.0977 records/second. Loss is 0.17229477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045351473922902496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3240/60000][Iteration 6027][Wall Clock 276.978088634s] Trained 120 records in 0.040301562 seconds. Throughput is 2977.5522 records/second. Loss is 0.15348813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045347360783602395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3360/60000][Iteration 6028][Wall Clock 277.026282115s] Trained 120 records in 0.048193481 seconds. Throughput is 2489.9634 records/second. Loss is 0.15102479. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004534324839031469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3480/60000][Iteration 6029][Wall Clock 277.077663044s] Trained 120 records in 0.051380929 seconds. Throughput is 2335.4968 records/second. Loss is 0.24652444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004533913674283642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3600/60000][Iteration 6030][Wall Clock 277.1225628s] Trained 120 records in 0.044899756 seconds. Throughput is 2672.6204 records/second. Loss is 0.22693753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045335025840964735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3720/60000][Iteration 6031][Wall Clock 277.162877094s] Trained 120 records in 0.040314294 seconds. Throughput is 2976.6116 records/second. Loss is 0.13811971. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004533091568449683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3840/60000][Iteration 6032][Wall Clock 277.203437963s] Trained 120 records in 0.040560869 seconds. Throughput is 2958.5166 records/second. Loss is 0.14466412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004532680627322999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 3960/60000][Iteration 6033][Wall Clock 277.243623383s] Trained 120 records in 0.04018542 seconds. Throughput is 2986.1575 records/second. Loss is 0.24640277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004532269760696156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4080/60000][Iteration 6034][Wall Clock 277.283777149s] Trained 120 records in 0.040153766 seconds. Throughput is 2988.512 records/second. Loss is 0.14541511. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004531858968548899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4200/60000][Iteration 6035][Wall Clock 277.323996318s] Trained 120 records in 0.040219169 seconds. Throughput is 2983.6519 records/second. Loss is 0.17059113. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004531448250860975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4320/60000][Iteration 6036][Wall Clock 277.364054566s] Trained 120 records in 0.040058248 seconds. Throughput is 2995.6377 records/second. Loss is 0.19241777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004531037607612144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4440/60000][Iteration 6037][Wall Clock 277.404266597s] Trained 120 records in 0.040212031 seconds. Throughput is 2984.1814 records/second. Loss is 0.22799246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004530627038782167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4560/60000][Iteration 6038][Wall Clock 277.444575473s] Trained 120 records in 0.040308876 seconds. Throughput is 2977.0117 records/second. Loss is 0.19203132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004530216544350821. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4680/60000][Iteration 6039][Wall Clock 277.485642185s] Trained 120 records in 0.041066712 seconds. Throughput is 2922.0745 records/second. Loss is 0.18862587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00452980612429788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4800/60000][Iteration 6040][Wall Clock 277.526127655s] Trained 120 records in 0.04048547 seconds. Throughput is 2964.0261 records/second. Loss is 0.16051675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045293957786031345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:43 INFO  DistriOptimizer$:406 - [Epoch 13 4920/60000][Iteration 6041][Wall Clock 277.566655132s] Trained 120 records in 0.040527477 seconds. Throughput is 2960.954 records/second. Loss is 0.17845958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004528985507246376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5040/60000][Iteration 6042][Wall Clock 277.618128325s] Trained 120 records in 0.051473193 seconds. Throughput is 2331.3105 records/second. Loss is 0.2095135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004528575310207408. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5160/60000][Iteration 6043][Wall Clock 277.660808498s] Trained 120 records in 0.042680173 seconds. Throughput is 2811.6099 records/second. Loss is 0.25070333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004528165187466038. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5280/60000][Iteration 6044][Wall Clock 277.701527434s] Trained 120 records in 0.040718936 seconds. Throughput is 2947.0317 records/second. Loss is 0.23008493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004527755139002083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5400/60000][Iteration 6045][Wall Clock 277.742647315s] Trained 120 records in 0.041119881 seconds. Throughput is 2918.2964 records/second. Loss is 0.18164918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004527345164795364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5520/60000][Iteration 6046][Wall Clock 277.783698003s] Trained 120 records in 0.041050688 seconds. Throughput is 2923.2153 records/second. Loss is 0.16310845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004526935264825713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5640/60000][Iteration 6047][Wall Clock 277.824662087s] Trained 120 records in 0.040964084 seconds. Throughput is 2929.3953 records/second. Loss is 0.20060934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004526525439072967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5760/60000][Iteration 6048][Wall Clock 277.864865918s] Trained 120 records in 0.040203831 seconds. Throughput is 2984.79 records/second. Loss is 0.18739814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004526115687516973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 5880/60000][Iteration 6049][Wall Clock 277.908746704s] Trained 120 records in 0.043880786 seconds. Throughput is 2734.6821 records/second. Loss is 0.19729228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004525706010137582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6000/60000][Iteration 6050][Wall Clock 277.949147423s] Trained 120 records in 0.040400719 seconds. Throughput is 2970.2444 records/second. Loss is 0.13933127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004525296406914653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6120/60000][Iteration 6051][Wall Clock 277.98876249s] Trained 120 records in 0.039615067 seconds. Throughput is 3029.1504 records/second. Loss is 0.15369819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004524886877828055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6240/60000][Iteration 6052][Wall Clock 278.02944351s] Trained 120 records in 0.04068102 seconds. Throughput is 2949.7786 records/second. Loss is 0.13905819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004524477422857659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6360/60000][Iteration 6053][Wall Clock 278.071222234s] Trained 120 records in 0.041778724 seconds. Throughput is 2872.2754 records/second. Loss is 0.18075609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004524068041983352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6480/60000][Iteration 6054][Wall Clock 278.124768042s] Trained 120 records in 0.053545808 seconds. Throughput is 2241.0718 records/second. Loss is 0.27360943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004523658735185017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6600/60000][Iteration 6055][Wall Clock 278.167815009s] Trained 120 records in 0.043046967 seconds. Throughput is 2787.6528 records/second. Loss is 0.17653951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045232495024425555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6720/60000][Iteration 6056][Wall Clock 278.210639361s] Trained 120 records in 0.042824352 seconds. Throughput is 2802.144 records/second. Loss is 0.30390644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045228403437358655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6840/60000][Iteration 6057][Wall Clock 278.252247892s] Trained 120 records in 0.041608531 seconds. Throughput is 2884.024 records/second. Loss is 0.16505887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004522431259044863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 6960/60000][Iteration 6058][Wall Clock 278.293437721s] Trained 120 records in 0.041189829 seconds. Throughput is 2913.3403 records/second. Loss is 0.24505368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004522022248349461. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 7080/60000][Iteration 6059][Wall Clock 278.33420377s] Trained 120 records in 0.040766049 seconds. Throughput is 2943.626 records/second. Loss is 0.22818397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00452161331162959. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 7200/60000][Iteration 6060][Wall Clock 278.374511243s] Trained 120 records in 0.040307473 seconds. Throughput is 2977.1155 records/second. Loss is 0.20845538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004521204448865178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 7320/60000][Iteration 6061][Wall Clock 278.414814306s] Trained 120 records in 0.040303063 seconds. Throughput is 2977.4412 records/second. Loss is 0.16504396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004520795660036167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 7440/60000][Iteration 6062][Wall Clock 278.454766103s] Trained 120 records in 0.039951797 seconds. Throughput is 3003.6196 records/second. Loss is 0.18868545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004520386945122502. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 7560/60000][Iteration 6063][Wall Clock 278.495179106s] Trained 120 records in 0.040413003 seconds. Throughput is 2969.3413 records/second. Loss is 0.267165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00451997830410414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 7680/60000][Iteration 6064][Wall Clock 278.535524767s] Trained 120 records in 0.040345661 seconds. Throughput is 2974.2976 records/second. Loss is 0.10793484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004519569736961041. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:44 INFO  DistriOptimizer$:406 - [Epoch 13 7800/60000][Iteration 6065][Wall Clock 278.575363246s] Trained 120 records in 0.039838479 seconds. Throughput is 3012.1633 records/second. Loss is 0.11745799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004519161243673174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 7920/60000][Iteration 6066][Wall Clock 278.615740972s] Trained 120 records in 0.040377726 seconds. Throughput is 2971.9355 records/second. Loss is 0.22493228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004518752824220515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8040/60000][Iteration 6067][Wall Clock 278.659627703s] Trained 120 records in 0.043886731 seconds. Throughput is 2734.3115 records/second. Loss is 0.23115854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004518344478583047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8160/60000][Iteration 6068][Wall Clock 278.709801225s] Trained 120 records in 0.050173522 seconds. Throughput is 2391.6997 records/second. Loss is 0.20926665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004517936206740761. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8280/60000][Iteration 6069][Wall Clock 278.756316579s] Trained 120 records in 0.046515354 seconds. Throughput is 2579.7935 records/second. Loss is 0.19759127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004517528008673654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8400/60000][Iteration 6070][Wall Clock 278.795924726s] Trained 120 records in 0.039608147 seconds. Throughput is 3029.6797 records/second. Loss is 0.23316857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004517119884361731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8520/60000][Iteration 6071][Wall Clock 278.835539286s] Trained 120 records in 0.03961456 seconds. Throughput is 3029.1895 records/second. Loss is 0.2537234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004516711833785005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8640/60000][Iteration 6072][Wall Clock 278.875965396s] Trained 120 records in 0.04042611 seconds. Throughput is 2968.3787 records/second. Loss is 0.18247461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004516303856923494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8760/60000][Iteration 6073][Wall Clock 278.915662874s] Trained 120 records in 0.039697478 seconds. Throughput is 3022.862 records/second. Loss is 0.25966635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004515895953757225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 8880/60000][Iteration 6074][Wall Clock 278.955183553s] Trained 120 records in 0.039520679 seconds. Throughput is 3036.3853 records/second. Loss is 0.15643492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004515488124266233. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9000/60000][Iteration 6075][Wall Clock 278.995499709s] Trained 120 records in 0.040316156 seconds. Throughput is 2976.474 records/second. Loss is 0.19857143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004515080368430557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9120/60000][Iteration 6076][Wall Clock 279.03519419s] Trained 120 records in 0.039694481 seconds. Throughput is 3023.0903 records/second. Loss is 0.19606267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004514672686230249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9240/60000][Iteration 6077][Wall Clock 279.075351596s] Trained 120 records in 0.040157406 seconds. Throughput is 2988.2407 records/second. Loss is 0.099581786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004514265077645359. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9360/60000][Iteration 6078][Wall Clock 279.118407574s] Trained 120 records in 0.043055978 seconds. Throughput is 2787.0693 records/second. Loss is 0.26436242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045138575426559545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9480/60000][Iteration 6079][Wall Clock 279.163026381s] Trained 120 records in 0.044618807 seconds. Throughput is 2689.4487 records/second. Loss is 0.30324134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004513450081242101. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9600/60000][Iteration 6080][Wall Clock 279.206002088s] Trained 120 records in 0.042975707 seconds. Throughput is 2792.2751 records/second. Loss is 0.23406881. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00451304269338388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9720/60000][Iteration 6081][Wall Clock 279.246484066s] Trained 120 records in 0.040481978 seconds. Throughput is 2964.282 records/second. Loss is 0.22782974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004512635379061372. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9840/60000][Iteration 6082][Wall Clock 279.286309284s] Trained 120 records in 0.039825218 seconds. Throughput is 3013.166 records/second. Loss is 0.32081252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004512228138254671. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 9960/60000][Iteration 6083][Wall Clock 279.326913905s] Trained 120 records in 0.040604621 seconds. Throughput is 2955.3286 records/second. Loss is 0.13793331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004511820970943873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 10080/60000][Iteration 6084][Wall Clock 279.366890015s] Trained 120 records in 0.03997611 seconds. Throughput is 3001.793 records/second. Loss is 0.21738122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004511413877109086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 10200/60000][Iteration 6085][Wall Clock 279.406258177s] Trained 120 records in 0.039368162 seconds. Throughput is 3048.1482 records/second. Loss is 0.2272947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004511006856730422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 10320/60000][Iteration 6086][Wall Clock 279.450328656s] Trained 120 records in 0.044070479 seconds. Throughput is 2722.9111 records/second. Loss is 0.19421835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045105999097880016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 10440/60000][Iteration 6087][Wall Clock 279.490837105s] Trained 120 records in 0.040508449 seconds. Throughput is 2962.345 records/second. Loss is 0.20574087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004510193036261952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 10560/60000][Iteration 6088][Wall Clock 279.531459872s] Trained 120 records in 0.040622767 seconds. Throughput is 2954.0085 records/second. Loss is 0.16704324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004509786236132407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:45 INFO  DistriOptimizer$:406 - [Epoch 13 10680/60000][Iteration 6089][Wall Clock 279.571812019s] Trained 120 records in 0.040352147 seconds. Throughput is 2973.8193 records/second. Loss is 0.2017973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004509379509379509. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 10800/60000][Iteration 6090][Wall Clock 279.612404554s] Trained 120 records in 0.040592535 seconds. Throughput is 2956.2085 records/second. Loss is 0.2290547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004508972855983407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 10920/60000][Iteration 6091][Wall Clock 279.652409403s] Trained 120 records in 0.040004849 seconds. Throughput is 2999.6362 records/second. Loss is 0.26779667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004508566275924256. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11040/60000][Iteration 6092][Wall Clock 279.692468942s] Trained 120 records in 0.040059539 seconds. Throughput is 2995.541 records/second. Loss is 0.16857092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00450815976918222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11160/60000][Iteration 6093][Wall Clock 279.731784959s] Trained 120 records in 0.039316017 seconds. Throughput is 3052.1912 records/second. Loss is 0.14646648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004507753335737469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11280/60000][Iteration 6094][Wall Clock 279.771367363s] Trained 120 records in 0.039582404 seconds. Throughput is 3031.6501 records/second. Loss is 0.18919381. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004507346975570179. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11400/60000][Iteration 6095][Wall Clock 279.818748621s] Trained 120 records in 0.047381258 seconds. Throughput is 2532.647 records/second. Loss is 0.22123839. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045069406886605375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11520/60000][Iteration 6096][Wall Clock 279.86551598s] Trained 120 records in 0.046767359 seconds. Throughput is 2565.8923 records/second. Loss is 0.1598021. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004506534474988733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11640/60000][Iteration 6097][Wall Clock 279.907537315s] Trained 120 records in 0.042021335 seconds. Throughput is 2855.6924 records/second. Loss is 0.14377996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004506128334534968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11760/60000][Iteration 6098][Wall Clock 279.946901816s] Trained 120 records in 0.039364501 seconds. Throughput is 3048.432 records/second. Loss is 0.24920708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045057222672794444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 11880/60000][Iteration 6099][Wall Clock 279.986877232s] Trained 120 records in 0.039975416 seconds. Throughput is 3001.845 records/second. Loss is 0.23909777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00450531627320238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12000/60000][Iteration 6100][Wall Clock 280.027206271s] Trained 120 records in 0.040329039 seconds. Throughput is 2975.5234 records/second. Loss is 0.11808081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004504910352283989. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12120/60000][Iteration 6101][Wall Clock 280.067120101s] Trained 120 records in 0.03991383 seconds. Throughput is 3006.4768 records/second. Loss is 0.10553212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004504504504504505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12240/60000][Iteration 6102][Wall Clock 280.107428105s] Trained 120 records in 0.040308004 seconds. Throughput is 2977.0764 records/second. Loss is 0.18055223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004504098729844158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12360/60000][Iteration 6103][Wall Clock 280.151561759s] Trained 120 records in 0.044133654 seconds. Throughput is 2719.0134 records/second. Loss is 0.18450408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004503693028283192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12480/60000][Iteration 6104][Wall Clock 280.202417589s] Trained 120 records in 0.05085583 seconds. Throughput is 2359.6116 records/second. Loss is 0.22027676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004503287399801856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12600/60000][Iteration 6105][Wall Clock 280.249726816s] Trained 120 records in 0.047309227 seconds. Throughput is 2536.5032 records/second. Loss is 0.20113988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045028818443804035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12720/60000][Iteration 6106][Wall Clock 280.290690596s] Trained 120 records in 0.04096378 seconds. Throughput is 2929.4172 records/second. Loss is 0.16184677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004502476361999099. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12840/60000][Iteration 6107][Wall Clock 280.330576349s] Trained 120 records in 0.039885753 seconds. Throughput is 3008.5933 records/second. Loss is 0.15511201. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0045020709526382135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 12960/60000][Iteration 6108][Wall Clock 280.370779034s] Trained 120 records in 0.040202685 seconds. Throughput is 2984.8752 records/second. Loss is 0.25752863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004501665616278023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 13080/60000][Iteration 6109][Wall Clock 280.411147667s] Trained 120 records in 0.040368633 seconds. Throughput is 2972.6052 records/second. Loss is 0.1579193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004501260352898812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 13200/60000][Iteration 6110][Wall Clock 280.452150344s] Trained 120 records in 0.041002677 seconds. Throughput is 2926.6382 records/second. Loss is 0.17237672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004500855162480871. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 13320/60000][Iteration 6111][Wall Clock 280.493295797s] Trained 120 records in 0.041145453 seconds. Throughput is 2916.4827 records/second. Loss is 0.2375246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004500450045004501. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 13440/60000][Iteration 6112][Wall Clock 280.534321424s] Trained 120 records in 0.041025627 seconds. Throughput is 2925.001 records/second. Loss is 0.1743274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004500045000450005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:46 INFO  DistriOptimizer$:406 - [Epoch 13 13560/60000][Iteration 6113][Wall Clock 280.574143616s] Trained 120 records in 0.039822192 seconds. Throughput is 3013.3953 records/second. Loss is 0.13855335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004499640028797695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 13680/60000][Iteration 6114][Wall Clock 280.613603968s] Trained 120 records in 0.039460352 seconds. Throughput is 3041.027 records/second. Loss is 0.16306625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044992351300278954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 13800/60000][Iteration 6115][Wall Clock 280.653937304s] Trained 120 records in 0.040333336 seconds. Throughput is 2975.2065 records/second. Loss is 0.19053908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004498830304120928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 13920/60000][Iteration 6116][Wall Clock 280.694760229s] Trained 120 records in 0.040822925 seconds. Throughput is 2939.525 records/second. Loss is 0.22838752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00449842555105713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14040/60000][Iteration 6117][Wall Clock 280.734881422s] Trained 120 records in 0.040121193 seconds. Throughput is 2990.938 records/second. Loss is 0.15239052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00449802087081684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14160/60000][Iteration 6118][Wall Clock 280.775999672s] Trained 120 records in 0.04111825 seconds. Throughput is 2918.412 records/second. Loss is 0.18067466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004497616263380409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14280/60000][Iteration 6119][Wall Clock 280.816783881s] Trained 120 records in 0.040784209 seconds. Throughput is 2942.3152 records/second. Loss is 0.14721905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004497211728728188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14400/60000][Iteration 6120][Wall Clock 280.856526183s] Trained 120 records in 0.039742302 seconds. Throughput is 3019.4526 records/second. Loss is 0.2112778. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004496807266840544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14520/60000][Iteration 6121][Wall Clock 280.89758807s] Trained 120 records in 0.041061887 seconds. Throughput is 2922.4182 records/second. Loss is 0.15616013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044964028776978415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14640/60000][Iteration 6122][Wall Clock 280.947089189s] Trained 120 records in 0.049501119 seconds. Throughput is 2424.1877 records/second. Loss is 0.12834416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004495998561280461. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14760/60000][Iteration 6123][Wall Clock 280.999527183s] Trained 120 records in 0.052437994 seconds. Throughput is 2288.417 records/second. Loss is 0.1834549. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004495594317568782. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 14880/60000][Iteration 6124][Wall Clock 281.044059607s] Trained 120 records in 0.044532424 seconds. Throughput is 2694.6658 records/second. Loss is 0.15357271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004495190146543198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15000/60000][Iteration 6125][Wall Clock 281.085522709s] Trained 120 records in 0.041463102 seconds. Throughput is 2894.1394 records/second. Loss is 0.21505785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004494786048184107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15120/60000][Iteration 6126][Wall Clock 281.126913492s] Trained 120 records in 0.041390783 seconds. Throughput is 2899.196 records/second. Loss is 0.15368505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00449438202247191. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15240/60000][Iteration 6127][Wall Clock 281.168526886s] Trained 120 records in 0.041613394 seconds. Throughput is 2883.687 records/second. Loss is 0.13386668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004493978069387021. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15360/60000][Iteration 6128][Wall Clock 281.210535464s] Trained 120 records in 0.042008578 seconds. Throughput is 2856.5593 records/second. Loss is 0.29754305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004493574188909859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15480/60000][Iteration 6129][Wall Clock 281.251938414s] Trained 120 records in 0.04140295 seconds. Throughput is 2898.3442 records/second. Loss is 0.21779074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004493170381020848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15600/60000][Iteration 6130][Wall Clock 281.298141974s] Trained 120 records in 0.04620356 seconds. Throughput is 2597.2024 records/second. Loss is 0.23050167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004492766645700422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15720/60000][Iteration 6131][Wall Clock 281.341269368s] Trained 120 records in 0.043127394 seconds. Throughput is 2782.454 records/second. Loss is 0.128821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004492362982929021. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15840/60000][Iteration 6132][Wall Clock 281.381488304s] Trained 120 records in 0.040218936 seconds. Throughput is 2983.6692 records/second. Loss is 0.16060622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044919593926870905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 15960/60000][Iteration 6133][Wall Clock 281.42147562s] Trained 120 records in 0.039987316 seconds. Throughput is 3000.9517 records/second. Loss is 0.1873894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044915558749550845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 16080/60000][Iteration 6134][Wall Clock 281.461472115s] Trained 120 records in 0.039996495 seconds. Throughput is 3000.263 records/second. Loss is 0.1538212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004491152429713464. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 16200/60000][Iteration 6135][Wall Clock 281.501669034s] Trained 120 records in 0.040196919 seconds. Throughput is 2985.3035 records/second. Loss is 0.21158528. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004490749056942698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 16320/60000][Iteration 6136][Wall Clock 281.54141783s] Trained 120 records in 0.039748796 seconds. Throughput is 3018.9595 records/second. Loss is 0.244785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044903457566232595. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:47 INFO  DistriOptimizer$:406 - [Epoch 13 16440/60000][Iteration 6137][Wall Clock 281.581241829s] Trained 120 records in 0.039823999 seconds. Throughput is 3013.2585 records/second. Loss is 0.20086782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004489942528735633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 16560/60000][Iteration 6138][Wall Clock 281.621078955s] Trained 120 records in 0.039837126 seconds. Throughput is 3012.2656 records/second. Loss is 0.12758769. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004489539373260303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 16680/60000][Iteration 6139][Wall Clock 281.660937504s] Trained 120 records in 0.039858549 seconds. Throughput is 3010.6465 records/second. Loss is 0.1166364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00448913629017777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 16800/60000][Iteration 6140][Wall Clock 281.700828552s] Trained 120 records in 0.039891048 seconds. Throughput is 3008.1936 records/second. Loss is 0.115567416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004488733279468533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 16920/60000][Iteration 6141][Wall Clock 281.741073298s] Trained 120 records in 0.040244746 seconds. Throughput is 2981.7556 records/second. Loss is 0.22141165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004488330341113106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17040/60000][Iteration 6142][Wall Clock 281.784810105s] Trained 120 records in 0.043736807 seconds. Throughput is 2743.6846 records/second. Loss is 0.38175017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004487927475092002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17160/60000][Iteration 6143][Wall Clock 281.825112248s] Trained 120 records in 0.040302143 seconds. Throughput is 2977.5093 records/second. Loss is 0.26823795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004487524681385747. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17280/60000][Iteration 6144][Wall Clock 281.864834831s] Trained 120 records in 0.039722583 seconds. Throughput is 3020.9514 records/second. Loss is 0.19852647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004487121959974872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17400/60000][Iteration 6145][Wall Clock 281.90419553s] Trained 120 records in 0.039360699 seconds. Throughput is 3048.7263 records/second. Loss is 0.18338297. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004486719310839914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17520/60000][Iteration 6146][Wall Clock 281.944142227s] Trained 120 records in 0.039946697 seconds. Throughput is 3004.003 records/second. Loss is 0.22445107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004486316733961417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17640/60000][Iteration 6147][Wall Clock 281.984218356s] Trained 120 records in 0.040076129 seconds. Throughput is 2994.3013 records/second. Loss is 0.2797626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004485914229319935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17760/60000][Iteration 6148][Wall Clock 282.024543214s] Trained 120 records in 0.040324858 seconds. Throughput is 2975.8318 records/second. Loss is 0.18499836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004485511796896026. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 17880/60000][Iteration 6149][Wall Clock 282.07516802s] Trained 120 records in 0.050624806 seconds. Throughput is 2370.3794 records/second. Loss is 0.18847704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004485109436670255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18000/60000][Iteration 6150][Wall Clock 282.118533687s] Trained 120 records in 0.043365667 seconds. Throughput is 2767.166 records/second. Loss is 0.16235478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004484707148623195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18120/60000][Iteration 6151][Wall Clock 282.158527286s] Trained 120 records in 0.039993599 seconds. Throughput is 3000.4802 records/second. Loss is 0.14580034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004484304932735426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18240/60000][Iteration 6152][Wall Clock 282.198883064s] Trained 120 records in 0.040355778 seconds. Throughput is 2973.5518 records/second. Loss is 0.13696922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004483902788987535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18360/60000][Iteration 6153][Wall Clock 282.239702233s] Trained 120 records in 0.040819169 seconds. Throughput is 2939.7954 records/second. Loss is 0.19450188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044835007173601145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18480/60000][Iteration 6154][Wall Clock 282.283443711s] Trained 120 records in 0.043741478 seconds. Throughput is 2743.3914 records/second. Loss is 0.190388. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004483098717833767. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18600/60000][Iteration 6155][Wall Clock 282.323352814s] Trained 120 records in 0.039909103 seconds. Throughput is 3006.8328 records/second. Loss is 0.24759075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044826967903890975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18720/60000][Iteration 6156][Wall Clock 282.36319808s] Trained 120 records in 0.039845266 seconds. Throughput is 3011.6501 records/second. Loss is 0.13208976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044822949350067235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18840/60000][Iteration 6157][Wall Clock 282.410449683s] Trained 120 records in 0.047251603 seconds. Throughput is 2539.5962 records/second. Loss is 0.29645762. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004481893151667264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 18960/60000][Iteration 6158][Wall Clock 282.45351168s] Trained 120 records in 0.043061997 seconds. Throughput is 2786.68 records/second. Loss is 0.19243868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00448149144035135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 19080/60000][Iteration 6159][Wall Clock 282.493161899s] Trained 120 records in 0.039650219 seconds. Throughput is 3026.4648 records/second. Loss is 0.2557907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004481089801039613. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 19200/60000][Iteration 6160][Wall Clock 282.533176551s] Trained 120 records in 0.040014652 seconds. Throughput is 2998.9016 records/second. Loss is 0.14183404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044806882337126985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:48 INFO  DistriOptimizer$:406 - [Epoch 13 19320/60000][Iteration 6161][Wall Clock 282.576946246s] Trained 120 records in 0.043769695 seconds. Throughput is 2741.623 records/second. Loss is 0.19653708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004480286738351254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 19440/60000][Iteration 6162][Wall Clock 282.616895771s] Trained 120 records in 0.039949525 seconds. Throughput is 3003.7903 records/second. Loss is 0.12059853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004479885314935938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 19560/60000][Iteration 6163][Wall Clock 282.656785903s] Trained 120 records in 0.039890132 seconds. Throughput is 3008.2627 records/second. Loss is 0.17946085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004479483963447411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 19680/60000][Iteration 6164][Wall Clock 282.696762148s] Trained 120 records in 0.039976245 seconds. Throughput is 3001.7825 records/second. Loss is 0.22837445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004479082683866344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 19800/60000][Iteration 6165][Wall Clock 282.737137664s] Trained 120 records in 0.040375516 seconds. Throughput is 2972.0981 records/second. Loss is 0.14215209. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004478681476173414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 19920/60000][Iteration 6166][Wall Clock 282.777754631s] Trained 120 records in 0.040616967 seconds. Throughput is 2954.4304 records/second. Loss is 0.15729. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044782803403493054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20040/60000][Iteration 6167][Wall Clock 282.818843159s] Trained 120 records in 0.041088528 seconds. Throughput is 2920.5232 records/second. Loss is 0.24443099. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004477879276374709. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20160/60000][Iteration 6168][Wall Clock 282.859347332s] Trained 120 records in 0.040504173 seconds. Throughput is 2962.6577 records/second. Loss is 0.25211585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004477478284230322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20280/60000][Iteration 6169][Wall Clock 282.900077692s] Trained 120 records in 0.04073036 seconds. Throughput is 2946.205 records/second. Loss is 0.12891063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004477077363896848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20400/60000][Iteration 6170][Wall Clock 282.940814837s] Trained 120 records in 0.040737145 seconds. Throughput is 2945.7146 records/second. Loss is 0.25516856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004476676515355001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20520/60000][Iteration 6171][Wall Clock 282.982233783s] Trained 120 records in 0.041418946 seconds. Throughput is 2897.2249 records/second. Loss is 0.17785783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004476275738585497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20640/60000][Iteration 6172][Wall Clock 283.02378876s] Trained 120 records in 0.041554977 seconds. Throughput is 2887.7407 records/second. Loss is 0.193284. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004475875033569063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20760/60000][Iteration 6173][Wall Clock 283.065084705s] Trained 120 records in 0.041295945 seconds. Throughput is 2905.8542 records/second. Loss is 0.17382641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004475474400286431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 20880/60000][Iteration 6174][Wall Clock 283.105720642s] Trained 120 records in 0.040635937 seconds. Throughput is 2953.0513 records/second. Loss is 0.20664829. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004475073838718338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21000/60000][Iteration 6175][Wall Clock 283.15495266s] Trained 120 records in 0.049232018 seconds. Throughput is 2437.4382 records/second. Loss is 0.24111539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004474673348845534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21120/60000][Iteration 6176][Wall Clock 283.204033311s] Trained 120 records in 0.049080651 seconds. Throughput is 2444.9553 records/second. Loss is 0.16702773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004474272930648769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21240/60000][Iteration 6177][Wall Clock 283.246770338s] Trained 120 records in 0.042737027 seconds. Throughput is 2807.8696 records/second. Loss is 0.45393103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004473872584108805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21360/60000][Iteration 6178][Wall Clock 283.297524134s] Trained 120 records in 0.050753796 seconds. Throughput is 2364.3552 records/second. Loss is 0.16527389. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004473472309206405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21480/60000][Iteration 6179][Wall Clock 283.342698568s] Trained 120 records in 0.045174434 seconds. Throughput is 2656.3696 records/second. Loss is 0.17134656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004473072105922348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21600/60000][Iteration 6180][Wall Clock 283.382323879s] Trained 120 records in 0.039625311 seconds. Throughput is 3028.3674 records/second. Loss is 0.13803378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004472671974237409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21720/60000][Iteration 6181][Wall Clock 283.422385499s] Trained 120 records in 0.04006162 seconds. Throughput is 2995.3857 records/second. Loss is 0.21890064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00447227191413238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21840/60000][Iteration 6182][Wall Clock 283.461982378s] Trained 120 records in 0.039596879 seconds. Throughput is 3030.542 records/second. Loss is 0.11953476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004471871925588051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 21960/60000][Iteration 6183][Wall Clock 283.502909928s] Trained 120 records in 0.04092755 seconds. Throughput is 2932.0103 records/second. Loss is 0.30228356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004471472008585226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:49 INFO  DistriOptimizer$:406 - [Epoch 13 22080/60000][Iteration 6184][Wall Clock 283.554822749s] Trained 120 records in 0.051912821 seconds. Throughput is 2311.5676 records/second. Loss is 0.18401013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044710721631047124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 22200/60000][Iteration 6185][Wall Clock 283.595587748s] Trained 120 records in 0.040764999 seconds. Throughput is 2943.702 records/second. Loss is 0.20196465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004470672389127324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 22320/60000][Iteration 6186][Wall Clock 283.636286992s] Trained 120 records in 0.040699244 seconds. Throughput is 2948.4578 records/second. Loss is 0.1730079. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004470272686633884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 22440/60000][Iteration 6187][Wall Clock 283.676922454s] Trained 120 records in 0.040635462 seconds. Throughput is 2953.0857 records/second. Loss is 0.16999139. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004469873055605221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 22560/60000][Iteration 6188][Wall Clock 283.717484769s] Trained 120 records in 0.040562315 seconds. Throughput is 2958.411 records/second. Loss is 0.1660462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044694734960221685. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 22680/60000][Iteration 6189][Wall Clock 283.758223694s] Trained 120 records in 0.040738925 seconds. Throughput is 2945.5857 records/second. Loss is 0.19698586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00446907400786557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 22800/60000][Iteration 6190][Wall Clock 283.798193992s] Trained 120 records in 0.039970298 seconds. Throughput is 3002.2292 records/second. Loss is 0.2842869. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004468674591116275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 22920/60000][Iteration 6191][Wall Clock 283.838346131s] Trained 120 records in 0.040152139 seconds. Throughput is 2988.6328 records/second. Loss is 0.27031368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004468275245755138. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23040/60000][Iteration 6192][Wall Clock 283.87829639s] Trained 120 records in 0.039950259 seconds. Throughput is 3003.735 records/second. Loss is 0.18714409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004467875971763024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23160/60000][Iteration 6193][Wall Clock 283.918390267s] Trained 120 records in 0.040093877 seconds. Throughput is 2992.9758 records/second. Loss is 0.27324075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044674767691208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23280/60000][Iteration 6194][Wall Clock 283.958063536s] Trained 120 records in 0.039673269 seconds. Throughput is 3024.7065 records/second. Loss is 0.20130326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004467077637809345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23400/60000][Iteration 6195][Wall Clock 283.998063478s] Trained 120 records in 0.039999942 seconds. Throughput is 3000.0042 records/second. Loss is 0.25081846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004466678577809541. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23520/60000][Iteration 6196][Wall Clock 284.038070102s] Trained 120 records in 0.040006624 seconds. Throughput is 2999.5034 records/second. Loss is 0.19878606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004466279589102278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23640/60000][Iteration 6197][Wall Clock 284.078061709s] Trained 120 records in 0.039991607 seconds. Throughput is 3000.6296 records/second. Loss is 0.2826029. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004465880671668453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23760/60000][Iteration 6198][Wall Clock 284.121489185s] Trained 120 records in 0.043427476 seconds. Throughput is 2763.2278 records/second. Loss is 0.19872074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004465481825488971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 23880/60000][Iteration 6199][Wall Clock 284.161704748s] Trained 120 records in 0.040215563 seconds. Throughput is 2983.9194 records/second. Loss is 0.13694707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004465083050544739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24000/60000][Iteration 6200][Wall Clock 284.201509688s] Trained 120 records in 0.03980494 seconds. Throughput is 3014.7012 records/second. Loss is 0.26968047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00446468434681668. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24120/60000][Iteration 6201][Wall Clock 284.242065958s] Trained 120 records in 0.04055627 seconds. Throughput is 2958.852 records/second. Loss is 0.15409663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004464285714285714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24240/60000][Iteration 6202][Wall Clock 284.292179472s] Trained 120 records in 0.050113514 seconds. Throughput is 2394.5637 records/second. Loss is 0.09862248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004463887152932775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24360/60000][Iteration 6203][Wall Clock 284.341247144s] Trained 120 records in 0.049067672 seconds. Throughput is 2445.602 records/second. Loss is 0.17560288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004463488662738797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24480/60000][Iteration 6204][Wall Clock 284.384352146s] Trained 120 records in 0.043105002 seconds. Throughput is 2783.8997 records/second. Loss is 0.2008164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004463090243684727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24600/60000][Iteration 6205][Wall Clock 284.424327186s] Trained 120 records in 0.03997504 seconds. Throughput is 3001.8733 records/second. Loss is 0.33843184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004462691895751517. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24720/60000][Iteration 6206][Wall Clock 284.463820712s] Trained 120 records in 0.039493526 seconds. Throughput is 3038.4727 records/second. Loss is 0.110090815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004462293618920125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24840/60000][Iteration 6207][Wall Clock 284.502751461s] Trained 120 records in 0.038930749 seconds. Throughput is 3082.3965 records/second. Loss is 0.23248222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004461895413171515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:50 INFO  DistriOptimizer$:406 - [Epoch 13 24960/60000][Iteration 6208][Wall Clock 284.541807512s] Trained 120 records in 0.039056051 seconds. Throughput is 3072.5073 records/second. Loss is 0.31528765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00446149727848666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25080/60000][Iteration 6209][Wall Clock 284.581245009s] Trained 120 records in 0.039437497 seconds. Throughput is 3042.7896 records/second. Loss is 0.21958116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004461099214846539. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25200/60000][Iteration 6210][Wall Clock 284.62752525s] Trained 120 records in 0.046280241 seconds. Throughput is 2592.8992 records/second. Loss is 0.14110194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004460701222232135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25320/60000][Iteration 6211][Wall Clock 284.671731103s] Trained 120 records in 0.044205853 seconds. Throughput is 2714.5728 records/second. Loss is 0.20051768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044603033006244425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25440/60000][Iteration 6212][Wall Clock 284.711949325s] Trained 120 records in 0.040218222 seconds. Throughput is 2983.7222 records/second. Loss is 0.13361818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00445990545000446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25560/60000][Iteration 6213][Wall Clock 284.752532195s] Trained 120 records in 0.04058287 seconds. Throughput is 2956.9126 records/second. Loss is 0.21248533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004459507670353193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25680/60000][Iteration 6214][Wall Clock 284.792755003s] Trained 120 records in 0.040222808 seconds. Throughput is 2983.3818 records/second. Loss is 0.11147092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044591099616516534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25800/60000][Iteration 6215][Wall Clock 284.832814545s] Trained 120 records in 0.040059542 seconds. Throughput is 2995.541 records/second. Loss is 0.16094245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004458712323880863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 25920/60000][Iteration 6216][Wall Clock 284.872891177s] Trained 120 records in 0.040076632 seconds. Throughput is 2994.2637 records/second. Loss is 0.15110281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004458314757021845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26040/60000][Iteration 6217][Wall Clock 284.916501826s] Trained 120 records in 0.043610649 seconds. Throughput is 2751.6216 records/second. Loss is 0.19152148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004457917261055635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26160/60000][Iteration 6218][Wall Clock 284.957180671s] Trained 120 records in 0.040678845 seconds. Throughput is 2949.9363 records/second. Loss is 0.14950077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004457519835963269. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26280/60000][Iteration 6219][Wall Clock 284.998324092s] Trained 120 records in 0.041143421 seconds. Throughput is 2916.6267 records/second. Loss is 0.2700874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004457122481725798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26400/60000][Iteration 6220][Wall Clock 285.039335894s] Trained 120 records in 0.041011802 seconds. Throughput is 2925.987 records/second. Loss is 0.15766929. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004456725198324271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26520/60000][Iteration 6221][Wall Clock 285.080717612s] Trained 120 records in 0.041381718 seconds. Throughput is 2899.8313 records/second. Loss is 0.19408713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004456327985739751. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26640/60000][Iteration 6222][Wall Clock 285.122095157s] Trained 120 records in 0.041377545 seconds. Throughput is 2900.1238 records/second. Loss is 0.0810174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004455930843953302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26760/60000][Iteration 6223][Wall Clock 285.163055066s] Trained 120 records in 0.040959909 seconds. Throughput is 2929.6938 records/second. Loss is 0.12665781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004455533772946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 26880/60000][Iteration 6224][Wall Clock 285.203316459s] Trained 120 records in 0.040261393 seconds. Throughput is 2980.523 records/second. Loss is 0.22126408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044551367726989215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27000/60000][Iteration 6225][Wall Clock 285.243353953s] Trained 120 records in 0.040037494 seconds. Throughput is 2997.1907 records/second. Loss is 0.16350761. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004454739843193158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27120/60000][Iteration 6226][Wall Clock 285.284195832s] Trained 120 records in 0.040841879 seconds. Throughput is 2938.1606 records/second. Loss is 0.21693529. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004454342984409799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27240/60000][Iteration 6227][Wall Clock 285.324504548s] Trained 120 records in 0.040308716 seconds. Throughput is 2977.0234 records/second. Loss is 0.20834637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004453946196329948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27360/60000][Iteration 6228][Wall Clock 285.379150743s] Trained 120 records in 0.054646195 seconds. Throughput is 2195.9443 records/second. Loss is 0.22661248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004453549478934711. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27480/60000][Iteration 6229][Wall Clock 285.422754042s] Trained 120 records in 0.043603299 seconds. Throughput is 2752.0854 records/second. Loss is 0.17355926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004453152832205202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27600/60000][Iteration 6230][Wall Clock 285.462568965s] Trained 120 records in 0.039814923 seconds. Throughput is 3013.9453 records/second. Loss is 0.16423228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00445275625612254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27720/60000][Iteration 6231][Wall Clock 285.502053897s] Trained 120 records in 0.039484932 seconds. Throughput is 3039.134 records/second. Loss is 0.3175731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004452359750667854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:51 INFO  DistriOptimizer$:406 - [Epoch 13 27840/60000][Iteration 6232][Wall Clock 285.541521359s] Trained 120 records in 0.039467462 seconds. Throughput is 3040.4792 records/second. Loss is 0.23144306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004451963315822278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 27960/60000][Iteration 6233][Wall Clock 285.582090494s] Trained 120 records in 0.040569135 seconds. Throughput is 2957.9138 records/second. Loss is 0.16611712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004451566951566952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28080/60000][Iteration 6234][Wall Clock 285.623070802s] Trained 120 records in 0.040980308 seconds. Throughput is 2928.2356 records/second. Loss is 0.19155693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004451170657883023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28200/60000][Iteration 6235][Wall Clock 285.66556525s] Trained 120 records in 0.042494448 seconds. Throughput is 2823.8982 records/second. Loss is 0.22513372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004450774434751646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28320/60000][Iteration 6236][Wall Clock 285.705281233s] Trained 120 records in 0.039715983 seconds. Throughput is 3021.4536 records/second. Loss is 0.18949029. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004450378282153984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28440/60000][Iteration 6237][Wall Clock 285.753089102s] Trained 120 records in 0.047807869 seconds. Throughput is 2510.047 records/second. Loss is 0.18511502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004449982200071199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28560/60000][Iteration 6238][Wall Clock 285.798678519s] Trained 120 records in 0.045589417 seconds. Throughput is 2632.19 records/second. Loss is 0.24552393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004449586188484471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28680/60000][Iteration 6239][Wall Clock 285.838904948s] Trained 120 records in 0.040226429 seconds. Throughput is 2983.1133 records/second. Loss is 0.20993908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004449190247374978. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28800/60000][Iteration 6240][Wall Clock 285.878819555s] Trained 120 records in 0.039914607 seconds. Throughput is 3006.4182 records/second. Loss is 0.16336752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004448794376723908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 28920/60000][Iteration 6241][Wall Clock 285.919614276s] Trained 120 records in 0.040794721 seconds. Throughput is 2941.557 records/second. Loss is 0.19807762. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004448398576512455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29040/60000][Iteration 6242][Wall Clock 285.960098018s] Trained 120 records in 0.040483742 seconds. Throughput is 2964.1528 records/second. Loss is 0.18925524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004448002846721822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29160/60000][Iteration 6243][Wall Clock 286.000590426s] Trained 120 records in 0.040492408 seconds. Throughput is 2963.5186 records/second. Loss is 0.15181608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004447607187333214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29280/60000][Iteration 6244][Wall Clock 286.040933553s] Trained 120 records in 0.040343127 seconds. Throughput is 2974.4844 records/second. Loss is 0.19238421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004447211598327849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29400/60000][Iteration 6245][Wall Clock 286.080990331s] Trained 120 records in 0.040056778 seconds. Throughput is 2995.7478 records/second. Loss is 0.2755213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004446816079686944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29520/60000][Iteration 6246][Wall Clock 286.121183676s] Trained 120 records in 0.040193345 seconds. Throughput is 2985.5688 records/second. Loss is 0.18320176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004446420631391729. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29640/60000][Iteration 6247][Wall Clock 286.161323283s] Trained 120 records in 0.040139607 seconds. Throughput is 2989.566 records/second. Loss is 0.2693888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044460252534234395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29760/60000][Iteration 6248][Wall Clock 286.200774443s] Trained 120 records in 0.03945116 seconds. Throughput is 3041.7356 records/second. Loss is 0.20394707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044456299457633144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 29880/60000][Iteration 6249][Wall Clock 286.240020398s] Trained 120 records in 0.039245955 seconds. Throughput is 3057.64 records/second. Loss is 0.17426938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004445234708392603. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 30000/60000][Iteration 6250][Wall Clock 286.281093112s] Trained 120 records in 0.041072714 seconds. Throughput is 2921.6477 records/second. Loss is 0.122382976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004444839541292559. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 30120/60000][Iteration 6251][Wall Clock 286.322723855s] Trained 120 records in 0.041630743 seconds. Throughput is 2882.4854 records/second. Loss is 0.38340253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044444444444444444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 30240/60000][Iteration 6252][Wall Clock 286.364113138s] Trained 120 records in 0.041389283 seconds. Throughput is 2899.3013 records/second. Loss is 0.118828155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044440494178295264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 30360/60000][Iteration 6253][Wall Clock 286.410215519s] Trained 120 records in 0.046102381 seconds. Throughput is 2602.9023 records/second. Loss is 0.19458875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00444365446142908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 30480/60000][Iteration 6254][Wall Clock 286.45981002s] Trained 120 records in 0.049594501 seconds. Throughput is 2419.6233 records/second. Loss is 0.23350972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004443259575224384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 30600/60000][Iteration 6255][Wall Clock 286.499713175s] Trained 120 records in 0.039903155 seconds. Throughput is 3007.281 records/second. Loss is 0.12883471. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00444286475919673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:52 INFO  DistriOptimizer$:406 - [Epoch 13 30720/60000][Iteration 6256][Wall Clock 286.538890869s] Trained 120 records in 0.039177694 seconds. Throughput is 3062.9675 records/second. Loss is 0.11703167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004442470013327409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 30840/60000][Iteration 6257][Wall Clock 286.578437618s] Trained 120 records in 0.039546749 seconds. Throughput is 3034.3833 records/second. Loss is 0.20686385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004442075337597726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 30960/60000][Iteration 6258][Wall Clock 286.618296673s] Trained 120 records in 0.039859055 seconds. Throughput is 3010.6082 records/second. Loss is 0.22943646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004441680731988984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31080/60000][Iteration 6259][Wall Clock 286.657966016s] Trained 120 records in 0.039669343 seconds. Throughput is 3025.006 records/second. Loss is 0.29479486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004441286196482502. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31200/60000][Iteration 6260][Wall Clock 286.69829186s] Trained 120 records in 0.040325844 seconds. Throughput is 2975.7593 records/second. Loss is 0.11474851. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004440891731059596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31320/60000][Iteration 6261][Wall Clock 286.738814252s] Trained 120 records in 0.040522392 seconds. Throughput is 2961.3257 records/second. Loss is 0.21552849. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004440497335701599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31440/60000][Iteration 6262][Wall Clock 286.779475814s] Trained 120 records in 0.040661562 seconds. Throughput is 2951.1902 records/second. Loss is 0.13349304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004440103010389841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31560/60000][Iteration 6263][Wall Clock 286.82054328s] Trained 120 records in 0.041067466 seconds. Throughput is 2922.021 records/second. Loss is 0.24547428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004439708755105666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31680/60000][Iteration 6264][Wall Clock 286.873466627s] Trained 120 records in 0.052923347 seconds. Throughput is 2267.4302 records/second. Loss is 0.30336925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004439314569830418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31800/60000][Iteration 6265][Wall Clock 286.91530789s] Trained 120 records in 0.041841263 seconds. Throughput is 2867.9822 records/second. Loss is 0.13868791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004438920454545454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 31920/60000][Iteration 6266][Wall Clock 286.956195349s] Trained 120 records in 0.040887459 seconds. Throughput is 2934.8853 records/second. Loss is 0.15290366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004438526409232135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32040/60000][Iteration 6267][Wall Clock 286.996638156s] Trained 120 records in 0.040442807 seconds. Throughput is 2967.153 records/second. Loss is 0.1966805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044381324338718265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32160/60000][Iteration 6268][Wall Clock 287.037517756s] Trained 120 records in 0.0408796 seconds. Throughput is 2935.4495 records/second. Loss is 0.20111944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004437738528445904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32280/60000][Iteration 6269][Wall Clock 287.07866839s] Trained 120 records in 0.041150634 seconds. Throughput is 2916.1155 records/second. Loss is 0.18725675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004437344692935747. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32400/60000][Iteration 6270][Wall Clock 287.119332884s] Trained 120 records in 0.040664494 seconds. Throughput is 2950.9773 records/second. Loss is 0.2139611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004436950927322744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32520/60000][Iteration 6271][Wall Clock 287.160274011s] Trained 120 records in 0.040941127 seconds. Throughput is 2931.038 records/second. Loss is 0.17302038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044365572315882874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32640/60000][Iteration 6272][Wall Clock 287.200352094s] Trained 120 records in 0.040078083 seconds. Throughput is 2994.1553 records/second. Loss is 0.16161102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044361636057137785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32760/60000][Iteration 6273][Wall Clock 287.244277863s] Trained 120 records in 0.043925769 seconds. Throughput is 2731.8816 records/second. Loss is 0.114101395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044357700496806245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 32880/60000][Iteration 6274][Wall Clock 287.285116754s] Trained 120 records in 0.040838891 seconds. Throughput is 2938.3757 records/second. Loss is 0.1284911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004435376563470239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 33000/60000][Iteration 6275][Wall Clock 287.325406252s] Trained 120 records in 0.040289498 seconds. Throughput is 2978.4436 records/second. Loss is 0.18447895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004434983147064041. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 33120/60000][Iteration 6276][Wall Clock 287.366063139s] Trained 120 records in 0.040656887 seconds. Throughput is 2951.5295 records/second. Loss is 0.1533544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004434589800443459. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 33240/60000][Iteration 6277][Wall Clock 287.406911535s] Trained 120 records in 0.040848396 seconds. Throughput is 2937.692 records/second. Loss is 0.15862255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004434196523589925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 33360/60000][Iteration 6278][Wall Clock 287.456201158s] Trained 120 records in 0.049289623 seconds. Throughput is 2434.5896 records/second. Loss is 0.2780334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004433803316484881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 33480/60000][Iteration 6279][Wall Clock 287.503370265s] Trained 120 records in 0.047169107 seconds. Throughput is 2544.0378 records/second. Loss is 0.20965223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004433410179109771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:53 INFO  DistriOptimizer$:406 - [Epoch 13 33600/60000][Iteration 6280][Wall Clock 287.544046154s] Trained 120 records in 0.040675889 seconds. Throughput is 2950.1506 records/second. Loss is 0.13542023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00443301711144605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 33720/60000][Iteration 6281][Wall Clock 287.584067114s] Trained 120 records in 0.04002096 seconds. Throughput is 2998.4287 records/second. Loss is 0.16726786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004432624113475177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 33840/60000][Iteration 6282][Wall Clock 287.623994675s] Trained 120 records in 0.039927561 seconds. Throughput is 3005.4429 records/second. Loss is 0.21567406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00443223118517862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 33960/60000][Iteration 6283][Wall Clock 287.664120814s] Trained 120 records in 0.040126139 seconds. Throughput is 2990.5693 records/second. Loss is 0.12847818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044318383265378476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34080/60000][Iteration 6284][Wall Clock 287.704084516s] Trained 120 records in 0.039963702 seconds. Throughput is 3002.7246 records/second. Loss is 0.20750722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004431445537534343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34200/60000][Iteration 6285][Wall Clock 287.744548773s] Trained 120 records in 0.040464257 seconds. Throughput is 2965.5803 records/second. Loss is 0.28322774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004431052818149592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34320/60000][Iteration 6286][Wall Clock 287.785244184s] Trained 120 records in 0.040695411 seconds. Throughput is 2948.7356 records/second. Loss is 0.17489427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004430660168365086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34440/60000][Iteration 6287][Wall Clock 287.825531999s] Trained 120 records in 0.040287815 seconds. Throughput is 2978.568 records/second. Loss is 0.18290876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004430267588162325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34560/60000][Iteration 6288][Wall Clock 287.865885882s] Trained 120 records in 0.040353883 seconds. Throughput is 2973.6914 records/second. Loss is 0.13576217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044298750775228135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34680/60000][Iteration 6289][Wall Clock 287.905783204s] Trained 120 records in 0.039897322 seconds. Throughput is 3007.7207 records/second. Loss is 0.2349365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004429482636428065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34800/60000][Iteration 6290][Wall Clock 287.953846342s] Trained 120 records in 0.048063138 seconds. Throughput is 2496.716 records/second. Loss is 0.20942992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004429090264859598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 34920/60000][Iteration 6291][Wall Clock 288.001457874s] Trained 120 records in 0.047611532 seconds. Throughput is 2520.398 records/second. Loss is 0.17844324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044286979627989375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35040/60000][Iteration 6292][Wall Clock 288.041694482s] Trained 120 records in 0.040236608 seconds. Throughput is 2982.359 records/second. Loss is 0.21659046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004428305730227615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35160/60000][Iteration 6293][Wall Clock 288.082814348s] Trained 120 records in 0.041119866 seconds. Throughput is 2918.2974 records/second. Loss is 0.1426881. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00442791356712717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35280/60000][Iteration 6294][Wall Clock 288.124077094s] Trained 120 records in 0.041262746 seconds. Throughput is 2908.1924 records/second. Loss is 0.13069695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004427521473479146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35400/60000][Iteration 6295][Wall Clock 288.165830282s] Trained 120 records in 0.041753188 seconds. Throughput is 2874.032 records/second. Loss is 0.11504824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004427129449265097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35520/60000][Iteration 6296][Wall Clock 288.207730808s] Trained 120 records in 0.041900526 seconds. Throughput is 2863.9258 records/second. Loss is 0.16080543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004426737494466578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35640/60000][Iteration 6297][Wall Clock 288.2494876s] Trained 120 records in 0.041756792 seconds. Throughput is 2873.784 records/second. Loss is 0.17196156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004426345609065156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35760/60000][Iteration 6298][Wall Clock 288.29100574s] Trained 120 records in 0.04151814 seconds. Throughput is 2890.3027 records/second. Loss is 0.25445965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044259537930424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 35880/60000][Iteration 6299][Wall Clock 288.332502081s] Trained 120 records in 0.041496341 seconds. Throughput is 2891.8213 records/second. Loss is 0.1422986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044255620463798905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 36000/60000][Iteration 6300][Wall Clock 288.373538233s] Trained 120 records in 0.041036152 seconds. Throughput is 2924.2507 records/second. Loss is 0.20351163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044251703690592085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 36120/60000][Iteration 6301][Wall Clock 288.413816811s] Trained 120 records in 0.040278578 seconds. Throughput is 2979.2512 records/second. Loss is 0.10471572. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004424778761061948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 36240/60000][Iteration 6302][Wall Clock 288.454449364s] Trained 120 records in 0.040632553 seconds. Throughput is 2953.297 records/second. Loss is 0.10415202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004424387222369702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:54 INFO  DistriOptimizer$:406 - [Epoch 13 36360/60000][Iteration 6303][Wall Clock 288.504116358s] Trained 120 records in 0.049666994 seconds. Throughput is 2416.0916 records/second. Loss is 0.1389777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004423995752964077. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 36480/60000][Iteration 6304][Wall Clock 288.555784407s] Trained 120 records in 0.051668049 seconds. Throughput is 2322.5186 records/second. Loss is 0.17485431. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004423604352826683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 36600/60000][Iteration 6305][Wall Clock 288.59635435s] Trained 120 records in 0.040569943 seconds. Throughput is 2957.8547 records/second. Loss is 0.14632635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004423213021939137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 36720/60000][Iteration 6306][Wall Clock 288.637115753s] Trained 120 records in 0.040761403 seconds. Throughput is 2943.9614 records/second. Loss is 0.15294363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004422821760283061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 36840/60000][Iteration 6307][Wall Clock 288.676861764s] Trained 120 records in 0.039746011 seconds. Throughput is 3019.171 records/second. Loss is 0.12534462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004422430567840085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 36960/60000][Iteration 6308][Wall Clock 288.717012136s] Trained 120 records in 0.040150372 seconds. Throughput is 2988.7644 records/second. Loss is 0.10744954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004422039444591846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37080/60000][Iteration 6309][Wall Clock 288.756872172s] Trained 120 records in 0.039860036 seconds. Throughput is 3010.5342 records/second. Loss is 0.14818121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044216483905199855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37200/60000][Iteration 6310][Wall Clock 288.800657161s] Trained 120 records in 0.043784989 seconds. Throughput is 2740.6655 records/second. Loss is 0.19255707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004421257405606154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37320/60000][Iteration 6311][Wall Clock 288.842034142s] Trained 120 records in 0.041376981 seconds. Throughput is 2900.163 records/second. Loss is 0.2144114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004420866489832007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37440/60000][Iteration 6312][Wall Clock 288.882792363s] Trained 120 records in 0.040758221 seconds. Throughput is 2944.1912 records/second. Loss is 0.1546463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004420475643179206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37560/60000][Iteration 6313][Wall Clock 288.923417467s] Trained 120 records in 0.040625104 seconds. Throughput is 2953.8386 records/second. Loss is 0.1450558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00442008486562942. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37680/60000][Iteration 6314][Wall Clock 288.964332835s] Trained 120 records in 0.040915368 seconds. Throughput is 2932.8835 records/second. Loss is 0.13631058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004419694157164324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37800/60000][Iteration 6315][Wall Clock 289.005247906s] Trained 120 records in 0.040915071 seconds. Throughput is 2932.9045 records/second. Loss is 0.29640335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044193035177656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 37920/60000][Iteration 6316][Wall Clock 289.045976611s] Trained 120 records in 0.040728705 seconds. Throughput is 2946.3252 records/second. Loss is 0.15263245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004418912947414936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38040/60000][Iteration 6317][Wall Clock 289.099526519s] Trained 120 records in 0.053549908 seconds. Throughput is 2240.9001 records/second. Loss is 0.119509175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004418522446094026. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38160/60000][Iteration 6318][Wall Clock 289.143089276s] Trained 120 records in 0.043562757 seconds. Throughput is 2754.6465 records/second. Loss is 0.18963724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004418132013784572. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38280/60000][Iteration 6319][Wall Clock 289.184202352s] Trained 120 records in 0.041113076 seconds. Throughput is 2918.7795 records/second. Loss is 0.2651936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00441774165046828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38400/60000][Iteration 6320][Wall Clock 289.225579195s] Trained 120 records in 0.041376843 seconds. Throughput is 2900.1729 records/second. Loss is 0.14417724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004417351356126867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38520/60000][Iteration 6321][Wall Clock 289.266561755s] Trained 120 records in 0.04098256 seconds. Throughput is 2928.0747 records/second. Loss is 0.1441213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004416961130742049. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38640/60000][Iteration 6322][Wall Clock 289.307577123s] Trained 120 records in 0.041015368 seconds. Throughput is 2925.7327 records/second. Loss is 0.12851073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004416570974295557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38760/60000][Iteration 6323][Wall Clock 289.348185518s] Trained 120 records in 0.040608395 seconds. Throughput is 2955.054 records/second. Loss is 0.07767318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004416180886769122. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 38880/60000][Iteration 6324][Wall Clock 289.38862572s] Trained 120 records in 0.040440202 seconds. Throughput is 2967.3442 records/second. Loss is 0.27956018. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004415790868144484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 39000/60000][Iteration 6325][Wall Clock 289.428807418s] Trained 120 records in 0.040181698 seconds. Throughput is 2986.4343 records/second. Loss is 0.20290186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044154009184033905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 39120/60000][Iteration 6326][Wall Clock 289.468942364s] Trained 120 records in 0.040134946 seconds. Throughput is 2989.9128 records/second. Loss is 0.26188204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004415011037527594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:55 INFO  DistriOptimizer$:406 - [Epoch 13 39240/60000][Iteration 6327][Wall Clock 289.509625571s] Trained 120 records in 0.040683207 seconds. Throughput is 2949.62 records/second. Loss is 0.27475023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004414621225498852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 39360/60000][Iteration 6328][Wall Clock 289.550985095s] Trained 120 records in 0.041359524 seconds. Throughput is 2901.3872 records/second. Loss is 0.12655336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004414231482298932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 39480/60000][Iteration 6329][Wall Clock 289.61021405s] Trained 120 records in 0.059228955 seconds. Throughput is 2026.036 records/second. Loss is 0.17728093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004413841807909605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 39600/60000][Iteration 6330][Wall Clock 289.652834681s] Trained 120 records in 0.042620631 seconds. Throughput is 2815.5378 records/second. Loss is 0.23419254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004413452202312649. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 39720/60000][Iteration 6331][Wall Clock 289.693440278s] Trained 120 records in 0.040605597 seconds. Throughput is 2955.2576 records/second. Loss is 0.13589859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044130626654898504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 39840/60000][Iteration 6332][Wall Clock 289.734651769s] Trained 120 records in 0.041211491 seconds. Throughput is 2911.8093 records/second. Loss is 0.1842466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004412673197422999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 39960/60000][Iteration 6333][Wall Clock 289.774948959s] Trained 120 records in 0.04029719 seconds. Throughput is 2977.875 records/second. Loss is 0.15693305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004412283798093893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40080/60000][Iteration 6334][Wall Clock 289.814831735s] Trained 120 records in 0.039882776 seconds. Throughput is 3008.8176 records/second. Loss is 0.26907697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004411894467484337. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40200/60000][Iteration 6335][Wall Clock 289.855540988s] Trained 120 records in 0.040709253 seconds. Throughput is 2947.7327 records/second. Loss is 0.18571599. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044115052055761425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40320/60000][Iteration 6336][Wall Clock 289.895980158s] Trained 120 records in 0.04043917 seconds. Throughput is 2967.42 records/second. Loss is 0.15167373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004411116012351124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40440/60000][Iteration 6337][Wall Clock 289.936272018s] Trained 120 records in 0.04029186 seconds. Throughput is 2978.269 records/second. Loss is 0.16106118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004410726887791108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40560/60000][Iteration 6338][Wall Clock 289.977684868s] Trained 120 records in 0.04141285 seconds. Throughput is 2897.6514 records/second. Loss is 0.2325398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004410337831877921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40680/60000][Iteration 6339][Wall Clock 290.018908013s] Trained 120 records in 0.041223145 seconds. Throughput is 2910.986 records/second. Loss is 0.1761857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004409948844593403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40800/60000][Iteration 6340][Wall Clock 290.060286757s] Trained 120 records in 0.041378744 seconds. Throughput is 2900.0398 records/second. Loss is 0.14747338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004409559925919393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 40920/60000][Iteration 6341][Wall Clock 290.101347147s] Trained 120 records in 0.04106039 seconds. Throughput is 2922.5244 records/second. Loss is 0.2809914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004409171075837743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41040/60000][Iteration 6342][Wall Clock 290.142547222s] Trained 120 records in 0.041200075 seconds. Throughput is 2912.616 records/second. Loss is 0.18355922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004408782294330306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41160/60000][Iteration 6343][Wall Clock 290.190301737s] Trained 120 records in 0.047754515 seconds. Throughput is 2512.8513 records/second. Loss is 0.115751594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004408393581378946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41280/60000][Iteration 6344][Wall Clock 290.240354031s] Trained 120 records in 0.050052294 seconds. Throughput is 2397.4927 records/second. Loss is 0.30271903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044080049369655296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41400/60000][Iteration 6345][Wall Clock 290.281995028s] Trained 120 records in 0.041640997 seconds. Throughput is 2881.7754 records/second. Loss is 0.32026947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004407616361071932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41520/60000][Iteration 6346][Wall Clock 290.323433398s] Trained 120 records in 0.04143837 seconds. Throughput is 2895.8667 records/second. Loss is 0.22452061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004407227853680035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41640/60000][Iteration 6347][Wall Clock 290.364831483s] Trained 120 records in 0.041398085 seconds. Throughput is 2898.6848 records/second. Loss is 0.21703371. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004406839414771726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41760/60000][Iteration 6348][Wall Clock 290.409433686s] Trained 120 records in 0.044602203 seconds. Throughput is 2690.45 records/second. Loss is 0.15324345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004406451044328898. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 41880/60000][Iteration 6349][Wall Clock 290.450313691s] Trained 120 records in 0.040880005 seconds. Throughput is 2935.4204 records/second. Loss is 0.27722892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044060627423334504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 42000/60000][Iteration 6350][Wall Clock 290.491113435s] Trained 120 records in 0.040799744 seconds. Throughput is 2941.1948 records/second. Loss is 0.16047281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004405674508767292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:56 INFO  DistriOptimizer$:406 - [Epoch 13 42120/60000][Iteration 6351][Wall Clock 290.53180183s] Trained 120 records in 0.040688395 seconds. Throughput is 2949.244 records/second. Loss is 0.2863206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004405286343612335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 42240/60000][Iteration 6352][Wall Clock 290.573450103s] Trained 120 records in 0.041648273 seconds. Throughput is 2881.272 records/second. Loss is 0.13812856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044048982468504975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 42360/60000][Iteration 6353][Wall Clock 290.617213944s] Trained 120 records in 0.043763841 seconds. Throughput is 2741.9895 records/second. Loss is 0.08150521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004404510218463707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 42480/60000][Iteration 6354][Wall Clock 290.66629143s] Trained 120 records in 0.049077486 seconds. Throughput is 2445.113 records/second. Loss is 0.14799057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004404122258433894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 42600/60000][Iteration 6355][Wall Clock 290.710056682s] Trained 120 records in 0.043765252 seconds. Throughput is 2741.9014 records/second. Loss is 0.1582206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004403734366742997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 42720/60000][Iteration 6356][Wall Clock 290.752588617s] Trained 120 records in 0.042531935 seconds. Throughput is 2821.4094 records/second. Loss is 0.16282971. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004403346543372964. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 42840/60000][Iteration 6357][Wall Clock 290.794030438s] Trained 120 records in 0.041441821 seconds. Throughput is 2895.6257 records/second. Loss is 0.17796709. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004402958788305741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 42960/60000][Iteration 6358][Wall Clock 290.835233807s] Trained 120 records in 0.041203369 seconds. Throughput is 2912.3833 records/second. Loss is 0.24093433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00440257110152329. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43080/60000][Iteration 6359][Wall Clock 290.876238735s] Trained 120 records in 0.041004928 seconds. Throughput is 2926.4773 records/second. Loss is 0.15760212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004402183483007571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43200/60000][Iteration 6360][Wall Clock 290.917273998s] Trained 120 records in 0.041035263 seconds. Throughput is 2924.314 records/second. Loss is 0.1678358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004401795932740558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43320/60000][Iteration 6361][Wall Clock 290.958666837s] Trained 120 records in 0.041392839 seconds. Throughput is 2899.052 records/second. Loss is 0.29643708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004401408450704225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43440/60000][Iteration 6362][Wall Clock 291.000056066s] Trained 120 records in 0.041389229 seconds. Throughput is 2899.305 records/second. Loss is 0.1872949. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0044010210368805565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43560/60000][Iteration 6363][Wall Clock 291.041590475s] Trained 120 records in 0.041534409 seconds. Throughput is 2889.1707 records/second. Loss is 0.17931098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00440063369125154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43680/60000][Iteration 6364][Wall Clock 291.082637747s] Trained 120 records in 0.041047272 seconds. Throughput is 2923.4587 records/second. Loss is 0.24347797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004400246413799174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43800/60000][Iteration 6365][Wall Clock 291.123958536s] Trained 120 records in 0.041320789 seconds. Throughput is 2904.1072 records/second. Loss is 0.3373244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004399859204505456. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 43920/60000][Iteration 6366][Wall Clock 291.165528834s] Trained 120 records in 0.041570298 seconds. Throughput is 2886.6765 records/second. Loss is 0.14002915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004399472063352398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44040/60000][Iteration 6367][Wall Clock 291.211381837s] Trained 120 records in 0.045853003 seconds. Throughput is 2617.0586 records/second. Loss is 0.09762192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004399084990322013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44160/60000][Iteration 6368][Wall Clock 291.253614482s] Trained 120 records in 0.042232645 seconds. Throughput is 2841.4038 records/second. Loss is 0.21797393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004398697985396323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44280/60000][Iteration 6369][Wall Clock 291.294475334s] Trained 120 records in 0.040860852 seconds. Throughput is 2936.7964 records/second. Loss is 0.13272648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004398311048557354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44400/60000][Iteration 6370][Wall Clock 291.345471154s] Trained 120 records in 0.05099582 seconds. Throughput is 2353.134 records/second. Loss is 0.16036825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00439792417978714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44520/60000][Iteration 6371][Wall Clock 291.393752909s] Trained 120 records in 0.048281755 seconds. Throughput is 2485.411 records/second. Loss is 0.19893949. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043975373790677225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44640/60000][Iteration 6372][Wall Clock 291.435870601s] Trained 120 records in 0.042117692 seconds. Throughput is 2849.159 records/second. Loss is 0.21834269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043971506463811455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44760/60000][Iteration 6373][Wall Clock 291.477807699s] Trained 120 records in 0.041937098 seconds. Throughput is 2861.4282 records/second. Loss is 0.22512102. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004396763981709462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:57 INFO  DistriOptimizer$:406 - [Epoch 13 44880/60000][Iteration 6374][Wall Clock 291.518837569s] Trained 120 records in 0.04102987 seconds. Throughput is 2924.6985 records/second. Loss is 0.22673874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043963773850347315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45000/60000][Iteration 6375][Wall Clock 291.559626629s] Trained 120 records in 0.04078906 seconds. Throughput is 2941.9653 records/second. Loss is 0.20616968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043959908563390195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45120/60000][Iteration 6376][Wall Clock 291.600737102s] Trained 120 records in 0.041110473 seconds. Throughput is 2918.964 records/second. Loss is 0.21371458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004395604395604395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45240/60000][Iteration 6377][Wall Clock 291.643184013s] Trained 120 records in 0.042446911 seconds. Throughput is 2827.0608 records/second. Loss is 0.21495153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00439521800281294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45360/60000][Iteration 6378][Wall Clock 291.686150767s] Trained 120 records in 0.042966754 seconds. Throughput is 2792.8572 records/second. Loss is 0.20057108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004394831677946734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45480/60000][Iteration 6379][Wall Clock 291.734786672s] Trained 120 records in 0.048635905 seconds. Throughput is 2467.313 records/second. Loss is 0.1276947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004394445420987872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45600/60000][Iteration 6380][Wall Clock 291.778699676s] Trained 120 records in 0.043913004 seconds. Throughput is 2732.6758 records/second. Loss is 0.12993534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004394059231918446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45720/60000][Iteration 6381][Wall Clock 291.820475824s] Trained 120 records in 0.041776148 seconds. Throughput is 2872.4526 records/second. Loss is 0.18994293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004393673110720563. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45840/60000][Iteration 6382][Wall Clock 291.861444189s] Trained 120 records in 0.040968365 seconds. Throughput is 2929.0894 records/second. Loss is 0.14372468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004393287057376329. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 45960/60000][Iteration 6383][Wall Clock 291.903546195s] Trained 120 records in 0.042102006 seconds. Throughput is 2850.2205 records/second. Loss is 0.12874229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004392901071867862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46080/60000][Iteration 6384][Wall Clock 291.944316984s] Trained 120 records in 0.040770789 seconds. Throughput is 2943.284 records/second. Loss is 0.20887156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004392515154177282. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46200/60000][Iteration 6385][Wall Clock 291.988815671s] Trained 120 records in 0.044498687 seconds. Throughput is 2696.7087 records/second. Loss is 0.26863533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004392129304286718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46320/60000][Iteration 6386][Wall Clock 292.029461359s] Trained 120 records in 0.040645688 seconds. Throughput is 2952.3425 records/second. Loss is 0.31008726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004391743522178305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46440/60000][Iteration 6387][Wall Clock 292.070464925s] Trained 120 records in 0.041003566 seconds. Throughput is 2926.5747 records/second. Loss is 0.19741477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004391357807834183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46560/60000][Iteration 6388][Wall Clock 292.112042126s] Trained 120 records in 0.041577201 seconds. Throughput is 2886.1973 records/second. Loss is 0.11597986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004390972161236498. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46680/60000][Iteration 6389][Wall Clock 292.154465925s] Trained 120 records in 0.042423799 seconds. Throughput is 2828.6008 records/second. Loss is 0.27245602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043905865823674044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46800/60000][Iteration 6390][Wall Clock 292.196582971s] Trained 120 records in 0.042117046 seconds. Throughput is 2849.203 records/second. Loss is 0.25099993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004390201071209061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 46920/60000][Iteration 6391][Wall Clock 292.23791529s] Trained 120 records in 0.041332319 seconds. Throughput is 2903.297 records/second. Loss is 0.3226384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004389815627743635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 47040/60000][Iteration 6392][Wall Clock 292.279669519s] Trained 120 records in 0.041754229 seconds. Throughput is 2873.9602 records/second. Loss is 0.25663817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043894302519532965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 47160/60000][Iteration 6393][Wall Clock 292.321314867s] Trained 120 records in 0.041645348 seconds. Throughput is 2881.4744 records/second. Loss is 0.28643337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004389044943820225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 47280/60000][Iteration 6394][Wall Clock 292.363042348s] Trained 120 records in 0.041727481 seconds. Throughput is 2875.8027 records/second. Loss is 0.17529263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004388659703326604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 47400/60000][Iteration 6395][Wall Clock 292.405346358s] Trained 120 records in 0.04230401 seconds. Throughput is 2836.6106 records/second. Loss is 0.13225228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004388274530454625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 47520/60000][Iteration 6396][Wall Clock 292.447060203s] Trained 120 records in 0.041713845 seconds. Throughput is 2876.7427 records/second. Loss is 0.24175599. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004387889425186486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:58 INFO  DistriOptimizer$:406 - [Epoch 13 47640/60000][Iteration 6397][Wall Clock 292.49703983s] Trained 120 records in 0.049979627 seconds. Throughput is 2400.9783 records/second. Loss is 0.3359853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004387504387504387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 47760/60000][Iteration 6398][Wall Clock 292.54558989s] Trained 120 records in 0.04855006 seconds. Throughput is 2471.6758 records/second. Loss is 0.16555145. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043871194173905415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 47880/60000][Iteration 6399][Wall Clock 292.5892167s] Trained 120 records in 0.04362681 seconds. Throughput is 2750.602 records/second. Loss is 0.20182227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043867345148271624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48000/60000][Iteration 6400][Wall Clock 292.630134236s] Trained 120 records in 0.040917536 seconds. Throughput is 2932.728 records/second. Loss is 0.17606689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004386349679796474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48120/60000][Iteration 6401][Wall Clock 292.673318319s] Trained 120 records in 0.043184083 seconds. Throughput is 2778.8015 records/second. Loss is 0.20053403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043859649122807015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48240/60000][Iteration 6402][Wall Clock 292.71446954s] Trained 120 records in 0.041151221 seconds. Throughput is 2916.0737 records/second. Loss is 0.19968338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004385580212262083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48360/60000][Iteration 6403][Wall Clock 292.758999182s] Trained 120 records in 0.044529642 seconds. Throughput is 2694.834 records/second. Loss is 0.22632484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004385195579722855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48480/60000][Iteration 6404][Wall Clock 292.807520418s] Trained 120 records in 0.048521236 seconds. Throughput is 2473.144 records/second. Loss is 0.15055981. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004384811014645269. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48600/60000][Iteration 6405][Wall Clock 292.858087887s] Trained 120 records in 0.050567469 seconds. Throughput is 2373.0671 records/second. Loss is 0.21425621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043844265170115745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48720/60000][Iteration 6406][Wall Clock 292.904386908s] Trained 120 records in 0.046299021 seconds. Throughput is 2591.8474 records/second. Loss is 0.2773721. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004384042086804033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48840/60000][Iteration 6407][Wall Clock 292.946349998s] Trained 120 records in 0.04196309 seconds. Throughput is 2859.656 records/second. Loss is 0.1341321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00438365772400491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 48960/60000][Iteration 6408][Wall Clock 292.988052543s] Trained 120 records in 0.041702545 seconds. Throughput is 2877.5222 records/second. Loss is 0.13532361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004383273428596476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49080/60000][Iteration 6409][Wall Clock 293.02920804s] Trained 120 records in 0.041155497 seconds. Throughput is 2915.7708 records/second. Loss is 0.21928936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00438288920056101. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49200/60000][Iteration 6410][Wall Clock 293.06977469s] Trained 120 records in 0.04056665 seconds. Throughput is 2958.095 records/second. Loss is 0.18758911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004382505039880796. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49320/60000][Iteration 6411][Wall Clock 293.111326927s] Trained 120 records in 0.041552237 seconds. Throughput is 2887.9312 records/second. Loss is 0.19035035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043821209465381246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49440/60000][Iteration 6412][Wall Clock 293.15291473s] Trained 120 records in 0.041587803 seconds. Throughput is 2885.4614 records/second. Loss is 0.15105799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004381736920515292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49560/60000][Iteration 6413][Wall Clock 293.195211117s] Trained 120 records in 0.042296387 seconds. Throughput is 2837.1218 records/second. Loss is 0.21217345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004381352961794602. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49680/60000][Iteration 6414][Wall Clock 293.236429062s] Trained 120 records in 0.041217945 seconds. Throughput is 2911.3533 records/second. Loss is 0.19832681. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004380969070358363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49800/60000][Iteration 6415][Wall Clock 293.277832388s] Trained 120 records in 0.041403326 seconds. Throughput is 2898.3179 records/second. Loss is 0.23164134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004380585246188891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 49920/60000][Iteration 6416][Wall Clock 293.318081535s] Trained 120 records in 0.040249147 seconds. Throughput is 2981.4297 records/second. Loss is 0.27441484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004380201489268506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 50040/60000][Iteration 6417][Wall Clock 293.358985552s] Trained 120 records in 0.040904017 seconds. Throughput is 2933.6973 records/second. Loss is 0.16617177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004379817799579537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 50160/60000][Iteration 6418][Wall Clock 293.400470082s] Trained 120 records in 0.04148453 seconds. Throughput is 2892.6445 records/second. Loss is 0.15633442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004379434177104318. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 50280/60000][Iteration 6419][Wall Clock 293.441835786s] Trained 120 records in 0.041365704 seconds. Throughput is 2900.9539 records/second. Loss is 0.2656104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004379050621825188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 50400/60000][Iteration 6420][Wall Clock 293.483024181s] Trained 120 records in 0.041188395 seconds. Throughput is 2913.442 records/second. Loss is 0.13321906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004378667133724493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:57:59 INFO  DistriOptimizer$:406 - [Epoch 13 50520/60000][Iteration 6421][Wall Clock 293.523370944s] Trained 120 records in 0.040346763 seconds. Throughput is 2974.2163 records/second. Loss is 0.20212997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043782837127845885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 50640/60000][Iteration 6422][Wall Clock 293.563408397s] Trained 120 records in 0.040037453 seconds. Throughput is 2997.1936 records/second. Loss is 0.26517314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004377900358987829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 50760/60000][Iteration 6423][Wall Clock 293.608066196s] Trained 120 records in 0.044657799 seconds. Throughput is 2687.1006 records/second. Loss is 0.21383375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043775170723165824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 50880/60000][Iteration 6424][Wall Clock 293.662568749s] Trained 120 records in 0.054502553 seconds. Throughput is 2201.7317 records/second. Loss is 0.16299346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004377133852753217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51000/60000][Iteration 6425][Wall Clock 293.70738853s] Trained 120 records in 0.044819781 seconds. Throughput is 2677.3894 records/second. Loss is 0.17545375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004376750700280112. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51120/60000][Iteration 6426][Wall Clock 293.748111136s] Trained 120 records in 0.040722606 seconds. Throughput is 2946.7664 records/second. Loss is 0.23532178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00437636761487965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51240/60000][Iteration 6427][Wall Clock 293.788565823s] Trained 120 records in 0.040454687 seconds. Throughput is 2966.2817 records/second. Loss is 0.12587199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00437598459653422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51360/60000][Iteration 6428][Wall Clock 293.830506827s] Trained 120 records in 0.041941004 seconds. Throughput is 2861.1616 records/second. Loss is 0.17513697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004375601645226219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51480/60000][Iteration 6429][Wall Clock 293.872126325s] Trained 120 records in 0.041619498 seconds. Throughput is 2883.264 records/second. Loss is 0.21645698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004375218760938047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51600/60000][Iteration 6430][Wall Clock 293.912866741s] Trained 120 records in 0.040740416 seconds. Throughput is 2945.478 records/second. Loss is 0.16572174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004374835943652113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51720/60000][Iteration 6431][Wall Clock 293.954130765s] Trained 120 records in 0.041264024 seconds. Throughput is 2908.1023 records/second. Loss is 0.18044041. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004374453193350831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51840/60000][Iteration 6432][Wall Clock 294.003350069s] Trained 120 records in 0.049219304 seconds. Throughput is 2438.0679 records/second. Loss is 0.13682635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004374070510016622. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 51960/60000][Iteration 6433][Wall Clock 294.048841032s] Trained 120 records in 0.045490963 seconds. Throughput is 2637.8867 records/second. Loss is 0.20920242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004373687893631911. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52080/60000][Iteration 6434][Wall Clock 294.089242438s] Trained 120 records in 0.040401406 seconds. Throughput is 2970.1936 records/second. Loss is 0.18154623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004373305344179131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52200/60000][Iteration 6435][Wall Clock 294.129618851s] Trained 120 records in 0.040376413 seconds. Throughput is 2972.0322 records/second. Loss is 0.19356108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00437292286164072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52320/60000][Iteration 6436][Wall Clock 294.170215278s] Trained 120 records in 0.040596427 seconds. Throughput is 2955.9253 records/second. Loss is 0.16968875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004372540445999126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52440/60000][Iteration 6437][Wall Clock 294.211778057s] Trained 120 records in 0.041562779 seconds. Throughput is 2887.1985 records/second. Loss is 0.24508974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004372158097236795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52560/60000][Iteration 6438][Wall Clock 294.253763194s] Trained 120 records in 0.041985137 seconds. Throughput is 2858.1543 records/second. Loss is 0.16552672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00437177581533619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52680/60000][Iteration 6439][Wall Clock 294.29494481s] Trained 120 records in 0.041181616 seconds. Throughput is 2913.9216 records/second. Loss is 0.21422814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004371393600279769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52800/60000][Iteration 6440][Wall Clock 294.335584697s] Trained 120 records in 0.040639887 seconds. Throughput is 2952.764 records/second. Loss is 0.10411306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004371011452050004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 52920/60000][Iteration 6441][Wall Clock 294.37962608s] Trained 120 records in 0.044041383 seconds. Throughput is 2724.71 records/second. Loss is 0.27331072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00437062937062937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 53040/60000][Iteration 6442][Wall Clock 294.42074113s] Trained 120 records in 0.04111505 seconds. Throughput is 2918.6394 records/second. Loss is 0.2462859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00437024735600035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 53160/60000][Iteration 6443][Wall Clock 294.461426584s] Trained 120 records in 0.040685454 seconds. Throughput is 2949.4573 records/second. Loss is 0.2500828. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004369865408145429. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:00 INFO  DistriOptimizer$:406 - [Epoch 13 53280/60000][Iteration 6444][Wall Clock 294.501942124s] Trained 120 records in 0.04051554 seconds. Throughput is 2961.8267 records/second. Loss is 0.15653159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004369483527047103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 53400/60000][Iteration 6445][Wall Clock 294.542714578s] Trained 120 records in 0.040772454 seconds. Throughput is 2943.1636 records/second. Loss is 0.19236876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004369101712687871. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 53520/60000][Iteration 6446][Wall Clock 294.583078141s] Trained 120 records in 0.040363563 seconds. Throughput is 2972.9785 records/second. Loss is 0.28903592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00436871996505024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 53640/60000][Iteration 6447][Wall Clock 294.623226731s] Trained 120 records in 0.04014859 seconds. Throughput is 2988.897 records/second. Loss is 0.17283188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004368338284116722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 53760/60000][Iteration 6448][Wall Clock 294.662965087s] Trained 120 records in 0.039738356 seconds. Throughput is 3019.7524 records/second. Loss is 0.18252324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004367956669869835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 53880/60000][Iteration 6449][Wall Clock 294.702529666s] Trained 120 records in 0.039564579 seconds. Throughput is 3033.0159 records/second. Loss is 0.16276263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004367575122292103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54000/60000][Iteration 6450][Wall Clock 294.753968835s] Trained 120 records in 0.051439169 seconds. Throughput is 2332.8525 records/second. Loss is 0.1423424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043671936413660585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54120/60000][Iteration 6451][Wall Clock 294.802958217s] Trained 120 records in 0.048989382 seconds. Throughput is 2449.5105 records/second. Loss is 0.22730191. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004366812227074236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54240/60000][Iteration 6452][Wall Clock 294.845514558s] Trained 120 records in 0.042556341 seconds. Throughput is 2819.7913 records/second. Loss is 0.17678718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043664308793991795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54360/60000][Iteration 6453][Wall Clock 294.886649269s] Trained 120 records in 0.041134711 seconds. Throughput is 2917.2441 records/second. Loss is 0.19425122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004366049598323437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54480/60000][Iteration 6454][Wall Clock 294.929322163s] Trained 120 records in 0.042672894 seconds. Throughput is 2812.0896 records/second. Loss is 0.23126504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004365668383829564. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54600/60000][Iteration 6455][Wall Clock 294.971120765s] Trained 120 records in 0.041798602 seconds. Throughput is 2870.9094 records/second. Loss is 0.15042268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004365287235900122. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54720/60000][Iteration 6456][Wall Clock 295.012440988s] Trained 120 records in 0.041320223 seconds. Throughput is 2904.147 records/second. Loss is 0.22192685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004364906154517677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54840/60000][Iteration 6457][Wall Clock 295.053805828s] Trained 120 records in 0.04136484 seconds. Throughput is 2901.0144 records/second. Loss is 0.15027216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004364525139664805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 54960/60000][Iteration 6458][Wall Clock 295.094653529s] Trained 120 records in 0.040847701 seconds. Throughput is 2937.742 records/second. Loss is 0.09930744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004364144191324081. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55080/60000][Iteration 6459][Wall Clock 295.144162598s] Trained 120 records in 0.049509069 seconds. Throughput is 2423.7983 records/second. Loss is 0.23566245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004363763309478094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55200/60000][Iteration 6460][Wall Clock 295.188475475s] Trained 120 records in 0.044312877 seconds. Throughput is 2708.0166 records/second. Loss is 0.33039096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004363382494109433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55320/60000][Iteration 6461][Wall Clock 295.229223414s] Trained 120 records in 0.040747939 seconds. Throughput is 2944.934 records/second. Loss is 0.15625785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004363001745200699. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55440/60000][Iteration 6462][Wall Clock 295.269931545s] Trained 120 records in 0.040708131 seconds. Throughput is 2947.814 records/second. Loss is 0.11482331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004362621062734491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55560/60000][Iteration 6463][Wall Clock 295.310009434s] Trained 120 records in 0.040077889 seconds. Throughput is 2994.1697 records/second. Loss is 0.22059864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004362240446693423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55680/60000][Iteration 6464][Wall Clock 295.350133199s] Trained 120 records in 0.040123765 seconds. Throughput is 2990.7463 records/second. Loss is 0.17551616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004361859897060106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55800/60000][Iteration 6465][Wall Clock 295.390777359s] Trained 120 records in 0.04064416 seconds. Throughput is 2952.4536 records/second. Loss is 0.20585273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004361479413817167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 55920/60000][Iteration 6466][Wall Clock 295.431929687s] Trained 120 records in 0.041152328 seconds. Throughput is 2915.9954 records/second. Loss is 0.1761937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00436109899694723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 56040/60000][Iteration 6467][Wall Clock 295.472550196s] Trained 120 records in 0.040620509 seconds. Throughput is 2954.1726 records/second. Loss is 0.15937826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004360718646432932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:01 INFO  DistriOptimizer$:406 - [Epoch 13 56160/60000][Iteration 6468][Wall Clock 295.513131747s] Trained 120 records in 0.040581551 seconds. Throughput is 2957.0088 records/second. Loss is 0.12825571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004360338362256911. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 56280/60000][Iteration 6469][Wall Clock 295.553473962s] Trained 120 records in 0.040342215 seconds. Throughput is 2974.5515 records/second. Loss is 0.117416754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004359958144401814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 56400/60000][Iteration 6470][Wall Clock 295.593720518s] Trained 120 records in 0.040246556 seconds. Throughput is 2981.6216 records/second. Loss is 0.26990107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004359577992850292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 56520/60000][Iteration 6471][Wall Clock 295.633982285s] Trained 120 records in 0.040261767 seconds. Throughput is 2980.495 records/second. Loss is 0.1419137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004359197907585004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 56640/60000][Iteration 6472][Wall Clock 295.673971707s] Trained 120 records in 0.039989422 seconds. Throughput is 3000.7935 records/second. Loss is 0.18957299. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004358817888588615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 56760/60000][Iteration 6473][Wall Clock 295.714608808s] Trained 120 records in 0.040637101 seconds. Throughput is 2952.9666 records/second. Loss is 0.2998161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004358437935843794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 56880/60000][Iteration 6474][Wall Clock 295.755035008s] Trained 120 records in 0.0404262 seconds. Throughput is 2968.372 records/second. Loss is 0.30067673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004358058049333217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57000/60000][Iteration 6475][Wall Clock 295.795879476s] Trained 120 records in 0.040844468 seconds. Throughput is 2937.9744 records/second. Loss is 0.19803193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004357678229039567. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57120/60000][Iteration 6476][Wall Clock 295.837261155s] Trained 120 records in 0.041381679 seconds. Throughput is 2899.834 records/second. Loss is 0.1927537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004357298474945534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57240/60000][Iteration 6477][Wall Clock 295.886981193s] Trained 120 records in 0.049720038 seconds. Throughput is 2413.514 records/second. Loss is 0.14050987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004356918787033809. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57360/60000][Iteration 6478][Wall Clock 295.939212646s] Trained 120 records in 0.052231453 seconds. Throughput is 2297.4663 records/second. Loss is 0.31017447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004356539165287096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57480/60000][Iteration 6479][Wall Clock 295.984704355s] Trained 120 records in 0.045491709 seconds. Throughput is 2637.8433 records/second. Loss is 0.22917344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004356159609688099. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57600/60000][Iteration 6480][Wall Clock 296.02561006s] Trained 120 records in 0.040905705 seconds. Throughput is 2933.576 records/second. Loss is 0.18897775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043557801202195314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57720/60000][Iteration 6481][Wall Clock 296.065916248s] Trained 120 records in 0.040306188 seconds. Throughput is 2977.2104 records/second. Loss is 0.116424516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004355400696864111. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57840/60000][Iteration 6482][Wall Clock 296.107068009s] Trained 120 records in 0.041151761 seconds. Throughput is 2916.0356 records/second. Loss is 0.21418993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004355021339604565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 57960/60000][Iteration 6483][Wall Clock 296.147736505s] Trained 120 records in 0.040668496 seconds. Throughput is 2950.687 records/second. Loss is 0.24023224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004354642048423619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58080/60000][Iteration 6484][Wall Clock 296.188692215s] Trained 120 records in 0.04095571 seconds. Throughput is 2929.9944 records/second. Loss is 0.17063357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043542628233040155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58200/60000][Iteration 6485][Wall Clock 296.238640872s] Trained 120 records in 0.049948657 seconds. Throughput is 2402.4668 records/second. Loss is 0.16316514. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004353883664228492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58320/60000][Iteration 6486][Wall Clock 296.283068582s] Trained 120 records in 0.04442771 seconds. Throughput is 2701.0168 records/second. Loss is 0.16245171. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043535045711798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58440/60000][Iteration 6487][Wall Clock 296.325980115s] Trained 120 records in 0.042911533 seconds. Throughput is 2796.451 records/second. Loss is 0.21104263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004353125544140693. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58560/60000][Iteration 6488][Wall Clock 296.368466843s] Trained 120 records in 0.042486728 seconds. Throughput is 2824.4114 records/second. Loss is 0.21271394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004352746583093932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58680/60000][Iteration 6489][Wall Clock 296.409988268s] Trained 120 records in 0.041521425 seconds. Throughput is 2890.0742 records/second. Loss is 0.18560174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004352367688022284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58800/60000][Iteration 6490][Wall Clock 296.451200153s] Trained 120 records in 0.041211885 seconds. Throughput is 2911.7815 records/second. Loss is 0.19681314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004351988858908521. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:02 INFO  DistriOptimizer$:406 - [Epoch 13 58920/60000][Iteration 6491][Wall Clock 296.492813359s] Trained 120 records in 0.041613206 seconds. Throughput is 2883.7 records/second. Loss is 0.16613583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004351610095735422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59040/60000][Iteration 6492][Wall Clock 296.534839364s] Trained 120 records in 0.042026005 seconds. Throughput is 2855.3748 records/second. Loss is 0.2297673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004351231398485772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59160/60000][Iteration 6493][Wall Clock 296.5756844s] Trained 120 records in 0.040845036 seconds. Throughput is 2937.9336 records/second. Loss is 0.15645747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00435085276714236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59280/60000][Iteration 6494][Wall Clock 296.616376448s] Trained 120 records in 0.040692048 seconds. Throughput is 2948.9792 records/second. Loss is 0.28697383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004350474201687984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59400/60000][Iteration 6495][Wall Clock 296.656218618s] Trained 120 records in 0.03984217 seconds. Throughput is 3011.8843 records/second. Loss is 0.1348031. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004350095702105447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59520/60000][Iteration 6496][Wall Clock 296.696342294s] Trained 120 records in 0.040123676 seconds. Throughput is 2990.753 records/second. Loss is 0.26190612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004349717268377555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59640/60000][Iteration 6497][Wall Clock 296.739294658s] Trained 120 records in 0.042952364 seconds. Throughput is 2793.7927 records/second. Loss is 0.14302835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004349338900487126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59760/60000][Iteration 6498][Wall Clock 296.778977501s] Trained 120 records in 0.039682843 seconds. Throughput is 3023.9768 records/second. Loss is 0.12155084. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004348960598416978. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 59880/60000][Iteration 6499][Wall Clock 296.818845572s] Trained 120 records in 0.039868071 seconds. Throughput is 3009.9272 records/second. Loss is 0.14886932. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043485823621499395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:406 - [Epoch 13 60000/60000][Iteration 6500][Wall Clock 296.85881584s] Trained 120 records in 0.039970268 seconds. Throughput is 3002.2317 records/second. Loss is 0.2346333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00434820419166884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:03 INFO  DistriOptimizer$:451 - [Epoch 13 60000/60000][Iteration 6500][Wall Clock 296.85881584s] Epoch finished. Wall clock time is 297655.391115 ms
2019-10-23 15:58:03 INFO  DistriOptimizer$:111 - [Epoch 13 60000/60000][Iteration 6500][Wall Clock 296.85881584s] Validate model...
2019-10-23 15:58:04 INFO  DistriOptimizer$:177 - [Epoch 13 60000/60000][Iteration 6500][Wall Clock 296.85881584s] validate model throughput is 14953.904 records/second
2019-10-23 15:58:04 INFO  DistriOptimizer$:180 - [Epoch 13 60000/60000][Iteration 6500][Wall Clock 296.85881584s] Top1Accuracy is Accuracy(correct: 9511, count: 10000, accuracy: 0.9511)
2019-10-23 15:58:04 INFO  DistriOptimizer$:220 - [Wall Clock 297.655391115s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:58:04 INFO  DistriOptimizer$:225 - [Wall Clock 297.655391115s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 120/60000][Iteration 6501][Wall Clock 297.716787544s] Trained 120 records in 0.061396429 seconds. Throughput is 1954.5111 records/second. Loss is 0.29376832. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004347826086956522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 240/60000][Iteration 6502][Wall Clock 297.770288113s] Trained 120 records in 0.053500569 seconds. Throughput is 2242.9668 records/second. Loss is 0.19710992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004347448047995826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 360/60000][Iteration 6503][Wall Clock 297.811222238s] Trained 120 records in 0.040934125 seconds. Throughput is 2931.5393 records/second. Loss is 0.17680053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004347070074769606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 480/60000][Iteration 6504][Wall Clock 297.851097557s] Trained 120 records in 0.039875319 seconds. Throughput is 3009.3804 records/second. Loss is 0.2059482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004346692167260714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 600/60000][Iteration 6505][Wall Clock 297.891476109s] Trained 120 records in 0.040378552 seconds. Throughput is 2971.8748 records/second. Loss is 0.18114349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004346314325452017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 720/60000][Iteration 6506][Wall Clock 297.931647818s] Trained 120 records in 0.040171709 seconds. Throughput is 2987.1768 records/second. Loss is 0.10592712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004345936549326379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 840/60000][Iteration 6507][Wall Clock 297.97205972s] Trained 120 records in 0.040411902 seconds. Throughput is 2969.4224 records/second. Loss is 0.13236211. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004345558838866678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 960/60000][Iteration 6508][Wall Clock 298.012609792s] Trained 120 records in 0.040550072 seconds. Throughput is 2959.3042 records/second. Loss is 0.19687198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004345181194055792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1080/60000][Iteration 6509][Wall Clock 298.053384193s] Trained 120 records in 0.040774401 seconds. Throughput is 2943.023 records/second. Loss is 0.08850046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043448036148766075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1200/60000][Iteration 6510][Wall Clock 298.094107436s] Trained 120 records in 0.040723243 seconds. Throughput is 2946.7202 records/second. Loss is 0.13841973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004344426101312016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1320/60000][Iteration 6511][Wall Clock 298.146107473s] Trained 120 records in 0.052000037 seconds. Throughput is 2307.6907 records/second. Loss is 0.21221589. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004344048653344918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1440/60000][Iteration 6512][Wall Clock 298.1873164s] Trained 120 records in 0.041208927 seconds. Throughput is 2911.9905 records/second. Loss is 0.10633413. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004343671270958214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1560/60000][Iteration 6513][Wall Clock 298.229285517s] Trained 120 records in 0.041969117 seconds. Throughput is 2859.2454 records/second. Loss is 0.24143168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004343293954134816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1680/60000][Iteration 6514][Wall Clock 298.274134887s] Trained 120 records in 0.04484937 seconds. Throughput is 2675.6228 records/second. Loss is 0.10055116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004342916702857639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1800/60000][Iteration 6515][Wall Clock 298.315889284s] Trained 120 records in 0.041754397 seconds. Throughput is 2873.9487 records/second. Loss is 0.21240443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004342539517109606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 1920/60000][Iteration 6516][Wall Clock 298.356747731s] Trained 120 records in 0.040858447 seconds. Throughput is 2936.9692 records/second. Loss is 0.16786988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004342162396873643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 2040/60000][Iteration 6517][Wall Clock 298.39664808s] Trained 120 records in 0.039900349 seconds. Throughput is 3007.4927 records/second. Loss is 0.14424062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004341785342132684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 2160/60000][Iteration 6518][Wall Clock 298.436934484s] Trained 120 records in 0.040286404 seconds. Throughput is 2978.6724 records/second. Loss is 0.21553746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004341408352869672. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 2280/60000][Iteration 6519][Wall Clock 298.477819709s] Trained 120 records in 0.040885225 seconds. Throughput is 2935.0457 records/second. Loss is 0.15716232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004341031429067546. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 2400/60000][Iteration 6520][Wall Clock 298.518226299s] Trained 120 records in 0.04040659 seconds. Throughput is 2969.8127 records/second. Loss is 0.1564482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004340654570709263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 2520/60000][Iteration 6521][Wall Clock 298.558452269s] Trained 120 records in 0.04022597 seconds. Throughput is 2983.1475 records/second. Loss is 0.19621333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004340277777777777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:04 INFO  DistriOptimizer$:406 - [Epoch 14 2640/60000][Iteration 6522][Wall Clock 298.598800733s] Trained 120 records in 0.040348464 seconds. Throughput is 2974.091 records/second. Loss is 0.23582506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004339901050256055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 2760/60000][Iteration 6523][Wall Clock 298.642058507s] Trained 120 records in 0.043257774 seconds. Throughput is 2774.0679 records/second. Loss is 0.12326536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004339524388127061. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 2880/60000][Iteration 6524][Wall Clock 298.685224163s] Trained 120 records in 0.043165656 seconds. Throughput is 2779.9878 records/second. Loss is 0.21759926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043391477913737745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3000/60000][Iteration 6525][Wall Clock 298.728636702s] Trained 120 records in 0.043412539 seconds. Throughput is 2764.1782 records/second. Loss is 0.19971947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043387712599791736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3120/60000][Iteration 6526][Wall Clock 298.786422343s] Trained 120 records in 0.057785641 seconds. Throughput is 2076.6404 records/second. Loss is 0.4111133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004338394793926247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3240/60000][Iteration 6527][Wall Clock 298.838430531s] Trained 120 records in 0.052008188 seconds. Throughput is 2307.3289 records/second. Loss is 0.23621397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004338018393197987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3360/60000][Iteration 6528][Wall Clock 298.879962779s] Trained 120 records in 0.041532248 seconds. Throughput is 2889.321 records/second. Loss is 0.19960347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004337642057777392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3480/60000][Iteration 6529][Wall Clock 298.920761277s] Trained 120 records in 0.040798498 seconds. Throughput is 2941.285 records/second. Loss is 0.2163057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004337265787647467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3600/60000][Iteration 6530][Wall Clock 298.961350653s] Trained 120 records in 0.040589376 seconds. Throughput is 2956.4385 records/second. Loss is 0.25478598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004336889582791222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3720/60000][Iteration 6531][Wall Clock 299.001475109s] Trained 120 records in 0.040124456 seconds. Throughput is 2990.6946 records/second. Loss is 0.26240548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004336513443191674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3840/60000][Iteration 6532][Wall Clock 299.041937642s] Trained 120 records in 0.040462533 seconds. Throughput is 2965.7068 records/second. Loss is 0.10894806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004336137368831845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 3960/60000][Iteration 6533][Wall Clock 299.086366705s] Trained 120 records in 0.044429063 seconds. Throughput is 2700.9348 records/second. Loss is 0.27104002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004335761359694762. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4080/60000][Iteration 6534][Wall Clock 299.127496217s] Trained 120 records in 0.041129512 seconds. Throughput is 2917.613 records/second. Loss is 0.18960094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004335385415763462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4200/60000][Iteration 6535][Wall Clock 299.167813247s] Trained 120 records in 0.04031703 seconds. Throughput is 2976.41 records/second. Loss is 0.18820466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004335009537020981. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4320/60000][Iteration 6536][Wall Clock 299.208354431s] Trained 120 records in 0.040541184 seconds. Throughput is 2959.9531 records/second. Loss is 0.25876218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004334633723450367. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4440/60000][Iteration 6537][Wall Clock 299.255907519s] Trained 120 records in 0.047553088 seconds. Throughput is 2523.4954 records/second. Loss is 0.14511442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004334257975034675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4560/60000][Iteration 6538][Wall Clock 299.302826757s] Trained 120 records in 0.046919238 seconds. Throughput is 2557.5862 records/second. Loss is 0.18661143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004333882291756955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4680/60000][Iteration 6539][Wall Clock 299.343108914s] Trained 120 records in 0.040282157 seconds. Throughput is 2978.9866 records/second. Loss is 0.114505306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004333506673600278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4800/60000][Iteration 6540][Wall Clock 299.383114194s] Trained 120 records in 0.04000528 seconds. Throughput is 2999.604 records/second. Loss is 0.12282265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004333131120547708. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 4920/60000][Iteration 6541][Wall Clock 299.423654515s] Trained 120 records in 0.040540321 seconds. Throughput is 2960.0159 records/second. Loss is 0.16616349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004332755632582323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 5040/60000][Iteration 6542][Wall Clock 299.46369551s] Trained 120 records in 0.040040995 seconds. Throughput is 2996.9285 records/second. Loss is 0.2668973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004332380209687202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 5160/60000][Iteration 6543][Wall Clock 299.504289185s] Trained 120 records in 0.040593675 seconds. Throughput is 2956.1255 records/second. Loss is 0.20207372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004332004851845435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 5280/60000][Iteration 6544][Wall Clock 299.544680466s] Trained 120 records in 0.040391281 seconds. Throughput is 2970.9382 records/second. Loss is 0.22216271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00433162955904011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:05 INFO  DistriOptimizer$:406 - [Epoch 14 5400/60000][Iteration 6545][Wall Clock 299.585359214s] Trained 120 records in 0.040678748 seconds. Throughput is 2949.9434 records/second. Loss is 0.21291278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004331254331254332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 5520/60000][Iteration 6546][Wall Clock 299.625511868s] Trained 120 records in 0.040152654 seconds. Throughput is 2988.5945 records/second. Loss is 0.17907129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043308791684712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 5640/60000][Iteration 6547][Wall Clock 299.665144395s] Trained 120 records in 0.039632527 seconds. Throughput is 3027.8162 records/second. Loss is 0.14597683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004330504070673826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 5760/60000][Iteration 6548][Wall Clock 299.705136311s] Trained 120 records in 0.039991916 seconds. Throughput is 3000.6064 records/second. Loss is 0.1765193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004330129037845328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 5880/60000][Iteration 6549][Wall Clock 299.744862908s] Trained 120 records in 0.039726597 seconds. Throughput is 3020.6465 records/second. Loss is 0.13419858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004329754069968826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6000/60000][Iteration 6550][Wall Clock 299.785073378s] Trained 120 records in 0.04021047 seconds. Throughput is 2984.2974 records/second. Loss is 0.14453363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004329379167027448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6120/60000][Iteration 6551][Wall Clock 299.835801185s] Trained 120 records in 0.050727807 seconds. Throughput is 2365.5664 records/second. Loss is 0.20137691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004329004329004329. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6240/60000][Iteration 6552][Wall Clock 299.886789162s] Trained 120 records in 0.050987977 seconds. Throughput is 2353.496 records/second. Loss is 0.21991782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004328629555882608. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6360/60000][Iteration 6553][Wall Clock 299.927338671s] Trained 120 records in 0.040549509 seconds. Throughput is 2959.3452 records/second. Loss is 0.24978839. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00432825484764543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6480/60000][Iteration 6554][Wall Clock 299.967059986s] Trained 120 records in 0.039721315 seconds. Throughput is 3021.048 records/second. Loss is 0.18136641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004327880204275946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6600/60000][Iteration 6555][Wall Clock 300.007437412s] Trained 120 records in 0.040377426 seconds. Throughput is 2971.9575 records/second. Loss is 0.100954026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004327505625757314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6720/60000][Iteration 6556][Wall Clock 300.048312307s] Trained 120 records in 0.040874895 seconds. Throughput is 2935.7874 records/second. Loss is 0.2819657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004327131112072696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6840/60000][Iteration 6557][Wall Clock 300.089416828s] Trained 120 records in 0.041104521 seconds. Throughput is 2919.387 records/second. Loss is 0.24391396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004326756663205261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 6960/60000][Iteration 6558][Wall Clock 300.130190525s] Trained 120 records in 0.040773697 seconds. Throughput is 2943.0737 records/second. Loss is 0.21037692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004326382279138185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7080/60000][Iteration 6559][Wall Clock 300.170939251s] Trained 120 records in 0.040748726 seconds. Throughput is 2944.8772 records/second. Loss is 0.16575576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004326007959854645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7200/60000][Iteration 6560][Wall Clock 300.211322534s] Trained 120 records in 0.040383283 seconds. Throughput is 2971.5266 records/second. Loss is 0.15889744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004325633705337832. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7320/60000][Iteration 6561][Wall Clock 300.251620031s] Trained 120 records in 0.040297497 seconds. Throughput is 2977.8525 records/second. Loss is 0.09359469. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004325259515570934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7440/60000][Iteration 6562][Wall Clock 300.29228511s] Trained 120 records in 0.040665079 seconds. Throughput is 2950.9348 records/second. Loss is 0.26052037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004324885390537151. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7560/60000][Iteration 6563][Wall Clock 300.33308292s] Trained 120 records in 0.04079781 seconds. Throughput is 2941.3342 records/second. Loss is 0.20005007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043245113302196846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7680/60000][Iteration 6564][Wall Clock 300.382780831s] Trained 120 records in 0.049697911 seconds. Throughput is 2414.5884 records/second. Loss is 0.23759201. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004324137334601748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7800/60000][Iteration 6565][Wall Clock 300.42959138s] Trained 120 records in 0.046810549 seconds. Throughput is 2563.5247 records/second. Loss is 0.13575436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004323763403666551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 7920/60000][Iteration 6566][Wall Clock 300.470636946s] Trained 120 records in 0.041045566 seconds. Throughput is 2923.58 records/second. Loss is 0.20818615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004323389537397319. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 8040/60000][Iteration 6567][Wall Clock 300.511332536s] Trained 120 records in 0.04069559 seconds. Throughput is 2948.7224 records/second. Loss is 0.10606699. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004323015735777278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:06 INFO  DistriOptimizer$:406 - [Epoch 14 8160/60000][Iteration 6568][Wall Clock 300.551561799s] Trained 120 records in 0.040229263 seconds. Throughput is 2982.903 records/second. Loss is 0.21179391. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00432264199878966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 8280/60000][Iteration 6569][Wall Clock 300.591717161s] Trained 120 records in 0.040155362 seconds. Throughput is 2988.3928 records/second. Loss is 0.2466063. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004322268326417704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 8400/60000][Iteration 6570][Wall Clock 300.634967225s] Trained 120 records in 0.043250064 seconds. Throughput is 2774.5623 records/second. Loss is 0.16469315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004321894718644654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 8520/60000][Iteration 6571][Wall Clock 300.6746446s] Trained 120 records in 0.039677375 seconds. Throughput is 3024.3938 records/second. Loss is 0.2501639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00432152117545376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 8640/60000][Iteration 6572][Wall Clock 300.714505378s] Trained 120 records in 0.039860778 seconds. Throughput is 3010.4783 records/second. Loss is 0.3098908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004321147696828277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 8760/60000][Iteration 6573][Wall Clock 300.754064821s] Trained 120 records in 0.039559443 seconds. Throughput is 3033.4097 records/second. Loss is 0.21898054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004320774282751469. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 8880/60000][Iteration 6574][Wall Clock 300.794073721s] Trained 120 records in 0.0400089 seconds. Throughput is 2999.3328 records/second. Loss is 0.17566048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004320400933206602. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9000/60000][Iteration 6575][Wall Clock 300.835097899s] Trained 120 records in 0.041024178 seconds. Throughput is 2925.1042 records/second. Loss is 0.16969101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043200276481769485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9120/60000][Iteration 6576][Wall Clock 300.877674824s] Trained 120 records in 0.042576925 seconds. Throughput is 2818.4282 records/second. Loss is 0.15666336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004319654427645788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9240/60000][Iteration 6577][Wall Clock 300.931059908s] Trained 120 records in 0.053385084 seconds. Throughput is 2247.8188 records/second. Loss is 0.25250608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004319281271596406. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9360/60000][Iteration 6578][Wall Clock 300.973385424s] Trained 120 records in 0.042325516 seconds. Throughput is 2835.1692 records/second. Loss is 0.18475309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004318908180012093. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9480/60000][Iteration 6579][Wall Clock 301.01449632s] Trained 120 records in 0.041110896 seconds. Throughput is 2918.9343 records/second. Loss is 0.15978588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004318535152876145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9600/60000][Iteration 6580][Wall Clock 301.05574285s] Trained 120 records in 0.04124653 seconds. Throughput is 2909.3357 records/second. Loss is 0.25405166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004318162190171862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9720/60000][Iteration 6581][Wall Clock 301.097907196s] Trained 120 records in 0.042164346 seconds. Throughput is 2846.0066 records/second. Loss is 0.15241612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004317789291882556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9840/60000][Iteration 6582][Wall Clock 301.139095349s] Trained 120 records in 0.041188153 seconds. Throughput is 2913.459 records/second. Loss is 0.14061342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004317416457991537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 9960/60000][Iteration 6583][Wall Clock 301.179432296s] Trained 120 records in 0.040336947 seconds. Throughput is 2974.94 records/second. Loss is 0.10668044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004317043688482128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10080/60000][Iteration 6584][Wall Clock 301.219098053s] Trained 120 records in 0.039665757 seconds. Throughput is 3025.2793 records/second. Loss is 0.16351408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00431667098333765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10200/60000][Iteration 6585][Wall Clock 301.258523769s] Trained 120 records in 0.039425716 seconds. Throughput is 3043.6987 records/second. Loss is 0.18026592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004316298342541437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10320/60000][Iteration 6586][Wall Clock 301.298793469s] Trained 120 records in 0.0402697 seconds. Throughput is 2979.908 records/second. Loss is 0.097224474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043159257660768235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10440/60000][Iteration 6587][Wall Clock 301.339225364s] Trained 120 records in 0.040431895 seconds. Throughput is 2967.9539 records/second. Loss is 0.12973328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004315553253927153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10560/60000][Iteration 6588][Wall Clock 301.379445116s] Trained 120 records in 0.040219752 seconds. Throughput is 2983.609 records/second. Loss is 0.21524614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004315180806075775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10680/60000][Iteration 6589][Wall Clock 301.422528104s] Trained 120 records in 0.043082988 seconds. Throughput is 2785.322 records/second. Loss is 0.24875434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00431480842250604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10800/60000][Iteration 6590][Wall Clock 301.462969564s] Trained 120 records in 0.04044146 seconds. Throughput is 2967.252 records/second. Loss is 0.23322655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004314436103201312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 10920/60000][Iteration 6591][Wall Clock 301.517590198s] Trained 120 records in 0.054620634 seconds. Throughput is 2196.972 records/second. Loss is 0.22370341. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004314063848144953. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:07 INFO  DistriOptimizer$:406 - [Epoch 14 11040/60000][Iteration 6592][Wall Clock 301.561746716s] Trained 120 records in 0.044156518 seconds. Throughput is 2717.6057 records/second. Loss is 0.18558972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004313691657320335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 11160/60000][Iteration 6593][Wall Clock 301.602813275s] Trained 120 records in 0.041066559 seconds. Throughput is 2922.0857 records/second. Loss is 0.26423714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004313319530710835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 11280/60000][Iteration 6594][Wall Clock 301.643134257s] Trained 120 records in 0.040320982 seconds. Throughput is 2976.1182 records/second. Loss is 0.16611706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043129474682998365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 11400/60000][Iteration 6595][Wall Clock 301.682982946s] Trained 120 records in 0.039848689 seconds. Throughput is 3011.3914 records/second. Loss is 0.20235491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004312575470070726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 11520/60000][Iteration 6596][Wall Clock 301.723113408s] Trained 120 records in 0.040130462 seconds. Throughput is 2990.247 records/second. Loss is 0.1436443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043122035360069. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 11640/60000][Iteration 6597][Wall Clock 301.763522918s] Trained 120 records in 0.04040951 seconds. Throughput is 2969.5981 records/second. Loss is 0.19566673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004311831666091755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 11760/60000][Iteration 6598][Wall Clock 301.803766556s] Trained 120 records in 0.040243638 seconds. Throughput is 2981.838 records/second. Loss is 0.15743028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004311459860308701. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 11880/60000][Iteration 6599][Wall Clock 301.844042735s] Trained 120 records in 0.040276179 seconds. Throughput is 2979.4287 records/second. Loss is 0.20502333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004311088118641145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12000/60000][Iteration 6600][Wall Clock 301.884835334s] Trained 120 records in 0.040792599 seconds. Throughput is 2941.71 records/second. Loss is 0.26553014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004310716441072507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12120/60000][Iteration 6601][Wall Clock 301.926254938s] Trained 120 records in 0.041419604 seconds. Throughput is 2897.179 records/second. Loss is 0.16055076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004310344827586207. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12240/60000][Iteration 6602][Wall Clock 301.972430656s] Trained 120 records in 0.046175718 seconds. Throughput is 2598.7686 records/second. Loss is 0.18202807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004309973278165676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12360/60000][Iteration 6603][Wall Clock 302.015870404s] Trained 120 records in 0.043439748 seconds. Throughput is 2762.4468 records/second. Loss is 0.14113358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043096017927943455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12480/60000][Iteration 6604][Wall Clock 302.055407686s] Trained 120 records in 0.039537282 seconds. Throughput is 3035.11 records/second. Loss is 0.25012717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004309230371455659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12600/60000][Iteration 6605][Wall Clock 302.095394826s] Trained 120 records in 0.03998714 seconds. Throughput is 3000.9648 records/second. Loss is 0.14364499. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043088590141330575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12720/60000][Iteration 6606][Wall Clock 302.135437396s] Trained 120 records in 0.04004257 seconds. Throughput is 2996.8105 records/second. Loss is 0.18466073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004308487720809996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12840/60000][Iteration 6607][Wall Clock 302.176029612s] Trained 120 records in 0.040592216 seconds. Throughput is 2956.2317 records/second. Loss is 0.1288669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004308116491469929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 12960/60000][Iteration 6608][Wall Clock 302.219779867s] Trained 120 records in 0.043750255 seconds. Throughput is 2742.841 records/second. Loss is 0.17959471. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004307745326096321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13080/60000][Iteration 6609][Wall Clock 302.260141809s] Trained 120 records in 0.040361942 seconds. Throughput is 2973.098 records/second. Loss is 0.12330001. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004307374224672639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13200/60000][Iteration 6610][Wall Clock 302.300108802s] Trained 120 records in 0.039966993 seconds. Throughput is 3002.4775 records/second. Loss is 0.13847882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004307003187182358. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13320/60000][Iteration 6611][Wall Clock 302.340086591s] Trained 120 records in 0.039977789 seconds. Throughput is 3001.6667 records/second. Loss is 0.17060088. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004306632213608958. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13440/60000][Iteration 6612][Wall Clock 302.380079627s] Trained 120 records in 0.039993036 seconds. Throughput is 3000.5225 records/second. Loss is 0.20903015. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004306261303935923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13560/60000][Iteration 6613][Wall Clock 302.419926183s] Trained 120 records in 0.039846556 seconds. Throughput is 3011.5527 records/second. Loss is 0.15721188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004305890458146745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13680/60000][Iteration 6614][Wall Clock 302.459214573s] Trained 120 records in 0.03928839 seconds. Throughput is 3054.3374 records/second. Loss is 0.2382151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043055196762249205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13800/60000][Iteration 6615][Wall Clock 302.498432324s] Trained 120 records in 0.039217751 seconds. Throughput is 3059.8389 records/second. Loss is 0.20303689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004305148958153952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 13920/60000][Iteration 6616][Wall Clock 302.538074643s] Trained 120 records in 0.039642319 seconds. Throughput is 3027.068 records/second. Loss is 0.16240388. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004304778303917348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:08 INFO  DistriOptimizer$:406 - [Epoch 14 14040/60000][Iteration 6617][Wall Clock 302.577322772s] Trained 120 records in 0.039248129 seconds. Throughput is 3057.4707 records/second. Loss is 0.09597774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004304407713498623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 14160/60000][Iteration 6618][Wall Clock 302.629281425s] Trained 120 records in 0.051958653 seconds. Throughput is 2309.5286 records/second. Loss is 0.13505568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0043040371868812944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 14280/60000][Iteration 6619][Wall Clock 302.67208647s] Trained 120 records in 0.042805045 seconds. Throughput is 2803.4077 records/second. Loss is 0.14833379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00430366672404889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 14400/60000][Iteration 6620][Wall Clock 302.711850468s] Trained 120 records in 0.039763998 seconds. Throughput is 3017.8052 records/second. Loss is 0.12994929. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004303296324984938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 14520/60000][Iteration 6621][Wall Clock 302.751269345s] Trained 120 records in 0.039418877 seconds. Throughput is 3044.2268 records/second. Loss is 0.15513617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004302925989672978. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 14640/60000][Iteration 6622][Wall Clock 302.790370601s] Trained 120 records in 0.039101256 seconds. Throughput is 3068.9553 records/second. Loss is 0.22274882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004302555718096549. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 14760/60000][Iteration 6623][Wall Clock 302.831203116s] Trained 120 records in 0.040832515 seconds. Throughput is 2938.8342 records/second. Loss is 0.20549488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004302185510239202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 14880/60000][Iteration 6624][Wall Clock 302.871798025s] Trained 120 records in 0.040594909 seconds. Throughput is 2956.0356 records/second. Loss is 0.1376672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004301815366084487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15000/60000][Iteration 6625][Wall Clock 302.911710895s] Trained 120 records in 0.03991287 seconds. Throughput is 3006.549 records/second. Loss is 0.118066214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004301445285615968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15120/60000][Iteration 6626][Wall Clock 302.955857868s] Trained 120 records in 0.044146973 seconds. Throughput is 2718.193 records/second. Loss is 0.17328222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004301075268817204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15240/60000][Iteration 6627][Wall Clock 303.006956276s] Trained 120 records in 0.051098408 seconds. Throughput is 2348.41 records/second. Loss is 0.17171855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00430070531567177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15360/60000][Iteration 6628][Wall Clock 303.052427249s] Trained 120 records in 0.045470973 seconds. Throughput is 2639.0464 records/second. Loss is 0.13247922. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004300335426163241. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15480/60000][Iteration 6629][Wall Clock 303.093336714s] Trained 120 records in 0.040909465 seconds. Throughput is 2933.3064 records/second. Loss is 0.22193694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004299965600275198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15600/60000][Iteration 6630][Wall Clock 303.134031286s] Trained 120 records in 0.040694572 seconds. Throughput is 2948.7961 records/second. Loss is 0.20461585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004299595837991229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15720/60000][Iteration 6631][Wall Clock 303.174241827s] Trained 120 records in 0.040210541 seconds. Throughput is 2984.292 records/second. Loss is 0.23321208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004299226139294927. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15840/60000][Iteration 6632][Wall Clock 303.21437585s] Trained 120 records in 0.040134023 seconds. Throughput is 2989.9817 records/second. Loss is 0.24751253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004298856504169891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 15960/60000][Iteration 6633][Wall Clock 303.254289071s] Trained 120 records in 0.039913221 seconds. Throughput is 3006.5225 records/second. Loss is 0.16364524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004298486932599725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 16080/60000][Iteration 6634][Wall Clock 303.294895946s] Trained 120 records in 0.040606875 seconds. Throughput is 2955.1646 records/second. Loss is 0.1035539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004298117424568039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 16200/60000][Iteration 6635][Wall Clock 303.335802811s] Trained 120 records in 0.040906865 seconds. Throughput is 2933.493 records/second. Loss is 0.09203385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042977479800584495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 16320/60000][Iteration 6636][Wall Clock 303.375976282s] Trained 120 records in 0.040173471 seconds. Throughput is 2987.046 records/second. Loss is 0.2844968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004297378599054577. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 16440/60000][Iteration 6637][Wall Clock 303.416531465s] Trained 120 records in 0.040555183 seconds. Throughput is 2958.9314 records/second. Loss is 0.12586339. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004297009281540047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 16560/60000][Iteration 6638][Wall Clock 303.457210503s] Trained 120 records in 0.040679038 seconds. Throughput is 2949.9224 records/second. Loss is 0.20694354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042966400274984965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 16680/60000][Iteration 6639][Wall Clock 303.497876355s] Trained 120 records in 0.040665852 seconds. Throughput is 2950.8787 records/second. Loss is 0.17901735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004296270836913559. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:09 INFO  DistriOptimizer$:406 - [Epoch 14 16800/60000][Iteration 6640][Wall Clock 303.5382915s] Trained 120 records in 0.040415145 seconds. Throughput is 2969.1838 records/second. Loss is 0.17197853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004295901709768881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 16920/60000][Iteration 6641][Wall Clock 303.579232093s] Trained 120 records in 0.040940593 seconds. Throughput is 2931.0762 records/second. Loss is 0.12830819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042955326460481094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17040/60000][Iteration 6642][Wall Clock 303.620319403s] Trained 120 records in 0.04108731 seconds. Throughput is 2920.6096 records/second. Loss is 0.18393786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004295163645734903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17160/60000][Iteration 6643][Wall Clock 303.660309372s] Trained 120 records in 0.039989969 seconds. Throughput is 3000.7524 records/second. Loss is 0.17490225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004294794708812918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17280/60000][Iteration 6644][Wall Clock 303.700768464s] Trained 120 records in 0.040459092 seconds. Throughput is 2965.9587 records/second. Loss is 0.21591653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004294425835265825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17400/60000][Iteration 6645][Wall Clock 303.758086071s] Trained 120 records in 0.057317607 seconds. Throughput is 2093.5974 records/second. Loss is 0.2065106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004294057025077293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17520/60000][Iteration 6646][Wall Clock 303.800943551s] Trained 120 records in 0.04285748 seconds. Throughput is 2799.978 records/second. Loss is 0.20963487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004293688278231001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17640/60000][Iteration 6647][Wall Clock 303.841060413s] Trained 120 records in 0.040116862 seconds. Throughput is 2991.261 records/second. Loss is 0.21741118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00429331959471063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17760/60000][Iteration 6648][Wall Clock 303.88116235s] Trained 120 records in 0.040101937 seconds. Throughput is 2992.374 records/second. Loss is 0.125411. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004292950974499871. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 17880/60000][Iteration 6649][Wall Clock 303.921061319s] Trained 120 records in 0.039898969 seconds. Throughput is 3007.5964 records/second. Loss is 0.19201712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004292582417582417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18000/60000][Iteration 6650][Wall Clock 303.961598549s] Trained 120 records in 0.04053723 seconds. Throughput is 2960.2417 records/second. Loss is 0.27786896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004292213923941969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18120/60000][Iteration 6651][Wall Clock 304.007989798s] Trained 120 records in 0.046391249 seconds. Throughput is 2586.6948 records/second. Loss is 0.20791994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004291845493562232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18240/60000][Iteration 6652][Wall Clock 304.052389849s] Trained 120 records in 0.044400051 seconds. Throughput is 2702.6995 records/second. Loss is 0.2424526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004291477126426916. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18360/60000][Iteration 6653][Wall Clock 304.099443763s] Trained 120 records in 0.047053914 seconds. Throughput is 2550.266 records/second. Loss is 0.17442611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004291108822519739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18480/60000][Iteration 6654][Wall Clock 304.142432364s] Trained 120 records in 0.042988601 seconds. Throughput is 2791.4375 records/second. Loss is 0.15201317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004290740581824423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18600/60000][Iteration 6655][Wall Clock 304.182754239s] Trained 120 records in 0.040321875 seconds. Throughput is 2976.052 records/second. Loss is 0.21773179. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004290372404324696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18720/60000][Iteration 6656][Wall Clock 304.225910774s] Trained 120 records in 0.043156535 seconds. Throughput is 2780.5754 records/second. Loss is 0.16999307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004290004290004291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18840/60000][Iteration 6657][Wall Clock 304.278395411s] Trained 120 records in 0.052484637 seconds. Throughput is 2286.3833 records/second. Loss is 0.12244676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004289636238846946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 18960/60000][Iteration 6658][Wall Clock 304.320159167s] Trained 120 records in 0.041763756 seconds. Throughput is 2873.3047 records/second. Loss is 0.18022178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004289268250836407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 19080/60000][Iteration 6659][Wall Clock 304.360057246s] Trained 120 records in 0.039898079 seconds. Throughput is 3007.6636 records/second. Loss is 0.11478359. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004288900325956425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 19200/60000][Iteration 6660][Wall Clock 304.399510098s] Trained 120 records in 0.039452852 seconds. Throughput is 3041.6052 records/second. Loss is 0.19117667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004288532464190754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 19320/60000][Iteration 6661][Wall Clock 304.439339778s] Trained 120 records in 0.03982968 seconds. Throughput is 3012.8286 records/second. Loss is 0.22354923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004288164665523156. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 19440/60000][Iteration 6662][Wall Clock 304.47962946s] Trained 120 records in 0.040289682 seconds. Throughput is 2978.4302 records/second. Loss is 0.17766796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004287796929937398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 19560/60000][Iteration 6663][Wall Clock 304.51945869s] Trained 120 records in 0.03982923 seconds. Throughput is 3012.8625 records/second. Loss is 0.21347393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004287429257417253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:10 INFO  DistriOptimizer$:406 - [Epoch 14 19680/60000][Iteration 6664][Wall Clock 304.563182644s] Trained 120 records in 0.043723954 seconds. Throughput is 2744.491 records/second. Loss is 0.22559708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004287061647946497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 19800/60000][Iteration 6665][Wall Clock 304.603705353s] Trained 120 records in 0.040522709 seconds. Throughput is 2961.3025 records/second. Loss is 0.2304087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042866941015089165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 19920/60000][Iteration 6666][Wall Clock 304.644366881s] Trained 120 records in 0.040661528 seconds. Throughput is 2951.1926 records/second. Loss is 0.21866967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042863266180882984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20040/60000][Iteration 6667][Wall Clock 304.685023578s] Trained 120 records in 0.040656697 seconds. Throughput is 2951.5432 records/second. Loss is 0.2353119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004285959197668438. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20160/60000][Iteration 6668][Wall Clock 304.725701573s] Trained 120 records in 0.040677995 seconds. Throughput is 2949.998 records/second. Loss is 0.22982234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004285591840233136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20280/60000][Iteration 6669][Wall Clock 304.766120022s] Trained 120 records in 0.040418449 seconds. Throughput is 2968.9412 records/second. Loss is 0.19069675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004285224545766198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20400/60000][Iteration 6670][Wall Clock 304.80677165s] Trained 120 records in 0.040651628 seconds. Throughput is 2951.9114 records/second. Loss is 0.16920213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004284857314251435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20520/60000][Iteration 6671][Wall Clock 304.854318214s] Trained 120 records in 0.047546564 seconds. Throughput is 2523.8416 records/second. Loss is 0.23322271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004284490145672665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20640/60000][Iteration 6672][Wall Clock 304.903774949s] Trained 120 records in 0.049456735 seconds. Throughput is 2426.3633 records/second. Loss is 0.1573802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004284123040013709. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20760/60000][Iteration 6673][Wall Clock 304.947455703s] Trained 120 records in 0.043680754 seconds. Throughput is 2747.2053 records/second. Loss is 0.20694664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004283755997258396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 20880/60000][Iteration 6674][Wall Clock 304.987827872s] Trained 120 records in 0.040372169 seconds. Throughput is 2972.3445 records/second. Loss is 0.29724672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00428338901739056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21000/60000][Iteration 6675][Wall Clock 305.028930684s] Trained 120 records in 0.041102812 seconds. Throughput is 2919.5083 records/second. Loss is 0.12940986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004283022100394038. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21120/60000][Iteration 6676][Wall Clock 305.070745047s] Trained 120 records in 0.041814363 seconds. Throughput is 2869.8271 records/second. Loss is 0.19237779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004282655246252677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21240/60000][Iteration 6677][Wall Clock 305.112472597s] Trained 120 records in 0.04172755 seconds. Throughput is 2875.7979 records/second. Loss is 0.13997789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004282288454950325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21360/60000][Iteration 6678][Wall Clock 305.153555602s] Trained 120 records in 0.041083005 seconds. Throughput is 2920.9158 records/second. Loss is 0.16765662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00428192172647084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21480/60000][Iteration 6679][Wall Clock 305.196157252s] Trained 120 records in 0.04260165 seconds. Throughput is 2816.7925 records/second. Loss is 0.17655574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004281555060798081. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21600/60000][Iteration 6680][Wall Clock 305.247057546s] Trained 120 records in 0.050900294 seconds. Throughput is 2357.55 records/second. Loss is 0.1816128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004281188457915918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21720/60000][Iteration 6681][Wall Clock 305.28794798s] Trained 120 records in 0.040890434 seconds. Throughput is 2934.6719 records/second. Loss is 0.19380836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004280821917808219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21840/60000][Iteration 6682][Wall Clock 305.33209434s] Trained 120 records in 0.04414636 seconds. Throughput is 2718.231 records/second. Loss is 0.12677234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004280455440458865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 21960/60000][Iteration 6683][Wall Clock 305.373264482s] Trained 120 records in 0.041170142 seconds. Throughput is 2914.7336 records/second. Loss is 0.25161827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004280089025851737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 22080/60000][Iteration 6684][Wall Clock 305.413994338s] Trained 120 records in 0.040729856 seconds. Throughput is 2946.242 records/second. Loss is 0.17456053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004279722673970727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 22200/60000][Iteration 6685][Wall Clock 305.454974865s] Trained 120 records in 0.040980527 seconds. Throughput is 2928.2202 records/second. Loss is 0.1846663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004279356384799726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 22320/60000][Iteration 6686][Wall Clock 305.496468062s] Trained 120 records in 0.041493197 seconds. Throughput is 2892.0405 records/second. Loss is 0.1323892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004278990158322636. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:11 INFO  DistriOptimizer$:406 - [Epoch 14 22440/60000][Iteration 6687][Wall Clock 305.537293479s] Trained 120 records in 0.040825417 seconds. Throughput is 2939.3455 records/second. Loss is 0.19595759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004278623994523361. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 22560/60000][Iteration 6688][Wall Clock 305.577632159s] Trained 120 records in 0.04033868 seconds. Throughput is 2974.8123 records/second. Loss is 0.18866004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004278257893385813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 22680/60000][Iteration 6689][Wall Clock 305.617355102s] Trained 120 records in 0.039722943 seconds. Throughput is 3020.9243 records/second. Loss is 0.11417239. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004277891854893908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 22800/60000][Iteration 6690][Wall Clock 305.657993318s] Trained 120 records in 0.040638216 seconds. Throughput is 2952.8855 records/second. Loss is 0.17602839. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004277525879031568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 22920/60000][Iteration 6691][Wall Clock 305.697906718s] Trained 120 records in 0.0399134 seconds. Throughput is 3006.509 records/second. Loss is 0.2126214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00427715996578272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23040/60000][Iteration 6692][Wall Clock 305.73782244s] Trained 120 records in 0.039915722 seconds. Throughput is 3006.3342 records/second. Loss is 0.17323534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004276794115131297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23160/60000][Iteration 6693][Wall Clock 305.777712969s] Trained 120 records in 0.039890529 seconds. Throughput is 3008.233 records/second. Loss is 0.22527473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004276428327061239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23280/60000][Iteration 6694][Wall Clock 305.817481488s] Trained 120 records in 0.039768519 seconds. Throughput is 3017.462 records/second. Loss is 0.124869354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004276062601556487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23400/60000][Iteration 6695][Wall Clock 305.857411233s] Trained 120 records in 0.039929745 seconds. Throughput is 3005.2786 records/second. Loss is 0.14349517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004275696938600992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23520/60000][Iteration 6696][Wall Clock 305.897760263s] Trained 120 records in 0.04034903 seconds. Throughput is 2974.0493 records/second. Loss is 0.20939738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004275331338178709. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23640/60000][Iteration 6697][Wall Clock 305.93758416s] Trained 120 records in 0.039823897 seconds. Throughput is 3013.266 records/second. Loss is 0.15815815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004274965800273598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23760/60000][Iteration 6698][Wall Clock 305.986895364s] Trained 120 records in 0.049311204 seconds. Throughput is 2433.524 records/second. Loss is 0.07833792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004274600324869624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 23880/60000][Iteration 6699][Wall Clock 306.034820193s] Trained 120 records in 0.047924829 seconds. Throughput is 2503.9214 records/second. Loss is 0.27056873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042742349119507615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24000/60000][Iteration 6700][Wall Clock 306.077392557s] Trained 120 records in 0.042572364 seconds. Throughput is 2818.73 records/second. Loss is 0.17747946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042738695615009824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24120/60000][Iteration 6701][Wall Clock 306.122137324s] Trained 120 records in 0.044744767 seconds. Throughput is 2681.878 records/second. Loss is 0.20568098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004273504273504274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24240/60000][Iteration 6702][Wall Clock 306.164265585s] Trained 120 records in 0.042128261 seconds. Throughput is 2848.444 records/second. Loss is 0.11801405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00427313904794462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24360/60000][Iteration 6703][Wall Clock 306.204473303s] Trained 120 records in 0.040207718 seconds. Throughput is 2984.5017 records/second. Loss is 0.15002891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004272773884806016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24480/60000][Iteration 6704][Wall Clock 306.244672365s] Trained 120 records in 0.040199062 seconds. Throughput is 2985.144 records/second. Loss is 0.20965256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00427240878407246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24600/60000][Iteration 6705][Wall Clock 306.285982628s] Trained 120 records in 0.041310263 seconds. Throughput is 2904.8472 records/second. Loss is 0.20063348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042720437457279565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24720/60000][Iteration 6706][Wall Clock 306.333810336s] Trained 120 records in 0.047827708 seconds. Throughput is 2509.0059 records/second. Loss is 0.31047612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004271678769756514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24840/60000][Iteration 6707][Wall Clock 306.379912494s] Trained 120 records in 0.046102158 seconds. Throughput is 2602.915 records/second. Loss is 0.16697653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004271313856142149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 24960/60000][Iteration 6708][Wall Clock 306.421237724s] Trained 120 records in 0.04132523 seconds. Throughput is 2903.7952 records/second. Loss is 0.16172233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004270949004868882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 25080/60000][Iteration 6709][Wall Clock 306.46152132s] Trained 120 records in 0.040283596 seconds. Throughput is 2978.8801 records/second. Loss is 0.19156747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004270584215920738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 25200/60000][Iteration 6710][Wall Clock 306.501477392s] Trained 120 records in 0.039956072 seconds. Throughput is 3003.2983 records/second. Loss is 0.23755403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004270219489281749. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:12 INFO  DistriOptimizer$:406 - [Epoch 14 25320/60000][Iteration 6711][Wall Clock 306.540908635s] Trained 120 records in 0.039431243 seconds. Throughput is 3043.272 records/second. Loss is 0.105511144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004269854824935952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 25440/60000][Iteration 6712][Wall Clock 306.581739619s] Trained 120 records in 0.040830984 seconds. Throughput is 2938.9446 records/second. Loss is 0.2736435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004269490222867389. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 25560/60000][Iteration 6713][Wall Clock 306.622554695s] Trained 120 records in 0.040815076 seconds. Throughput is 2940.0898 records/second. Loss is 0.17586704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00426912568306011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 25680/60000][Iteration 6714][Wall Clock 306.663436357s] Trained 120 records in 0.040881662 seconds. Throughput is 2935.3013 records/second. Loss is 0.28505787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004268761205498165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 25800/60000][Iteration 6715][Wall Clock 306.703886062s] Trained 120 records in 0.040449705 seconds. Throughput is 2966.6472 records/second. Loss is 0.23184432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004268396790165614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 25920/60000][Iteration 6716][Wall Clock 306.743894144s] Trained 120 records in 0.040008082 seconds. Throughput is 2999.3938 records/second. Loss is 0.20243222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004268032437046522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26040/60000][Iteration 6717][Wall Clock 306.784004249s] Trained 120 records in 0.040110105 seconds. Throughput is 2991.765 records/second. Loss is 0.21788666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004267668146124956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26160/60000][Iteration 6718][Wall Clock 306.824043584s] Trained 120 records in 0.040039335 seconds. Throughput is 2997.0527 records/second. Loss is 0.2320549. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004267303917384996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26280/60000][Iteration 6719][Wall Clock 306.865014136s] Trained 120 records in 0.040970552 seconds. Throughput is 2928.9329 records/second. Loss is 0.13826878. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004266939750810718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26400/60000][Iteration 6720][Wall Clock 306.908647461s] Trained 120 records in 0.043633325 seconds. Throughput is 2750.1917 records/second. Loss is 0.17377132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004266575646386211. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26520/60000][Iteration 6721][Wall Clock 306.949076142s] Trained 120 records in 0.040428681 seconds. Throughput is 2968.19 records/second. Loss is 0.17823222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004266211604095562. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26640/60000][Iteration 6722][Wall Clock 306.990872722s] Trained 120 records in 0.04179658 seconds. Throughput is 2871.0483 records/second. Loss is 0.21317317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004265847623922874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26760/60000][Iteration 6723][Wall Clock 307.031385987s] Trained 120 records in 0.040513265 seconds. Throughput is 2961.9927 records/second. Loss is 0.17632008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042654837058522434. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 26880/60000][Iteration 6724][Wall Clock 307.072466285s] Trained 120 records in 0.041080298 seconds. Throughput is 2921.1082 records/second. Loss is 0.16578417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042651198498677816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27000/60000][Iteration 6725][Wall Clock 307.126653211s] Trained 120 records in 0.054186926 seconds. Throughput is 2214.5564 records/second. Loss is 0.24936531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004264756055953599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27120/60000][Iteration 6726][Wall Clock 307.174173103s] Trained 120 records in 0.047519892 seconds. Throughput is 2525.2583 records/second. Loss is 0.1463174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004264392324093817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27240/60000][Iteration 6727][Wall Clock 307.216244791s] Trained 120 records in 0.042071688 seconds. Throughput is 2852.2744 records/second. Loss is 0.14695914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004264028654272557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27360/60000][Iteration 6728][Wall Clock 307.256903727s] Trained 120 records in 0.040658936 seconds. Throughput is 2951.3806 records/second. Loss is 0.19386064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004263665046473949. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27480/60000][Iteration 6729][Wall Clock 307.297325972s] Trained 120 records in 0.040422245 seconds. Throughput is 2968.6624 records/second. Loss is 0.17460033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004263301500682128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27600/60000][Iteration 6730][Wall Clock 307.337337476s] Trained 120 records in 0.040011504 seconds. Throughput is 2999.1375 records/second. Loss is 0.17487472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004262938016881234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27720/60000][Iteration 6731][Wall Clock 307.377408022s] Trained 120 records in 0.040070546 seconds. Throughput is 2994.7185 records/second. Loss is 0.15365744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004262574595055414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27840/60000][Iteration 6732][Wall Clock 307.41725335s] Trained 120 records in 0.039845328 seconds. Throughput is 3011.6453 records/second. Loss is 0.13585545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004262211235188816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 27960/60000][Iteration 6733][Wall Clock 307.4753736s] Trained 120 records in 0.05812025 seconds. Throughput is 2064.6848 records/second. Loss is 0.14538017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042618479372655985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:13 INFO  DistriOptimizer$:406 - [Epoch 14 28080/60000][Iteration 6734][Wall Clock 307.521352584s] Trained 120 records in 0.045978984 seconds. Throughput is 2609.888 records/second. Loss is 0.16055408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004261484701269923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 28200/60000][Iteration 6735][Wall Clock 307.561761861s] Trained 120 records in 0.040409277 seconds. Throughput is 2969.615 records/second. Loss is 0.21840169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004261121527185955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 28320/60000][Iteration 6736][Wall Clock 307.602470162s] Trained 120 records in 0.040708301 seconds. Throughput is 2947.8018 records/second. Loss is 0.109105036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00426075841499787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 28440/60000][Iteration 6737][Wall Clock 307.642792415s] Trained 120 records in 0.040322253 seconds. Throughput is 2976.0242 records/second. Loss is 0.18764658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004260395364689844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 28560/60000][Iteration 6738][Wall Clock 307.682851763s] Trained 120 records in 0.040059348 seconds. Throughput is 2995.5557 records/second. Loss is 0.19975449. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004260032376246059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 28680/60000][Iteration 6739][Wall Clock 307.726598032s] Trained 120 records in 0.043746269 seconds. Throughput is 2743.091 records/second. Loss is 0.15453252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004259669449650707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 28800/60000][Iteration 6740][Wall Clock 307.76746631s] Trained 120 records in 0.040868278 seconds. Throughput is 2936.2627 records/second. Loss is 0.10203204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00425930658488798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 28920/60000][Iteration 6741][Wall Clock 307.807632825s] Trained 120 records in 0.040166515 seconds. Throughput is 2987.563 records/second. Loss is 0.26624605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004258943781942079. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29040/60000][Iteration 6742][Wall Clock 307.847962575s] Trained 120 records in 0.04032975 seconds. Throughput is 2975.471 records/second. Loss is 0.1138118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004258581040797206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29160/60000][Iteration 6743][Wall Clock 307.888860854s] Trained 120 records in 0.040898279 seconds. Throughput is 2934.109 records/second. Loss is 0.19754563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042582183614375746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29280/60000][Iteration 6744][Wall Clock 307.928543587s] Trained 120 records in 0.039682733 seconds. Throughput is 3023.985 records/second. Loss is 0.18791111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004257855743847398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29400/60000][Iteration 6745][Wall Clock 307.96896367s] Trained 120 records in 0.040420083 seconds. Throughput is 2968.8213 records/second. Loss is 0.1476837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042574931880109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29520/60000][Iteration 6746][Wall Clock 308.009833812s] Trained 120 records in 0.040870142 seconds. Throughput is 2936.129 records/second. Loss is 0.17993638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004257130693912303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29640/60000][Iteration 6747][Wall Clock 308.05047941s] Trained 120 records in 0.040645598 seconds. Throughput is 2952.349 records/second. Loss is 0.21821673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004256768261535843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29760/60000][Iteration 6748][Wall Clock 308.091718233s] Trained 120 records in 0.041238823 seconds. Throughput is 2909.8794 records/second. Loss is 0.27444917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004256405890865753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 29880/60000][Iteration 6749][Wall Clock 308.133710568s] Trained 120 records in 0.041992335 seconds. Throughput is 2857.6643 records/second. Loss is 0.1522867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004256043581886278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30000/60000][Iteration 6750][Wall Clock 308.182864057s] Trained 120 records in 0.049153489 seconds. Throughput is 2441.3323 records/second. Loss is 0.08557568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004255681334581666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30120/60000][Iteration 6751][Wall Clock 308.234317897s] Trained 120 records in 0.05145384 seconds. Throughput is 2332.1875 records/second. Loss is 0.07933131. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00425531914893617. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30240/60000][Iteration 6752][Wall Clock 308.281507978s] Trained 120 records in 0.047190081 seconds. Throughput is 2542.9072 records/second. Loss is 0.09726822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004254957024934048. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30360/60000][Iteration 6753][Wall Clock 308.322356834s] Trained 120 records in 0.040848856 seconds. Throughput is 2937.659 records/second. Loss is 0.17558537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004254594962559565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30480/60000][Iteration 6754][Wall Clock 308.36410399s] Trained 120 records in 0.041747156 seconds. Throughput is 2874.4473 records/second. Loss is 0.21171132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004254232961796988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30600/60000][Iteration 6755][Wall Clock 308.404695101s] Trained 120 records in 0.040591111 seconds. Throughput is 2956.3125 records/second. Loss is 0.21189165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004253871022630594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30720/60000][Iteration 6756][Wall Clock 308.44552945s] Trained 120 records in 0.040834349 seconds. Throughput is 2938.7024 records/second. Loss is 0.28355747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004253509145044662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30840/60000][Iteration 6757][Wall Clock 308.489562173s] Trained 120 records in 0.044032723 seconds. Throughput is 2725.2458 records/second. Loss is 0.20518987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004253147329023477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:14 INFO  DistriOptimizer$:406 - [Epoch 14 30960/60000][Iteration 6758][Wall Clock 308.530235142s] Trained 120 records in 0.040672969 seconds. Throughput is 2950.3625 records/second. Loss is 0.24306765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004252785574551331. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31080/60000][Iteration 6759][Wall Clock 308.570967527s] Trained 120 records in 0.040732385 seconds. Throughput is 2946.0588 records/second. Loss is 0.1647454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004252423881612518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31200/60000][Iteration 6760][Wall Clock 308.622485139s] Trained 120 records in 0.051517612 seconds. Throughput is 2329.3005 records/second. Loss is 0.18419324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004252062250191343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31320/60000][Iteration 6761][Wall Clock 308.664280388s] Trained 120 records in 0.041795249 seconds. Throughput is 2871.1396 records/second. Loss is 0.23251802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004251700680272108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31440/60000][Iteration 6762][Wall Clock 308.705242077s] Trained 120 records in 0.040961689 seconds. Throughput is 2929.5667 records/second. Loss is 0.16060042. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042513391718391295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31560/60000][Iteration 6763][Wall Clock 308.745913178s] Trained 120 records in 0.040671101 seconds. Throughput is 2950.4978 records/second. Loss is 0.12159472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042509777248767215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31680/60000][Iteration 6764][Wall Clock 308.786381728s] Trained 120 records in 0.04046855 seconds. Throughput is 2965.2656 records/second. Loss is 0.108246475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004250616339369209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31800/60000][Iteration 6765][Wall Clock 308.827343171s] Trained 120 records in 0.040961443 seconds. Throughput is 2929.5842 records/second. Loss is 0.14439745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004250255015300917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 31920/60000][Iteration 6766][Wall Clock 308.867508927s] Trained 120 records in 0.040165756 seconds. Throughput is 2987.6196 records/second. Loss is 0.22879711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004249893752656184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32040/60000][Iteration 6767][Wall Clock 308.90764483s] Trained 120 records in 0.040135903 seconds. Throughput is 2989.8418 records/second. Loss is 0.29596144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004249532551419344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32160/60000][Iteration 6768][Wall Clock 308.947974738s] Trained 120 records in 0.040329908 seconds. Throughput is 2975.4595 records/second. Loss is 0.19979592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042491714115747425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32280/60000][Iteration 6769][Wall Clock 308.988774224s] Trained 120 records in 0.040799486 seconds. Throughput is 2941.2134 records/second. Loss is 0.29122034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00424881033310673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32400/60000][Iteration 6770][Wall Clock 309.029247138s] Trained 120 records in 0.040472914 seconds. Throughput is 2964.946 records/second. Loss is 0.12596771. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00424844931599966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32520/60000][Iteration 6771][Wall Clock 309.070122566s] Trained 120 records in 0.040875428 seconds. Throughput is 2935.749 records/second. Loss is 0.1788725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004248088360237893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32640/60000][Iteration 6772][Wall Clock 309.110251757s] Trained 120 records in 0.040129191 seconds. Throughput is 2990.3418 records/second. Loss is 0.17946668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004247727465805794. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32760/60000][Iteration 6773][Wall Clock 309.150584288s] Trained 120 records in 0.040332531 seconds. Throughput is 2975.2659 records/second. Loss is 0.25258562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004247366632687734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 32880/60000][Iteration 6774][Wall Clock 309.190553839s] Trained 120 records in 0.039969551 seconds. Throughput is 3002.2854 records/second. Loss is 0.1747377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004247005860868088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33000/60000][Iteration 6775][Wall Clock 309.230940249s] Trained 120 records in 0.04038641 seconds. Throughput is 2971.2966 records/second. Loss is 0.2518325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004246645150331238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33120/60000][Iteration 6776][Wall Clock 309.280386716s] Trained 120 records in 0.049446467 seconds. Throughput is 2426.867 records/second. Loss is 0.18378939. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004246284501061571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33240/60000][Iteration 6777][Wall Clock 309.329984029s] Trained 120 records in 0.049597313 seconds. Throughput is 2419.486 records/second. Loss is 0.115508765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004245923913043478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33360/60000][Iteration 6778][Wall Clock 309.371494354s] Trained 120 records in 0.041510325 seconds. Throughput is 2890.847 records/second. Loss is 0.18209168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004245563386261356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33480/60000][Iteration 6779][Wall Clock 309.412331243s] Trained 120 records in 0.040836889 seconds. Throughput is 2938.5195 records/second. Loss is 0.10855985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042452029206996094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33600/60000][Iteration 6780][Wall Clock 309.452469994s] Trained 120 records in 0.040138751 seconds. Throughput is 2989.6296 records/second. Loss is 0.21142676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042448425163426435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33720/60000][Iteration 6781][Wall Clock 309.492188451s] Trained 120 records in 0.039718457 seconds. Throughput is 3021.2654 records/second. Loss is 0.10948117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004244482173174873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:15 INFO  DistriOptimizer$:406 - [Epoch 14 33840/60000][Iteration 6782][Wall Clock 309.531308012s] Trained 120 records in 0.039119561 seconds. Throughput is 3067.519 records/second. Loss is 0.2934372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004244121891180714. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 33960/60000][Iteration 6783][Wall Clock 309.571054634s] Trained 120 records in 0.039746622 seconds. Throughput is 3019.1243 records/second. Loss is 0.17075112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004243761670344594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34080/60000][Iteration 6784][Wall Clock 309.611077003s] Trained 120 records in 0.040022369 seconds. Throughput is 2998.3232 records/second. Loss is 0.15567954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004243401510650937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34200/60000][Iteration 6785][Wall Clock 309.652009154s] Trained 120 records in 0.040932151 seconds. Throughput is 2931.6807 records/second. Loss is 0.11650678. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004243041412084182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34320/60000][Iteration 6786][Wall Clock 309.698698817s] Trained 120 records in 0.046689663 seconds. Throughput is 2570.162 records/second. Loss is 0.13617341. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004242681374628765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34440/60000][Iteration 6787][Wall Clock 309.743178682s] Trained 120 records in 0.044479865 seconds. Throughput is 2697.8499 records/second. Loss is 0.21468614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004242321398269133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34560/60000][Iteration 6788][Wall Clock 309.783172584s] Trained 120 records in 0.039993902 seconds. Throughput is 3000.4575 records/second. Loss is 0.11300669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004241961482989734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34680/60000][Iteration 6789][Wall Clock 309.822961701s] Trained 120 records in 0.039789117 seconds. Throughput is 3015.9 records/second. Loss is 0.24972402. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004241601628775025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34800/60000][Iteration 6790][Wall Clock 309.862707218s] Trained 120 records in 0.039745517 seconds. Throughput is 3019.2085 records/second. Loss is 0.14967902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004241241835609466. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 34920/60000][Iteration 6791][Wall Clock 309.902224047s] Trained 120 records in 0.039516829 seconds. Throughput is 3036.681 records/second. Loss is 0.20626289. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004240882103477523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35040/60000][Iteration 6792][Wall Clock 309.941540066s] Trained 120 records in 0.039316019 seconds. Throughput is 3052.1912 records/second. Loss is 0.18906845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042405224323636675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35160/60000][Iteration 6793][Wall Clock 309.981234156s] Trained 120 records in 0.03969409 seconds. Throughput is 3023.12 records/second. Loss is 0.10963564. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004240162822252374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35280/60000][Iteration 6794][Wall Clock 310.02134665s] Trained 120 records in 0.040112494 seconds. Throughput is 2991.5864 records/second. Loss is 0.22066276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004239803273128127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35400/60000][Iteration 6795][Wall Clock 310.065886567s] Trained 120 records in 0.044539917 seconds. Throughput is 2694.2124 records/second. Loss is 0.199722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004239443784975411. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35520/60000][Iteration 6796][Wall Clock 310.106716835s] Trained 120 records in 0.040830268 seconds. Throughput is 2938.996 records/second. Loss is 0.25969666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00423908435777872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35640/60000][Iteration 6797][Wall Clock 310.147917517s] Trained 120 records in 0.041200682 seconds. Throughput is 2912.573 records/second. Loss is 0.18009461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00423872499152255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35760/60000][Iteration 6798][Wall Clock 310.188489278s] Trained 120 records in 0.040571761 seconds. Throughput is 2957.7222 records/second. Loss is 0.11034473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004238365686191405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 35880/60000][Iteration 6799][Wall Clock 310.228887635s] Trained 120 records in 0.040398357 seconds. Throughput is 2970.418 records/second. Loss is 0.20186296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004238006441769791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 36000/60000][Iteration 6800][Wall Clock 310.269367678s] Trained 120 records in 0.040480043 seconds. Throughput is 2964.4236 records/second. Loss is 0.21256024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004237647258242224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 36120/60000][Iteration 6801][Wall Clock 310.319300793s] Trained 120 records in 0.049933115 seconds. Throughput is 2403.2148 records/second. Loss is 0.1772907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042372881355932195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 36240/60000][Iteration 6802][Wall Clock 310.369835719s] Trained 120 records in 0.050534926 seconds. Throughput is 2374.5952 records/second. Loss is 0.23781617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004236929073807304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 36360/60000][Iteration 6803][Wall Clock 310.410932752s] Trained 120 records in 0.041097033 seconds. Throughput is 2919.9187 records/second. Loss is 0.15333372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042365700728690045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 36480/60000][Iteration 6804][Wall Clock 310.451900471s] Trained 120 records in 0.040967719 seconds. Throughput is 2929.1355 records/second. Loss is 0.15202017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004236211132762857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 36600/60000][Iteration 6805][Wall Clock 310.493803807s] Trained 120 records in 0.041903336 seconds. Throughput is 2863.734 records/second. Loss is 0.27543786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042358522534733985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:16 INFO  DistriOptimizer$:406 - [Epoch 14 36720/60000][Iteration 6806][Wall Clock 310.534987972s] Trained 120 records in 0.041184165 seconds. Throughput is 2913.7412 records/second. Loss is 0.12060924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004235493434985176. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 36840/60000][Iteration 6807][Wall Clock 310.575600436s] Trained 120 records in 0.040612464 seconds. Throughput is 2954.758 records/second. Loss is 0.10063874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042351346772827375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 36960/60000][Iteration 6808][Wall Clock 310.616127963s] Trained 120 records in 0.040527527 seconds. Throughput is 2960.9504 records/second. Loss is 0.1416151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004234775980350639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37080/60000][Iteration 6809][Wall Clock 310.656294744s] Trained 120 records in 0.040166781 seconds. Throughput is 2987.5435 records/second. Loss is 0.16839927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004234417344173441. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37200/60000][Iteration 6810][Wall Clock 310.696551813s] Trained 120 records in 0.040257069 seconds. Throughput is 2980.8428 records/second. Loss is 0.14885706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00423405876873571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37320/60000][Iteration 6811][Wall Clock 310.736194829s] Trained 120 records in 0.039643016 seconds. Throughput is 3027.015 records/second. Loss is 0.1972161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004233700254022015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37440/60000][Iteration 6812][Wall Clock 310.776227975s] Trained 120 records in 0.040033146 seconds. Throughput is 2997.516 records/second. Loss is 0.20360254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004233341800016934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37560/60000][Iteration 6813][Wall Clock 310.825199309s] Trained 120 records in 0.048971334 seconds. Throughput is 2450.413 records/second. Loss is 0.15461282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004232983406705046. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37680/60000][Iteration 6814][Wall Clock 310.876066701s] Trained 120 records in 0.050867392 seconds. Throughput is 2359.075 records/second. Loss is 0.21553902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004232625074070939. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37800/60000][Iteration 6815][Wall Clock 310.916565655s] Trained 120 records in 0.040498954 seconds. Throughput is 2963.0396 records/second. Loss is 0.13525201. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004232266802099204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 37920/60000][Iteration 6816][Wall Clock 310.956384654s] Trained 120 records in 0.039818999 seconds. Throughput is 3013.6367 records/second. Loss is 0.1815143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004231908590774439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38040/60000][Iteration 6817][Wall Clock 310.997184719s] Trained 120 records in 0.040800065 seconds. Throughput is 2941.1719 records/second. Loss is 0.31205028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004231550440081246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38160/60000][Iteration 6818][Wall Clock 311.038368437s] Trained 120 records in 0.041183718 seconds. Throughput is 2913.773 records/second. Loss is 0.21331091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00423119235000423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38280/60000][Iteration 6819][Wall Clock 311.080243741s] Trained 120 records in 0.041875304 seconds. Throughput is 2865.651 records/second. Loss is 0.17081591. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004230834320528008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38400/60000][Iteration 6820][Wall Clock 311.122148833s] Trained 120 records in 0.041905092 seconds. Throughput is 2863.614 records/second. Loss is 0.2251305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004230476351637194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38520/60000][Iteration 6821][Wall Clock 311.164089147s] Trained 120 records in 0.041940314 seconds. Throughput is 2861.209 records/second. Loss is 0.21706367. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004230118443316413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38640/60000][Iteration 6822][Wall Clock 311.204727547s] Trained 120 records in 0.0406384 seconds. Throughput is 2952.8723 records/second. Loss is 0.24327224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004229760595550291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38760/60000][Iteration 6823][Wall Clock 311.245654334s] Trained 120 records in 0.040926787 seconds. Throughput is 2932.065 records/second. Loss is 0.20690912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004229402808323465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 38880/60000][Iteration 6824][Wall Clock 311.286243616s] Trained 120 records in 0.040589282 seconds. Throughput is 2956.4456 records/second. Loss is 0.20005783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042290450816205695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 39000/60000][Iteration 6825][Wall Clock 311.326716506s] Trained 120 records in 0.04047289 seconds. Throughput is 2964.9475 records/second. Loss is 0.18395814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042286874154262525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 39120/60000][Iteration 6826][Wall Clock 311.374491555s] Trained 120 records in 0.047775049 seconds. Throughput is 2511.7715 records/second. Loss is 0.21350092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004228329809725158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 39240/60000][Iteration 6827][Wall Clock 311.429919664s] Trained 120 records in 0.055428109 seconds. Throughput is 2164.9666 records/second. Loss is 0.19086955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042279722645019455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 39360/60000][Iteration 6828][Wall Clock 311.471011435s] Trained 120 records in 0.041091771 seconds. Throughput is 2920.2927 records/second. Loss is 0.30180976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00422761477974127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:17 INFO  DistriOptimizer$:406 - [Epoch 14 39480/60000][Iteration 6829][Wall Clock 311.511532988s] Trained 120 records in 0.040521553 seconds. Throughput is 2961.387 records/second. Loss is 0.16229245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004227257355427798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 39600/60000][Iteration 6830][Wall Clock 311.551992713s] Trained 120 records in 0.040459725 seconds. Throughput is 2965.9124 records/second. Loss is 0.19050963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042268999915462. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 39720/60000][Iteration 6831][Wall Clock 311.592242683s] Trained 120 records in 0.04024997 seconds. Throughput is 2981.3687 records/second. Loss is 0.20877734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004226542688081149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 39840/60000][Iteration 6832][Wall Clock 311.636029089s] Trained 120 records in 0.043786406 seconds. Throughput is 2740.5767 records/second. Loss is 0.20616814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004226185445017327. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 39960/60000][Iteration 6833][Wall Clock 311.676403554s] Trained 120 records in 0.040374465 seconds. Throughput is 2972.1755 records/second. Loss is 0.17692225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042258282623394185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40080/60000][Iteration 6834][Wall Clock 311.716812775s] Trained 120 records in 0.040409221 seconds. Throughput is 2969.6191 records/second. Loss is 0.2547383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004225471140032113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40200/60000][Iteration 6835][Wall Clock 311.75809484s] Trained 120 records in 0.041282065 seconds. Throughput is 2906.8313 records/second. Loss is 0.17853372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004225114078080109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40320/60000][Iteration 6836][Wall Clock 311.798521098s] Trained 120 records in 0.040426258 seconds. Throughput is 2968.3677 records/second. Loss is 0.18298656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042247570764681035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40440/60000][Iteration 6837][Wall Clock 311.838465787s] Trained 120 records in 0.039944689 seconds. Throughput is 3004.154 records/second. Loss is 0.13142316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004224400135180805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40560/60000][Iteration 6838][Wall Clock 311.878580446s] Trained 120 records in 0.040114659 seconds. Throughput is 2991.425 records/second. Loss is 0.110379316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004224043254202923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40680/60000][Iteration 6839][Wall Clock 311.919038288s] Trained 120 records in 0.040457842 seconds. Throughput is 2966.0505 records/second. Loss is 0.15764607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004223686433519175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40800/60000][Iteration 6840][Wall Clock 311.968554098s] Trained 120 records in 0.04951581 seconds. Throughput is 2423.4685 records/second. Loss is 0.25922164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042233296731142836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 40920/60000][Iteration 6841][Wall Clock 312.014369326s] Trained 120 records in 0.045815228 seconds. Throughput is 2619.2163 records/second. Loss is 0.13635638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004222972972972972. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41040/60000][Iteration 6842][Wall Clock 312.055320869s] Trained 120 records in 0.040951543 seconds. Throughput is 2930.2925 records/second. Loss is 0.18008186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004222616333079977. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41160/60000][Iteration 6843][Wall Clock 312.096183014s] Trained 120 records in 0.040862145 seconds. Throughput is 2936.7034 records/second. Loss is 0.1872829. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00422225975342003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41280/60000][Iteration 6844][Wall Clock 312.13658392s] Trained 120 records in 0.040400906 seconds. Throughput is 2970.2302 records/second. Loss is 0.11616711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004221903233977878. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41400/60000][Iteration 6845][Wall Clock 312.176813408s] Trained 120 records in 0.040229488 seconds. Throughput is 2982.8865 records/second. Loss is 0.25209785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004221546774738264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41520/60000][Iteration 6846][Wall Clock 312.216877615s] Trained 120 records in 0.040064207 seconds. Throughput is 2995.1921 records/second. Loss is 0.09468393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004221190375685944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41640/60000][Iteration 6847][Wall Clock 312.257333199s] Trained 120 records in 0.040455584 seconds. Throughput is 2966.216 records/second. Loss is 0.18507122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004220834036805673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41760/60000][Iteration 6848][Wall Clock 312.298136906s] Trained 120 records in 0.040803707 seconds. Throughput is 2940.9092 records/second. Loss is 0.1458355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042204777580822144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 41880/60000][Iteration 6849][Wall Clock 312.339208803s] Trained 120 records in 0.041071897 seconds. Throughput is 2921.7058 records/second. Loss is 0.12785129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004220121539500337. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 42000/60000][Iteration 6850][Wall Clock 312.380678406s] Trained 120 records in 0.041469603 seconds. Throughput is 2893.6858 records/second. Loss is 0.19927272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004219765381044814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 42120/60000][Iteration 6851][Wall Clock 312.428787907s] Trained 120 records in 0.048109501 seconds. Throughput is 2494.3098 records/second. Loss is 0.1147554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004219409282700422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 42240/60000][Iteration 6852][Wall Clock 312.483197689s] Trained 120 records in 0.054409782 seconds. Throughput is 2205.4856 records/second. Loss is 0.14315714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004219053244451945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:18 INFO  DistriOptimizer$:406 - [Epoch 14 42360/60000][Iteration 6853][Wall Clock 312.524365777s] Trained 120 records in 0.041168088 seconds. Throughput is 2914.8792 records/second. Loss is 0.16320424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004218697266284171. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 42480/60000][Iteration 6854][Wall Clock 312.564248925s] Trained 120 records in 0.039883148 seconds. Throughput is 3008.7896 records/second. Loss is 0.14341576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004218341348181895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 42600/60000][Iteration 6855][Wall Clock 312.604354409s] Trained 120 records in 0.040105484 seconds. Throughput is 2992.1094 records/second. Loss is 0.24681887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004217985490129914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 42720/60000][Iteration 6856][Wall Clock 312.64453089s] Trained 120 records in 0.040176481 seconds. Throughput is 2986.822 records/second. Loss is 0.109959476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004217629692113032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 42840/60000][Iteration 6857][Wall Clock 312.683725083s] Trained 120 records in 0.039194193 seconds. Throughput is 3061.678 records/second. Loss is 0.20318374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004217273954116059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 42960/60000][Iteration 6858][Wall Clock 312.722812031s] Trained 120 records in 0.039086948 seconds. Throughput is 3070.0784 records/second. Loss is 0.17747952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004216918276123808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43080/60000][Iteration 6859][Wall Clock 312.761553818s] Trained 120 records in 0.038741787 seconds. Throughput is 3097.4307 records/second. Loss is 0.18484227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042165626581211. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43200/60000][Iteration 6860][Wall Clock 312.801487798s] Trained 120 records in 0.03993398 seconds. Throughput is 3004.9597 records/second. Loss is 0.119388565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004216207100092756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43320/60000][Iteration 6861][Wall Clock 312.841538771s] Trained 120 records in 0.040050973 seconds. Throughput is 2996.182 records/second. Loss is 0.11744782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004215851602023609. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43440/60000][Iteration 6862][Wall Clock 312.88114855s] Trained 120 records in 0.039609779 seconds. Throughput is 3029.555 records/second. Loss is 0.13680902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00421549616389849. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43560/60000][Iteration 6863][Wall Clock 312.921358888s] Trained 120 records in 0.040210338 seconds. Throughput is 2984.3074 records/second. Loss is 0.22375207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004215140785702243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43680/60000][Iteration 6864][Wall Clock 312.962002092s] Trained 120 records in 0.040643204 seconds. Throughput is 2952.5232 records/second. Loss is 0.20503451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004214785467419708. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43800/60000][Iteration 6865][Wall Clock 313.002317419s] Trained 120 records in 0.040315327 seconds. Throughput is 2976.5354 records/second. Loss is 0.14104329. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004214430209035739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 43920/60000][Iteration 6866][Wall Clock 313.043453804s] Trained 120 records in 0.041136385 seconds. Throughput is 2917.1257 records/second. Loss is 0.12907109. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004214075010535188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44040/60000][Iteration 6867][Wall Clock 313.099923526s] Trained 120 records in 0.056469722 seconds. Throughput is 2125.0325 records/second. Loss is 0.19457836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042137198719029165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44160/60000][Iteration 6868][Wall Clock 313.144263425s] Trained 120 records in 0.044339899 seconds. Throughput is 2706.3662 records/second. Loss is 0.31118792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004213364793123789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44280/60000][Iteration 6869][Wall Clock 313.188159303s] Trained 120 records in 0.043895878 seconds. Throughput is 2733.742 records/second. Loss is 0.13592193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004213009774182676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44400/60000][Iteration 6870][Wall Clock 313.228957929s] Trained 120 records in 0.040798626 seconds. Throughput is 2941.2754 records/second. Loss is 0.2867756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004212654815064453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44520/60000][Iteration 6871][Wall Clock 313.269443879s] Trained 120 records in 0.04048595 seconds. Throughput is 2963.9915 records/second. Loss is 0.17242403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004212299915754001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44640/60000][Iteration 6872][Wall Clock 313.309527437s] Trained 120 records in 0.040083558 seconds. Throughput is 2993.7463 records/second. Loss is 0.19017753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004211945076236206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44760/60000][Iteration 6873][Wall Clock 313.34999133s] Trained 120 records in 0.040463893 seconds. Throughput is 2965.6067 records/second. Loss is 0.21339461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042115902964959566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 44880/60000][Iteration 6874][Wall Clock 313.390064609s] Trained 120 records in 0.040073279 seconds. Throughput is 2994.5142 records/second. Loss is 0.17359133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004211235576518151. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 45000/60000][Iteration 6875][Wall Clock 313.432109728s] Trained 120 records in 0.042045119 seconds. Throughput is 2854.0767 records/second. Loss is 0.08932323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004210880916287687. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 45120/60000][Iteration 6876][Wall Clock 313.475798964s] Trained 120 records in 0.043689236 seconds. Throughput is 2746.6719 records/second. Loss is 0.16072659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004210526315789474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:19 INFO  DistriOptimizer$:406 - [Epoch 14 45240/60000][Iteration 6877][Wall Clock 313.527103295s] Trained 120 records in 0.051304331 seconds. Throughput is 2338.984 records/second. Loss is 0.17019364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004210171775008421. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 45360/60000][Iteration 6878][Wall Clock 313.571785063s] Trained 120 records in 0.044681768 seconds. Throughput is 2685.6592 records/second. Loss is 0.15916859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042098172939294435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 45480/60000][Iteration 6879][Wall Clock 313.614410802s] Trained 120 records in 0.042625739 seconds. Throughput is 2815.2004 records/second. Loss is 0.1306825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004209462872537464. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 45600/60000][Iteration 6880][Wall Clock 313.655742329s] Trained 120 records in 0.041331527 seconds. Throughput is 2903.3528 records/second. Loss is 0.069707036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004209108510817409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 45720/60000][Iteration 6881][Wall Clock 313.696781418s] Trained 120 records in 0.041039089 seconds. Throughput is 2924.0415 records/second. Loss is 0.15942024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004208754208754209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 45840/60000][Iteration 6882][Wall Clock 313.737337192s] Trained 120 records in 0.040555774 seconds. Throughput is 2958.8882 records/second. Loss is 0.18449475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004208399966332801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 45960/60000][Iteration 6883][Wall Clock 313.778386568s] Trained 120 records in 0.041049376 seconds. Throughput is 2923.3088 records/second. Loss is 0.16461927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004208045783538125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46080/60000][Iteration 6884][Wall Clock 313.819173633s] Trained 120 records in 0.040787065 seconds. Throughput is 2942.1094 records/second. Loss is 0.16789344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042076916603551295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46200/60000][Iteration 6885][Wall Clock 313.859608215s] Trained 120 records in 0.040434582 seconds. Throughput is 2967.7568 records/second. Loss is 0.2081627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004207337596768764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46320/60000][Iteration 6886][Wall Clock 313.900684954s] Trained 120 records in 0.041076739 seconds. Throughput is 2921.3613 records/second. Loss is 0.21090522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004206983592763989. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46440/60000][Iteration 6887][Wall Clock 313.941145693s] Trained 120 records in 0.040460739 seconds. Throughput is 2965.8381 records/second. Loss is 0.08880453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004206629648325761. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46560/60000][Iteration 6888][Wall Clock 313.984943872s] Trained 120 records in 0.043798179 seconds. Throughput is 2739.84 records/second. Loss is 0.20654628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004206275763439051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46680/60000][Iteration 6889][Wall Clock 314.026261598s] Trained 120 records in 0.041317726 seconds. Throughput is 2904.3223 records/second. Loss is 0.20388766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0042059219380888285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46800/60000][Iteration 6890][Wall Clock 314.066941099s] Trained 120 records in 0.040679501 seconds. Throughput is 2949.889 records/second. Loss is 0.10023386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004205568172260072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 46920/60000][Iteration 6891][Wall Clock 314.107631158s] Trained 120 records in 0.040690059 seconds. Throughput is 2949.123 records/second. Loss is 0.20269766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004205214465937763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47040/60000][Iteration 6892][Wall Clock 314.148194957s] Trained 120 records in 0.040563799 seconds. Throughput is 2958.3027 records/second. Loss is 0.11916354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004204860819106888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47160/60000][Iteration 6893][Wall Clock 314.188936203s] Trained 120 records in 0.040741246 seconds. Throughput is 2945.418 records/second. Loss is 0.15196185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004204507231752439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47280/60000][Iteration 6894][Wall Clock 314.242538932s] Trained 120 records in 0.053602729 seconds. Throughput is 2238.692 records/second. Loss is 0.1506277. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004204153703859413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47400/60000][Iteration 6895][Wall Clock 314.284897424s] Trained 120 records in 0.042358492 seconds. Throughput is 2832.9622 records/second. Loss is 0.26170924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004203800235412813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47520/60000][Iteration 6896][Wall Clock 314.325351584s] Trained 120 records in 0.04045416 seconds. Throughput is 2966.3203 records/second. Loss is 0.1346905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004203446826397646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47640/60000][Iteration 6897][Wall Clock 314.366132713s] Trained 120 records in 0.040781129 seconds. Throughput is 2942.5374 records/second. Loss is 0.1482169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004203093476798924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47760/60000][Iteration 6898][Wall Clock 314.407016927s] Trained 120 records in 0.040884214 seconds. Throughput is 2935.1182 records/second. Loss is 0.19297676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004202740186601665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 47880/60000][Iteration 6899][Wall Clock 314.448090808s] Trained 120 records in 0.041073881 seconds. Throughput is 2921.5647 records/second. Loss is 0.17454286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00420238695579089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:20 INFO  DistriOptimizer$:406 - [Epoch 14 48000/60000][Iteration 6900][Wall Clock 314.489230181s] Trained 120 records in 0.041139373 seconds. Throughput is 2916.9138 records/second. Loss is 0.18972225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004202033784351625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48120/60000][Iteration 6901][Wall Clock 314.533371544s] Trained 120 records in 0.044141363 seconds. Throughput is 2718.5386 records/second. Loss is 0.105897345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004201680672268908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48240/60000][Iteration 6902][Wall Clock 314.580698573s] Trained 120 records in 0.047327029 seconds. Throughput is 2535.5488 records/second. Loss is 0.21452846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004201327619527771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48360/60000][Iteration 6903][Wall Clock 314.625615589s] Trained 120 records in 0.044917016 seconds. Throughput is 2671.5933 records/second. Loss is 0.25704616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004200974626113259. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48480/60000][Iteration 6904][Wall Clock 314.666283494s] Trained 120 records in 0.040667905 seconds. Throughput is 2950.7297 records/second. Loss is 0.1617654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004200621692010417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48600/60000][Iteration 6905][Wall Clock 314.706595219s] Trained 120 records in 0.040311725 seconds. Throughput is 2976.8015 records/second. Loss is 0.22503407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004200268817204302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48720/60000][Iteration 6906][Wall Clock 314.746976343s] Trained 120 records in 0.040381124 seconds. Throughput is 2971.6855 records/second. Loss is 0.20755336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004199916001679966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48840/60000][Iteration 6907][Wall Clock 314.790007354s] Trained 120 records in 0.043031011 seconds. Throughput is 2788.6865 records/second. Loss is 0.2562695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041995632454224765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 48960/60000][Iteration 6908][Wall Clock 314.830317766s] Trained 120 records in 0.040310412 seconds. Throughput is 2976.8984 records/second. Loss is 0.18437417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004199210548416897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49080/60000][Iteration 6909][Wall Clock 314.870371023s] Trained 120 records in 0.040053257 seconds. Throughput is 2996.0112 records/second. Loss is 0.19324516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004198857910648304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49200/60000][Iteration 6910][Wall Clock 314.910636249s] Trained 120 records in 0.040265226 seconds. Throughput is 2980.2393 records/second. Loss is 0.1709417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004198505332101771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49320/60000][Iteration 6911][Wall Clock 314.950571415s] Trained 120 records in 0.039935166 seconds. Throughput is 3004.8706 records/second. Loss is 0.10419437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041981528127623844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49440/60000][Iteration 6912][Wall Clock 314.990977855s] Trained 120 records in 0.04040644 seconds. Throughput is 2969.8237 records/second. Loss is 0.11504607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004197800352615229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49560/60000][Iteration 6913][Wall Clock 315.03203225s] Trained 120 records in 0.041054395 seconds. Throughput is 2922.9514 records/second. Loss is 0.1385364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041974479516454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49680/60000][Iteration 6914][Wall Clock 315.073343509s] Trained 120 records in 0.041311259 seconds. Throughput is 2904.777 records/second. Loss is 0.20229766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004197095609837992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49800/60000][Iteration 6915][Wall Clock 315.114050463s] Trained 120 records in 0.040706954 seconds. Throughput is 2947.8992 records/second. Loss is 0.17269571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004196743327178109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 49920/60000][Iteration 6916][Wall Clock 315.154033947s] Trained 120 records in 0.039983484 seconds. Throughput is 3001.2393 records/second. Loss is 0.20720215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00419639110365086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50040/60000][Iteration 6917][Wall Clock 315.194220135s] Trained 120 records in 0.040186188 seconds. Throughput is 2986.1006 records/second. Loss is 0.13871077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004196038939241357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50160/60000][Iteration 6918][Wall Clock 315.234665626s] Trained 120 records in 0.040445491 seconds. Throughput is 2966.956 records/second. Loss is 0.12270355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004195686833934715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50280/60000][Iteration 6919][Wall Clock 315.274895717s] Trained 120 records in 0.040230091 seconds. Throughput is 2982.8418 records/second. Loss is 0.12709065. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004195334787716059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50400/60000][Iteration 6920][Wall Clock 315.315090897s] Trained 120 records in 0.04019518 seconds. Throughput is 2985.4326 records/second. Loss is 0.19173291. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004194982800570518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50520/60000][Iteration 6921][Wall Clock 315.370058875s] Trained 120 records in 0.054967978 seconds. Throughput is 2183.0894 records/second. Loss is 0.18900622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004194630872483221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50640/60000][Iteration 6922][Wall Clock 315.416818123s] Trained 120 records in 0.046759248 seconds. Throughput is 2566.3372 records/second. Loss is 0.24577588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004194279003439309. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50760/60000][Iteration 6923][Wall Clock 315.458673149s] Trained 120 records in 0.041855026 seconds. Throughput is 2867.0393 records/second. Loss is 0.19085032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004193927193423922. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:21 INFO  DistriOptimizer$:406 - [Epoch 14 50880/60000][Iteration 6924][Wall Clock 315.499959728s] Trained 120 records in 0.041286579 seconds. Throughput is 2906.5134 records/second. Loss is 0.060894117. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00419357544242221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51000/60000][Iteration 6925][Wall Clock 315.541676422s] Trained 120 records in 0.041716694 seconds. Throughput is 2876.5461 records/second. Loss is 0.24900815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004193223750419322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51120/60000][Iteration 6926][Wall Clock 315.594777193s] Trained 120 records in 0.053100771 seconds. Throughput is 2259.8542 records/second. Loss is 0.18801242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041928721174004195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51240/60000][Iteration 6927][Wall Clock 315.63651003s] Trained 120 records in 0.041732837 seconds. Throughput is 2875.4336 records/second. Loss is 0.14745882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004192520543350662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51360/60000][Iteration 6928][Wall Clock 315.677072302s] Trained 120 records in 0.040562272 seconds. Throughput is 2958.414 records/second. Loss is 0.1854869. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00419216902825522. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51480/60000][Iteration 6929][Wall Clock 315.72547837s] Trained 120 records in 0.048406068 seconds. Throughput is 2479.028 records/second. Loss is 0.14445314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004191817572099262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51600/60000][Iteration 6930][Wall Clock 315.769690967s] Trained 120 records in 0.044212597 seconds. Throughput is 2714.1584 records/second. Loss is 0.10672262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004191466174867969. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51720/60000][Iteration 6931][Wall Clock 315.81075759s] Trained 120 records in 0.041066623 seconds. Throughput is 2922.081 records/second. Loss is 0.1840376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004191114836546521. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51840/60000][Iteration 6932][Wall Clock 315.851164842s] Trained 120 records in 0.040407252 seconds. Throughput is 2969.764 records/second. Loss is 0.10305287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004190763557120107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 51960/60000][Iteration 6933][Wall Clock 315.891654444s] Trained 120 records in 0.040489602 seconds. Throughput is 2963.7239 records/second. Loss is 0.14647385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004190412336573919. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52080/60000][Iteration 6934][Wall Clock 315.931715506s] Trained 120 records in 0.040061062 seconds. Throughput is 2995.4275 records/second. Loss is 0.23750441. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004190061174893153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52200/60000][Iteration 6935][Wall Clock 315.972091652s] Trained 120 records in 0.040376146 seconds. Throughput is 2972.052 records/second. Loss is 0.1929623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004189710072063014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52320/60000][Iteration 6936][Wall Clock 316.012464305s] Trained 120 records in 0.040372653 seconds. Throughput is 2972.3088 records/second. Loss is 0.13467073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041893590280687055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52440/60000][Iteration 6937][Wall Clock 316.052570112s] Trained 120 records in 0.040105807 seconds. Throughput is 2992.0852 records/second. Loss is 0.19310859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041890080428954425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52560/60000][Iteration 6938][Wall Clock 316.092635884s] Trained 120 records in 0.040065772 seconds. Throughput is 2995.0752 records/second. Loss is 0.14544907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041886571165284416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52680/60000][Iteration 6939][Wall Clock 316.132397839s] Trained 120 records in 0.039761955 seconds. Throughput is 3017.9602 records/second. Loss is 0.17869005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041883062489529235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52800/60000][Iteration 6940][Wall Clock 316.171944038s] Trained 120 records in 0.039546199 seconds. Throughput is 3034.4255 records/second. Loss is 0.23554568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004187955440154116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 52920/60000][Iteration 6941][Wall Clock 316.21170539s] Trained 120 records in 0.039761352 seconds. Throughput is 3018.0059 records/second. Loss is 0.138998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004187604690117253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 53040/60000][Iteration 6942][Wall Clock 316.252595937s] Trained 120 records in 0.040890547 seconds. Throughput is 2934.6636 records/second. Loss is 0.14138064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041872539988275686. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 53160/60000][Iteration 6943][Wall Clock 316.294059351s] Trained 120 records in 0.041463414 seconds. Throughput is 2894.118 records/second. Loss is 0.22355455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004186903366270307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 53280/60000][Iteration 6944][Wall Clock 316.335347583s] Trained 120 records in 0.041288232 seconds. Throughput is 2906.3972 records/second. Loss is 0.1573783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004186552792430712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 53400/60000][Iteration 6945][Wall Clock 316.378740447s] Trained 120 records in 0.043392864 seconds. Throughput is 2765.4316 records/second. Loss is 0.26859108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004186202277294039. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 53520/60000][Iteration 6946][Wall Clock 316.419656387s] Trained 120 records in 0.04091594 seconds. Throughput is 2932.8423 records/second. Loss is 0.13834614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004185851820845542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 53640/60000][Iteration 6947][Wall Clock 316.467421218s] Trained 120 records in 0.047764831 seconds. Throughput is 2512.3088 records/second. Loss is 0.12891996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004185501423070484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:22 INFO  DistriOptimizer$:406 - [Epoch 14 53760/60000][Iteration 6948][Wall Clock 316.513886717s] Trained 120 records in 0.046465499 seconds. Throughput is 2582.5613 records/second. Loss is 0.18824086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004185151083954131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 53880/60000][Iteration 6949][Wall Clock 316.556973296s] Trained 120 records in 0.043086579 seconds. Throughput is 2785.09 records/second. Loss is 0.19564025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004184800803481754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54000/60000][Iteration 6950][Wall Clock 316.598540337s] Trained 120 records in 0.041567041 seconds. Throughput is 2886.9026 records/second. Loss is 0.19121167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004184450581638631. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54120/60000][Iteration 6951][Wall Clock 316.639743395s] Trained 120 records in 0.041203058 seconds. Throughput is 2912.405 records/second. Loss is 0.16021068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041841004184100415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54240/60000][Iteration 6952][Wall Clock 316.680536844s] Trained 120 records in 0.040793449 seconds. Throughput is 2941.649 records/second. Loss is 0.1597393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041837503137812735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54360/60000][Iteration 6953][Wall Clock 316.71975151s] Trained 120 records in 0.039214666 seconds. Throughput is 3060.0796 records/second. Loss is 0.24907497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004183400267737617. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54480/60000][Iteration 6954][Wall Clock 316.759312481s] Trained 120 records in 0.039560971 seconds. Throughput is 3033.2927 records/second. Loss is 0.13007195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004183050280264369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54600/60000][Iteration 6955][Wall Clock 316.798999966s] Trained 120 records in 0.039687485 seconds. Throughput is 3023.6233 records/second. Loss is 0.18459068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004182700351346829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54720/60000][Iteration 6956][Wall Clock 316.84938574s] Trained 120 records in 0.050385774 seconds. Throughput is 2381.6248 records/second. Loss is 0.21161886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004182350480970306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54840/60000][Iteration 6957][Wall Clock 316.889234824s] Trained 120 records in 0.039849084 seconds. Throughput is 3011.3616 records/second. Loss is 0.12836032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004182000669120107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 54960/60000][Iteration 6958][Wall Clock 316.92894464s] Trained 120 records in 0.039709816 seconds. Throughput is 3021.9226 records/second. Loss is 0.17838934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004181650915781551. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55080/60000][Iteration 6959][Wall Clock 316.970649833s] Trained 120 records in 0.041705193 seconds. Throughput is 2877.3394 records/second. Loss is 0.2218613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004181301220939956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55200/60000][Iteration 6960][Wall Clock 317.012329559s] Trained 120 records in 0.041679726 seconds. Throughput is 2879.0977 records/second. Loss is 0.09691536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004180951584580651. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55320/60000][Iteration 6961][Wall Clock 317.053200705s] Trained 120 records in 0.040871146 seconds. Throughput is 2936.0566 records/second. Loss is 0.15306638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004180602006688963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55440/60000][Iteration 6962][Wall Clock 317.093495713s] Trained 120 records in 0.040295008 seconds. Throughput is 2978.0364 records/second. Loss is 0.110175006. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00418025248725023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55560/60000][Iteration 6963][Wall Clock 317.137805658s] Trained 120 records in 0.044309945 seconds. Throughput is 2708.1958 records/second. Loss is 0.2149071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004179903026249791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55680/60000][Iteration 6964][Wall Clock 317.17777268s] Trained 120 records in 0.039967022 seconds. Throughput is 3002.4753 records/second. Loss is 0.17278942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041795536236729925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55800/60000][Iteration 6965][Wall Clock 317.218476704s] Trained 120 records in 0.040704024 seconds. Throughput is 2948.1116 records/second. Loss is 0.11209725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004179204279505182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 55920/60000][Iteration 6966][Wall Clock 317.258928716s] Trained 120 records in 0.040452012 seconds. Throughput is 2966.478 records/second. Loss is 0.22662531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004178854993731718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 56040/60000][Iteration 6967][Wall Clock 317.299084413s] Trained 120 records in 0.040155697 seconds. Throughput is 2988.368 records/second. Loss is 0.17386237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004178505766337957. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 56160/60000][Iteration 6968][Wall Clock 317.339371604s] Trained 120 records in 0.040287191 seconds. Throughput is 2978.6143 records/second. Loss is 0.13257556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004178156597309268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 56280/60000][Iteration 6969][Wall Clock 317.379839237s] Trained 120 records in 0.040467633 seconds. Throughput is 2965.3328 records/second. Loss is 0.13591765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004177807486631016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 56400/60000][Iteration 6970][Wall Clock 317.420938724s] Trained 120 records in 0.041099487 seconds. Throughput is 2919.7444 records/second. Loss is 0.17905003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004177458434288578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 56520/60000][Iteration 6971][Wall Clock 317.461606737s] Trained 120 records in 0.040668013 seconds. Throughput is 2950.722 records/second. Loss is 0.20705046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004177109440267335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:23 INFO  DistriOptimizer$:406 - [Epoch 14 56640/60000][Iteration 6972][Wall Clock 317.50219829s] Trained 120 records in 0.040591553 seconds. Throughput is 2956.28 records/second. Loss is 0.26960716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004176760504552669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 56760/60000][Iteration 6973][Wall Clock 317.542562925s] Trained 120 records in 0.040364635 seconds. Throughput is 2972.8994 records/second. Loss is 0.20617981. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00417641162712997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 56880/60000][Iteration 6974][Wall Clock 317.591882307s] Trained 120 records in 0.049319382 seconds. Throughput is 2433.1204 records/second. Loss is 0.15663268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004176062807984632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57000/60000][Iteration 6975][Wall Clock 317.640128945s] Trained 120 records in 0.048246638 seconds. Throughput is 2487.22 records/second. Loss is 0.17351708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041757140471020545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57120/60000][Iteration 6976][Wall Clock 317.684703814s] Trained 120 records in 0.044574869 seconds. Throughput is 2692.0999 records/second. Loss is 0.2117129. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004175365344467641. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57240/60000][Iteration 6977][Wall Clock 317.72647464s] Trained 120 records in 0.041770826 seconds. Throughput is 2872.8184 records/second. Loss is 0.10088246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004175016700066801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57360/60000][Iteration 6978][Wall Clock 317.767322763s] Trained 120 records in 0.040848123 seconds. Throughput is 2937.7114 records/second. Loss is 0.1720059. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004174668113884946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57480/60000][Iteration 6979][Wall Clock 317.808431402s] Trained 120 records in 0.041108639 seconds. Throughput is 2919.0945 records/second. Loss is 0.1371939. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004174319585907497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57600/60000][Iteration 6980][Wall Clock 317.848535333s] Trained 120 records in 0.040103931 seconds. Throughput is 2992.2253 records/second. Loss is 0.117981605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004173971116119876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57720/60000][Iteration 6981][Wall Clock 317.889090385s] Trained 120 records in 0.040555052 seconds. Throughput is 2958.941 records/second. Loss is 0.15027313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004173622704507513. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57840/60000][Iteration 6982][Wall Clock 317.940351952s] Trained 120 records in 0.051261567 seconds. Throughput is 2340.935 records/second. Loss is 0.14682347. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004173274351055838. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 57960/60000][Iteration 6983][Wall Clock 317.985639468s] Trained 120 records in 0.045287516 seconds. Throughput is 2649.7368 records/second. Loss is 0.16268489. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004172926055750293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58080/60000][Iteration 6984][Wall Clock 318.027188945s] Trained 120 records in 0.041549477 seconds. Throughput is 2888.123 records/second. Loss is 0.102097556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004172577818576316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58200/60000][Iteration 6985][Wall Clock 318.068388972s] Trained 120 records in 0.041200027 seconds. Throughput is 2912.6194 records/second. Loss is 0.15844275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00417222963951936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58320/60000][Iteration 6986][Wall Clock 318.109931558s] Trained 120 records in 0.041542586 seconds. Throughput is 2888.602 records/second. Loss is 0.18021338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004171881518564872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58440/60000][Iteration 6987][Wall Clock 318.151367145s] Trained 120 records in 0.041435587 seconds. Throughput is 2896.0613 records/second. Loss is 0.23896226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004171533455698315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58560/60000][Iteration 6988][Wall Clock 318.19211794s] Trained 120 records in 0.040750795 seconds. Throughput is 2944.7278 records/second. Loss is 0.18079859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004171185450905147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58680/60000][Iteration 6989][Wall Clock 318.233573476s] Trained 120 records in 0.041455536 seconds. Throughput is 2894.6675 records/second. Loss is 0.16584376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004170837504170837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58800/60000][Iteration 6990][Wall Clock 318.27446739s] Trained 120 records in 0.040893914 seconds. Throughput is 2934.422 records/second. Loss is 0.23968904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041704896154808576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 58920/60000][Iteration 6991][Wall Clock 318.315383123s] Trained 120 records in 0.040915733 seconds. Throughput is 2932.8572 records/second. Loss is 0.15510313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004170141784820684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 59040/60000][Iteration 6992][Wall Clock 318.356396895s] Trained 120 records in 0.041013772 seconds. Throughput is 2925.8464 records/second. Loss is 0.1647034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004169794012175799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 59160/60000][Iteration 6993][Wall Clock 318.397893s] Trained 120 records in 0.041496105 seconds. Throughput is 2891.8376 records/second. Loss is 0.23861228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004169446297531688. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 59280/60000][Iteration 6994][Wall Clock 318.440018065s] Trained 120 records in 0.042125065 seconds. Throughput is 2848.6604 records/second. Loss is 0.20474361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004169098640873843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:24 INFO  DistriOptimizer$:406 - [Epoch 14 59400/60000][Iteration 6995][Wall Clock 318.481802357s] Trained 120 records in 0.041784292 seconds. Throughput is 2871.8928 records/second. Loss is 0.19649999. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00416875104218776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:25 INFO  DistriOptimizer$:406 - [Epoch 14 59520/60000][Iteration 6996][Wall Clock 318.522664358s] Trained 120 records in 0.040862001 seconds. Throughput is 2936.7136 records/second. Loss is 0.2613256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004168403501458941. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:25 INFO  DistriOptimizer$:406 - [Epoch 14 59640/60000][Iteration 6997][Wall Clock 318.563309499s] Trained 120 records in 0.040645141 seconds. Throughput is 2952.3823 records/second. Loss is 0.17257021. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004168056018672891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:25 INFO  DistriOptimizer$:406 - [Epoch 14 59760/60000][Iteration 6998][Wall Clock 318.603831148s] Trained 120 records in 0.040521649 seconds. Throughput is 2961.3801 records/second. Loss is 0.18017955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00416770859381512. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:25 INFO  DistriOptimizer$:406 - [Epoch 14 59880/60000][Iteration 6999][Wall Clock 318.644860081s] Trained 120 records in 0.041028933 seconds. Throughput is 2924.7654 records/second. Loss is 0.16920255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004167361226871145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:25 INFO  DistriOptimizer$:406 - [Epoch 14 60000/60000][Iteration 7000][Wall Clock 318.6938162s] Trained 120 records in 0.048956119 seconds. Throughput is 2451.1748 records/second. Loss is 0.14621623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004167013917826486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:25 INFO  DistriOptimizer$:451 - [Epoch 14 60000/60000][Iteration 7000][Wall Clock 318.6938162s] Epoch finished. Wall clock time is 319495.093491 ms
2019-10-23 15:58:25 INFO  DistriOptimizer$:111 - [Epoch 14 60000/60000][Iteration 7000][Wall Clock 318.6938162s] Validate model...
2019-10-23 15:58:25 INFO  DistriOptimizer$:177 - [Epoch 14 60000/60000][Iteration 7000][Wall Clock 318.6938162s] validate model throughput is 14694.791 records/second
2019-10-23 15:58:25 INFO  DistriOptimizer$:180 - [Epoch 14 60000/60000][Iteration 7000][Wall Clock 318.6938162s] Top1Accuracy is Accuracy(correct: 9533, count: 10000, accuracy: 0.9533)
2019-10-23 15:58:25 INFO  DistriOptimizer$:220 - [Wall Clock 319.495093491s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:58:25 INFO  DistriOptimizer$:225 - [Wall Clock 319.495093491s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:58:25 INFO  DistriOptimizer$:406 - [Epoch 15 120/60000][Iteration 7001][Wall Clock 319.542171294s] Trained 120 records in 0.047077803 seconds. Throughput is 2548.972 records/second. Loss is 0.18141538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004166666666666666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:25 INFO  DistriOptimizer$:406 - [Epoch 15 240/60000][Iteration 7002][Wall Clock 319.583245392s] Trained 120 records in 0.041074098 seconds. Throughput is 2921.5493 records/second. Loss is 0.21838634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004166319473377218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 360/60000][Iteration 7003][Wall Clock 319.623648742s] Trained 120 records in 0.04040335 seconds. Throughput is 2970.0508 records/second. Loss is 0.21179415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004165972337943675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 480/60000][Iteration 7004][Wall Clock 319.663688299s] Trained 120 records in 0.040039557 seconds. Throughput is 2997.0361 records/second. Loss is 0.1699953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004165625260351579. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 600/60000][Iteration 7005][Wall Clock 319.704159073s] Trained 120 records in 0.040470774 seconds. Throughput is 2965.1025 records/second. Loss is 0.21496071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004165278240586471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 720/60000][Iteration 7006][Wall Clock 319.74445033s] Trained 120 records in 0.040291257 seconds. Throughput is 2978.3137 records/second. Loss is 0.25090483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004164931278633903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 840/60000][Iteration 7007][Wall Clock 319.785648049s] Trained 120 records in 0.041197719 seconds. Throughput is 2912.7827 records/second. Loss is 0.21347682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041645843744794265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 960/60000][Iteration 7008][Wall Clock 319.837217334s] Trained 120 records in 0.051569285 seconds. Throughput is 2326.9666 records/second. Loss is 0.26709688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004164237528108604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1080/60000][Iteration 7009][Wall Clock 319.87764861s] Trained 120 records in 0.040431276 seconds. Throughput is 2967.9993 records/second. Loss is 0.23105761. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041638907395069955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1200/60000][Iteration 7010][Wall Clock 319.91742545s] Trained 120 records in 0.03977684 seconds. Throughput is 3016.831 records/second. Loss is 0.1970053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041635440086601715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1320/60000][Iteration 7011][Wall Clock 319.957703975s] Trained 120 records in 0.040278525 seconds. Throughput is 2979.2551 records/second. Loss is 0.24074173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004163197335553705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1440/60000][Iteration 7012][Wall Clock 319.998151055s] Trained 120 records in 0.04044708 seconds. Throughput is 2966.8398 records/second. Loss is 0.12523971. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004162850720173175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1560/60000][Iteration 7013][Wall Clock 320.039041246s] Trained 120 records in 0.040890191 seconds. Throughput is 2934.6892 records/second. Loss is 0.18399805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004162504162504162. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1680/60000][Iteration 7014][Wall Clock 320.079352874s] Trained 120 records in 0.040311628 seconds. Throughput is 2976.8086 records/second. Loss is 0.15168715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004162157662532257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1800/60000][Iteration 7015][Wall Clock 320.119903834s] Trained 120 records in 0.04055096 seconds. Throughput is 2959.2395 records/second. Loss is 0.2598098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00416181122024305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 1920/60000][Iteration 7016][Wall Clock 320.160335147s] Trained 120 records in 0.040431313 seconds. Throughput is 2967.9966 records/second. Loss is 0.14047863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004161464835622139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2040/60000][Iteration 7017][Wall Clock 320.200472325s] Trained 120 records in 0.040137178 seconds. Throughput is 2989.7468 records/second. Loss is 0.2155438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004161118508655127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2160/60000][Iteration 7018][Wall Clock 320.244179271s] Trained 120 records in 0.043706946 seconds. Throughput is 2745.559 records/second. Loss is 0.19642451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041607722393276194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2280/60000][Iteration 7019][Wall Clock 320.285294212s] Trained 120 records in 0.041114941 seconds. Throughput is 2918.647 records/second. Loss is 0.17328256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041604260276252285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2400/60000][Iteration 7020][Wall Clock 320.32609883s] Trained 120 records in 0.040804618 seconds. Throughput is 2940.8438 records/second. Loss is 0.2515221. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041600798735335716. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2520/60000][Iteration 7021][Wall Clock 320.3665204s] Trained 120 records in 0.04042157 seconds. Throughput is 2968.712 records/second. Loss is 0.11965385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00415973377703827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2640/60000][Iteration 7022][Wall Clock 320.407133306s] Trained 120 records in 0.040612906 seconds. Throughput is 2954.7258 records/second. Loss is 0.19127537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004159387738124947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2760/60000][Iteration 7023][Wall Clock 320.447783439s] Trained 120 records in 0.040650133 seconds. Throughput is 2952.0198 records/second. Loss is 0.15493862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004159041756779239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 2880/60000][Iteration 7024][Wall Clock 320.493865493s] Trained 120 records in 0.046082054 seconds. Throughput is 2604.0505 records/second. Loss is 0.2247687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004158695832986775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:26 INFO  DistriOptimizer$:406 - [Epoch 15 3000/60000][Iteration 7025][Wall Clock 320.547203429s] Trained 120 records in 0.053337936 seconds. Throughput is 2249.806 records/second. Loss is 0.26871035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004158349966733201. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3120/60000][Iteration 7026][Wall Clock 320.588366283s] Trained 120 records in 0.041162854 seconds. Throughput is 2915.25 records/second. Loss is 0.19440807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004158004158004157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3240/60000][Iteration 7027][Wall Clock 320.628851574s] Trained 120 records in 0.040485291 seconds. Throughput is 2964.0393 records/second. Loss is 0.22927824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004157658406785299. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3360/60000][Iteration 7028][Wall Clock 320.6695681s] Trained 120 records in 0.040716526 seconds. Throughput is 2947.2063 records/second. Loss is 0.23629414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004157312713062277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3480/60000][Iteration 7029][Wall Clock 320.709928909s] Trained 120 records in 0.040360809 seconds. Throughput is 2973.1814 records/second. Loss is 0.13854837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004156967076820752. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3600/60000][Iteration 7030][Wall Clock 320.750283995s] Trained 120 records in 0.040355086 seconds. Throughput is 2973.6028 records/second. Loss is 0.16501859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004156621498046388. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3720/60000][Iteration 7031][Wall Clock 320.790475601s] Trained 120 records in 0.040191606 seconds. Throughput is 2985.698 records/second. Loss is 0.19660495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004156275976724855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3840/60000][Iteration 7032][Wall Clock 320.83084854s] Trained 120 records in 0.040372939 seconds. Throughput is 2972.288 records/second. Loss is 0.11049902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004155930512841825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 3960/60000][Iteration 7033][Wall Clock 320.870754158s] Trained 120 records in 0.039905618 seconds. Throughput is 3007.0952 records/second. Loss is 0.1321281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004155585106382979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4080/60000][Iteration 7034][Wall Clock 320.922680638s] Trained 120 records in 0.05192648 seconds. Throughput is 2310.9597 records/second. Loss is 0.21564986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004155239757333998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4200/60000][Iteration 7035][Wall Clock 320.962949466s] Trained 120 records in 0.040268828 seconds. Throughput is 2979.9727 records/second. Loss is 0.19164962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041548944656805715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4320/60000][Iteration 7036][Wall Clock 321.006654376s] Trained 120 records in 0.04370491 seconds. Throughput is 2745.687 records/second. Loss is 0.16977428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004154549231408392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4440/60000][Iteration 7037][Wall Clock 321.047074843s] Trained 120 records in 0.040420467 seconds. Throughput is 2968.7932 records/second. Loss is 0.17246655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004154204054503157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4560/60000][Iteration 7038][Wall Clock 321.087849072s] Trained 120 records in 0.040774229 seconds. Throughput is 2943.0354 records/second. Loss is 0.10832. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004153858934950569. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4680/60000][Iteration 7039][Wall Clock 321.128380909s] Trained 120 records in 0.040531837 seconds. Throughput is 2960.6357 records/second. Loss is 0.13357875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004153513872736335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4800/60000][Iteration 7040][Wall Clock 321.168327387s] Trained 120 records in 0.039946478 seconds. Throughput is 3004.0195 records/second. Loss is 0.16015953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004153168867846167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 4920/60000][Iteration 7041][Wall Clock 321.209266508s] Trained 120 records in 0.040939121 seconds. Throughput is 2931.1816 records/second. Loss is 0.16296168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00415282392026578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5040/60000][Iteration 7042][Wall Clock 321.250906277s] Trained 120 records in 0.041639769 seconds. Throughput is 2881.8604 records/second. Loss is 0.14313659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041524790299808986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5160/60000][Iteration 7043][Wall Clock 321.293131965s] Trained 120 records in 0.042225688 seconds. Throughput is 2841.8718 records/second. Loss is 0.20123672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004152134196977246. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5280/60000][Iteration 7044][Wall Clock 321.335035835s] Trained 120 records in 0.04190387 seconds. Throughput is 2863.6975 records/second. Loss is 0.25892273. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004151789421240555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5400/60000][Iteration 7045][Wall Clock 321.375237117s] Trained 120 records in 0.040201282 seconds. Throughput is 2984.9795 records/second. Loss is 0.20002787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041514447027565585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5520/60000][Iteration 7046][Wall Clock 321.414991126s] Trained 120 records in 0.039754009 seconds. Throughput is 3018.5632 records/second. Loss is 0.14157034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004151100041511001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5640/60000][Iteration 7047][Wall Clock 321.455020105s] Trained 120 records in 0.040028979 seconds. Throughput is 2997.8281 records/second. Loss is 0.1587093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041507554374896225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5760/60000][Iteration 7048][Wall Clock 321.495685002s] Trained 120 records in 0.040664897 seconds. Throughput is 2950.9482 records/second. Loss is 0.24014075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004150410890678177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:27 INFO  DistriOptimizer$:406 - [Epoch 15 5880/60000][Iteration 7049][Wall Clock 321.546090273s] Trained 120 records in 0.050405271 seconds. Throughput is 2380.7034 records/second. Loss is 0.23137242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004150066401062417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6000/60000][Iteration 7050][Wall Clock 321.594829417s] Trained 120 records in 0.048739144 seconds. Throughput is 2462.087 records/second. Loss is 0.17577697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004149721968628102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6120/60000][Iteration 7051][Wall Clock 321.636489951s] Trained 120 records in 0.041660534 seconds. Throughput is 2880.424 records/second. Loss is 0.099804275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004149377593360996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6240/60000][Iteration 7052][Wall Clock 321.676697897s] Trained 120 records in 0.040207946 seconds. Throughput is 2984.4849 records/second. Loss is 0.18032166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004149033275246868. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6360/60000][Iteration 7053][Wall Clock 321.716648276s] Trained 120 records in 0.039950379 seconds. Throughput is 3003.7263 records/second. Loss is 0.17030893. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00414868901427149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6480/60000][Iteration 7054][Wall Clock 321.757085467s] Trained 120 records in 0.040437191 seconds. Throughput is 2967.5652 records/second. Loss is 0.20695336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004148344810420642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6600/60000][Iteration 7055][Wall Clock 321.8006133s] Trained 120 records in 0.043527833 seconds. Throughput is 2756.8567 records/second. Loss is 0.19747639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004148000663680106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6720/60000][Iteration 7056][Wall Clock 321.840763242s] Trained 120 records in 0.040149942 seconds. Throughput is 2988.7964 records/second. Loss is 0.20194986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00414765657403567. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6840/60000][Iteration 7057][Wall Clock 321.88116048s] Trained 120 records in 0.040397238 seconds. Throughput is 2970.5 records/second. Loss is 0.20604642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004147312541473125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 6960/60000][Iteration 7058][Wall Clock 321.921156685s] Trained 120 records in 0.039996205 seconds. Throughput is 3000.2844 records/second. Loss is 0.12800597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00414696856597827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7080/60000][Iteration 7059][Wall Clock 321.96125398s] Trained 120 records in 0.040097295 seconds. Throughput is 2992.7205 records/second. Loss is 0.1083749. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004146624647536905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7200/60000][Iteration 7060][Wall Clock 322.009348511s] Trained 120 records in 0.048094531 seconds. Throughput is 2495.0862 records/second. Loss is 0.13905309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041462807861348365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7320/60000][Iteration 7061][Wall Clock 322.054138881s] Trained 120 records in 0.04479037 seconds. Throughput is 2679.1475 records/second. Loss is 0.2774753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041459369817578775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7440/60000][Iteration 7062][Wall Clock 322.096175773s] Trained 120 records in 0.042036892 seconds. Throughput is 2854.6355 records/second. Loss is 0.11941944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004145593234391841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7560/60000][Iteration 7063][Wall Clock 322.138072977s] Trained 120 records in 0.041897204 seconds. Throughput is 2864.153 records/second. Loss is 0.23575163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00414524954402255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7680/60000][Iteration 7064][Wall Clock 322.180087743s] Trained 120 records in 0.042014766 seconds. Throughput is 2856.1387 records/second. Loss is 0.14983363. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004144905910635828. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7800/60000][Iteration 7065][Wall Clock 322.221962998s] Trained 120 records in 0.041875255 seconds. Throughput is 2865.6543 records/second. Loss is 0.3152736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004144562334217507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 7920/60000][Iteration 7066][Wall Clock 322.26478541s] Trained 120 records in 0.042822412 seconds. Throughput is 2802.2708 records/second. Loss is 0.21785358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004144218814753418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 8040/60000][Iteration 7067][Wall Clock 322.305761097s] Trained 120 records in 0.040975687 seconds. Throughput is 2928.566 records/second. Loss is 0.12501039. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004143875352229405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 8160/60000][Iteration 7068][Wall Clock 322.345453844s] Trained 120 records in 0.039692747 seconds. Throughput is 3023.2222 records/second. Loss is 0.12200715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004143531946631308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 8280/60000][Iteration 7069][Wall Clock 322.384793708s] Trained 120 records in 0.039339864 seconds. Throughput is 3050.341 records/second. Loss is 0.18189672. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004143188597944979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 8400/60000][Iteration 7070][Wall Clock 322.424802765s] Trained 120 records in 0.040009057 seconds. Throughput is 2999.321 records/second. Loss is 0.13651973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004142845306156268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 8520/60000][Iteration 7071][Wall Clock 322.465720838s] Trained 120 records in 0.040918073 seconds. Throughput is 2932.6892 records/second. Loss is 0.10700585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004142502071251036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 8640/60000][Iteration 7072][Wall Clock 322.506313427s] Trained 120 records in 0.040592589 seconds. Throughput is 2956.2046 records/second. Loss is 0.21260539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004142158893215143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:28 INFO  DistriOptimizer$:406 - [Epoch 15 8760/60000][Iteration 7073][Wall Clock 322.546056669s] Trained 120 records in 0.039743242 seconds. Throughput is 3019.3813 records/second. Loss is 0.16364488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00414181577203446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 8880/60000][Iteration 7074][Wall Clock 322.595877992s] Trained 120 records in 0.049821323 seconds. Throughput is 2408.6072 records/second. Loss is 0.19941692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004141472707694856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9000/60000][Iteration 7075][Wall Clock 322.64368651s] Trained 120 records in 0.047808518 seconds. Throughput is 2510.013 records/second. Loss is 0.1468792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004141129700182209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9120/60000][Iteration 7076][Wall Clock 322.687572932s] Trained 120 records in 0.043886422 seconds. Throughput is 2734.3308 records/second. Loss is 0.19124106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004140786749482402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9240/60000][Iteration 7077][Wall Clock 322.728187262s] Trained 120 records in 0.04061433 seconds. Throughput is 2954.6223 records/second. Loss is 0.29627985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004140443855581318. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9360/60000][Iteration 7078][Wall Clock 322.769052905s] Trained 120 records in 0.040865643 seconds. Throughput is 2936.452 records/second. Loss is 0.17005417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041401010184648505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9480/60000][Iteration 7079][Wall Clock 322.809326966s] Trained 120 records in 0.040274061 seconds. Throughput is 2979.5852 records/second. Loss is 0.14870928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004139758238118894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9600/60000][Iteration 7080][Wall Clock 322.849307493s] Trained 120 records in 0.039980527 seconds. Throughput is 3001.4612 records/second. Loss is 0.18641166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004139415514529348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9720/60000][Iteration 7081][Wall Clock 322.889167658s] Trained 120 records in 0.039860165 seconds. Throughput is 3010.5244 records/second. Loss is 0.35362256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004139072847682119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9840/60000][Iteration 7082][Wall Clock 322.929216242s] Trained 120 records in 0.040048584 seconds. Throughput is 2996.3606 records/second. Loss is 0.11274942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004138730237563116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 9960/60000][Iteration 7083][Wall Clock 322.969939624s] Trained 120 records in 0.040723382 seconds. Throughput is 2946.71 records/second. Loss is 0.09478342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004138387684158251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10080/60000][Iteration 7084][Wall Clock 323.011089721s] Trained 120 records in 0.041150097 seconds. Throughput is 2916.1536 records/second. Loss is 0.1067766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004138045187453448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10200/60000][Iteration 7085][Wall Clock 323.052124646s] Trained 120 records in 0.041034925 seconds. Throughput is 2924.3381 records/second. Loss is 0.17785747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004137702747434624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10320/60000][Iteration 7086][Wall Clock 323.092669486s] Trained 120 records in 0.04054484 seconds. Throughput is 2959.686 records/second. Loss is 0.14368182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004137360364087713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10440/60000][Iteration 7087][Wall Clock 323.141499047s] Trained 120 records in 0.048829561 seconds. Throughput is 2457.5278 records/second. Loss is 0.12267538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041370180373986425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10560/60000][Iteration 7088][Wall Clock 323.187504612s] Trained 120 records in 0.046005565 seconds. Throughput is 2608.3801 records/second. Loss is 0.10832482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004136675767353356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10680/60000][Iteration 7089][Wall Clock 323.227765719s] Trained 120 records in 0.040261107 seconds. Throughput is 2980.544 records/second. Loss is 0.119786724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00413633355393779. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10800/60000][Iteration 7090][Wall Clock 323.268358826s] Trained 120 records in 0.040593107 seconds. Throughput is 2956.167 records/second. Loss is 0.172151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004135991397137894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 10920/60000][Iteration 7091][Wall Clock 323.308897876s] Trained 120 records in 0.04053905 seconds. Throughput is 2960.109 records/second. Loss is 0.22902784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041356492969396195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 11040/60000][Iteration 7092][Wall Clock 323.353062199s] Trained 120 records in 0.044164323 seconds. Throughput is 2717.1252 records/second. Loss is 0.13165079. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041353072533289225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 11160/60000][Iteration 7093][Wall Clock 323.394294102s] Trained 120 records in 0.041231903 seconds. Throughput is 2910.3677 records/second. Loss is 0.23406753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004134965266291763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 11280/60000][Iteration 7094][Wall Clock 323.434725714s] Trained 120 records in 0.040431612 seconds. Throughput is 2967.9746 records/second. Loss is 0.19818036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004134623335814107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 11400/60000][Iteration 7095][Wall Clock 323.476228663s] Trained 120 records in 0.041502949 seconds. Throughput is 2891.3608 records/second. Loss is 0.24027409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004134281461881925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 11520/60000][Iteration 7096][Wall Clock 323.517964922s] Trained 120 records in 0.041736259 seconds. Throughput is 2875.1978 records/second. Loss is 0.23093034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00413393964448119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:29 INFO  DistriOptimizer$:406 - [Epoch 15 11640/60000][Iteration 7097][Wall Clock 323.559167038s] Trained 120 records in 0.041202116 seconds. Throughput is 2912.4717 records/second. Loss is 0.17842627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004133597883597883. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 11760/60000][Iteration 7098][Wall Clock 323.600470062s] Trained 120 records in 0.041303024 seconds. Throughput is 2905.3562 records/second. Loss is 0.12140758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004133256179217988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 11880/60000][Iteration 7099][Wall Clock 323.642888506s] Trained 120 records in 0.042418444 seconds. Throughput is 2828.9583 records/second. Loss is 0.21594861. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004132914531327492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12000/60000][Iteration 7100][Wall Clock 323.692641516s] Trained 120 records in 0.04975301 seconds. Throughput is 2411.9143 records/second. Loss is 0.23123553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041325729399123885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12120/60000][Iteration 7101][Wall Clock 323.739289312s] Trained 120 records in 0.046647796 seconds. Throughput is 2572.469 records/second. Loss is 0.22127. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004132231404958678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12240/60000][Iteration 7102][Wall Clock 323.780684142s] Trained 120 records in 0.04139483 seconds. Throughput is 2898.9128 records/second. Loss is 0.16961342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004131889926452359. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12360/60000][Iteration 7103][Wall Clock 323.821152991s] Trained 120 records in 0.040468849 seconds. Throughput is 2965.2437 records/second. Loss is 0.25883934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041315485043794415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12480/60000][Iteration 7104][Wall Clock 323.861912696s] Trained 120 records in 0.040759705 seconds. Throughput is 2944.0842 records/second. Loss is 0.10902406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004131207138725936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12600/60000][Iteration 7105][Wall Clock 323.90265869s] Trained 120 records in 0.040745994 seconds. Throughput is 2945.075 records/second. Loss is 0.21328492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004130865829477859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12720/60000][Iteration 7106][Wall Clock 323.942653243s] Trained 120 records in 0.039994553 seconds. Throughput is 3000.4087 records/second. Loss is 0.21033709. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004130524576621231. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12840/60000][Iteration 7107][Wall Clock 323.98258611s] Trained 120 records in 0.039932867 seconds. Throughput is 3005.0435 records/second. Loss is 0.2452422. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004130183380142078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 12960/60000][Iteration 7108][Wall Clock 324.023818891s] Trained 120 records in 0.041232781 seconds. Throughput is 2910.306 records/second. Loss is 0.15931338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004129842240026431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13080/60000][Iteration 7109][Wall Clock 324.064963447s] Trained 120 records in 0.041144556 seconds. Throughput is 2916.5461 records/second. Loss is 0.12587008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004129501156260324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13200/60000][Iteration 7110][Wall Clock 324.10566133s] Trained 120 records in 0.040697883 seconds. Throughput is 2948.5562 records/second. Loss is 0.10678007. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041291601288297956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13320/60000][Iteration 7111][Wall Clock 324.14928327s] Trained 120 records in 0.04362194 seconds. Throughput is 2750.9094 records/second. Loss is 0.15347134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004128819157720892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13440/60000][Iteration 7112][Wall Clock 324.190157679s] Trained 120 records in 0.040874409 seconds. Throughput is 2935.8223 records/second. Loss is 0.19150774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00412847824291966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13560/60000][Iteration 7113][Wall Clock 324.230384149s] Trained 120 records in 0.04022647 seconds. Throughput is 2983.1104 records/second. Loss is 0.18251091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004128137384412153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13680/60000][Iteration 7114][Wall Clock 324.287111105s] Trained 120 records in 0.056726956 seconds. Throughput is 2115.3965 records/second. Loss is 0.12880234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041277965821844296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13800/60000][Iteration 7115][Wall Clock 324.330536197s] Trained 120 records in 0.043425092 seconds. Throughput is 2763.3794 records/second. Loss is 0.25824556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041274558362225525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 13920/60000][Iteration 7116][Wall Clock 324.371054617s] Trained 120 records in 0.04051842 seconds. Throughput is 2961.616 records/second. Loss is 0.21066776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004127115146512587. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 14040/60000][Iteration 7117][Wall Clock 324.411239354s] Trained 120 records in 0.040184737 seconds. Throughput is 2986.2085 records/second. Loss is 0.14798254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004126774513040607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 14160/60000][Iteration 7118][Wall Clock 324.45175688s] Trained 120 records in 0.040517526 seconds. Throughput is 2961.6812 records/second. Loss is 0.1780958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004126433935792688. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 14280/60000][Iteration 7119][Wall Clock 324.492543069s] Trained 120 records in 0.040786189 seconds. Throughput is 2942.1724 records/second. Loss is 0.16891241. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00412609341475491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:30 INFO  DistriOptimizer$:406 - [Epoch 15 14400/60000][Iteration 7120][Wall Clock 324.533085561s] Trained 120 records in 0.040542492 seconds. Throughput is 2959.8577 records/second. Loss is 0.18557855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00412575294991336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 14520/60000][Iteration 7121][Wall Clock 324.572439929s] Trained 120 records in 0.039354368 seconds. Throughput is 3049.2168 records/second. Loss is 0.18960743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004125412541254125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 14640/60000][Iteration 7122][Wall Clock 324.613118669s] Trained 120 records in 0.04067874 seconds. Throughput is 2949.9438 records/second. Loss is 0.1465378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004125072188763303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 14760/60000][Iteration 7123][Wall Clock 324.653705094s] Trained 120 records in 0.040586425 seconds. Throughput is 2956.6536 records/second. Loss is 0.29571512. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004124731892426992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 14880/60000][Iteration 7124][Wall Clock 324.695457807s] Trained 120 records in 0.041752713 seconds. Throughput is 2874.0647 records/second. Loss is 0.2041193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004124391652231297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15000/60000][Iteration 7125][Wall Clock 324.743895725s] Trained 120 records in 0.048437918 seconds. Throughput is 2477.398 records/second. Loss is 0.16315264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004124051468162322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15120/60000][Iteration 7126][Wall Clock 324.787466181s] Trained 120 records in 0.043570456 seconds. Throughput is 2754.16 records/second. Loss is 0.23798709. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004123711340206186. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15240/60000][Iteration 7127][Wall Clock 324.828222315s] Trained 120 records in 0.040756134 seconds. Throughput is 2944.3423 records/second. Loss is 0.1487337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004123371268349002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15360/60000][Iteration 7128][Wall Clock 324.868773348s] Trained 120 records in 0.040551033 seconds. Throughput is 2959.2341 records/second. Loss is 0.13268965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004123031252576895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15480/60000][Iteration 7129][Wall Clock 324.908743373s] Trained 120 records in 0.039970025 seconds. Throughput is 3002.2498 records/second. Loss is 0.21612269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041226912928759895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15600/60000][Iteration 7130][Wall Clock 324.952597541s] Trained 120 records in 0.043854168 seconds. Throughput is 2736.3418 records/second. Loss is 0.13699125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004122351389232418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15720/60000][Iteration 7131][Wall Clock 324.992855289s] Trained 120 records in 0.040257748 seconds. Throughput is 2980.7927 records/second. Loss is 0.15141946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004122011541632316. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15840/60000][Iteration 7132][Wall Clock 325.033809108s] Trained 120 records in 0.040953819 seconds. Throughput is 2930.1296 records/second. Loss is 0.1825478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004121671750061825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 15960/60000][Iteration 7133][Wall Clock 325.074758764s] Trained 120 records in 0.040949656 seconds. Throughput is 2930.4275 records/second. Loss is 0.20459548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004121332014507088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16080/60000][Iteration 7134][Wall Clock 325.115930089s] Trained 120 records in 0.041171325 seconds. Throughput is 2914.6501 records/second. Loss is 0.1152293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004120992334954257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16200/60000][Iteration 7135][Wall Clock 325.156627837s] Trained 120 records in 0.040697748 seconds. Throughput is 2948.566 records/second. Loss is 0.1440883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041206527113894845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16320/60000][Iteration 7136][Wall Clock 325.196748688s] Trained 120 records in 0.040120851 seconds. Throughput is 2990.9634 records/second. Loss is 0.18596503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004120313143798929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16440/60000][Iteration 7137][Wall Clock 325.236722268s] Trained 120 records in 0.03997358 seconds. Throughput is 3001.983 records/second. Loss is 0.107608534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004119973632168754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16560/60000][Iteration 7138][Wall Clock 325.277363785s] Trained 120 records in 0.040641517 seconds. Throughput is 2952.6458 records/second. Loss is 0.26229998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004119634176485128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16680/60000][Iteration 7139][Wall Clock 325.317771979s] Trained 120 records in 0.040408194 seconds. Throughput is 2969.6948 records/second. Loss is 0.10373872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004119294776734223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16800/60000][Iteration 7140][Wall Clock 325.357620255s] Trained 120 records in 0.039848276 seconds. Throughput is 3011.4226 records/second. Loss is 0.19870634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004118955432902216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 16920/60000][Iteration 7141][Wall Clock 325.412449451s] Trained 120 records in 0.054829196 seconds. Throughput is 2188.615 records/second. Loss is 0.16196993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004118616144975288. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 17040/60000][Iteration 7142][Wall Clock 325.456987333s] Trained 120 records in 0.044537882 seconds. Throughput is 2694.3354 records/second. Loss is 0.19539261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041182769129396255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 17160/60000][Iteration 7143][Wall Clock 325.497899447s] Trained 120 records in 0.040912114 seconds. Throughput is 2933.1165 records/second. Loss is 0.22196992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00411793773678142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:31 INFO  DistriOptimizer$:406 - [Epoch 15 17280/60000][Iteration 7144][Wall Clock 325.537962633s] Trained 120 records in 0.040063186 seconds. Throughput is 2995.2683 records/second. Loss is 0.1752964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004117598616486864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 17400/60000][Iteration 7145][Wall Clock 325.57774985s] Trained 120 records in 0.039787217 seconds. Throughput is 3016.044 records/second. Loss is 0.16376139. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004117259552042161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 17520/60000][Iteration 7146][Wall Clock 325.617249801s] Trained 120 records in 0.039499951 seconds. Throughput is 3037.9785 records/second. Loss is 0.14330898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004116920543433511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 17640/60000][Iteration 7147][Wall Clock 325.656950079s] Trained 120 records in 0.039700278 seconds. Throughput is 3022.649 records/second. Loss is 0.19591261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004116581590647127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 17760/60000][Iteration 7148][Wall Clock 325.697145359s] Trained 120 records in 0.04019528 seconds. Throughput is 2985.4253 records/second. Loss is 0.085300684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004116242693669218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 17880/60000][Iteration 7149][Wall Clock 325.742908305s] Trained 120 records in 0.045762946 seconds. Throughput is 2622.209 records/second. Loss is 0.1792356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004115903852486006. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18000/60000][Iteration 7150][Wall Clock 325.791047057s] Trained 120 records in 0.048138752 seconds. Throughput is 2492.7942 records/second. Loss is 0.14747687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00411556506708371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18120/60000][Iteration 7151][Wall Clock 325.834786092s] Trained 120 records in 0.043739035 seconds. Throughput is 2743.5447 records/second. Loss is 0.26504436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004115226337448559. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18240/60000][Iteration 7152][Wall Clock 325.87438585s] Trained 120 records in 0.039599758 seconds. Throughput is 3030.3215 records/second. Loss is 0.11124465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004114887663566784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18360/60000][Iteration 7153][Wall Clock 325.914131451s] Trained 120 records in 0.039745601 seconds. Throughput is 3019.202 records/second. Loss is 0.15361062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004114549045424621. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18480/60000][Iteration 7154][Wall Clock 325.953746962s] Trained 120 records in 0.039615511 seconds. Throughput is 3029.1165 records/second. Loss is 0.19044851. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041142104830083105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18600/60000][Iteration 7155][Wall Clock 325.993894626s] Trained 120 records in 0.040147664 seconds. Throughput is 2988.966 records/second. Loss is 0.2039924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004113871976304097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18720/60000][Iteration 7156][Wall Clock 326.034910311s] Trained 120 records in 0.041015685 seconds. Throughput is 2925.71 records/second. Loss is 0.23063208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004113533525298231. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18840/60000][Iteration 7157][Wall Clock 326.075560826s] Trained 120 records in 0.040650515 seconds. Throughput is 2951.992 records/second. Loss is 0.13906938. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004113195129976966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 18960/60000][Iteration 7158][Wall Clock 326.115966813s] Trained 120 records in 0.040405987 seconds. Throughput is 2969.8567 records/second. Loss is 0.14402366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004112856790326561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19080/60000][Iteration 7159][Wall Clock 326.156034083s] Trained 120 records in 0.04006727 seconds. Throughput is 2994.9631 records/second. Loss is 0.1610214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004112518506333279. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19200/60000][Iteration 7160][Wall Clock 326.19579853s] Trained 120 records in 0.039764447 seconds. Throughput is 3017.7712 records/second. Loss is 0.24641898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004112180277983387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19320/60000][Iteration 7161][Wall Clock 326.235748376s] Trained 120 records in 0.039949846 seconds. Throughput is 3003.7664 records/second. Loss is 0.20045264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004111842105263158. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19440/60000][Iteration 7162][Wall Clock 326.276917661s] Trained 120 records in 0.041169285 seconds. Throughput is 2914.7944 records/second. Loss is 0.14673471. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004111503988158869. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19560/60000][Iteration 7163][Wall Clock 326.318587894s] Trained 120 records in 0.041670233 seconds. Throughput is 2879.7534 records/second. Loss is 0.16118965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004111165926656799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19680/60000][Iteration 7164][Wall Clock 326.360394909s] Trained 120 records in 0.041807015 seconds. Throughput is 2870.3318 records/second. Loss is 0.15131345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004110827920743238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19800/60000][Iteration 7165][Wall Clock 326.401585939s] Trained 120 records in 0.04119103 seconds. Throughput is 2913.2556 records/second. Loss is 0.2261603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004110489970404472. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 19920/60000][Iteration 7166][Wall Clock 326.442811687s] Trained 120 records in 0.041225748 seconds. Throughput is 2910.8025 records/second. Loss is 0.26468977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004110152075626799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 20040/60000][Iteration 7167][Wall Clock 326.492316888s] Trained 120 records in 0.049505201 seconds. Throughput is 2423.9878 records/second. Loss is 0.25864002. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004109814236396514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:32 INFO  DistriOptimizer$:406 - [Epoch 15 20160/60000][Iteration 7168][Wall Clock 326.542177577s] Trained 120 records in 0.049860689 seconds. Throughput is 2406.7056 records/second. Loss is 0.30159742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004109476452699926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 20280/60000][Iteration 7169][Wall Clock 326.583928493s] Trained 120 records in 0.041750916 seconds. Throughput is 2874.1885 records/second. Loss is 0.19467601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00410913872452334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 20400/60000][Iteration 7170][Wall Clock 326.624111928s] Trained 120 records in 0.040183435 seconds. Throughput is 2986.3052 records/second. Loss is 0.24900128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00410880105185307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 20520/60000][Iteration 7171][Wall Clock 326.663997041s] Trained 120 records in 0.039885113 seconds. Throughput is 3008.6416 records/second. Loss is 0.18843958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004108463434675432. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 20640/60000][Iteration 7172][Wall Clock 326.704040926s] Trained 120 records in 0.040043885 seconds. Throughput is 2996.7122 records/second. Loss is 0.13710311. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004108125872976748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 20760/60000][Iteration 7173][Wall Clock 326.743280672s] Trained 120 records in 0.039239746 seconds. Throughput is 3058.1238 records/second. Loss is 0.17967074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004107788366743345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 20880/60000][Iteration 7174][Wall Clock 326.784867815s] Trained 120 records in 0.041587143 seconds. Throughput is 2885.507 records/second. Loss is 0.1214294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004107450915961554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21000/60000][Iteration 7175][Wall Clock 326.827542402s] Trained 120 records in 0.042674587 seconds. Throughput is 2811.978 records/second. Loss is 0.105694935. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041071135206177094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21120/60000][Iteration 7176][Wall Clock 326.872524955s] Trained 120 records in 0.044982553 seconds. Throughput is 2667.701 records/second. Loss is 0.21098605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004106776180698152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21240/60000][Iteration 7177][Wall Clock 326.915339431s] Trained 120 records in 0.042814476 seconds. Throughput is 2802.7905 records/second. Loss is 0.283325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004106438896189225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21360/60000][Iteration 7178][Wall Clock 326.95532328s] Trained 120 records in 0.039983849 seconds. Throughput is 3001.2117 records/second. Loss is 0.17397518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004106101667077277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21480/60000][Iteration 7179][Wall Clock 326.995699288s] Trained 120 records in 0.040376008 seconds. Throughput is 2972.062 records/second. Loss is 0.16558199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004105764493348662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21600/60000][Iteration 7180][Wall Clock 327.036203603s] Trained 120 records in 0.040504315 seconds. Throughput is 2962.6475 records/second. Loss is 0.26806158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004105427374989736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21720/60000][Iteration 7181][Wall Clock 327.078208837s] Trained 120 records in 0.042005234 seconds. Throughput is 2856.7869 records/second. Loss is 0.1888009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004105090311986864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21840/60000][Iteration 7182][Wall Clock 327.119004505s] Trained 120 records in 0.040795668 seconds. Throughput is 2941.4888 records/second. Loss is 0.16594522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00410475330432641. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 21960/60000][Iteration 7183][Wall Clock 327.159881235s] Trained 120 records in 0.04087673 seconds. Throughput is 2935.6555 records/second. Loss is 0.21183322. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004104416351994746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22080/60000][Iteration 7184][Wall Clock 327.200652311s] Trained 120 records in 0.040771076 seconds. Throughput is 2943.2632 records/second. Loss is 0.10406539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004104079454978248. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22200/60000][Iteration 7185][Wall Clock 327.240329369s] Trained 120 records in 0.039677058 seconds. Throughput is 3024.4177 records/second. Loss is 0.21884446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0041037426132632965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22320/60000][Iteration 7186][Wall Clock 327.2840892s] Trained 120 records in 0.043759831 seconds. Throughput is 2742.241 records/second. Loss is 0.229688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004103405826836274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22440/60000][Iteration 7187][Wall Clock 327.324504942s] Trained 120 records in 0.040415742 seconds. Throughput is 2969.1401 records/second. Loss is 0.12276662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004103069095683571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22560/60000][Iteration 7188][Wall Clock 327.364518754s] Trained 120 records in 0.040013812 seconds. Throughput is 2998.9644 records/second. Loss is 0.20870584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004102732419791581. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22680/60000][Iteration 7189][Wall Clock 327.404798339s] Trained 120 records in 0.040279585 seconds. Throughput is 2979.1765 records/second. Loss is 0.1591715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004102395799146702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22800/60000][Iteration 7190][Wall Clock 327.446131981s] Trained 120 records in 0.041333642 seconds. Throughput is 2903.204 records/second. Loss is 0.16416651. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004102059233735335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 22920/60000][Iteration 7191][Wall Clock 327.48643765s] Trained 120 records in 0.040305669 seconds. Throughput is 2977.2485 records/second. Loss is 0.1656185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004101722723543888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:33 INFO  DistriOptimizer$:406 - [Epoch 15 23040/60000][Iteration 7192][Wall Clock 327.526517895s] Trained 120 records in 0.040080245 seconds. Throughput is 2993.9937 records/second. Loss is 0.10584099. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004101386268558773. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 23160/60000][Iteration 7193][Wall Clock 327.566757411s] Trained 120 records in 0.040239516 seconds. Throughput is 2982.143 records/second. Loss is 0.17694072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004101049868766404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 23280/60000][Iteration 7194][Wall Clock 327.615738853s] Trained 120 records in 0.048981442 seconds. Throughput is 2449.9075 records/second. Loss is 0.17598939. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004100713524153202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 23400/60000][Iteration 7195][Wall Clock 327.665565843s] Trained 120 records in 0.04982699 seconds. Throughput is 2408.3333 records/second. Loss is 0.18833385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004100377234705593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 23520/60000][Iteration 7196][Wall Clock 327.707575236s] Trained 120 records in 0.042009393 seconds. Throughput is 2856.504 records/second. Loss is 0.18561293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004100041000410004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 23640/60000][Iteration 7197][Wall Clock 327.747559669s] Trained 120 records in 0.039984433 seconds. Throughput is 3001.1677 records/second. Loss is 0.23517126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040997048212528696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 23760/60000][Iteration 7198][Wall Clock 327.787454536s] Trained 120 records in 0.039894867 seconds. Throughput is 3007.9058 records/second. Loss is 0.2057583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004099368697220628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 23880/60000][Iteration 7199][Wall Clock 327.829440701s] Trained 120 records in 0.041986165 seconds. Throughput is 2858.0845 records/second. Loss is 0.1752768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004099032628299721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24000/60000][Iteration 7200][Wall Clock 327.871441609s] Trained 120 records in 0.042000908 seconds. Throughput is 2857.081 records/second. Loss is 0.09507596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004098696614476597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24120/60000][Iteration 7201][Wall Clock 327.914051452s] Trained 120 records in 0.042609843 seconds. Throughput is 2816.2505 records/second. Loss is 0.1862412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004098360655737704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24240/60000][Iteration 7202][Wall Clock 327.962371968s] Trained 120 records in 0.048320516 seconds. Throughput is 2483.4172 records/second. Loss is 0.16605534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004098024752069503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24360/60000][Iteration 7203][Wall Clock 328.006469398s] Trained 120 records in 0.04409743 seconds. Throughput is 2721.247 records/second. Loss is 0.26492244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004097688903458449. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24480/60000][Iteration 7204][Wall Clock 328.047613926s] Trained 120 records in 0.041144528 seconds. Throughput is 2916.5483 records/second. Loss is 0.16826335. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004097353109891011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24600/60000][Iteration 7205][Wall Clock 328.092605514s] Trained 120 records in 0.044991588 seconds. Throughput is 2667.1653 records/second. Loss is 0.21939936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004097017371353654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24720/60000][Iteration 7206][Wall Clock 328.134184333s] Trained 120 records in 0.041578819 seconds. Throughput is 2886.085 records/second. Loss is 0.21305847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004096681687832855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24840/60000][Iteration 7207][Wall Clock 328.175361989s] Trained 120 records in 0.041177656 seconds. Throughput is 2914.202 records/second. Loss is 0.23190646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004096346059315091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 24960/60000][Iteration 7208][Wall Clock 328.216172504s] Trained 120 records in 0.040810515 seconds. Throughput is 2940.4187 records/second. Loss is 0.16249505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004096010485786844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25080/60000][Iteration 7209][Wall Clock 328.257054419s] Trained 120 records in 0.040881915 seconds. Throughput is 2935.2834 records/second. Loss is 0.1211494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040956749672346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25200/60000][Iteration 7210][Wall Clock 328.298071127s] Trained 120 records in 0.041016708 seconds. Throughput is 2925.637 records/second. Loss is 0.20078312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004095339503644852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25320/60000][Iteration 7211][Wall Clock 328.338955933s] Trained 120 records in 0.040884806 seconds. Throughput is 2935.0757 records/second. Loss is 0.2813123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004095004095004095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25440/60000][Iteration 7212][Wall Clock 328.379751656s] Trained 120 records in 0.040795723 seconds. Throughput is 2941.4846 records/second. Loss is 0.08807906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004094668741298829. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25560/60000][Iteration 7213][Wall Clock 328.419671249s] Trained 120 records in 0.039919593 seconds. Throughput is 3006.0427 records/second. Loss is 0.17562784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004094333442515558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25680/60000][Iteration 7214][Wall Clock 328.46002914s] Trained 120 records in 0.040357891 seconds. Throughput is 2973.3962 records/second. Loss is 0.08722789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004093998198640793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25800/60000][Iteration 7215][Wall Clock 328.500609629s] Trained 120 records in 0.040580489 seconds. Throughput is 2957.0862 records/second. Loss is 0.114661835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040936630096610445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:34 INFO  DistriOptimizer$:406 - [Epoch 15 25920/60000][Iteration 7216][Wall Clock 328.540448615s] Trained 120 records in 0.039838986 seconds. Throughput is 3012.125 records/second. Loss is 0.08653011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004093327875562832. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26040/60000][Iteration 7217][Wall Clock 328.580552796s] Trained 120 records in 0.040104181 seconds. Throughput is 2992.2068 records/second. Loss is 0.12960729. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004092992796332679. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26160/60000][Iteration 7218][Wall Clock 328.620990134s] Trained 120 records in 0.040437338 seconds. Throughput is 2967.5544 records/second. Loss is 0.1425838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004092657771957109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26280/60000][Iteration 7219][Wall Clock 328.661136634s] Trained 120 records in 0.0401465 seconds. Throughput is 2989.0525 records/second. Loss is 0.10333861. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004092322802422655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26400/60000][Iteration 7220][Wall Clock 328.700630966s] Trained 120 records in 0.039494332 seconds. Throughput is 3038.4106 records/second. Loss is 0.2135582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004091987887715852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26520/60000][Iteration 7221][Wall Clock 328.75417572s] Trained 120 records in 0.053544754 seconds. Throughput is 2241.116 records/second. Loss is 0.24435711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004091653027823241. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26640/60000][Iteration 7222][Wall Clock 328.797570465s] Trained 120 records in 0.043394745 seconds. Throughput is 2765.3118 records/second. Loss is 0.15725984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004091318222731364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26760/60000][Iteration 7223][Wall Clock 328.842182344s] Trained 120 records in 0.044611879 seconds. Throughput is 2689.8665 records/second. Loss is 0.14002617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004090983472426772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 26880/60000][Iteration 7224][Wall Clock 328.883925244s] Trained 120 records in 0.0417429 seconds. Throughput is 2874.7405 records/second. Loss is 0.12622379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004090648776896015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27000/60000][Iteration 7225][Wall Clock 328.924872161s] Trained 120 records in 0.040946917 seconds. Throughput is 2930.6238 records/second. Loss is 0.19203217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004090314136125654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27120/60000][Iteration 7226][Wall Clock 328.965941677s] Trained 120 records in 0.041069516 seconds. Throughput is 2921.8752 records/second. Loss is 0.22983238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004089979550102249. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27240/60000][Iteration 7227][Wall Clock 329.006751588s] Trained 120 records in 0.040809911 seconds. Throughput is 2940.4622 records/second. Loss is 0.1215636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004089645018812368. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27360/60000][Iteration 7228][Wall Clock 329.048014724s] Trained 120 records in 0.041263136 seconds. Throughput is 2908.1648 records/second. Loss is 0.14307301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004089310542242578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27480/60000][Iteration 7229][Wall Clock 329.099160249s] Trained 120 records in 0.051145525 seconds. Throughput is 2346.2463 records/second. Loss is 0.18094842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040889761203794575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27600/60000][Iteration 7230][Wall Clock 329.139802067s] Trained 120 records in 0.040641818 seconds. Throughput is 2952.6238 records/second. Loss is 0.23664014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004088641753209584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27720/60000][Iteration 7231][Wall Clock 329.179489667s] Trained 120 records in 0.0396876 seconds. Throughput is 3023.6145 records/second. Loss is 0.10233226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004088307440719542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27840/60000][Iteration 7232][Wall Clock 329.219000836s] Trained 120 records in 0.039511169 seconds. Throughput is 3037.1157 records/second. Loss is 0.26626378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00408797318289592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 27960/60000][Iteration 7233][Wall Clock 329.258783326s] Trained 120 records in 0.03978249 seconds. Throughput is 3016.4023 records/second. Loss is 0.12763391. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004087638979725311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 28080/60000][Iteration 7234][Wall Clock 329.298741255s] Trained 120 records in 0.039957929 seconds. Throughput is 3003.1587 records/second. Loss is 0.10981282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00408730483119431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 28200/60000][Iteration 7235][Wall Clock 329.338432829s] Trained 120 records in 0.039691574 seconds. Throughput is 3023.3115 records/second. Loss is 0.23467855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004086970737289521. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 28320/60000][Iteration 7236][Wall Clock 329.378788566s] Trained 120 records in 0.040355737 seconds. Throughput is 2973.555 records/second. Loss is 0.1763782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004086636697997548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 28440/60000][Iteration 7237][Wall Clock 329.418876177s] Trained 120 records in 0.040087611 seconds. Throughput is 2993.4436 records/second. Loss is 0.16638926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004086302713305002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 28560/60000][Iteration 7238][Wall Clock 329.458439155s] Trained 120 records in 0.039562978 seconds. Throughput is 3033.1387 records/second. Loss is 0.32042667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004085968783198496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 28680/60000][Iteration 7239][Wall Clock 329.498417647s] Trained 120 records in 0.039978492 seconds. Throughput is 3001.614 records/second. Loss is 0.14131622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004085634907664651. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:35 INFO  DistriOptimizer$:406 - [Epoch 15 28800/60000][Iteration 7240][Wall Clock 329.538623463s] Trained 120 records in 0.040205816 seconds. Throughput is 2984.6426 records/second. Loss is 0.13363674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040853010866900895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 28920/60000][Iteration 7241][Wall Clock 329.578772334s] Trained 120 records in 0.040148871 seconds. Throughput is 2988.8762 records/second. Loss is 0.30242327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004084967320261437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29040/60000][Iteration 7242][Wall Clock 329.618733098s] Trained 120 records in 0.039960764 seconds. Throughput is 3002.9456 records/second. Loss is 0.23582138. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00408463360836533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29160/60000][Iteration 7243][Wall Clock 329.662519062s] Trained 120 records in 0.043785964 seconds. Throughput is 2740.6042 records/second. Loss is 0.1096694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040842999509884004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29280/60000][Iteration 7244][Wall Clock 329.702680182s] Trained 120 records in 0.04016112 seconds. Throughput is 2987.9644 records/second. Loss is 0.15261848. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004083966348117292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29400/60000][Iteration 7245][Wall Clock 329.742589749s] Trained 120 records in 0.039909567 seconds. Throughput is 3006.7979 records/second. Loss is 0.10834269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004083632799738647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29520/60000][Iteration 7246][Wall Clock 329.78221834s] Trained 120 records in 0.039628591 seconds. Throughput is 3028.1167 records/second. Loss is 0.28595683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004083299305839118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29640/60000][Iteration 7247][Wall Clock 329.831169288s] Trained 120 records in 0.048950948 seconds. Throughput is 2451.4336 records/second. Loss is 0.14200681. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004082965866405356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29760/60000][Iteration 7248][Wall Clock 329.880592816s] Trained 120 records in 0.049423528 seconds. Throughput is 2427.9934 records/second. Loss is 0.21662349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004082632481424022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 29880/60000][Iteration 7249][Wall Clock 329.924077619s] Trained 120 records in 0.043484803 seconds. Throughput is 2759.5847 records/second. Loss is 0.17113629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004082299150881776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30000/60000][Iteration 7250][Wall Clock 329.966133621s] Trained 120 records in 0.042056002 seconds. Throughput is 2853.3384 records/second. Loss is 0.21786736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004081965874765288. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30120/60000][Iteration 7251][Wall Clock 330.007445098s] Trained 120 records in 0.041311477 seconds. Throughput is 2904.7617 records/second. Loss is 0.19290267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004081632653061224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30240/60000][Iteration 7252][Wall Clock 330.047837903s] Trained 120 records in 0.040392805 seconds. Throughput is 2970.8262 records/second. Loss is 0.15225768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004081299485756264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30360/60000][Iteration 7253][Wall Clock 330.088578333s] Trained 120 records in 0.04074043 seconds. Throughput is 2945.477 records/second. Loss is 0.14522465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004080966372837088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30480/60000][Iteration 7254][Wall Clock 330.128793105s] Trained 120 records in 0.040214772 seconds. Throughput is 2983.978 records/second. Loss is 0.16261269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004080633314290378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30600/60000][Iteration 7255][Wall Clock 330.177476635s] Trained 120 records in 0.04868353 seconds. Throughput is 2464.8992 records/second. Loss is 0.16334462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004080300310102824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30720/60000][Iteration 7256][Wall Clock 330.220437671s] Trained 120 records in 0.042961036 seconds. Throughput is 2793.2288 records/second. Loss is 0.14376429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004079967360261118. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30840/60000][Iteration 7257][Wall Clock 330.260316051s] Trained 120 records in 0.03987838 seconds. Throughput is 3009.1494 records/second. Loss is 0.29261062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004079634464751959. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 30960/60000][Iteration 7258][Wall Clock 330.300176591s] Trained 120 records in 0.03986054 seconds. Throughput is 3010.496 records/second. Loss is 0.11840701. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004079301623562046. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 31080/60000][Iteration 7259][Wall Clock 330.340197459s] Trained 120 records in 0.040020868 seconds. Throughput is 2998.4358 records/second. Loss is 0.23979148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004078968836678088. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 31200/60000][Iteration 7260][Wall Clock 330.380478163s] Trained 120 records in 0.040280704 seconds. Throughput is 2979.094 records/second. Loss is 0.309419. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004078636104086793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 31320/60000][Iteration 7261][Wall Clock 330.424327155s] Trained 120 records in 0.043848992 seconds. Throughput is 2736.665 records/second. Loss is 0.21887083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004078303425774878. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 31440/60000][Iteration 7262][Wall Clock 330.463730391s] Trained 120 records in 0.039403236 seconds. Throughput is 3045.435 records/second. Loss is 0.23205519. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004077970801729059. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 31560/60000][Iteration 7263][Wall Clock 330.50348329s] Trained 120 records in 0.039752899 seconds. Throughput is 3018.6477 records/second. Loss is 0.25700763. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004077638231936063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:36 INFO  DistriOptimizer$:406 - [Epoch 15 31680/60000][Iteration 7264][Wall Clock 330.543563935s] Trained 120 records in 0.040080645 seconds. Throughput is 2993.9639 records/second. Loss is 0.19763184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004077305716382614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 31800/60000][Iteration 7265][Wall Clock 330.583581657s] Trained 120 records in 0.040017722 seconds. Throughput is 2998.6716 records/second. Loss is 0.15102388. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040769732550554475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 31920/60000][Iteration 7266][Wall Clock 330.623249716s] Trained 120 records in 0.039668059 seconds. Throughput is 3025.1038 records/second. Loss is 0.1357991. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004076640847941296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32040/60000][Iteration 7267][Wall Clock 330.663130582s] Trained 120 records in 0.039880866 seconds. Throughput is 3008.962 records/second. Loss is 0.18363383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004076308495026904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32160/60000][Iteration 7268][Wall Clock 330.70275998s] Trained 120 records in 0.039629398 seconds. Throughput is 3028.055 records/second. Loss is 0.20919843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004075976196299013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32280/60000][Iteration 7269][Wall Clock 330.742579414s] Trained 120 records in 0.039819434 seconds. Throughput is 3013.6038 records/second. Loss is 0.18111919. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004075643951744376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32400/60000][Iteration 7270][Wall Clock 330.782344858s] Trained 120 records in 0.039765444 seconds. Throughput is 3017.6956 records/second. Loss is 0.11733999. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004075311761349743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32520/60000][Iteration 7271][Wall Clock 330.822155291s] Trained 120 records in 0.039810433 seconds. Throughput is 3014.2852 records/second. Loss is 0.15206249. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004074979625101875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32640/60000][Iteration 7272][Wall Clock 330.862669713s] Trained 120 records in 0.040514422 seconds. Throughput is 2961.9082 records/second. Loss is 0.095239595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040746475429875315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32760/60000][Iteration 7273][Wall Clock 330.902743109s] Trained 120 records in 0.040073396 seconds. Throughput is 2994.5054 records/second. Loss is 0.21545686. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004074315514993481. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 32880/60000][Iteration 7274][Wall Clock 330.963603269s] Trained 120 records in 0.06086016 seconds. Throughput is 1971.7332 records/second. Loss is 0.20572805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004073983541106494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33000/60000][Iteration 7275][Wall Clock 331.008586682s] Trained 120 records in 0.044983413 seconds. Throughput is 2667.65 records/second. Loss is 0.23072706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004073651621313346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33120/60000][Iteration 7276][Wall Clock 331.050024296s] Trained 120 records in 0.041437614 seconds. Throughput is 2895.9197 records/second. Loss is 0.21481575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004073319755600814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33240/60000][Iteration 7277][Wall Clock 331.090713736s] Trained 120 records in 0.04068944 seconds. Throughput is 2949.1682 records/second. Loss is 0.13498816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004072987943955686. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33360/60000][Iteration 7278][Wall Clock 331.131368313s] Trained 120 records in 0.040654577 seconds. Throughput is 2951.6973 records/second. Loss is 0.19738083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040726561863647474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33480/60000][Iteration 7279][Wall Clock 331.171741585s] Trained 120 records in 0.040373272 seconds. Throughput is 2972.2634 records/second. Loss is 0.1342957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004072324482814791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33600/60000][Iteration 7280][Wall Clock 331.215179761s] Trained 120 records in 0.043438176 seconds. Throughput is 2762.5469 records/second. Loss is 0.27134916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004071992833292614. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33720/60000][Iteration 7281][Wall Clock 331.256617195s] Trained 120 records in 0.041437434 seconds. Throughput is 2895.9324 records/second. Loss is 0.13292891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004071661237785016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33840/60000][Iteration 7282][Wall Clock 331.308166925s] Trained 120 records in 0.05154973 seconds. Throughput is 2327.8494 records/second. Loss is 0.24732058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004071329696278805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 33960/60000][Iteration 7283][Wall Clock 331.348715324s] Trained 120 records in 0.040548399 seconds. Throughput is 2959.4263 records/second. Loss is 0.10046105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040709982087607875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 34080/60000][Iteration 7284][Wall Clock 331.389042721s] Trained 120 records in 0.040327397 seconds. Throughput is 2975.6445 records/second. Loss is 0.19080074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004070666775217781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 34200/60000][Iteration 7285][Wall Clock 331.428981635s] Trained 120 records in 0.039938914 seconds. Throughput is 3004.5884 records/second. Loss is 0.2643321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040703353956366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 34320/60000][Iteration 7286][Wall Clock 331.468814719s] Trained 120 records in 0.039833084 seconds. Throughput is 3012.5713 records/second. Loss is 0.15304664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004070004070004071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:37 INFO  DistriOptimizer$:406 - [Epoch 15 34440/60000][Iteration 7287][Wall Clock 331.508807125s] Trained 120 records in 0.039992406 seconds. Throughput is 3000.5696 records/second. Loss is 0.13604546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004069672798307016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 34560/60000][Iteration 7288][Wall Clock 331.549244957s] Trained 120 records in 0.040437832 seconds. Throughput is 2967.518 records/second. Loss is 0.2569098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040693415805322704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 34680/60000][Iteration 7289][Wall Clock 331.58933122s] Trained 120 records in 0.040086263 seconds. Throughput is 2993.5442 records/second. Loss is 0.10126092. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004069010416666666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 34800/60000][Iteration 7290][Wall Clock 331.629560576s] Trained 120 records in 0.040229356 seconds. Throughput is 2982.8962 records/second. Loss is 0.19432831. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004068679306697047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 34920/60000][Iteration 7291][Wall Clock 331.670370954s] Trained 120 records in 0.040810378 seconds. Throughput is 2940.4287 records/second. Loss is 0.1301616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040683482506102524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35040/60000][Iteration 7292][Wall Clock 331.711267766s] Trained 120 records in 0.040896812 seconds. Throughput is 2934.214 records/second. Loss is 0.2040704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004068017248393133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35160/60000][Iteration 7293][Wall Clock 331.751912782s] Trained 120 records in 0.040645016 seconds. Throughput is 2952.3916 records/second. Loss is 0.15531059. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004067686300032541. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35280/60000][Iteration 7294][Wall Clock 331.791495785s] Trained 120 records in 0.039583003 seconds. Throughput is 3031.6045 records/second. Loss is 0.13662414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004067355405515334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35400/60000][Iteration 7295][Wall Clock 331.831734637s] Trained 120 records in 0.040238852 seconds. Throughput is 2982.1924 records/second. Loss is 0.1871509. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004067024564828371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35520/60000][Iteration 7296][Wall Clock 331.872458013s] Trained 120 records in 0.040723376 seconds. Throughput is 2946.7104 records/second. Loss is 0.1701573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004066693777958519. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35640/60000][Iteration 7297][Wall Clock 331.912546645s] Trained 120 records in 0.040088632 seconds. Throughput is 2993.3674 records/second. Loss is 0.24866404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004066363044892648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35760/60000][Iteration 7298][Wall Clock 331.952790328s] Trained 120 records in 0.040243683 seconds. Throughput is 2981.8345 records/second. Loss is 0.21173407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004066032365617631. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 35880/60000][Iteration 7299][Wall Clock 332.004072034s] Trained 120 records in 0.051281706 seconds. Throughput is 2340.0159 records/second. Loss is 0.108765356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004065701740120345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36000/60000][Iteration 7300][Wall Clock 332.054917915s] Trained 120 records in 0.050845881 seconds. Throughput is 2360.0732 records/second. Loss is 0.15850575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040653711683876735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36120/60000][Iteration 7301][Wall Clock 332.095623579s] Trained 120 records in 0.040705664 seconds. Throughput is 2947.993 records/second. Loss is 0.15789986. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040650406504065045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36240/60000][Iteration 7302][Wall Clock 332.135833389s] Trained 120 records in 0.04020981 seconds. Throughput is 2984.3462 records/second. Loss is 0.1348898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004064710186163726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36360/60000][Iteration 7303][Wall Clock 332.175980798s] Trained 120 records in 0.040147409 seconds. Throughput is 2988.9849 records/second. Loss is 0.13337077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004064379775646236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36480/60000][Iteration 7304][Wall Clock 332.216156782s] Trained 120 records in 0.040175984 seconds. Throughput is 2986.859 records/second. Loss is 0.23054774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040640494188409326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36600/60000][Iteration 7305][Wall Clock 332.256319155s] Trained 120 records in 0.040162373 seconds. Throughput is 2987.8713 records/second. Loss is 0.21906249. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004063719115734721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36720/60000][Iteration 7306][Wall Clock 332.295959503s] Trained 120 records in 0.039640348 seconds. Throughput is 3027.2185 records/second. Loss is 0.114839695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004063388866314506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36840/60000][Iteration 7307][Wall Clock 332.335306501s] Trained 120 records in 0.039346998 seconds. Throughput is 3049.788 records/second. Loss is 0.260819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004063058670567203. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 36960/60000][Iteration 7308][Wall Clock 332.384224687s] Trained 120 records in 0.048918186 seconds. Throughput is 2453.0754 records/second. Loss is 0.17717715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004062728528479727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 37080/60000][Iteration 7309][Wall Clock 332.427914568s] Trained 120 records in 0.043689881 seconds. Throughput is 2746.6313 records/second. Loss is 0.23796228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004062398440038999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 37200/60000][Iteration 7310][Wall Clock 332.468172611s] Trained 120 records in 0.040258043 seconds. Throughput is 2980.7708 records/second. Loss is 0.17901151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004062068405231944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:38 INFO  DistriOptimizer$:406 - [Epoch 15 37320/60000][Iteration 7311][Wall Clock 332.507822633s] Trained 120 records in 0.039650022 seconds. Throughput is 3026.48 records/second. Loss is 0.25640395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004061738424045492. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 37440/60000][Iteration 7312][Wall Clock 332.547635624s] Trained 120 records in 0.039812991 seconds. Throughput is 3014.0916 records/second. Loss is 0.18497579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004061408496466574. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 37560/60000][Iteration 7313][Wall Clock 332.587635255s] Trained 120 records in 0.039999631 seconds. Throughput is 3000.0278 records/second. Loss is 0.15850313. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004061078622482131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 37680/60000][Iteration 7314][Wall Clock 332.627340238s] Trained 120 records in 0.039704983 seconds. Throughput is 3022.2908 records/second. Loss is 0.24186869. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004060748802079103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 37800/60000][Iteration 7315][Wall Clock 332.667270338s] Trained 120 records in 0.0399301 seconds. Throughput is 3005.2515 records/second. Loss is 0.113812804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004060419035244437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 37920/60000][Iteration 7316][Wall Clock 332.707202342s] Trained 120 records in 0.039932004 seconds. Throughput is 3005.1084 records/second. Loss is 0.17374654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004060089321965083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38040/60000][Iteration 7317][Wall Clock 332.750431305s] Trained 120 records in 0.043228963 seconds. Throughput is 2775.9167 records/second. Loss is 0.19928354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004059759662227996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38160/60000][Iteration 7318][Wall Clock 332.790804076s] Trained 120 records in 0.040372771 seconds. Throughput is 2972.3003 records/second. Loss is 0.22964974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004059430056020135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38280/60000][Iteration 7319][Wall Clock 332.830755381s] Trained 120 records in 0.039951305 seconds. Throughput is 3003.6565 records/second. Loss is 0.13649155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004059100503328463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38400/60000][Iteration 7320][Wall Clock 332.871510947s] Trained 120 records in 0.040755566 seconds. Throughput is 2944.383 records/second. Loss is 0.1405119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004058771004139946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38520/60000][Iteration 7321][Wall Clock 332.911727492s] Trained 120 records in 0.040216545 seconds. Throughput is 2983.8464 records/second. Loss is 0.27627128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004058441558441559. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38640/60000][Iteration 7322][Wall Clock 332.951942096s] Trained 120 records in 0.040214604 seconds. Throughput is 2983.9905 records/second. Loss is 0.15099294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040581121662202745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38760/60000][Iteration 7323][Wall Clock 332.992813014s] Trained 120 records in 0.040870918 seconds. Throughput is 2936.073 records/second. Loss is 0.15968451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004057782827463074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 38880/60000][Iteration 7324][Wall Clock 333.043834094s] Trained 120 records in 0.05102108 seconds. Throughput is 2351.969 records/second. Loss is 0.17410213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040574535421569425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39000/60000][Iteration 7325][Wall Clock 333.092005891s] Trained 120 records in 0.048171797 seconds. Throughput is 2491.0842 records/second. Loss is 0.19594511. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004057124310288867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39120/60000][Iteration 7326][Wall Clock 333.133161916s] Trained 120 records in 0.041156025 seconds. Throughput is 2915.7336 records/second. Loss is 0.18044016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004056795131845842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39240/60000][Iteration 7327][Wall Clock 333.172963825s] Trained 120 records in 0.039801909 seconds. Throughput is 3014.9307 records/second. Loss is 0.10713443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004056466006814863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39360/60000][Iteration 7328][Wall Clock 333.212610137s] Trained 120 records in 0.039646312 seconds. Throughput is 3026.7632 records/second. Loss is 0.21848914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004056136935182932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39480/60000][Iteration 7329][Wall Clock 333.252063825s] Trained 120 records in 0.039453688 seconds. Throughput is 3041.5408 records/second. Loss is 0.15598597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004055807916937054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39600/60000][Iteration 7330][Wall Clock 333.2919062s] Trained 120 records in 0.039842375 seconds. Throughput is 3011.8687 records/second. Loss is 0.22425508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040554789520642395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39720/60000][Iteration 7331][Wall Clock 333.33200902s] Trained 120 records in 0.04010282 seconds. Throughput is 2992.308 records/second. Loss is 0.17424664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040551500405515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39840/60000][Iteration 7332][Wall Clock 333.372112424s] Trained 120 records in 0.040103404 seconds. Throughput is 2992.2646 records/second. Loss is 0.15440801. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040548211823858565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 39960/60000][Iteration 7333][Wall Clock 333.411890353s] Trained 120 records in 0.039777929 seconds. Throughput is 3016.7483 records/second. Loss is 0.19729285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00405449237755433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 40080/60000][Iteration 7334][Wall Clock 333.451273882s] Trained 120 records in 0.039383529 seconds. Throughput is 3046.959 records/second. Loss is 0.13878371. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004054163626043947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:39 INFO  DistriOptimizer$:406 - [Epoch 15 40200/60000][Iteration 7335][Wall Clock 333.50179729s] Trained 120 records in 0.050523408 seconds. Throughput is 2375.1367 records/second. Loss is 0.18519494. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004053834927841738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 40320/60000][Iteration 7336][Wall Clock 333.549481815s] Trained 120 records in 0.047684525 seconds. Throughput is 2516.5398 records/second. Loss is 0.23951207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004053506282934738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 40440/60000][Iteration 7337][Wall Clock 333.59008936s] Trained 120 records in 0.040607545 seconds. Throughput is 2955.1157 records/second. Loss is 0.20962054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004053177691309987. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 40560/60000][Iteration 7338][Wall Clock 333.630429203s] Trained 120 records in 0.040339843 seconds. Throughput is 2974.7266 records/second. Loss is 0.111832656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004052849152954527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 40680/60000][Iteration 7339][Wall Clock 333.670744121s] Trained 120 records in 0.040314918 seconds. Throughput is 2976.5657 records/second. Loss is 0.14292558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004052520667855406. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 40800/60000][Iteration 7340][Wall Clock 333.711517625s] Trained 120 records in 0.040773504 seconds. Throughput is 2943.088 records/second. Loss is 0.13646081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004052192235999676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 40920/60000][Iteration 7341][Wall Clock 333.75170295s] Trained 120 records in 0.040185325 seconds. Throughput is 2986.1648 records/second. Loss is 0.14505741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004051863857374392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41040/60000][Iteration 7342][Wall Clock 333.791760262s] Trained 120 records in 0.040057312 seconds. Throughput is 2995.7078 records/second. Loss is 0.1274317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004051535531966615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41160/60000][Iteration 7343][Wall Clock 333.831940499s] Trained 120 records in 0.040180237 seconds. Throughput is 2986.543 records/second. Loss is 0.10164296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00405120725976341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41280/60000][Iteration 7344][Wall Clock 333.872472145s] Trained 120 records in 0.040531646 seconds. Throughput is 2960.6494 records/second. Loss is 0.16491087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004050879040751842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41400/60000][Iteration 7345][Wall Clock 333.912560509s] Trained 120 records in 0.040088364 seconds. Throughput is 2993.3875 records/second. Loss is 0.10396421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00405055087491899. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41520/60000][Iteration 7346][Wall Clock 333.95311865s] Trained 120 records in 0.040558141 seconds. Throughput is 2958.7156 records/second. Loss is 0.15137056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004050222762251923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41640/60000][Iteration 7347][Wall Clock 333.993349606s] Trained 120 records in 0.040230956 seconds. Throughput is 2982.7778 records/second. Loss is 0.21711941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004049894702737729. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41760/60000][Iteration 7348][Wall Clock 334.034273063s] Trained 120 records in 0.040923457 seconds. Throughput is 2932.3035 records/second. Loss is 0.13091736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004049566696363489. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 41880/60000][Iteration 7349][Wall Clock 334.084106358s] Trained 120 records in 0.049833295 seconds. Throughput is 2408.0286 records/second. Loss is 0.1765945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004049238743116294. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42000/60000][Iteration 7350][Wall Clock 334.137895762s] Trained 120 records in 0.053789404 seconds. Throughput is 2230.9226 records/second. Loss is 0.11422506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004048910842983237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42120/60000][Iteration 7351][Wall Clock 334.179419112s] Trained 120 records in 0.04152335 seconds. Throughput is 2889.9404 records/second. Loss is 0.21278806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004048582995951418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42240/60000][Iteration 7352][Wall Clock 334.219391694s] Trained 120 records in 0.039972582 seconds. Throughput is 3002.0579 records/second. Loss is 0.2200001. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004048255202007934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42360/60000][Iteration 7353][Wall Clock 334.259318736s] Trained 120 records in 0.039927042 seconds. Throughput is 3005.4817 records/second. Loss is 0.1510562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004047927461139896. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42480/60000][Iteration 7354][Wall Clock 334.299460549s] Trained 120 records in 0.040141813 seconds. Throughput is 2989.4016 records/second. Loss is 0.15757526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004047599773334413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42600/60000][Iteration 7355][Wall Clock 334.343205048s] Trained 120 records in 0.043744499 seconds. Throughput is 2743.202 records/second. Loss is 0.18588683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004047272138578598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42720/60000][Iteration 7356][Wall Clock 334.383056974s] Trained 120 records in 0.039851926 seconds. Throughput is 3011.1467 records/second. Loss is 0.18971676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004046944556859571. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42840/60000][Iteration 7357][Wall Clock 334.422920513s] Trained 120 records in 0.039863539 seconds. Throughput is 3010.2698 records/second. Loss is 0.113847174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004046617028164455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 42960/60000][Iteration 7358][Wall Clock 334.462859877s] Trained 120 records in 0.039939364 seconds. Throughput is 3004.5547 records/second. Loss is 0.16201259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040462895524803755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:40 INFO  DistriOptimizer$:406 - [Epoch 15 43080/60000][Iteration 7359][Wall Clock 334.50287946s] Trained 120 records in 0.040019583 seconds. Throughput is 2998.532 records/second. Loss is 0.12875421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004045962129794465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 43200/60000][Iteration 7360][Wall Clock 334.542088925s] Trained 120 records in 0.039209465 seconds. Throughput is 3060.4854 records/second. Loss is 0.23139726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004045634760093859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 43320/60000][Iteration 7361][Wall Clock 334.5816831s] Trained 120 records in 0.039594175 seconds. Throughput is 3030.749 records/second. Loss is 0.27529746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004045307443365696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 43440/60000][Iteration 7362][Wall Clock 334.634061258s] Trained 120 records in 0.052378158 seconds. Throughput is 2291.0312 records/second. Loss is 0.13660388. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00404498017959712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 43560/60000][Iteration 7363][Wall Clock 334.677303707s] Trained 120 records in 0.043242449 seconds. Throughput is 2775.0508 records/second. Loss is 0.13736452. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004044652968775279. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 43680/60000][Iteration 7364][Wall Clock 334.717310109s] Trained 120 records in 0.040006402 seconds. Throughput is 2999.5198 records/second. Loss is 0.16053085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004044325810887326. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 43800/60000][Iteration 7365][Wall Clock 334.757260988s] Trained 120 records in 0.039950879 seconds. Throughput is 3003.6887 records/second. Loss is 0.16631648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004043998705920413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 43920/60000][Iteration 7366][Wall Clock 334.796747453s] Trained 120 records in 0.039486465 seconds. Throughput is 3039.016 records/second. Loss is 0.15358153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040436716538617065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44040/60000][Iteration 7367][Wall Clock 334.836108817s] Trained 120 records in 0.039361364 seconds. Throughput is 3048.6748 records/second. Loss is 0.15607919. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004043344654698366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44160/60000][Iteration 7368][Wall Clock 334.875340657s] Trained 120 records in 0.03923184 seconds. Throughput is 3058.74 records/second. Loss is 0.13648613. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004043017708417564. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44280/60000][Iteration 7369][Wall Clock 334.91598241s] Trained 120 records in 0.040641753 seconds. Throughput is 2952.6287 records/second. Loss is 0.19951867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004042690815006468. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44400/60000][Iteration 7370][Wall Clock 334.956546879s] Trained 120 records in 0.040564469 seconds. Throughput is 2958.254 records/second. Loss is 0.23376271. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00404236397445226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44520/60000][Iteration 7371][Wall Clock 334.997352253s] Trained 120 records in 0.040805374 seconds. Throughput is 2940.789 records/second. Loss is 0.30084652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040420371867421175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44640/60000][Iteration 7372][Wall Clock 335.038755934s] Trained 120 records in 0.041403681 seconds. Throughput is 2898.293 records/second. Loss is 0.10834487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004041710451863229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44760/60000][Iteration 7373][Wall Clock 335.079552542s] Trained 120 records in 0.040796608 seconds. Throughput is 2941.4211 records/second. Loss is 0.12294647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040413837698027805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 44880/60000][Iteration 7374][Wall Clock 335.127305448s] Trained 120 records in 0.047752906 seconds. Throughput is 2512.936 records/second. Loss is 0.22287278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004041057140547967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45000/60000][Iteration 7375][Wall Clock 335.183338514s] Trained 120 records in 0.056033066 seconds. Throughput is 2141.5925 records/second. Loss is 0.19592616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040407305640859864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45120/60000][Iteration 7376][Wall Clock 335.225134712s] Trained 120 records in 0.041796198 seconds. Throughput is 2871.0747 records/second. Loss is 0.23054744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00404040404040404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45240/60000][Iteration 7377][Wall Clock 335.265335765s] Trained 120 records in 0.040201053 seconds. Throughput is 2984.9963 records/second. Loss is 0.17937732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004040077569489335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45360/60000][Iteration 7378][Wall Clock 335.304685573s] Trained 120 records in 0.039349808 seconds. Throughput is 3049.57 records/second. Loss is 0.1449806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004039751151329078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45480/60000][Iteration 7379][Wall Clock 335.343742005s] Trained 120 records in 0.039056432 seconds. Throughput is 3072.4773 records/second. Loss is 0.14407517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004039424785910487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45600/60000][Iteration 7380][Wall Clock 335.383729274s] Trained 120 records in 0.039987269 seconds. Throughput is 3000.955 records/second. Loss is 0.22586355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004039098473220777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45720/60000][Iteration 7381][Wall Clock 335.423120449s] Trained 120 records in 0.039391175 seconds. Throughput is 3046.3677 records/second. Loss is 0.20750019. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004038772213247173. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45840/60000][Iteration 7382][Wall Clock 335.461786048s] Trained 120 records in 0.038665599 seconds. Throughput is 3103.534 records/second. Loss is 0.19714142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040384460059769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:41 INFO  DistriOptimizer$:406 - [Epoch 15 45960/60000][Iteration 7383][Wall Clock 335.5010481s] Trained 120 records in 0.039262052 seconds. Throughput is 3056.3862 records/second. Loss is 0.104340576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040381198513971895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46080/60000][Iteration 7384][Wall Clock 335.541117285s] Trained 120 records in 0.040069185 seconds. Throughput is 2994.82 records/second. Loss is 0.21584877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004037793749495275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46200/60000][Iteration 7385][Wall Clock 335.580666421s] Trained 120 records in 0.039549136 seconds. Throughput is 3034.2004 records/second. Loss is 0.16498344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040374677002583985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46320/60000][Iteration 7386][Wall Clock 335.620900301s] Trained 120 records in 0.04023388 seconds. Throughput is 2982.561 records/second. Loss is 0.2863816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004037141703673798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46440/60000][Iteration 7387][Wall Clock 335.660841168s] Trained 120 records in 0.039940867 seconds. Throughput is 3004.4414 records/second. Loss is 0.29921305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004036815759728726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46560/60000][Iteration 7388][Wall Clock 335.710519552s] Trained 120 records in 0.049678384 seconds. Throughput is 2415.5374 records/second. Loss is 0.17218833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00403648986841043. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46680/60000][Iteration 7389][Wall Clock 335.757042268s] Trained 120 records in 0.046522716 seconds. Throughput is 2579.3853 records/second. Loss is 0.16885822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004036164029706167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46800/60000][Iteration 7390][Wall Clock 335.797250832s] Trained 120 records in 0.040208564 seconds. Throughput is 2984.439 records/second. Loss is 0.30493385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004035838243603196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 46920/60000][Iteration 7391][Wall Clock 335.83781291s] Trained 120 records in 0.040562078 seconds. Throughput is 2958.4282 records/second. Loss is 0.18727954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004035512510088782. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47040/60000][Iteration 7392][Wall Clock 335.881068799s] Trained 120 records in 0.043255889 seconds. Throughput is 2774.1887 records/second. Loss is 0.24901797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004035186829150189. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47160/60000][Iteration 7393][Wall Clock 335.921461918s] Trained 120 records in 0.040393119 seconds. Throughput is 2970.8032 records/second. Loss is 0.2549805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004034861200774694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47280/60000][Iteration 7394][Wall Clock 335.962225401s] Trained 120 records in 0.040763483 seconds. Throughput is 2943.8113 records/second. Loss is 0.17892967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004034535624949568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47400/60000][Iteration 7395][Wall Clock 336.002998949s] Trained 120 records in 0.040773548 seconds. Throughput is 2943.0845 records/second. Loss is 0.2135968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004034210101662094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47520/60000][Iteration 7396][Wall Clock 336.042752143s] Trained 120 records in 0.039753194 seconds. Throughput is 3018.6252 records/second. Loss is 0.17767486. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004033884630899556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47640/60000][Iteration 7397][Wall Clock 336.082696087s] Trained 120 records in 0.039943944 seconds. Throughput is 3004.21 records/second. Loss is 0.21082543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004033559212649242. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47760/60000][Iteration 7398][Wall Clock 336.122265261s] Trained 120 records in 0.039569174 seconds. Throughput is 3032.6638 records/second. Loss is 0.20337974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040332338468984435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 47880/60000][Iteration 7399][Wall Clock 336.163116584s] Trained 120 records in 0.040851323 seconds. Throughput is 2937.4812 records/second. Loss is 0.13546261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004032908533634457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48000/60000][Iteration 7400][Wall Clock 336.21128361s] Trained 120 records in 0.048167026 seconds. Throughput is 2491.3308 records/second. Loss is 0.2915124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004032583272844584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48120/60000][Iteration 7401][Wall Clock 336.255364069s] Trained 120 records in 0.044080459 seconds. Throughput is 2722.2947 records/second. Loss is 0.15138587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004032258064516129. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48240/60000][Iteration 7402][Wall Clock 336.296887261s] Trained 120 records in 0.041523192 seconds. Throughput is 2889.9512 records/second. Loss is 0.10862916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004031932908636401. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48360/60000][Iteration 7403][Wall Clock 336.338230461s] Trained 120 records in 0.0413432 seconds. Throughput is 2902.533 records/second. Loss is 0.15859461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004031607805192711. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48480/60000][Iteration 7404][Wall Clock 336.379388791s] Trained 120 records in 0.04115833 seconds. Throughput is 2915.5703 records/second. Loss is 0.13607207. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004031282754172378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48600/60000][Iteration 7405][Wall Clock 336.420134219s] Trained 120 records in 0.040745428 seconds. Throughput is 2945.1155 records/second. Loss is 0.19826354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004030957755562721. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48720/60000][Iteration 7406][Wall Clock 336.460841271s] Trained 120 records in 0.040707052 seconds. Throughput is 2947.892 records/second. Loss is 0.18759279. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004030632809351068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:42 INFO  DistriOptimizer$:406 - [Epoch 15 48840/60000][Iteration 7407][Wall Clock 336.500744698s] Trained 120 records in 0.039903427 seconds. Throughput is 3007.2605 records/second. Loss is 0.10637987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004030307915524746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 48960/60000][Iteration 7408][Wall Clock 336.541110985s] Trained 120 records in 0.040366287 seconds. Throughput is 2972.7776 records/second. Loss is 0.15739396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040299830740710895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49080/60000][Iteration 7409][Wall Clock 336.58158269s] Trained 120 records in 0.040471705 seconds. Throughput is 2965.0344 records/second. Loss is 0.23457012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004029658284977433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49200/60000][Iteration 7410][Wall Clock 336.62161389s] Trained 120 records in 0.0400312 seconds. Throughput is 2997.6619 records/second. Loss is 0.21467775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004029333548231123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49320/60000][Iteration 7411][Wall Clock 336.665554055s] Trained 120 records in 0.043940165 seconds. Throughput is 2730.9866 records/second. Loss is 0.18401691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040290088638195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49440/60000][Iteration 7412][Wall Clock 336.706079355s] Trained 120 records in 0.0405253 seconds. Throughput is 2961.1133 records/second. Loss is 0.2068614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004028684231729918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49560/60000][Iteration 7413][Wall Clock 336.745941402s] Trained 120 records in 0.039862047 seconds. Throughput is 3010.3823 records/second. Loss is 0.14146143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040283596519497256. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49680/60000][Iteration 7414][Wall Clock 336.785536342s] Trained 120 records in 0.03959494 seconds. Throughput is 3030.6902 records/second. Loss is 0.24323533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040280351244662855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49800/60000][Iteration 7415][Wall Clock 336.841874469s] Trained 120 records in 0.056338127 seconds. Throughput is 2129.9963 records/second. Loss is 0.16982634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040277106492669565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 49920/60000][Iteration 7416][Wall Clock 336.884399518s] Trained 120 records in 0.042525049 seconds. Throughput is 2821.8662 records/second. Loss is 0.17928144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004027386226339105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50040/60000][Iteration 7417][Wall Clock 336.924527783s] Trained 120 records in 0.040128265 seconds. Throughput is 2990.411 records/second. Loss is 0.2323259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004027061855670103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50160/60000][Iteration 7418][Wall Clock 336.965176675s] Trained 120 records in 0.040648892 seconds. Throughput is 2952.1099 records/second. Loss is 0.17927592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004026737537247322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50280/60000][Iteration 7419][Wall Clock 337.005601746s] Trained 120 records in 0.040425071 seconds. Throughput is 2968.455 records/second. Loss is 0.13781582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004026413271058142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50400/60000][Iteration 7420][Wall Clock 337.046127524s] Trained 120 records in 0.040525778 seconds. Throughput is 2961.0781 records/second. Loss is 0.16684519. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004026089057089943. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50520/60000][Iteration 7421][Wall Clock 337.088182848s] Trained 120 records in 0.042055324 seconds. Throughput is 2853.3843 records/second. Loss is 0.27774283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004025764895330113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50640/60000][Iteration 7422][Wall Clock 337.129201438s] Trained 120 records in 0.04101859 seconds. Throughput is 2925.5027 records/second. Loss is 0.22571501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040254407857660416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50760/60000][Iteration 7423][Wall Clock 337.169856077s] Trained 120 records in 0.040654639 seconds. Throughput is 2951.6926 records/second. Loss is 0.19904408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040251167283851235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 50880/60000][Iteration 7424][Wall Clock 337.211586407s] Trained 120 records in 0.04173033 seconds. Throughput is 2875.6064 records/second. Loss is 0.1420186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004024792723174756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 51000/60000][Iteration 7425][Wall Clock 337.259496747s] Trained 120 records in 0.04791034 seconds. Throughput is 2504.6785 records/second. Loss is 0.17861468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004024468770122344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 51120/60000][Iteration 7426][Wall Clock 337.304084713s] Trained 120 records in 0.044587966 seconds. Throughput is 2691.309 records/second. Loss is 0.20118614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004024144869215291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 51240/60000][Iteration 7427][Wall Clock 337.34407313s] Trained 120 records in 0.039988417 seconds. Throughput is 3000.869 records/second. Loss is 0.1974039. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004023821020441011. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 51360/60000][Iteration 7428][Wall Clock 337.383896025s] Trained 120 records in 0.039822895 seconds. Throughput is 3013.342 records/second. Loss is 0.19951493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004023497223786915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 51480/60000][Iteration 7429][Wall Clock 337.427839722s] Trained 120 records in 0.043943697 seconds. Throughput is 2730.767 records/second. Loss is 0.09259001. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004023173479240426. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 51600/60000][Iteration 7430][Wall Clock 337.468040346s] Trained 120 records in 0.040200624 seconds. Throughput is 2985.0283 records/second. Loss is 0.10807319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004022849786788961. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:43 INFO  DistriOptimizer$:406 - [Epoch 15 51720/60000][Iteration 7431][Wall Clock 337.507853967s] Trained 120 records in 0.039813621 seconds. Throughput is 3014.0437 records/second. Loss is 0.20754476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004022526146419952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 51840/60000][Iteration 7432][Wall Clock 337.548291207s] Trained 120 records in 0.04043724 seconds. Throughput is 2967.5615 records/second. Loss is 0.14912054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004022202558120826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 51960/60000][Iteration 7433][Wall Clock 337.588444079s] Trained 120 records in 0.040152872 seconds. Throughput is 2988.5781 records/second. Loss is 0.16512424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004021879021879022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52080/60000][Iteration 7434][Wall Clock 337.628256464s] Trained 120 records in 0.039812385 seconds. Throughput is 3014.1375 records/second. Loss is 0.25675768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004021555537681975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52200/60000][Iteration 7435][Wall Clock 337.66835576s] Trained 120 records in 0.040099296 seconds. Throughput is 2992.5713 records/second. Loss is 0.10709474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00402123210551713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52320/60000][Iteration 7436][Wall Clock 337.70926127s] Trained 120 records in 0.04090551 seconds. Throughput is 2933.59 records/second. Loss is 0.16938253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004020908725371934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52440/60000][Iteration 7437][Wall Clock 337.749863577s] Trained 120 records in 0.040602307 seconds. Throughput is 2955.497 records/second. Loss is 0.100649945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004020585397233837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52560/60000][Iteration 7438][Wall Clock 337.789588418s] Trained 120 records in 0.039724841 seconds. Throughput is 3020.7798 records/second. Loss is 0.20263705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004020262121090295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52680/60000][Iteration 7439][Wall Clock 337.829869584s] Trained 120 records in 0.040281166 seconds. Throughput is 2979.0598 records/second. Loss is 0.08894762. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004019938896928766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52800/60000][Iteration 7440][Wall Clock 337.869993958s] Trained 120 records in 0.040124374 seconds. Throughput is 2990.7007 records/second. Loss is 0.22756952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004019615724736715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 52920/60000][Iteration 7441][Wall Clock 337.910582556s] Trained 120 records in 0.040588598 seconds. Throughput is 2956.4954 records/second. Loss is 0.22308879. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040192926045016075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53040/60000][Iteration 7442][Wall Clock 337.963579959s] Trained 120 records in 0.052997403 seconds. Throughput is 2264.262 records/second. Loss is 0.1438983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004018969536210916. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53160/60000][Iteration 7443][Wall Clock 338.008536083s] Trained 120 records in 0.044956124 seconds. Throughput is 2669.2693 records/second. Loss is 0.09861301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040186465198521135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53280/60000][Iteration 7444][Wall Clock 338.049631935s] Trained 120 records in 0.041095852 seconds. Throughput is 2920.0027 records/second. Loss is 0.24387573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004018323555412682. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53400/60000][Iteration 7445][Wall Clock 338.091607074s] Trained 120 records in 0.041975139 seconds. Throughput is 2858.835 records/second. Loss is 0.23143913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004018000642880102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53520/60000][Iteration 7446][Wall Clock 338.134377084s] Trained 120 records in 0.04277001 seconds. Throughput is 2805.7043 records/second. Loss is 0.12079964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004017677782241865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53640/60000][Iteration 7447][Wall Clock 338.175440918s] Trained 120 records in 0.041063834 seconds. Throughput is 2922.2795 records/second. Loss is 0.12514873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004017354973485457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53760/60000][Iteration 7448][Wall Clock 338.220351862s] Trained 120 records in 0.044910944 seconds. Throughput is 2671.9543 records/second. Loss is 0.2633947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040170322165983775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 53880/60000][Iteration 7449][Wall Clock 338.262717451s] Trained 120 records in 0.042365589 seconds. Throughput is 2832.4875 records/second. Loss is 0.14243218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004016709511568123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 54000/60000][Iteration 7450][Wall Clock 338.3040272s] Trained 120 records in 0.041309749 seconds. Throughput is 2904.8833 records/second. Loss is 0.16455697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040163868583822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 54120/60000][Iteration 7451][Wall Clock 338.357614364s] Trained 120 records in 0.053587164 seconds. Throughput is 2239.3423 records/second. Loss is 0.08336765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004016064257028112. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 54240/60000][Iteration 7452][Wall Clock 338.398884086s] Trained 120 records in 0.041269722 seconds. Throughput is 2907.7007 records/second. Loss is 0.14581786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004015741707493374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 54360/60000][Iteration 7453][Wall Clock 338.439792356s] Trained 120 records in 0.04090827 seconds. Throughput is 2933.3923 records/second. Loss is 0.09336829. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004015419209765499. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:44 INFO  DistriOptimizer$:406 - [Epoch 15 54480/60000][Iteration 7454][Wall Clock 338.480117942s] Trained 120 records in 0.040325586 seconds. Throughput is 2975.7783 records/second. Loss is 0.26208976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004015096763832008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 54600/60000][Iteration 7455][Wall Clock 338.520086418s] Trained 120 records in 0.039968476 seconds. Throughput is 3002.3662 records/second. Loss is 0.13725942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004014774369680424. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 54720/60000][Iteration 7456][Wall Clock 338.560105151s] Trained 120 records in 0.040018733 seconds. Throughput is 2998.5957 records/second. Loss is 0.17992288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004014452027298274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 54840/60000][Iteration 7457][Wall Clock 338.600554346s] Trained 120 records in 0.040449195 seconds. Throughput is 2966.6846 records/second. Loss is 0.20719549. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004014129736673089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 54960/60000][Iteration 7458][Wall Clock 338.640634908s] Trained 120 records in 0.040080562 seconds. Throughput is 2993.97 records/second. Loss is 0.20887977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004013807497792406. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55080/60000][Iteration 7459][Wall Clock 338.680192088s] Trained 120 records in 0.03955718 seconds. Throughput is 3033.5833 records/second. Loss is 0.26565892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004013485310643763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55200/60000][Iteration 7460][Wall Clock 338.720178814s] Trained 120 records in 0.039986726 seconds. Throughput is 3000.9958 records/second. Loss is 0.16827147. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004013163175214704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55320/60000][Iteration 7461][Wall Clock 338.760126149s] Trained 120 records in 0.039947335 seconds. Throughput is 3003.955 records/second. Loss is 0.18854097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004012841091492777. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55440/60000][Iteration 7462][Wall Clock 338.800544837s] Trained 120 records in 0.040418688 seconds. Throughput is 2968.9236 records/second. Loss is 0.24623182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004012519059465532. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55560/60000][Iteration 7463][Wall Clock 338.84022699s] Trained 120 records in 0.039682153 seconds. Throughput is 3024.0295 records/second. Loss is 0.19018885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040121970791205264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55680/60000][Iteration 7464][Wall Clock 338.879842956s] Trained 120 records in 0.039615966 seconds. Throughput is 3029.0818 records/second. Loss is 0.17509595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040118751504453175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55800/60000][Iteration 7465][Wall Clock 338.920128381s] Trained 120 records in 0.040285425 seconds. Throughput is 2978.7449 records/second. Loss is 0.15407391. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004011553273427471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 55920/60000][Iteration 7466][Wall Clock 338.960974953s] Trained 120 records in 0.040846572 seconds. Throughput is 2937.823 records/second. Loss is 0.12943931. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004011231448054552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56040/60000][Iteration 7467][Wall Clock 339.005529105s] Trained 120 records in 0.044554152 seconds. Throughput is 2693.3518 records/second. Loss is 0.22520748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004010909674314135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56160/60000][Iteration 7468][Wall Clock 339.04654729s] Trained 120 records in 0.041018185 seconds. Throughput is 2925.5317 records/second. Loss is 0.16136746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004010587952193791. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56280/60000][Iteration 7469][Wall Clock 339.101261478s] Trained 120 records in 0.054714188 seconds. Throughput is 2193.2153 records/second. Loss is 0.18233089. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004010266281681104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56400/60000][Iteration 7470][Wall Clock 339.146321784s] Trained 120 records in 0.045060306 seconds. Throughput is 2663.0977 records/second. Loss is 0.13183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040099446627636535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56520/60000][Iteration 7471][Wall Clock 339.186438522s] Trained 120 records in 0.040116738 seconds. Throughput is 2991.27 records/second. Loss is 0.13770169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040096230954290305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56640/60000][Iteration 7472][Wall Clock 339.226936584s] Trained 120 records in 0.040498062 seconds. Throughput is 2963.1047 records/second. Loss is 0.24354555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004009301579664822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56760/60000][Iteration 7473][Wall Clock 339.267053683s] Trained 120 records in 0.040117099 seconds. Throughput is 2991.2432 records/second. Loss is 0.17990737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040089801154586276. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 56880/60000][Iteration 7474][Wall Clock 339.309080175s] Trained 120 records in 0.042026492 seconds. Throughput is 2855.3418 records/second. Loss is 0.13380814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004008658702798044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 57000/60000][Iteration 7475][Wall Clock 339.352858688s] Trained 120 records in 0.043778513 seconds. Throughput is 2741.0708 records/second. Loss is 0.19823144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004008337341670675. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 57120/60000][Iteration 7476][Wall Clock 339.396608054s] Trained 120 records in 0.043749366 seconds. Throughput is 2742.897 records/second. Loss is 0.17228204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004008016032064128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 57240/60000][Iteration 7477][Wall Clock 339.443623313s] Trained 120 records in 0.047015259 seconds. Throughput is 2552.363 records/second. Loss is 0.2840346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040076947739660146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:45 INFO  DistriOptimizer$:406 - [Epoch 15 57360/60000][Iteration 7478][Wall Clock 339.486627199s] Trained 120 records in 0.043003886 seconds. Throughput is 2790.4456 records/second. Loss is 0.17988546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00400737356736395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 57480/60000][Iteration 7479][Wall Clock 339.52683606s] Trained 120 records in 0.040208861 seconds. Throughput is 2984.4167 records/second. Loss is 0.20710722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040070524122455525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 57600/60000][Iteration 7480][Wall Clock 339.567393201s] Trained 120 records in 0.040557141 seconds. Throughput is 2958.7883 records/second. Loss is 0.298762. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004006731308598446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 57720/60000][Iteration 7481][Wall Clock 339.608013089s] Trained 120 records in 0.040619888 seconds. Throughput is 2954.218 records/second. Loss is 0.21434961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004006410256410257. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 57840/60000][Iteration 7482][Wall Clock 339.648689332s] Trained 120 records in 0.040676243 seconds. Throughput is 2950.125 records/second. Loss is 0.112687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040060892556686165. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 57960/60000][Iteration 7483][Wall Clock 339.689083592s] Trained 120 records in 0.04039426 seconds. Throughput is 2970.719 records/second. Loss is 0.1741385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004005768306361159. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58080/60000][Iteration 7484][Wall Clock 339.728890118s] Trained 120 records in 0.039806526 seconds. Throughput is 3014.581 records/second. Loss is 0.19150883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040054474084755265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58200/60000][Iteration 7485][Wall Clock 339.769101675s] Trained 120 records in 0.040211557 seconds. Throughput is 2984.2166 records/second. Loss is 0.21256022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004005126561999359. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58320/60000][Iteration 7486][Wall Clock 339.813199044s] Trained 120 records in 0.044097369 seconds. Throughput is 2721.251 records/second. Loss is 0.277624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004004805766920304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58440/60000][Iteration 7487][Wall Clock 339.853274221s] Trained 120 records in 0.040075177 seconds. Throughput is 2994.3723 records/second. Loss is 0.17692693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004004485023226013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58560/60000][Iteration 7488][Wall Clock 339.893327143s] Trained 120 records in 0.040052922 seconds. Throughput is 2996.0361 records/second. Loss is 0.2387257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004004164330904141. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58680/60000][Iteration 7489][Wall Clock 339.934098809s] Trained 120 records in 0.040771666 seconds. Throughput is 2943.2205 records/second. Loss is 0.23904565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040038436899423446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58800/60000][Iteration 7490][Wall Clock 339.974216367s] Trained 120 records in 0.040117558 seconds. Throughput is 2991.209 records/second. Loss is 0.12741996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004003523100328289. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 58920/60000][Iteration 7491][Wall Clock 340.014407796s] Trained 120 records in 0.040191429 seconds. Throughput is 2985.7112 records/second. Loss is 0.15718473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0040032025620496394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59040/60000][Iteration 7492][Wall Clock 340.054359494s] Trained 120 records in 0.039951698 seconds. Throughput is 3003.6272 records/second. Loss is 0.17543547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004002882075094068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59160/60000][Iteration 7493][Wall Clock 340.095040555s] Trained 120 records in 0.040681061 seconds. Throughput is 2949.7756 records/second. Loss is 0.18059461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004002561639449247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59280/60000][Iteration 7494][Wall Clock 340.13470953s] Trained 120 records in 0.039668975 seconds. Throughput is 3025.0342 records/second. Loss is 0.30088398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004002241255102857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59400/60000][Iteration 7495][Wall Clock 340.182632415s] Trained 120 records in 0.047922885 seconds. Throughput is 2504.023 records/second. Loss is 0.13427475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00400192092204258. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59520/60000][Iteration 7496][Wall Clock 340.229612901s] Trained 120 records in 0.046980486 seconds. Throughput is 2554.252 records/second. Loss is 0.24856761. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004001600640256103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59640/60000][Iteration 7497][Wall Clock 340.272174195s] Trained 120 records in 0.042561294 seconds. Throughput is 2819.4631 records/second. Loss is 0.18106337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004001280409731114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59760/60000][Iteration 7498][Wall Clock 340.311621949s] Trained 120 records in 0.039447754 seconds. Throughput is 3041.9983 records/second. Loss is 0.16715248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004000960230455309. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 59880/60000][Iteration 7499][Wall Clock 340.354247625s] Trained 120 records in 0.042625676 seconds. Throughput is 2815.2046 records/second. Loss is 0.15691091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004000640102416387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:406 - [Epoch 15 60000/60000][Iteration 7500][Wall Clock 340.397295399s] Trained 120 records in 0.043047774 seconds. Throughput is 2787.6006 records/second. Loss is 0.077094905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004000320025602048. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:46 INFO  DistriOptimizer$:451 - [Epoch 15 60000/60000][Iteration 7500][Wall Clock 340.397295399s] Epoch finished. Wall clock time is 341214.891761 ms
2019-10-23 15:58:46 INFO  DistriOptimizer$:111 - [Epoch 15 60000/60000][Iteration 7500][Wall Clock 340.397295399s] Validate model...
2019-10-23 15:58:47 INFO  DistriOptimizer$:177 - [Epoch 15 60000/60000][Iteration 7500][Wall Clock 340.397295399s] validate model throughput is 14969.396 records/second
2019-10-23 15:58:47 INFO  DistriOptimizer$:180 - [Epoch 15 60000/60000][Iteration 7500][Wall Clock 340.397295399s] Top1Accuracy is Accuracy(correct: 9537, count: 10000, accuracy: 0.9537)
2019-10-23 15:58:47 INFO  DistriOptimizer$:220 - [Wall Clock 341.214891761s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:58:47 INFO  DistriOptimizer$:225 - [Wall Clock 341.214891761s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 120/60000][Iteration 7501][Wall Clock 341.260894806s] Trained 120 records in 0.046003045 seconds. Throughput is 2608.523 records/second. Loss is 0.23275222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 240/60000][Iteration 7502][Wall Clock 341.308565502s] Trained 120 records in 0.047670696 seconds. Throughput is 2517.2698 records/second. Loss is 0.18971352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003999680025597952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 360/60000][Iteration 7503][Wall Clock 341.355478861s] Trained 120 records in 0.046913359 seconds. Throughput is 2557.9067 records/second. Loss is 0.19579868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039993601023836185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 480/60000][Iteration 7504][Wall Clock 341.396824408s] Trained 120 records in 0.041345547 seconds. Throughput is 2902.3682 records/second. Loss is 0.1606631. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003999040230344717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 600/60000][Iteration 7505][Wall Clock 341.438380693s] Trained 120 records in 0.041556285 seconds. Throughput is 2887.65 records/second. Loss is 0.16065475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00399872040946897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 720/60000][Iteration 7506][Wall Clock 341.479119133s] Trained 120 records in 0.04073844 seconds. Throughput is 2945.6208 records/second. Loss is 0.23875085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039984006397441015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 840/60000][Iteration 7507][Wall Clock 341.519203276s] Trained 120 records in 0.040084143 seconds. Throughput is 2993.7026 records/second. Loss is 0.18890215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003998080921157845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 960/60000][Iteration 7508][Wall Clock 341.559689788s] Trained 120 records in 0.040486512 seconds. Throughput is 2963.9502 records/second. Loss is 0.13473636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003997761253697929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:47 INFO  DistriOptimizer$:406 - [Epoch 16 1080/60000][Iteration 7509][Wall Clock 341.599559631s] Trained 120 records in 0.039869843 seconds. Throughput is 3009.7937 records/second. Loss is 0.2885652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003997441637352095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 1200/60000][Iteration 7510][Wall Clock 341.639833933s] Trained 120 records in 0.040274302 seconds. Throughput is 2979.5674 records/second. Loss is 0.12579574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003997122072108082. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 1320/60000][Iteration 7511][Wall Clock 341.679878212s] Trained 120 records in 0.040044279 seconds. Throughput is 2996.6829 records/second. Loss is 0.13953449. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003996802557953637. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 1440/60000][Iteration 7512][Wall Clock 341.719901346s] Trained 120 records in 0.040023134 seconds. Throughput is 2998.266 records/second. Loss is 0.13807033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003996483094876508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 1560/60000][Iteration 7513][Wall Clock 341.760091418s] Trained 120 records in 0.040190072 seconds. Throughput is 2985.812 records/second. Loss is 0.15005098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039961636828644495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 1680/60000][Iteration 7514][Wall Clock 341.800105527s] Trained 120 records in 0.040014109 seconds. Throughput is 2998.9421 records/second. Loss is 0.16732307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003995844321905219. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 1800/60000][Iteration 7515][Wall Clock 341.839481645s] Trained 120 records in 0.039376118 seconds. Throughput is 3047.5325 records/second. Loss is 0.1299016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003995525011986575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 1920/60000][Iteration 7516][Wall Clock 341.878859774s] Trained 120 records in 0.039378129 seconds. Throughput is 3047.377 records/second. Loss is 0.1355484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003995205753096284. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2040/60000][Iteration 7517][Wall Clock 341.918775632s] Trained 120 records in 0.039915858 seconds. Throughput is 3006.3237 records/second. Loss is 0.220344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003994886545222115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2160/60000][Iteration 7518][Wall Clock 341.959261471s] Trained 120 records in 0.040485839 seconds. Throughput is 2963.9993 records/second. Loss is 0.13033012. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003994567388351841. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2280/60000][Iteration 7519][Wall Clock 341.999052539s] Trained 120 records in 0.039791068 seconds. Throughput is 3015.7522 records/second. Loss is 0.1720975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003994248282473239. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2400/60000][Iteration 7520][Wall Clock 342.049654763s] Trained 120 records in 0.050602224 seconds. Throughput is 2371.4373 records/second. Loss is 0.20558587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003993929227574087. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2520/60000][Iteration 7521][Wall Clock 342.098646953s] Trained 120 records in 0.04899219 seconds. Throughput is 2449.3699 records/second. Loss is 0.1527045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003993610223642172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2640/60000][Iteration 7522][Wall Clock 342.142421016s] Trained 120 records in 0.043774063 seconds. Throughput is 2741.3494 records/second. Loss is 0.35967734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003993291270665282. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2760/60000][Iteration 7523][Wall Clock 342.184075812s] Trained 120 records in 0.041654796 seconds. Throughput is 2880.8208 records/second. Loss is 0.12102189. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003992972368631209. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 2880/60000][Iteration 7524][Wall Clock 342.22454149s] Trained 120 records in 0.040465678 seconds. Throughput is 2965.476 records/second. Loss is 0.19552867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039926535175277495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3000/60000][Iteration 7525][Wall Clock 342.26485252s] Trained 120 records in 0.04031103 seconds. Throughput is 2976.8525 records/second. Loss is 0.113507695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003992334717342702. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3120/60000][Iteration 7526][Wall Clock 342.305206815s] Trained 120 records in 0.040354295 seconds. Throughput is 2973.6611 records/second. Loss is 0.14331515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003992015968063873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3240/60000][Iteration 7527][Wall Clock 342.351907077s] Trained 120 records in 0.046700262 seconds. Throughput is 2569.5789 records/second. Loss is 0.16650422. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003991697269679067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3360/60000][Iteration 7528][Wall Clock 342.393925059s] Trained 120 records in 0.042017982 seconds. Throughput is 2855.9202 records/second. Loss is 0.14819808. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039913786221761. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3480/60000][Iteration 7529][Wall Clock 342.433873164s] Trained 120 records in 0.039948105 seconds. Throughput is 3003.8972 records/second. Loss is 0.24283232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003991060025542783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3600/60000][Iteration 7530][Wall Clock 342.473543459s] Trained 120 records in 0.039670295 seconds. Throughput is 3024.9333 records/second. Loss is 0.15755855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003990741479766941. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3720/60000][Iteration 7531][Wall Clock 342.513472368s] Trained 120 records in 0.039928909 seconds. Throughput is 3005.3413 records/second. Loss is 0.15308605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039904229848363925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3840/60000][Iteration 7532][Wall Clock 342.553457537s] Trained 120 records in 0.039985169 seconds. Throughput is 3001.1128 records/second. Loss is 0.16079639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003990104540738968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:48 INFO  DistriOptimizer$:406 - [Epoch 16 3960/60000][Iteration 7533][Wall Clock 342.59335085s] Trained 120 records in 0.039893313 seconds. Throughput is 3008.023 records/second. Loss is 0.24639663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003989786147462496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4080/60000][Iteration 7534][Wall Clock 342.633453201s] Trained 120 records in 0.040102351 seconds. Throughput is 2992.3433 records/second. Loss is 0.167872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003989467804994814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4200/60000][Iteration 7535][Wall Clock 342.673997134s] Trained 120 records in 0.040543933 seconds. Throughput is 2959.7524 records/second. Loss is 0.21485083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003989149513323759. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4320/60000][Iteration 7536][Wall Clock 342.71419852s] Trained 120 records in 0.040201386 seconds. Throughput is 2984.972 records/second. Loss is 0.17069653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003988831272437176. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4440/60000][Iteration 7537][Wall Clock 342.754487886s] Trained 120 records in 0.040289366 seconds. Throughput is 2978.4536 records/second. Loss is 0.16638616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00398851308232291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4560/60000][Iteration 7538][Wall Clock 342.795254954s] Trained 120 records in 0.040767068 seconds. Throughput is 2943.5525 records/second. Loss is 0.2369949. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003988194942968812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4680/60000][Iteration 7539][Wall Clock 342.835521525s] Trained 120 records in 0.040266571 seconds. Throughput is 2980.1396 records/second. Loss is 0.2634504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003987876854362737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4800/60000][Iteration 7540][Wall Clock 342.878836499s] Trained 120 records in 0.043314974 seconds. Throughput is 2770.4045 records/second. Loss is 0.13152924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003987558816492543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 4920/60000][Iteration 7541][Wall Clock 342.919030696s] Trained 120 records in 0.040194197 seconds. Throughput is 2985.5054 records/second. Loss is 0.28691146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003987240829346092. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5040/60000][Iteration 7542][Wall Clock 342.95870166s] Trained 120 records in 0.039670964 seconds. Throughput is 3024.8826 records/second. Loss is 0.14143232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003986922892911251. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5160/60000][Iteration 7543][Wall Clock 342.999624604s] Trained 120 records in 0.040922944 seconds. Throughput is 2932.3403 records/second. Loss is 0.073903196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003986605007175889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5280/60000][Iteration 7544][Wall Clock 343.040073043s] Trained 120 records in 0.040448439 seconds. Throughput is 2966.74 records/second. Loss is 0.14632381. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039862871721278795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5400/60000][Iteration 7545][Wall Clock 343.08943818s] Trained 120 records in 0.049365137 seconds. Throughput is 2430.8652 records/second. Loss is 0.14460325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003985969387755102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5520/60000][Iteration 7546][Wall Clock 343.140671312s] Trained 120 records in 0.051233132 seconds. Throughput is 2342.2344 records/second. Loss is 0.22165197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003985651654045436. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5640/60000][Iteration 7547][Wall Clock 343.185381538s] Trained 120 records in 0.044710226 seconds. Throughput is 2683.9497 records/second. Loss is 0.17628142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003985333970986769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5760/60000][Iteration 7548][Wall Clock 343.226997224s] Trained 120 records in 0.041615686 seconds. Throughput is 2883.528 records/second. Loss is 0.19887017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003985016338566988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 5880/60000][Iteration 7549][Wall Clock 343.268609545s] Trained 120 records in 0.041612321 seconds. Throughput is 2883.7615 records/second. Loss is 0.2305472. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003984698756773988. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 6000/60000][Iteration 7550][Wall Clock 343.310696317s] Trained 120 records in 0.042086772 seconds. Throughput is 2851.2522 records/second. Loss is 0.12073252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003984381225595665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 6120/60000][Iteration 7551][Wall Clock 343.351801549s] Trained 120 records in 0.041105232 seconds. Throughput is 2919.3364 records/second. Loss is 0.16492079. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003984063745019921. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 6240/60000][Iteration 7552][Wall Clock 343.392569621s] Trained 120 records in 0.040768072 seconds. Throughput is 2943.48 records/second. Loss is 0.17009732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003983746315034659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 6360/60000][Iteration 7553][Wall Clock 343.44123612s] Trained 120 records in 0.048666499 seconds. Throughput is 2465.762 records/second. Loss is 0.100658685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003983428935627789. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 6480/60000][Iteration 7554][Wall Clock 343.487117888s] Trained 120 records in 0.045881768 seconds. Throughput is 2615.418 records/second. Loss is 0.12056097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003983111606787222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 6600/60000][Iteration 7555][Wall Clock 343.528308517s] Trained 120 records in 0.041190629 seconds. Throughput is 2913.2842 records/second. Loss is 0.22531055. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003982794328500876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:49 INFO  DistriOptimizer$:406 - [Epoch 16 6720/60000][Iteration 7556][Wall Clock 343.568681008s] Trained 120 records in 0.040372491 seconds. Throughput is 2972.321 records/second. Loss is 0.2215126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00398247710075667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 6840/60000][Iteration 7557][Wall Clock 343.609441533s] Trained 120 records in 0.040760525 seconds. Throughput is 2944.025 records/second. Loss is 0.15007308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00398215992354253. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 6960/60000][Iteration 7558][Wall Clock 343.649862929s] Trained 120 records in 0.040421396 seconds. Throughput is 2968.7249 records/second. Loss is 0.15381576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003981842796846381. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7080/60000][Iteration 7559][Wall Clock 343.693695563s] Trained 120 records in 0.043832634 seconds. Throughput is 2737.6863 records/second. Loss is 0.19212554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003981525720656155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7200/60000][Iteration 7560][Wall Clock 343.733404472s] Trained 120 records in 0.039708909 seconds. Throughput is 3021.992 records/second. Loss is 0.2586229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00398120869495979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7320/60000][Iteration 7561][Wall Clock 343.774025478s] Trained 120 records in 0.040621006 seconds. Throughput is 2954.1367 records/second. Loss is 0.19525614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003980891719745223. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7440/60000][Iteration 7562][Wall Clock 343.814979763s] Trained 120 records in 0.040954285 seconds. Throughput is 2930.0964 records/second. Loss is 0.20402499. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003980574795000399. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7560/60000][Iteration 7563][Wall Clock 343.85553875s] Trained 120 records in 0.040558987 seconds. Throughput is 2958.6538 records/second. Loss is 0.22623022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003980257920713263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7680/60000][Iteration 7564][Wall Clock 343.896271668s] Trained 120 records in 0.040732918 seconds. Throughput is 2946.0203 records/second. Loss is 0.2038815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039799410968717665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7800/60000][Iteration 7565][Wall Clock 343.936586719s] Trained 120 records in 0.040315051 seconds. Throughput is 2976.556 records/second. Loss is 0.23059706. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003979624323463864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 7920/60000][Iteration 7566][Wall Clock 343.977032897s] Trained 120 records in 0.040446178 seconds. Throughput is 2966.9058 records/second. Loss is 0.17802052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003979307600477517. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8040/60000][Iteration 7567][Wall Clock 344.017523936s] Trained 120 records in 0.040491039 seconds. Throughput is 2963.6187 records/second. Loss is 0.12453532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003978990927900684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8160/60000][Iteration 7568][Wall Clock 344.058385333s] Trained 120 records in 0.040861397 seconds. Throughput is 2936.757 records/second. Loss is 0.17584167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003978674305721334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8280/60000][Iteration 7569][Wall Clock 344.099803088s] Trained 120 records in 0.041417755 seconds. Throughput is 2897.308 records/second. Loss is 0.14379616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039783577339274345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8400/60000][Iteration 7570][Wall Clock 344.140325185s] Trained 120 records in 0.040522097 seconds. Throughput is 2961.3472 records/second. Loss is 0.22871657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039780412125069615. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8520/60000][Iteration 7571][Wall Clock 344.188356976s] Trained 120 records in 0.048031791 seconds. Throughput is 2498.3452 records/second. Loss is 0.22793576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003977724741447891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8640/60000][Iteration 7572][Wall Clock 344.242227194s] Trained 120 records in 0.053870218 seconds. Throughput is 2227.576 records/second. Loss is 0.12330406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003977408320738208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8760/60000][Iteration 7573][Wall Clock 344.294562594s] Trained 120 records in 0.0523354 seconds. Throughput is 2292.903 records/second. Loss is 0.1369856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003977091950365892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 8880/60000][Iteration 7574][Wall Clock 344.335081132s] Trained 120 records in 0.040518538 seconds. Throughput is 2961.6074 records/second. Loss is 0.17449202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003976775630318937. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 9000/60000][Iteration 7575][Wall Clock 344.374870048s] Trained 120 records in 0.039788916 seconds. Throughput is 3015.9153 records/second. Loss is 0.1075136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003976459360585335. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 9120/60000][Iteration 7576][Wall Clock 344.414678004s] Trained 120 records in 0.039807956 seconds. Throughput is 3014.4727 records/second. Loss is 0.12404881. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003976143141153081. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 9240/60000][Iteration 7577][Wall Clock 344.45511518s] Trained 120 records in 0.040437176 seconds. Throughput is 2967.5662 records/second. Loss is 0.15805565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003975826972010178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 9360/60000][Iteration 7578][Wall Clock 344.499031466s] Trained 120 records in 0.043916286 seconds. Throughput is 2732.4717 records/second. Loss is 0.13816492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003975510853144629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 9480/60000][Iteration 7579][Wall Clock 344.539030443s] Trained 120 records in 0.039998977 seconds. Throughput is 3000.0767 records/second. Loss is 0.1877136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003975194784544443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:50 INFO  DistriOptimizer$:406 - [Epoch 16 9600/60000][Iteration 7580][Wall Clock 344.587772487s] Trained 120 records in 0.048742044 seconds. Throughput is 2461.9402 records/second. Loss is 0.16363522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003974878766197631. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 9720/60000][Iteration 7581][Wall Clock 344.627928375s] Trained 120 records in 0.040155888 seconds. Throughput is 2988.3538 records/second. Loss is 0.17954665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00397456279809221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 9840/60000][Iteration 7582][Wall Clock 344.668264058s] Trained 120 records in 0.040335683 seconds. Throughput is 2975.0334 records/second. Loss is 0.18384756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003974246880216199. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 9960/60000][Iteration 7583][Wall Clock 344.709369767s] Trained 120 records in 0.041105709 seconds. Throughput is 2919.3025 records/second. Loss is 0.18253204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039739310125576225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10080/60000][Iteration 7584][Wall Clock 344.750453603s] Trained 120 records in 0.041083836 seconds. Throughput is 2920.857 records/second. Loss is 0.11674288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003973615195104505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10200/60000][Iteration 7585][Wall Clock 344.790957312s] Trained 120 records in 0.040503709 seconds. Throughput is 2962.6917 records/second. Loss is 0.24254198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003973299427844882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10320/60000][Iteration 7586][Wall Clock 344.830969727s] Trained 120 records in 0.040012415 seconds. Throughput is 2999.069 records/second. Loss is 0.1522734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003972983710766785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10440/60000][Iteration 7587][Wall Clock 344.871391523s] Trained 120 records in 0.040421796 seconds. Throughput is 2968.6956 records/second. Loss is 0.09165789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003972668043858255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10560/60000][Iteration 7588][Wall Clock 344.911991301s] Trained 120 records in 0.040599778 seconds. Throughput is 2955.6812 records/second. Loss is 0.13846976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003972352427107332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10680/60000][Iteration 7589][Wall Clock 344.952155191s] Trained 120 records in 0.04016389 seconds. Throughput is 2987.7585 records/second. Loss is 0.20853867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003972036860502065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10800/60000][Iteration 7590][Wall Clock 344.992741777s] Trained 120 records in 0.040586586 seconds. Throughput is 2956.6418 records/second. Loss is 0.108206496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003971721344030502. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 10920/60000][Iteration 7591][Wall Clock 345.033160792s] Trained 120 records in 0.040419015 seconds. Throughput is 2968.8997 records/second. Loss is 0.1883913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039714058776807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11040/60000][Iteration 7592][Wall Clock 345.073779101s] Trained 120 records in 0.040618309 seconds. Throughput is 2954.3328 records/second. Loss is 0.22136144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003971090461440711. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11160/60000][Iteration 7593][Wall Clock 345.115355555s] Trained 120 records in 0.041576454 seconds. Throughput is 2886.249 records/second. Loss is 0.120676726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039707750952986025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11280/60000][Iteration 7594][Wall Clock 345.156121526s] Trained 120 records in 0.040765971 seconds. Throughput is 2943.6316 records/second. Loss is 0.16900489. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003970459779242436. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11400/60000][Iteration 7595][Wall Clock 345.19694692s] Trained 120 records in 0.040825394 seconds. Throughput is 2939.3472 records/second. Loss is 0.10072196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039701445132602825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11520/60000][Iteration 7596][Wall Clock 345.237468601s] Trained 120 records in 0.040521681 seconds. Throughput is 2961.3777 records/second. Loss is 0.21824214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003969829297340214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11640/60000][Iteration 7597][Wall Clock 345.286937649s] Trained 120 records in 0.049469048 seconds. Throughput is 2425.7593 records/second. Loss is 0.1839642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003969514131470308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11760/60000][Iteration 7598][Wall Clock 345.339038362s] Trained 120 records in 0.052100713 seconds. Throughput is 2303.2314 records/second. Loss is 0.13624872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003969199015638644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 11880/60000][Iteration 7599][Wall Clock 345.379780856s] Trained 120 records in 0.040742494 seconds. Throughput is 2945.328 records/second. Loss is 0.16788524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003968883949833307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 12000/60000][Iteration 7600][Wall Clock 345.420182148s] Trained 120 records in 0.040401292 seconds. Throughput is 2970.2021 records/second. Loss is 0.13814786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003968568934042385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 12120/60000][Iteration 7601][Wall Clock 345.461027595s] Trained 120 records in 0.040845447 seconds. Throughput is 2937.904 records/second. Loss is 0.092128016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003968253968253968. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 12240/60000][Iteration 7602][Wall Clock 345.502048866s] Trained 120 records in 0.041021271 seconds. Throughput is 2925.3115 records/second. Loss is 0.19502954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003967939052456154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 12360/60000][Iteration 7603][Wall Clock 345.542735611s] Trained 120 records in 0.040686745 seconds. Throughput is 2949.3635 records/second. Loss is 0.23151305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003967624186637042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:51 INFO  DistriOptimizer$:406 - [Epoch 16 12480/60000][Iteration 7604][Wall Clock 345.583196054s] Trained 120 records in 0.040460443 seconds. Throughput is 2965.8599 records/second. Loss is 0.15587203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003967309370784734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 12600/60000][Iteration 7605][Wall Clock 345.625195295s] Trained 120 records in 0.041999241 seconds. Throughput is 2857.1946 records/second. Loss is 0.22356413. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003966994604887337. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 12720/60000][Iteration 7606][Wall Clock 345.672364592s] Trained 120 records in 0.047169297 seconds. Throughput is 2544.0276 records/second. Loss is 0.15423009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039666798889329636. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 12840/60000][Iteration 7607][Wall Clock 345.715506954s] Trained 120 records in 0.043142362 seconds. Throughput is 2781.4888 records/second. Loss is 0.2383412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003966365222909725. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 12960/60000][Iteration 7608][Wall Clock 345.755633602s] Trained 120 records in 0.040126648 seconds. Throughput is 2990.5315 records/second. Loss is 0.16205326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003966050606805743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13080/60000][Iteration 7609][Wall Clock 345.795655674s] Trained 120 records in 0.040022072 seconds. Throughput is 2998.3455 records/second. Loss is 0.15848951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003965736040609137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13200/60000][Iteration 7610][Wall Clock 345.835807206s] Trained 120 records in 0.040151532 seconds. Throughput is 2988.678 records/second. Loss is 0.28954056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003965421524308035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13320/60000][Iteration 7611][Wall Clock 345.875720566s] Trained 120 records in 0.03991336 seconds. Throughput is 3006.5122 records/second. Loss is 0.112548575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003965107057890563. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13440/60000][Iteration 7612][Wall Clock 345.915664724s] Trained 120 records in 0.039944158 seconds. Throughput is 3004.194 records/second. Loss is 0.17300764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003964792641344858. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13560/60000][Iteration 7613][Wall Clock 345.955386415s] Trained 120 records in 0.039721691 seconds. Throughput is 3021.0195 records/second. Loss is 0.12086586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003964478274659055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13680/60000][Iteration 7614][Wall Clock 345.995393192s] Trained 120 records in 0.040006777 seconds. Throughput is 2999.492 records/second. Loss is 0.19697338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003964163957821295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13800/60000][Iteration 7615][Wall Clock 346.039227425s] Trained 120 records in 0.043834233 seconds. Throughput is 2737.5864 records/second. Loss is 0.12841992. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003963849690819724. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 13920/60000][Iteration 7616][Wall Clock 346.079751277s] Trained 120 records in 0.040523852 seconds. Throughput is 2961.219 records/second. Loss is 0.15410258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003963535473642489. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14040/60000][Iteration 7617][Wall Clock 346.120076157s] Trained 120 records in 0.04032488 seconds. Throughput is 2975.83 records/second. Loss is 0.19631603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003963221306277742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14160/60000][Iteration 7618][Wall Clock 346.160938415s] Trained 120 records in 0.040862258 seconds. Throughput is 2936.6953 records/second. Loss is 0.112456106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00396290718871364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14280/60000][Iteration 7619][Wall Clock 346.201462871s] Trained 120 records in 0.040524456 seconds. Throughput is 2961.1748 records/second. Loss is 0.12188675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003962593120938342. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14400/60000][Iteration 7620][Wall Clock 346.241670936s] Trained 120 records in 0.040208065 seconds. Throughput is 2984.4758 records/second. Loss is 0.15804513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039622791029400115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14520/60000][Iteration 7621][Wall Clock 346.283062313s] Trained 120 records in 0.041391377 seconds. Throughput is 2899.1545 records/second. Loss is 0.15918182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003961965134706815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14640/60000][Iteration 7622][Wall Clock 346.333731688s] Trained 120 records in 0.050669375 seconds. Throughput is 2368.2944 records/second. Loss is 0.29000032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003961651216226924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14760/60000][Iteration 7623][Wall Clock 346.38560996s] Trained 120 records in 0.051878272 seconds. Throughput is 2313.107 records/second. Loss is 0.16137521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039613373474885125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 14880/60000][Iteration 7624][Wall Clock 346.427621371s] Trained 120 records in 0.042011411 seconds. Throughput is 2856.367 records/second. Loss is 0.20245375. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003961023528479758. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 15000/60000][Iteration 7625][Wall Clock 346.469468722s] Trained 120 records in 0.041847351 seconds. Throughput is 2867.565 records/second. Loss is 0.08571534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003960709759188847. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 15120/60000][Iteration 7626][Wall Clock 346.511369605s] Trained 120 records in 0.041900883 seconds. Throughput is 2863.9014 records/second. Loss is 0.18385659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00396039603960396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:52 INFO  DistriOptimizer$:406 - [Epoch 16 15240/60000][Iteration 7627][Wall Clock 346.552332866s] Trained 120 records in 0.040963261 seconds. Throughput is 2929.454 records/second. Loss is 0.1235174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039600823697132905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 15360/60000][Iteration 7628][Wall Clock 346.593365521s] Trained 120 records in 0.041032655 seconds. Throughput is 2924.5002 records/second. Loss is 0.24078579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003959768749505028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 15480/60000][Iteration 7629][Wall Clock 346.634253228s] Trained 120 records in 0.040887707 seconds. Throughput is 2934.8674 records/second. Loss is 0.1723699. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039594551789673745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 15600/60000][Iteration 7630][Wall Clock 346.674967371s] Trained 120 records in 0.040714143 seconds. Throughput is 2947.3787 records/second. Loss is 0.15311453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003959141658088526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 15720/60000][Iteration 7631][Wall Clock 346.715792881s] Trained 120 records in 0.04082551 seconds. Throughput is 2939.3389 records/second. Loss is 0.10498773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003958828186856691. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 15840/60000][Iteration 7632][Wall Clock 346.755883264s] Trained 120 records in 0.040090383 seconds. Throughput is 2993.2366 records/second. Loss is 0.10312342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003958514765260074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 15960/60000][Iteration 7633][Wall Clock 346.80457506s] Trained 120 records in 0.048691796 seconds. Throughput is 2464.481 records/second. Loss is 0.15175073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003958201393286891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16080/60000][Iteration 7634][Wall Clock 346.853908761s] Trained 120 records in 0.049333701 seconds. Throughput is 2432.4143 records/second. Loss is 0.15059677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003957888070925354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16200/60000][Iteration 7635][Wall Clock 346.894585721s] Trained 120 records in 0.04067696 seconds. Throughput is 2950.073 records/second. Loss is 0.16773328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039575747981636855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16320/60000][Iteration 7636][Wall Clock 346.934675103s] Trained 120 records in 0.040089382 seconds. Throughput is 2993.3113 records/second. Loss is 0.16821265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003957261574990107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16440/60000][Iteration 7637][Wall Clock 346.975009442s] Trained 120 records in 0.040334339 seconds. Throughput is 2975.1323 records/second. Loss is 0.17695025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003956948401392846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16560/60000][Iteration 7638][Wall Clock 347.01644108s] Trained 120 records in 0.041431638 seconds. Throughput is 2896.3372 records/second. Loss is 0.16287798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003956635277360133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16680/60000][Iteration 7639][Wall Clock 347.057999502s] Trained 120 records in 0.041558422 seconds. Throughput is 2887.5015 records/second. Loss is 0.1669956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003956322202880202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16800/60000][Iteration 7640][Wall Clock 347.099792821s] Trained 120 records in 0.041793319 seconds. Throughput is 2871.2722 records/second. Loss is 0.14128515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003956009177941293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 16920/60000][Iteration 7641][Wall Clock 347.140697545s] Trained 120 records in 0.040904724 seconds. Throughput is 2933.6465 records/second. Loss is 0.17750317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003955696202531646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17040/60000][Iteration 7642][Wall Clock 347.182876332s] Trained 120 records in 0.042178787 seconds. Throughput is 2845.032 records/second. Loss is 0.16685854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003955383276639506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17160/60000][Iteration 7643][Wall Clock 347.224933748s] Trained 120 records in 0.042057416 seconds. Throughput is 2853.2422 records/second. Loss is 0.18604608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003955070400253125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17280/60000][Iteration 7644][Wall Clock 347.265459592s] Trained 120 records in 0.040525844 seconds. Throughput is 2961.0735 records/second. Loss is 0.14790362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039547575733607536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17400/60000][Iteration 7645][Wall Clock 347.305668128s] Trained 120 records in 0.040208536 seconds. Throughput is 2984.441 records/second. Loss is 0.2153051. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003954444795950648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17520/60000][Iteration 7646][Wall Clock 347.346166702s] Trained 120 records in 0.040498574 seconds. Throughput is 2963.0674 records/second. Loss is 0.1539854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039541320680110716. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17640/60000][Iteration 7647][Wall Clock 347.393298712s] Trained 120 records in 0.04713201 seconds. Throughput is 2546.0403 records/second. Loss is 0.2383623. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039538193895302855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17760/60000][Iteration 7648][Wall Clock 347.442429208s] Trained 120 records in 0.049130496 seconds. Throughput is 2442.4749 records/second. Loss is 0.13854913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039535067604965606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 17880/60000][Iteration 7649][Wall Clock 347.485581783s] Trained 120 records in 0.043152575 seconds. Throughput is 2780.8306 records/second. Loss is 0.16735315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039531941808981655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 18000/60000][Iteration 7650][Wall Clock 347.525781624s] Trained 120 records in 0.040199841 seconds. Throughput is 2985.0864 records/second. Loss is 0.1904257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003952881650723378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:53 INFO  DistriOptimizer$:406 - [Epoch 16 18120/60000][Iteration 7651][Wall Clock 347.565269817s] Trained 120 records in 0.039488193 seconds. Throughput is 3038.883 records/second. Loss is 0.12273794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003952569169960474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 18240/60000][Iteration 7652][Wall Clock 347.608521701s] Trained 120 records in 0.043251884 seconds. Throughput is 2774.4456 records/second. Loss is 0.20024128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00395225673859774. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 18360/60000][Iteration 7653][Wall Clock 347.648560189s] Trained 120 records in 0.040038488 seconds. Throughput is 2997.1162 records/second. Loss is 0.19017503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003951944356623459. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 18480/60000][Iteration 7654][Wall Clock 347.688578943s] Trained 120 records in 0.040018754 seconds. Throughput is 2998.5942 records/second. Loss is 0.1170691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003951632024025923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 18600/60000][Iteration 7655][Wall Clock 347.72866242s] Trained 120 records in 0.040083477 seconds. Throughput is 2993.7524 records/second. Loss is 0.21358067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003951319740793425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 18720/60000][Iteration 7656][Wall Clock 347.768812942s] Trained 120 records in 0.040150522 seconds. Throughput is 2988.7532 records/second. Loss is 0.15194516. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003951007506914263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 18840/60000][Iteration 7657][Wall Clock 347.809767962s] Trained 120 records in 0.04095502 seconds. Throughput is 2930.044 records/second. Loss is 0.14919798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003950695322376738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 18960/60000][Iteration 7658][Wall Clock 347.849821015s] Trained 120 records in 0.040053053 seconds. Throughput is 2996.0261 records/second. Loss is 0.13352916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003950383187169155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19080/60000][Iteration 7659][Wall Clock 347.890144815s] Trained 120 records in 0.0403238 seconds. Throughput is 2975.91 records/second. Loss is 0.1607483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003950071101279823. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19200/60000][Iteration 7660][Wall Clock 347.94387733s] Trained 120 records in 0.053732515 seconds. Throughput is 2233.2847 records/second. Loss is 0.12943973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003949759064697054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19320/60000][Iteration 7661][Wall Clock 347.986471052s] Trained 120 records in 0.042593722 seconds. Throughput is 2817.3167 records/second. Loss is 0.24214372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039494470774091624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19440/60000][Iteration 7662][Wall Clock 348.027260712s] Trained 120 records in 0.04078966 seconds. Throughput is 2941.922 records/second. Loss is 0.16435836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003949135139404471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19560/60000][Iteration 7663][Wall Clock 348.068095923s] Trained 120 records in 0.040835211 seconds. Throughput is 2938.6406 records/second. Loss is 0.13807052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039488232506713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19680/60000][Iteration 7664][Wall Clock 348.10959619s] Trained 120 records in 0.041500267 seconds. Throughput is 2891.5476 records/second. Loss is 0.25264183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003948511411197978. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19800/60000][Iteration 7665][Wall Clock 348.151266611s] Trained 120 records in 0.041670421 seconds. Throughput is 2879.7407 records/second. Loss is 0.15386531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003948199620972837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 19920/60000][Iteration 7666][Wall Clock 348.192535066s] Trained 120 records in 0.041268455 seconds. Throughput is 2907.7898 records/second. Loss is 0.20510416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003947887879984208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20040/60000][Iteration 7667][Wall Clock 348.233996787s] Trained 120 records in 0.041461721 seconds. Throughput is 2894.2358 records/second. Loss is 0.13819292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003947576188220433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20160/60000][Iteration 7668][Wall Clock 348.275655129s] Trained 120 records in 0.041658342 seconds. Throughput is 2880.5754 records/second. Loss is 0.14893694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00394726454566985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20280/60000][Iteration 7669][Wall Clock 348.315934106s] Trained 120 records in 0.040278977 seconds. Throughput is 2979.2214 records/second. Loss is 0.14738254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003946952952320808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20400/60000][Iteration 7670][Wall Clock 348.356138318s] Trained 120 records in 0.040204212 seconds. Throughput is 2984.762 records/second. Loss is 0.18158434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039466414081616545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20520/60000][Iteration 7671][Wall Clock 348.400124804s] Trained 120 records in 0.043986486 seconds. Throughput is 2728.1108 records/second. Loss is 0.15124628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003946329913180742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20640/60000][Iteration 7672][Wall Clock 348.450306393s] Trained 120 records in 0.050181589 seconds. Throughput is 2391.3152 records/second. Loss is 0.1961932. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003946018467366427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20760/60000][Iteration 7673][Wall Clock 348.49955782s] Trained 120 records in 0.049251427 seconds. Throughput is 2436.4778 records/second. Loss is 0.16278142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003945707070707071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:54 INFO  DistriOptimizer$:406 - [Epoch 16 20880/60000][Iteration 7674][Wall Clock 348.544318476s] Trained 120 records in 0.044760656 seconds. Throughput is 2680.9258 records/second. Loss is 0.20855373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003945395723191036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21000/60000][Iteration 7675][Wall Clock 348.585288637s] Trained 120 records in 0.040970161 seconds. Throughput is 2928.961 records/second. Loss is 0.16059698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039450844248066904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21120/60000][Iteration 7676][Wall Clock 348.62607672s] Trained 120 records in 0.040788083 seconds. Throughput is 2942.0356 records/second. Loss is 0.19253069. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039447731755424065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21240/60000][Iteration 7677][Wall Clock 348.666710855s] Trained 120 records in 0.040634135 seconds. Throughput is 2953.182 records/second. Loss is 0.15298077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003944461975386557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21360/60000][Iteration 7678][Wall Clock 348.707471653s] Trained 120 records in 0.040760798 seconds. Throughput is 2944.0054 records/second. Loss is 0.22868223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039441508243275225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21480/60000][Iteration 7679][Wall Clock 348.748507386s] Trained 120 records in 0.041035733 seconds. Throughput is 2924.2805 records/second. Loss is 0.11007822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003943839722353683. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21600/60000][Iteration 7680][Wall Clock 348.789250643s] Trained 120 records in 0.040743257 seconds. Throughput is 2945.2725 records/second. Loss is 0.12921318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003943528669453427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21720/60000][Iteration 7681][Wall Clock 348.831301943s] Trained 120 records in 0.0420513 seconds. Throughput is 2853.6572 records/second. Loss is 0.10896465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003943217665615142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21840/60000][Iteration 7682][Wall Clock 348.871958631s] Trained 120 records in 0.040656688 seconds. Throughput is 2951.5437 records/second. Loss is 0.17313151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003942906710827222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 21960/60000][Iteration 7683][Wall Clock 348.912572846s] Trained 120 records in 0.040614215 seconds. Throughput is 2954.6306 records/second. Loss is 0.21327846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003942595805078063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22080/60000][Iteration 7684][Wall Clock 348.952896811s] Trained 120 records in 0.040323965 seconds. Throughput is 2975.8977 records/second. Loss is 0.22686386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003942284948356067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22200/60000][Iteration 7685][Wall Clock 348.993385617s] Trained 120 records in 0.040488806 seconds. Throughput is 2963.7822 records/second. Loss is 0.11618648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003941974140649637. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22320/60000][Iteration 7686][Wall Clock 349.044386352s] Trained 120 records in 0.051000735 seconds. Throughput is 2352.9072 records/second. Loss is 0.1616392. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003941663381947182. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22440/60000][Iteration 7687][Wall Clock 349.091546271s] Trained 120 records in 0.047159919 seconds. Throughput is 2544.5337 records/second. Loss is 0.15018104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003941352672237111. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22560/60000][Iteration 7688][Wall Clock 349.132922958s] Trained 120 records in 0.041376687 seconds. Throughput is 2900.1838 records/second. Loss is 0.22892514. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003941042011507843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22680/60000][Iteration 7689][Wall Clock 349.174212131s] Trained 120 records in 0.041289173 seconds. Throughput is 2906.3308 records/second. Loss is 0.090631165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003940731399747792. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22800/60000][Iteration 7690][Wall Clock 349.218645053s] Trained 120 records in 0.044432922 seconds. Throughput is 2700.7002 records/second. Loss is 0.19454582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003940420836945386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 22920/60000][Iteration 7691][Wall Clock 349.259513328s] Trained 120 records in 0.040868275 seconds. Throughput is 2936.263 records/second. Loss is 0.1829094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003940110323089046. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 23040/60000][Iteration 7692][Wall Clock 349.300534917s] Trained 120 records in 0.041021589 seconds. Throughput is 2925.2888 records/second. Loss is 0.117124036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003939799858167206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 23160/60000][Iteration 7693][Wall Clock 349.3409754s] Trained 120 records in 0.040440483 seconds. Throughput is 2967.3237 records/second. Loss is 0.19234142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003939489442168295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 23280/60000][Iteration 7694][Wall Clock 349.38157917s] Trained 120 records in 0.04060377 seconds. Throughput is 2955.3904 records/second. Loss is 0.19148295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003939179075080753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 23400/60000][Iteration 7695][Wall Clock 349.422429994s] Trained 120 records in 0.040850824 seconds. Throughput is 2937.517 records/second. Loss is 0.19321553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00393886875689302. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 23520/60000][Iteration 7696][Wall Clock 349.464003137s] Trained 120 records in 0.041573143 seconds. Throughput is 2886.4788 records/second. Loss is 0.21101503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003938558487593541. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 23640/60000][Iteration 7697][Wall Clock 349.505484916s] Trained 120 records in 0.041481779 seconds. Throughput is 2892.8364 records/second. Loss is 0.13432555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003938248267170762. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:55 INFO  DistriOptimizer$:406 - [Epoch 16 23760/60000][Iteration 7698][Wall Clock 349.551375506s] Trained 120 records in 0.04589059 seconds. Throughput is 2614.9153 records/second. Loss is 0.18139973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039379380956131365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 23880/60000][Iteration 7699][Wall Clock 349.596350595s] Trained 120 records in 0.044975089 seconds. Throughput is 2668.1436 records/second. Loss is 0.15857226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039376279729091196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24000/60000][Iteration 7700][Wall Clock 349.636195207s] Trained 120 records in 0.039844612 seconds. Throughput is 3011.6995 records/second. Loss is 0.16461305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003937317899047169. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24120/60000][Iteration 7701][Wall Clock 349.676153677s] Trained 120 records in 0.03995847 seconds. Throughput is 3003.118 records/second. Loss is 0.1582792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003937007874015748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24240/60000][Iteration 7702][Wall Clock 349.716806446s] Trained 120 records in 0.040652769 seconds. Throughput is 2951.8284 records/second. Loss is 0.14988431. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003936697897803322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24360/60000][Iteration 7703][Wall Clock 349.757239883s] Trained 120 records in 0.040433437 seconds. Throughput is 2967.8408 records/second. Loss is 0.17765501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003936387970398363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24480/60000][Iteration 7704][Wall Clock 349.797888683s] Trained 120 records in 0.0406488 seconds. Throughput is 2952.1167 records/second. Loss is 0.14797682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003936078091789341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24600/60000][Iteration 7705][Wall Clock 349.83771991s] Trained 120 records in 0.039831227 seconds. Throughput is 3012.7114 records/second. Loss is 0.116402164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003935768261964736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24720/60000][Iteration 7706][Wall Clock 349.878161812s] Trained 120 records in 0.040441902 seconds. Throughput is 2967.2197 records/second. Loss is 0.10919345. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003935458480913026. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24840/60000][Iteration 7707][Wall Clock 349.918320925s] Trained 120 records in 0.040159113 seconds. Throughput is 2988.1138 records/second. Loss is 0.12606467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003935148748622698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 24960/60000][Iteration 7708][Wall Clock 349.958786208s] Trained 120 records in 0.040465283 seconds. Throughput is 2965.505 records/second. Loss is 0.13473637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003934839065082238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25080/60000][Iteration 7709][Wall Clock 350.002844307s] Trained 120 records in 0.044058099 seconds. Throughput is 2723.6763 records/second. Loss is 0.14741334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003934529430280139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25200/60000][Iteration 7710][Wall Clock 350.042490576s] Trained 120 records in 0.039646269 seconds. Throughput is 3026.7666 records/second. Loss is 0.27009743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003934219844204894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25320/60000][Iteration 7711][Wall Clock 350.082394211s] Trained 120 records in 0.039903635 seconds. Throughput is 3007.2449 records/second. Loss is 0.11278667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003933910306845004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25440/60000][Iteration 7712][Wall Clock 350.122252348s] Trained 120 records in 0.039858137 seconds. Throughput is 3010.6777 records/second. Loss is 0.17109728. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039336008181889695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25560/60000][Iteration 7713][Wall Clock 350.17096164s] Trained 120 records in 0.048709292 seconds. Throughput is 2463.5957 records/second. Loss is 0.16111898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003933291378225299. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25680/60000][Iteration 7714][Wall Clock 350.218695732s] Trained 120 records in 0.047734092 seconds. Throughput is 2513.9265 records/second. Loss is 0.11306837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003932981986942499. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25800/60000][Iteration 7715][Wall Clock 350.259890098s] Trained 120 records in 0.041194366 seconds. Throughput is 2913.0198 records/second. Loss is 0.25831056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003932672644329086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 25920/60000][Iteration 7716][Wall Clock 350.300277607s] Trained 120 records in 0.040387509 seconds. Throughput is 2971.2158 records/second. Loss is 0.17643048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003932363350373574. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 26040/60000][Iteration 7717][Wall Clock 350.339785457s] Trained 120 records in 0.03950785 seconds. Throughput is 3037.371 records/second. Loss is 0.17766361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003932054105064486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 26160/60000][Iteration 7718][Wall Clock 350.379300279s] Trained 120 records in 0.039514822 seconds. Throughput is 3036.8352 records/second. Loss is 0.14948303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003931744908390344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 26280/60000][Iteration 7719][Wall Clock 350.419557393s] Trained 120 records in 0.040257114 seconds. Throughput is 2980.8396 records/second. Loss is 0.21643056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003931435760339676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 26400/60000][Iteration 7720][Wall Clock 350.46006154s] Trained 120 records in 0.040504147 seconds. Throughput is 2962.6597 records/second. Loss is 0.19914134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039311266609010145. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 26520/60000][Iteration 7721][Wall Clock 350.499736054s] Trained 120 records in 0.039674514 seconds. Throughput is 3024.6118 records/second. Loss is 0.14549637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003930817610062893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:56 INFO  DistriOptimizer$:406 - [Epoch 16 26640/60000][Iteration 7722][Wall Clock 350.540422479s] Trained 120 records in 0.040686425 seconds. Throughput is 2949.3867 records/second. Loss is 0.14995243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003930508607813851. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 26760/60000][Iteration 7723][Wall Clock 350.588431498s] Trained 120 records in 0.048009019 seconds. Throughput is 2499.5303 records/second. Loss is 0.22914426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003930199654142431. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 26880/60000][Iteration 7724][Wall Clock 350.634003485s] Trained 120 records in 0.045571987 seconds. Throughput is 2633.1965 records/second. Loss is 0.15721108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003929890749037177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27000/60000][Iteration 7725][Wall Clock 350.674864874s] Trained 120 records in 0.040861389 seconds. Throughput is 2936.7576 records/second. Loss is 0.17260435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003929581892486639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27120/60000][Iteration 7726][Wall Clock 350.714770247s] Trained 120 records in 0.039905373 seconds. Throughput is 3007.1138 records/second. Loss is 0.15289474. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003929273084479372. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27240/60000][Iteration 7727][Wall Clock 350.758137467s] Trained 120 records in 0.04336722 seconds. Throughput is 2767.0671 records/second. Loss is 0.17997216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003928964325003928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27360/60000][Iteration 7728][Wall Clock 350.798023129s] Trained 120 records in 0.039885662 seconds. Throughput is 3008.5999 records/second. Loss is 0.1730924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003928655614048873. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27480/60000][Iteration 7729][Wall Clock 350.838143695s] Trained 120 records in 0.040120566 seconds. Throughput is 2990.9849 records/second. Loss is 0.2667761. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003928346951602765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27600/60000][Iteration 7730][Wall Clock 350.878391419s] Trained 120 records in 0.040247724 seconds. Throughput is 2981.5352 records/second. Loss is 0.1716693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039280383376541755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27720/60000][Iteration 7731][Wall Clock 350.918915726s] Trained 120 records in 0.040524307 seconds. Throughput is 2961.1858 records/second. Loss is 0.16674648. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003927729772191673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27840/60000][Iteration 7732][Wall Clock 350.959836439s] Trained 120 records in 0.040920713 seconds. Throughput is 2932.5002 records/second. Loss is 0.13916607. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003927421255203833. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 27960/60000][Iteration 7733][Wall Clock 351.000020492s] Trained 120 records in 0.040184053 seconds. Throughput is 2986.259 records/second. Loss is 0.1382575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003927112786679233. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28080/60000][Iteration 7734][Wall Clock 351.040417512s] Trained 120 records in 0.04039702 seconds. Throughput is 2970.5164 records/second. Loss is 0.20035456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003926804366606456. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28200/60000][Iteration 7735][Wall Clock 351.081454721s] Trained 120 records in 0.041037209 seconds. Throughput is 2924.1755 records/second. Loss is 0.15391353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003926495994974085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28320/60000][Iteration 7736][Wall Clock 351.122040305s] Trained 120 records in 0.040585584 seconds. Throughput is 2956.7148 records/second. Loss is 0.27180445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039261876717707105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28440/60000][Iteration 7737][Wall Clock 351.16272963s] Trained 120 records in 0.040689325 seconds. Throughput is 2949.1763 records/second. Loss is 0.123645425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003925879396984924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28560/60000][Iteration 7738][Wall Clock 351.202537075s] Trained 120 records in 0.039807445 seconds. Throughput is 3014.5115 records/second. Loss is 0.1603577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003925571170605323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28680/60000][Iteration 7739][Wall Clock 351.241845718s] Trained 120 records in 0.039308643 seconds. Throughput is 3052.7637 records/second. Loss is 0.17833014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003925262992620505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28800/60000][Iteration 7740][Wall Clock 351.290849812s] Trained 120 records in 0.049004094 seconds. Throughput is 2448.7751 records/second. Loss is 0.22478537. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003924954863019075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 28920/60000][Iteration 7741][Wall Clock 351.338643364s] Trained 120 records in 0.047793552 seconds. Throughput is 2510.7988 records/second. Loss is 0.16629505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003924646781789639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 29040/60000][Iteration 7742][Wall Clock 351.379157779s] Trained 120 records in 0.040514415 seconds. Throughput is 2961.909 records/second. Loss is 0.14380728. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003924338748920807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 29160/60000][Iteration 7743][Wall Clock 351.420076165s] Trained 120 records in 0.040918386 seconds. Throughput is 2932.667 records/second. Loss is 0.17975779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003924030764401193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 29280/60000][Iteration 7744][Wall Clock 351.461271279s] Trained 120 records in 0.041195114 seconds. Throughput is 2912.9668 records/second. Loss is 0.15789396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003923722828219415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 29400/60000][Iteration 7745][Wall Clock 351.50094656s] Trained 120 records in 0.039675281 seconds. Throughput is 3024.5532 records/second. Loss is 0.16932665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003923414940364093. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:57 INFO  DistriOptimizer$:406 - [Epoch 16 29520/60000][Iteration 7746][Wall Clock 351.544302747s] Trained 120 records in 0.043356187 seconds. Throughput is 2767.771 records/second. Loss is 0.11203377. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003923107100823852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 29640/60000][Iteration 7747][Wall Clock 351.585269116s] Trained 120 records in 0.040966369 seconds. Throughput is 2929.232 records/second. Loss is 0.19512247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003922799309587321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 29760/60000][Iteration 7748][Wall Clock 351.626010078s] Trained 120 records in 0.040740962 seconds. Throughput is 2945.4385 records/second. Loss is 0.16185932. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003922491566643131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 29880/60000][Iteration 7749][Wall Clock 351.677161784s] Trained 120 records in 0.051151706 seconds. Throughput is 2345.9626 records/second. Loss is 0.16105372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003922183871979919. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30000/60000][Iteration 7750][Wall Clock 351.717127447s] Trained 120 records in 0.039965663 seconds. Throughput is 3002.5774 records/second. Loss is 0.16569437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00392187622558632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30120/60000][Iteration 7751][Wall Clock 351.75741218s] Trained 120 records in 0.040284733 seconds. Throughput is 2978.796 records/second. Loss is 0.22587807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00392156862745098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30240/60000][Iteration 7752][Wall Clock 351.797426182s] Trained 120 records in 0.040014002 seconds. Throughput is 2998.9502 records/second. Loss is 0.15480438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003921261077562544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30360/60000][Iteration 7753][Wall Clock 351.838192193s] Trained 120 records in 0.040766011 seconds. Throughput is 2943.6287 records/second. Loss is 0.13881245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039209535759096616. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30480/60000][Iteration 7754][Wall Clock 351.878120351s] Trained 120 records in 0.039928158 seconds. Throughput is 3005.398 records/second. Loss is 0.15040421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003920646122480984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30600/60000][Iteration 7755][Wall Clock 351.918817459s] Trained 120 records in 0.040697108 seconds. Throughput is 2948.6123 records/second. Loss is 0.14369692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039203387172651715. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30720/60000][Iteration 7756][Wall Clock 351.958362928s] Trained 120 records in 0.039545469 seconds. Throughput is 3034.4817 records/second. Loss is 0.14687125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003920031360250882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30840/60000][Iteration 7757][Wall Clock 351.998046565s] Trained 120 records in 0.039683637 seconds. Throughput is 3023.9165 records/second. Loss is 0.19800526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00391972405142678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 30960/60000][Iteration 7758][Wall Clock 352.038011753s] Trained 120 records in 0.039965188 seconds. Throughput is 3002.6133 records/second. Loss is 0.14156169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003919416790781532. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31080/60000][Iteration 7759][Wall Clock 352.078249512s] Trained 120 records in 0.040237759 seconds. Throughput is 2982.2734 records/second. Loss is 0.15770997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003919109578303809. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31200/60000][Iteration 7760][Wall Clock 352.11756045s] Trained 120 records in 0.039310938 seconds. Throughput is 3052.5854 records/second. Loss is 0.08992311. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003918802413982287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31320/60000][Iteration 7761][Wall Clock 352.158255827s] Trained 120 records in 0.040695377 seconds. Throughput is 2948.7378 records/second. Loss is 0.24272896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003918495297805642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31440/60000][Iteration 7762][Wall Clock 352.198271181s] Trained 120 records in 0.040015354 seconds. Throughput is 2998.8489 records/second. Loss is 0.1958325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039181882297625575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31560/60000][Iteration 7763][Wall Clock 352.237479953s] Trained 120 records in 0.039208772 seconds. Throughput is 3060.5396 records/second. Loss is 0.15675226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003917881209841718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31680/60000][Iteration 7764][Wall Clock 352.279113421s] Trained 120 records in 0.041633468 seconds. Throughput is 2882.2966 records/second. Loss is 0.19443159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039175742380318105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31800/60000][Iteration 7765][Wall Clock 352.323946353s] Trained 120 records in 0.044832932 seconds. Throughput is 2676.6038 records/second. Loss is 0.15306918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003917267314321529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 31920/60000][Iteration 7766][Wall Clock 352.365022174s] Trained 120 records in 0.041075821 seconds. Throughput is 2921.4265 records/second. Loss is 0.15549101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039169604386995694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 32040/60000][Iteration 7767][Wall Clock 352.420970721s] Trained 120 records in 0.055948547 seconds. Throughput is 2144.828 records/second. Loss is 0.2042693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003916653611154629. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 32160/60000][Iteration 7768][Wall Clock 352.465814938s] Trained 120 records in 0.044844217 seconds. Throughput is 2675.9302 records/second. Loss is 0.15040395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003916346831675414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 32280/60000][Iteration 7769][Wall Clock 352.507060203s] Trained 120 records in 0.041245265 seconds. Throughput is 2909.4248 records/second. Loss is 0.19823456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003916040100250626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:58 INFO  DistriOptimizer$:406 - [Epoch 16 32400/60000][Iteration 7770][Wall Clock 352.547816168s] Trained 120 records in 0.040755965 seconds. Throughput is 2944.3542 records/second. Loss is 0.18926325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00391573341686898. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 32520/60000][Iteration 7771][Wall Clock 352.588825577s] Trained 120 records in 0.041009409 seconds. Throughput is 2926.158 records/second. Loss is 0.11934066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003915426781519185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 32640/60000][Iteration 7772][Wall Clock 352.631131119s] Trained 120 records in 0.042305542 seconds. Throughput is 2836.5078 records/second. Loss is 0.13799544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003915120194189962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 32760/60000][Iteration 7773][Wall Clock 352.674051991s] Trained 120 records in 0.042920872 seconds. Throughput is 2795.8425 records/second. Loss is 0.20100062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003914813654870028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 32880/60000][Iteration 7774][Wall Clock 352.716325023s] Trained 120 records in 0.042273032 seconds. Throughput is 2838.6892 records/second. Loss is 0.19656493. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003914507163548109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33000/60000][Iteration 7775][Wall Clock 352.765716746s] Trained 120 records in 0.049391723 seconds. Throughput is 2429.557 records/second. Loss is 0.1588945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003914200720212932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33120/60000][Iteration 7776][Wall Clock 352.808870947s] Trained 120 records in 0.043154201 seconds. Throughput is 2780.7256 records/second. Loss is 0.2600156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003913894324853229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33240/60000][Iteration 7777][Wall Clock 352.849576161s] Trained 120 records in 0.040705214 seconds. Throughput is 2948.0251 records/second. Loss is 0.16757299. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003913587977457733. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33360/60000][Iteration 7778][Wall Clock 352.890554022s] Trained 120 records in 0.040977861 seconds. Throughput is 2928.4104 records/second. Loss is 0.11368141. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003913281678015183. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33480/60000][Iteration 7779][Wall Clock 352.930973006s] Trained 120 records in 0.040418984 seconds. Throughput is 2968.902 records/second. Loss is 0.20875749. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003912975426514321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33600/60000][Iteration 7780][Wall Clock 352.971965337s] Trained 120 records in 0.040992331 seconds. Throughput is 2927.377 records/second. Loss is 0.22812496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003912669222943892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33720/60000][Iteration 7781][Wall Clock 353.013224924s] Trained 120 records in 0.041259587 seconds. Throughput is 2908.415 records/second. Loss is 0.2133186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003912363067292645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33840/60000][Iteration 7782][Wall Clock 353.054472255s] Trained 120 records in 0.041247331 seconds. Throughput is 2909.2793 records/second. Loss is 0.18440734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003912056959549331. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 33960/60000][Iteration 7783][Wall Clock 353.098854516s] Trained 120 records in 0.044382261 seconds. Throughput is 2703.783 records/second. Loss is 0.10102067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003911750899702707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34080/60000][Iteration 7784][Wall Clock 353.140691986s] Trained 120 records in 0.04183747 seconds. Throughput is 2868.2424 records/second. Loss is 0.21362795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003911444887741532. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34200/60000][Iteration 7785][Wall Clock 353.181510686s] Trained 120 records in 0.0408187 seconds. Throughput is 2939.829 records/second. Loss is 0.27044567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003911138923654568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34320/60000][Iteration 7786][Wall Clock 353.221858428s] Trained 120 records in 0.040347742 seconds. Throughput is 2974.144 records/second. Loss is 0.2082905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003910833007430582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34440/60000][Iteration 7787][Wall Clock 353.262300902s] Trained 120 records in 0.040442474 seconds. Throughput is 2967.1775 records/second. Loss is 0.16759586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003910527139058345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34560/60000][Iteration 7788][Wall Clock 353.302859655s] Trained 120 records in 0.040558753 seconds. Throughput is 2958.671 records/second. Loss is 0.16630727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003910221318526628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34680/60000][Iteration 7789][Wall Clock 353.343364657s] Trained 120 records in 0.040505002 seconds. Throughput is 2962.597 records/second. Loss is 0.22146119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00390991554582421. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34800/60000][Iteration 7790][Wall Clock 353.383634007s] Trained 120 records in 0.04026935 seconds. Throughput is 2979.934 records/second. Loss is 0.30083624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039096098209398696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 34920/60000][Iteration 7791][Wall Clock 353.424554561s] Trained 120 records in 0.040920554 seconds. Throughput is 2932.5115 records/second. Loss is 0.15814447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003909304143862393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 35040/60000][Iteration 7792][Wall Clock 353.465890592s] Trained 120 records in 0.041336031 seconds. Throughput is 2903.0364 records/second. Loss is 0.23722802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003908998514580564. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:58:59 INFO  DistriOptimizer$:406 - [Epoch 16 35160/60000][Iteration 7793][Wall Clock 353.519689688s] Trained 120 records in 0.053799096 seconds. Throughput is 2230.5208 records/second. Loss is 0.14498372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003908692933083178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 35280/60000][Iteration 7794][Wall Clock 353.567499209s] Trained 120 records in 0.047809521 seconds. Throughput is 2509.9602 records/second. Loss is 0.18530501. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003908387399359024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 35400/60000][Iteration 7795][Wall Clock 353.610684931s] Trained 120 records in 0.043185722 seconds. Throughput is 2778.696 records/second. Loss is 0.13455251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003908081913396905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 35520/60000][Iteration 7796][Wall Clock 353.651582073s] Trained 120 records in 0.040897142 seconds. Throughput is 2934.1904 records/second. Loss is 0.1895887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003907776475185619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 35640/60000][Iteration 7797][Wall Clock 353.695422036s] Trained 120 records in 0.043839963 seconds. Throughput is 2737.2288 records/second. Loss is 0.117812075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003907471084713973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 35760/60000][Iteration 7798][Wall Clock 353.737695513s] Trained 120 records in 0.042273477 seconds. Throughput is 2838.6594 records/second. Loss is 0.2871284. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039071657419707745. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 35880/60000][Iteration 7799][Wall Clock 353.778454327s] Trained 120 records in 0.040758814 seconds. Throughput is 2944.1484 records/second. Loss is 0.13407026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003906860446944835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36000/60000][Iteration 7800][Wall Clock 353.818744859s] Trained 120 records in 0.040290532 seconds. Throughput is 2978.3674 records/second. Loss is 0.1822768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003906555199624971. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36120/60000][Iteration 7801][Wall Clock 353.859134571s] Trained 120 records in 0.040389712 seconds. Throughput is 2971.0535 records/second. Loss is 0.17458853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00390625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36240/60000][Iteration 7802][Wall Clock 353.913768565s] Trained 120 records in 0.054633994 seconds. Throughput is 2196.4348 records/second. Loss is 0.09967618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039059448480587454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36360/60000][Iteration 7803][Wall Clock 353.955206259s] Trained 120 records in 0.041437694 seconds. Throughput is 2895.914 records/second. Loss is 0.21611121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003905639743790033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36480/60000][Iteration 7804][Wall Clock 353.996499226s] Trained 120 records in 0.041292967 seconds. Throughput is 2906.064 records/second. Loss is 0.15590034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039053346871826917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36600/60000][Iteration 7805][Wall Clock 354.037264778s] Trained 120 records in 0.040765552 seconds. Throughput is 2943.6616 records/second. Loss is 0.15455557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039050296782255547. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36720/60000][Iteration 7806][Wall Clock 354.078583318s] Trained 120 records in 0.04131854 seconds. Throughput is 2904.2654 records/second. Loss is 0.15430911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039047247169074584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36840/60000][Iteration 7807][Wall Clock 354.118911088s] Trained 120 records in 0.04032777 seconds. Throughput is 2975.6172 records/second. Loss is 0.28543797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039044198032172415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 36960/60000][Iteration 7808][Wall Clock 354.159989584s] Trained 120 records in 0.041078496 seconds. Throughput is 2921.2363 records/second. Loss is 0.15402637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00390411493714375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37080/60000][Iteration 7809][Wall Clock 354.200359691s] Trained 120 records in 0.040370107 seconds. Throughput is 2972.4966 records/second. Loss is 0.24231003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003903810118675827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37200/60000][Iteration 7810][Wall Clock 354.241533269s] Trained 120 records in 0.041173578 seconds. Throughput is 2914.4905 records/second. Loss is 0.10320275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039035053478023267. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37320/60000][Iteration 7811][Wall Clock 354.281930711s] Trained 120 records in 0.040397442 seconds. Throughput is 2970.485 records/second. Loss is 0.2304027. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039032006245120995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37440/60000][Iteration 7812][Wall Clock 354.322292833s] Trained 120 records in 0.040362122 seconds. Throughput is 2973.0845 records/second. Loss is 0.16776285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039028959487940056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37560/60000][Iteration 7813][Wall Clock 354.362374962s] Trained 120 records in 0.040082129 seconds. Throughput is 2993.8528 records/second. Loss is 0.18275909. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003902591320636903. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37680/60000][Iteration 7814][Wall Clock 354.402361314s] Trained 120 records in 0.039986352 seconds. Throughput is 3001.024 records/second. Loss is 0.20579977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003902286740029658. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37800/60000][Iteration 7815][Wall Clock 354.443755425s] Trained 120 records in 0.041394111 seconds. Throughput is 2898.9631 records/second. Loss is 0.114766434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003901982206961136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 37920/60000][Iteration 7816][Wall Clock 354.48417438s] Trained 120 records in 0.040418955 seconds. Throughput is 2968.904 records/second. Loss is 0.09988019. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039016777214202106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:00 INFO  DistriOptimizer$:406 - [Epoch 16 38040/60000][Iteration 7817][Wall Clock 354.524008653s] Trained 120 records in 0.039834273 seconds. Throughput is 3012.4812 records/second. Loss is 0.15506697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039013732833957553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 38160/60000][Iteration 7818][Wall Clock 354.563962996s] Trained 120 records in 0.039954343 seconds. Throughput is 3003.4282 records/second. Loss is 0.21147285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003901068892876648. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 38280/60000][Iteration 7819][Wall Clock 354.604380122s] Trained 120 records in 0.040417126 seconds. Throughput is 2969.0383 records/second. Loss is 0.17561425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003900764549851771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 38400/60000][Iteration 7820][Wall Clock 354.655548264s] Trained 120 records in 0.051168142 seconds. Throughput is 2345.2092 records/second. Loss is 0.22592838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039004602543100085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 38520/60000][Iteration 7821][Wall Clock 354.706950129s] Trained 120 records in 0.051401865 seconds. Throughput is 2334.5457 records/second. Loss is 0.31452975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0039001560062402497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 38640/60000][Iteration 7822][Wall Clock 354.751681303s] Trained 120 records in 0.044731174 seconds. Throughput is 2682.6929 records/second. Loss is 0.10930754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003899851805631386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 38760/60000][Iteration 7823][Wall Clock 354.793464515s] Trained 120 records in 0.041783212 seconds. Throughput is 2871.9668 records/second. Loss is 0.16793624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038995476524723133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 38880/60000][Iteration 7824][Wall Clock 354.834190419s] Trained 120 records in 0.040725904 seconds. Throughput is 2946.5276 records/second. Loss is 0.2079916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038992435467519303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39000/60000][Iteration 7825][Wall Clock 354.874499341s] Trained 120 records in 0.040308922 seconds. Throughput is 2977.0083 records/second. Loss is 0.15783246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003898939488459139. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39120/60000][Iteration 7826][Wall Clock 354.914647526s] Trained 120 records in 0.040148185 seconds. Throughput is 2988.9272 records/second. Loss is 0.12388578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038986354775828454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39240/60000][Iteration 7827][Wall Clock 354.955768541s] Trained 120 records in 0.041121015 seconds. Throughput is 2918.216 records/second. Loss is 0.13784167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00389833151411196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39360/60000][Iteration 7828][Wall Clock 355.003086944s] Trained 120 records in 0.047318403 seconds. Throughput is 2536.0112 records/second. Loss is 0.18615617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038980275980353934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39480/60000][Iteration 7829][Wall Clock 355.048420245s] Trained 120 records in 0.045333301 seconds. Throughput is 2647.0608 records/second. Loss is 0.12657578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038977237293420647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39600/60000][Iteration 7830][Wall Clock 355.0908336s] Trained 120 records in 0.042413355 seconds. Throughput is 2829.2976 records/second. Loss is 0.19555609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00389741990802089. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39720/60000][Iteration 7831][Wall Clock 355.13302539s] Trained 120 records in 0.04219179 seconds. Throughput is 2844.1553 records/second. Loss is 0.20041394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038971161340607954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39840/60000][Iteration 7832][Wall Clock 355.174070905s] Trained 120 records in 0.041045515 seconds. Throughput is 2923.5835 records/second. Loss is 0.2183666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003896812407450705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 39960/60000][Iteration 7833][Wall Clock 355.214619397s] Trained 120 records in 0.040548492 seconds. Throughput is 2959.4194 records/second. Loss is 0.15211396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038965087281795517. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40080/60000][Iteration 7834][Wall Clock 355.255213747s] Trained 120 records in 0.04059435 seconds. Throughput is 2956.0764 records/second. Loss is 0.21329562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038962050962362657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40200/60000][Iteration 7835][Wall Clock 355.295556436s] Trained 120 records in 0.040342689 seconds. Throughput is 2974.5166 records/second. Loss is 0.2536497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003895901511609787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40320/60000][Iteration 7836][Wall Clock 355.336222339s] Trained 120 records in 0.040665903 seconds. Throughput is 2950.8752 records/second. Loss is 0.23700853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038955979742890533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40440/60000][Iteration 7837][Wall Clock 355.376478097s] Trained 120 records in 0.040255758 seconds. Throughput is 2980.94 records/second. Loss is 0.17168923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00389529448426301. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40560/60000][Iteration 7838][Wall Clock 355.41663308s] Trained 120 records in 0.040154983 seconds. Throughput is 2988.4211 records/second. Loss is 0.20756634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038949910415206042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40680/60000][Iteration 7839][Wall Clock 355.457981552s] Trained 120 records in 0.041348472 seconds. Throughput is 2902.1628 records/second. Loss is 0.24232315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038946876460507866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40800/60000][Iteration 7840][Wall Clock 355.501478473s] Trained 120 records in 0.043496921 seconds. Throughput is 2758.816 records/second. Loss is 0.21313693. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003894384297842511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:01 INFO  DistriOptimizer$:406 - [Epoch 16 40920/60000][Iteration 7841][Wall Clock 355.541753527s] Trained 120 records in 0.040275054 seconds. Throughput is 2979.512 records/second. Loss is 0.12541424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003894080996884735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41040/60000][Iteration 7842][Wall Clock 355.582640699s] Trained 120 records in 0.040887172 seconds. Throughput is 2934.9058 records/second. Loss is 0.14753784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00389377774316642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41160/60000][Iteration 7843][Wall Clock 355.623078106s] Trained 120 records in 0.040437407 seconds. Throughput is 2967.5493 records/second. Loss is 0.15138482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00389347453667653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41280/60000][Iteration 7844][Wall Clock 355.663830024s] Trained 120 records in 0.040751918 seconds. Throughput is 2944.6465 records/second. Loss is 0.19966096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038931713774040333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41400/60000][Iteration 7845][Wall Clock 355.705039203s] Trained 120 records in 0.041209179 seconds. Throughput is 2911.9724 records/second. Loss is 0.07425531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038928682653379012. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41520/60000][Iteration 7846][Wall Clock 355.745758895s] Trained 120 records in 0.040719692 seconds. Throughput is 2946.977 records/second. Loss is 0.16003497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003892565200467108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41640/60000][Iteration 7847][Wall Clock 355.800207228s] Trained 120 records in 0.054448333 seconds. Throughput is 2203.9243 records/second. Loss is 0.16730009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038922621827806314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41760/60000][Iteration 7848][Wall Clock 355.846542189s] Trained 120 records in 0.046334961 seconds. Throughput is 2589.8372 records/second. Loss is 0.15260057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038919592122674557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 41880/60000][Iteration 7849][Wall Clock 355.887720725s] Trained 120 records in 0.041178536 seconds. Throughput is 2914.1396 records/second. Loss is 0.23628283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038916562889165624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42000/60000][Iteration 7850][Wall Clock 355.927602477s] Trained 120 records in 0.039881752 seconds. Throughput is 3008.895 records/second. Loss is 0.20020299. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038913534127169433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42120/60000][Iteration 7851][Wall Clock 355.967241323s] Trained 120 records in 0.039638846 seconds. Throughput is 3027.3333 records/second. Loss is 0.19167058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003891050583657587. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42240/60000][Iteration 7852][Wall Clock 356.00871229s] Trained 120 records in 0.041470967 seconds. Throughput is 2893.5906 records/second. Loss is 0.2171736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038907478017274925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42360/60000][Iteration 7853][Wall Clock 356.049855785s] Trained 120 records in 0.041143495 seconds. Throughput is 2916.6213 records/second. Loss is 0.23680349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003890445066915655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42480/60000][Iteration 7854][Wall Clock 356.089584142s] Trained 120 records in 0.039728357 seconds. Throughput is 3020.5125 records/second. Loss is 0.15703885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038901423792110797. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42600/60000][Iteration 7855][Wall Clock 356.136670995s] Trained 120 records in 0.047086853 seconds. Throughput is 2548.482 records/second. Loss is 0.19812435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003889839738602769. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42720/60000][Iteration 7856][Wall Clock 356.179103599s] Trained 120 records in 0.042432604 seconds. Throughput is 2828.0142 records/second. Loss is 0.20641248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038895371450797353. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42840/60000][Iteration 7857][Wall Clock 356.219061984s] Trained 120 records in 0.039958385 seconds. Throughput is 3003.1245 records/second. Loss is 0.24773602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003889234598630989. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 42960/60000][Iteration 7858][Wall Clock 356.263243479s] Trained 120 records in 0.044181495 seconds. Throughput is 2716.069 records/second. Loss is 0.20002021. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003888932099245547. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 43080/60000][Iteration 7859][Wall Clock 356.304531646s] Trained 120 records in 0.041288167 seconds. Throughput is 2906.4016 records/second. Loss is 0.26050475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003888629646912428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 43200/60000][Iteration 7860][Wall Clock 356.345718171s] Trained 120 records in 0.041186525 seconds. Throughput is 2913.5742 records/second. Loss is 0.114524536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003888327241620655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 43320/60000][Iteration 7861][Wall Clock 356.386754362s] Trained 120 records in 0.041036191 seconds. Throughput is 2924.2478 records/second. Loss is 0.080572136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038880248833592533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 43440/60000][Iteration 7862][Wall Clock 356.427724501s] Trained 120 records in 0.040970139 seconds. Throughput is 2928.9624 records/second. Loss is 0.15170379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003887722572117254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 43560/60000][Iteration 7863][Wall Clock 356.468469657s] Trained 120 records in 0.040745156 seconds. Throughput is 2945.1353 records/second. Loss is 0.18833476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038874203078836885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:02 INFO  DistriOptimizer$:406 - [Epoch 16 43680/60000][Iteration 7864][Wall Clock 356.509398392s] Trained 120 records in 0.040928735 seconds. Throughput is 2931.9253 records/second. Loss is 0.10191645. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038871180906475938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 43800/60000][Iteration 7865][Wall Clock 356.550846829s] Trained 120 records in 0.041448437 seconds. Throughput is 2895.1636 records/second. Loss is 0.29803506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00388681592039801. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 43920/60000][Iteration 7866][Wall Clock 356.592579154s] Trained 120 records in 0.041732325 seconds. Throughput is 2875.4688 records/second. Loss is 0.11736533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003886513797123979. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44040/60000][Iteration 7867][Wall Clock 356.63377081s] Trained 120 records in 0.041191656 seconds. Throughput is 2913.2114 records/second. Loss is 0.23297134. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00388621172081455. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44160/60000][Iteration 7868][Wall Clock 356.6743226s] Trained 120 records in 0.04055179 seconds. Throughput is 2959.179 records/second. Loss is 0.14811116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00388590969145877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44280/60000][Iteration 7869][Wall Clock 356.715189109s] Trained 120 records in 0.040866509 seconds. Throughput is 2936.39 records/second. Loss is 0.24990384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003885607709045695. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44400/60000][Iteration 7870][Wall Clock 356.755824426s] Trained 120 records in 0.040635317 seconds. Throughput is 2953.0962 records/second. Loss is 0.12460497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003885305773564379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44520/60000][Iteration 7871][Wall Clock 356.796445147s] Trained 120 records in 0.040620721 seconds. Throughput is 2954.1572 records/second. Loss is 0.16196622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038850038850038854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44640/60000][Iteration 7872][Wall Clock 356.842423913s] Trained 120 records in 0.045978766 seconds. Throughput is 2609.9004 records/second. Loss is 0.14956312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038847020433532744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44760/60000][Iteration 7873][Wall Clock 356.893258784s] Trained 120 records in 0.050834871 seconds. Throughput is 2360.5842 records/second. Loss is 0.16879116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038844002486016164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 44880/60000][Iteration 7874][Wall Clock 356.934453998s] Trained 120 records in 0.041195214 seconds. Throughput is 2912.9597 records/second. Loss is 0.15421279. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038840985007379783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45000/60000][Iteration 7875][Wall Clock 356.975155894s] Trained 120 records in 0.040701896 seconds. Throughput is 2948.2656 records/second. Loss is 0.19613193. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038837967997514375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45120/60000][Iteration 7876][Wall Clock 357.015572221s] Trained 120 records in 0.040416327 seconds. Throughput is 2969.0972 records/second. Loss is 0.16387753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003883495145631068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45240/60000][Iteration 7877][Wall Clock 357.060011689s] Trained 120 records in 0.044439468 seconds. Throughput is 2700.3022 records/second. Loss is 0.25050887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003883193538365952. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45360/60000][Iteration 7878][Wall Clock 357.100709604s] Trained 120 records in 0.040697915 seconds. Throughput is 2948.5542 records/second. Loss is 0.1299198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038828919779451735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45480/60000][Iteration 7879][Wall Clock 357.141349674s] Trained 120 records in 0.04064007 seconds. Throughput is 2952.7507 records/second. Loss is 0.1059111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038825904643578196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45600/60000][Iteration 7880][Wall Clock 357.183040299s] Trained 120 records in 0.041690625 seconds. Throughput is 2878.345 records/second. Loss is 0.29197475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038822889975929807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45720/60000][Iteration 7881][Wall Clock 357.230845666s] Trained 120 records in 0.047805367 seconds. Throughput is 2510.1785 records/second. Loss is 0.15780327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038819875776397515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45840/60000][Iteration 7882][Wall Clock 357.277049503s] Trained 120 records in 0.046203837 seconds. Throughput is 2597.187 records/second. Loss is 0.17021827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038816862044872293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 45960/60000][Iteration 7883][Wall Clock 357.318009855s] Trained 120 records in 0.040960352 seconds. Throughput is 2929.6624 records/second. Loss is 0.19931068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003881384878124515. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 46080/60000][Iteration 7884][Wall Clock 357.35884403s] Trained 120 records in 0.040834175 seconds. Throughput is 2938.715 records/second. Loss is 0.11987021. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038810835985407127. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 46200/60000][Iteration 7885][Wall Clock 357.399479183s] Trained 120 records in 0.040635153 seconds. Throughput is 2953.1082 records/second. Loss is 0.09674044. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00388078236572493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 46320/60000][Iteration 7886][Wall Clock 357.440398713s] Trained 120 records in 0.04091953 seconds. Throughput is 2932.585 records/second. Loss is 0.16470724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038804811796662787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 46440/60000][Iteration 7887][Wall Clock 357.481618179s] Trained 120 records in 0.041219466 seconds. Throughput is 2911.2458 records/second. Loss is 0.10474242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038801800403538717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:03 INFO  DistriOptimizer$:406 - [Epoch 16 46560/60000][Iteration 7888][Wall Clock 357.52321012s] Trained 120 records in 0.041591941 seconds. Throughput is 2885.1743 records/second. Loss is 0.18549338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038798789477768295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 46680/60000][Iteration 7889][Wall Clock 357.56412735s] Trained 120 records in 0.04091723 seconds. Throughput is 2932.75 records/second. Loss is 0.12183221. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00387957790192427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 46800/60000][Iteration 7890][Wall Clock 357.604284821s] Trained 120 records in 0.040157471 seconds. Throughput is 2988.236 records/second. Loss is 0.18481144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003879276902785321. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 46920/60000][Iteration 7891][Wall Clock 357.644357248s] Trained 120 records in 0.040072427 seconds. Throughput is 2994.578 records/second. Loss is 0.18002081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038789759503491074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47040/60000][Iteration 7892][Wall Clock 357.68469936s] Trained 120 records in 0.040342112 seconds. Throughput is 2974.5593 records/second. Loss is 0.18051186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038786750446047633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47160/60000][Iteration 7893][Wall Clock 357.724936091s] Trained 120 records in 0.040236731 seconds. Throughput is 2982.3496 records/second. Loss is 0.15728708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038783741855414207. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47280/60000][Iteration 7894][Wall Clock 357.765991115s] Trained 120 records in 0.041055024 seconds. Throughput is 2922.9065 records/second. Loss is 0.1593454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038780733731482203. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47400/60000][Iteration 7895][Wall Clock 357.805593821s] Trained 120 records in 0.039602706 seconds. Throughput is 3030.0962 records/second. Loss is 0.15836312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003877772607414301. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47520/60000][Iteration 7896][Wall Clock 357.84983754s] Trained 120 records in 0.044243719 seconds. Throughput is 2712.2493 records/second. Loss is 0.25008667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038774718883288093. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47640/60000][Iteration 7897][Wall Clock 357.902488885s] Trained 120 records in 0.052651345 seconds. Throughput is 2279.144 records/second. Loss is 0.114833355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003877171215880893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47760/60000][Iteration 7898][Wall Clock 357.953636165s] Trained 120 records in 0.05114728 seconds. Throughput is 2346.1658 records/second. Loss is 0.26195684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038768705900597035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 47880/60000][Iteration 7899][Wall Clock 357.994157742s] Trained 120 records in 0.040521577 seconds. Throughput is 2961.3853 records/second. Loss is 0.13791068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003876570010854396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48000/60000][Iteration 7900][Wall Clock 358.035197839s] Trained 120 records in 0.041040097 seconds. Throughput is 2923.9697 records/second. Loss is 0.15073225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003876269478254128. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48120/60000][Iteration 7901][Wall Clock 358.076265468s] Trained 120 records in 0.041067629 seconds. Throughput is 2922.0093 records/second. Loss is 0.15156573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003875968992248062. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48240/60000][Iteration 7902][Wall Clock 358.11787711s] Trained 120 records in 0.041611642 seconds. Throughput is 2883.8083 records/second. Loss is 0.13383321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038756685528253624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48360/60000][Iteration 7903][Wall Clock 358.159408639s] Trained 120 records in 0.041531529 seconds. Throughput is 2889.371 records/second. Loss is 0.18204522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038753681599751977. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48480/60000][Iteration 7904][Wall Clock 358.200363706s] Trained 120 records in 0.040955067 seconds. Throughput is 2930.0403 records/second. Loss is 0.1551857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038750678136867398. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48600/60000][Iteration 7905][Wall Clock 358.241208482s] Trained 120 records in 0.040844776 seconds. Throughput is 2937.9521 records/second. Loss is 0.19309951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003874767513949163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48720/60000][Iteration 7906][Wall Clock 358.281428572s] Trained 120 records in 0.04022009 seconds. Throughput is 2983.5837 records/second. Loss is 0.16955115. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038744672607516463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48840/60000][Iteration 7907][Wall Clock 358.321635043s] Trained 120 records in 0.040206471 seconds. Throughput is 2984.5942 records/second. Loss is 0.15579669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038741670540833723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 48960/60000][Iteration 7908][Wall Clock 358.369393888s] Trained 120 records in 0.047758845 seconds. Throughput is 2512.6235 records/second. Loss is 0.20505199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003873866893933524. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 49080/60000][Iteration 7909][Wall Clock 358.416168209s] Trained 120 records in 0.046774321 seconds. Throughput is 2565.5103 records/second. Loss is 0.19491294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038735667802912922. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 49200/60000][Iteration 7910][Wall Clock 358.457292813s] Trained 120 records in 0.041124604 seconds. Throughput is 2917.9612 records/second. Loss is 0.11922833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003873266713145867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:04 INFO  DistriOptimizer$:406 - [Epoch 16 49320/60000][Iteration 7911][Wall Clock 358.497438359s] Trained 120 records in 0.040145546 seconds. Throughput is 2989.1235 records/second. Loss is 0.17590941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038729666924864447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 49440/60000][Iteration 7912][Wall Clock 358.53706389s] Trained 120 records in 0.039625531 seconds. Throughput is 3028.3508 records/second. Loss is 0.1978865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038726667183022227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 49560/60000][Iteration 7913][Wall Clock 358.580065218s] Trained 120 records in 0.043001328 seconds. Throughput is 2790.6116 records/second. Loss is 0.1510748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003872366790582404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 49680/60000][Iteration 7914][Wall Clock 358.62692811s] Trained 120 records in 0.046862892 seconds. Throughput is 2560.6614 records/second. Loss is 0.101648554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038720669093161926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 49800/60000][Iteration 7915][Wall Clock 358.669996983s] Trained 120 records in 0.043068873 seconds. Throughput is 2786.2349 records/second. Loss is 0.1983053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003871767074492799. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 49920/60000][Iteration 7916][Wall Clock 358.71295381s] Trained 120 records in 0.042956827 seconds. Throughput is 2793.5024 records/second. Loss is 0.13297214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038714672861014324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50040/60000][Iteration 7917][Wall Clock 358.75390497s] Trained 120 records in 0.04095116 seconds. Throughput is 2930.32 records/second. Loss is 0.09925616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00387116754413131. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50160/60000][Iteration 7918][Wall Clock 358.79396679s] Trained 120 records in 0.04006182 seconds. Throughput is 2995.3706 records/second. Loss is 0.13944297. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038708678485716496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50280/60000][Iteration 7919][Wall Clock 358.834299923s] Trained 120 records in 0.040333133 seconds. Throughput is 2975.2214 records/second. Loss is 0.18815632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038705681994116734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50400/60000][Iteration 7920][Wall Clock 358.874424465s] Trained 120 records in 0.040124542 seconds. Throughput is 2990.6882 records/second. Loss is 0.29928175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038702685966406068. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50520/60000][Iteration 7921][Wall Clock 358.914518932s] Trained 120 records in 0.040094467 seconds. Throughput is 2992.9316 records/second. Loss is 0.100767635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003869969040247678. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50640/60000][Iteration 7922][Wall Clock 358.957576076s] Trained 120 records in 0.043057144 seconds. Throughput is 2786.994 records/second. Loss is 0.19602251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003869669530222119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50760/60000][Iteration 7923][Wall Clock 359.01492896s] Trained 120 records in 0.057352884 seconds. Throughput is 2092.3098 records/second. Loss is 0.17787786. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038693700665531653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 50880/60000][Iteration 7924][Wall Clock 359.058810037s] Trained 120 records in 0.043881077 seconds. Throughput is 2734.664 records/second. Loss is 0.19243708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003869070649230055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51000/60000][Iteration 7925][Wall Clock 359.100153838s] Trained 120 records in 0.041343801 seconds. Throughput is 2902.4907 records/second. Loss is 0.17734405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038687712782420306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51120/60000][Iteration 7926][Wall Clock 359.141747266s] Trained 120 records in 0.041593428 seconds. Throughput is 2885.071 records/second. Loss is 0.10156333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038684719535783366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51240/60000][Iteration 7927][Wall Clock 359.181754316s] Trained 120 records in 0.04000705 seconds. Throughput is 2999.4712 records/second. Loss is 0.18173972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003868172675228222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51360/60000][Iteration 7928][Wall Clock 359.221686996s] Trained 120 records in 0.03993268 seconds. Throughput is 3005.0576 records/second. Loss is 0.2739988. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038678734431809394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51480/60000][Iteration 7929][Wall Clock 359.262082205s] Trained 120 records in 0.040395209 seconds. Throughput is 2970.6494 records/second. Loss is 0.16282725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003867574257425742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51600/60000][Iteration 7930][Wall Clock 359.301974283s] Trained 120 records in 0.039892078 seconds. Throughput is 3008.1162 records/second. Loss is 0.17078528. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003867275117951891. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51720/60000][Iteration 7931][Wall Clock 359.342045173s] Trained 120 records in 0.04007089 seconds. Throughput is 2994.6926 records/second. Loss is 0.13258894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003866976024748646. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51840/60000][Iteration 7932][Wall Clock 359.382538559s] Trained 120 records in 0.040493386 seconds. Throughput is 2963.4468 records/second. Loss is 0.3419229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038666769778052746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 51960/60000][Iteration 7933][Wall Clock 359.427335528s] Trained 120 records in 0.044796969 seconds. Throughput is 2678.7527 records/second. Loss is 0.17125008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003866377977111042. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 52080/60000][Iteration 7934][Wall Clock 359.467617357s] Trained 120 records in 0.040281829 seconds. Throughput is 2979.0107 records/second. Loss is 0.11341357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038660790226552233. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:05 INFO  DistriOptimizer$:406 - [Epoch 16 52200/60000][Iteration 7935][Wall Clock 359.518873968s] Trained 120 records in 0.051256611 seconds. Throughput is 2341.1614 records/second. Loss is 0.13311192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003865780114427091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 52320/60000][Iteration 7936][Wall Clock 359.563041175s] Trained 120 records in 0.044167207 seconds. Throughput is 2716.948 records/second. Loss is 0.32061735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038654812524159263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 52440/60000][Iteration 7937][Wall Clock 359.604763224s] Trained 120 records in 0.041722049 seconds. Throughput is 2876.177 records/second. Loss is 0.23021913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038651824366110078. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 52560/60000][Iteration 7938][Wall Clock 359.645583383s] Trained 120 records in 0.040820159 seconds. Throughput is 2939.7239 records/second. Loss is 0.14426383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003864883667001623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 52680/60000][Iteration 7939][Wall Clock 359.685683333s] Trained 120 records in 0.04009995 seconds. Throughput is 2992.5225 records/second. Loss is 0.14837809. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038645849435770597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 52800/60000][Iteration 7940][Wall Clock 359.725844163s] Trained 120 records in 0.04016083 seconds. Throughput is 2987.986 records/second. Loss is 0.23118943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038642862663266094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 52920/60000][Iteration 7941][Wall Clock 359.766055344s] Trained 120 records in 0.040211181 seconds. Throughput is 2984.2446 records/second. Loss is 0.26157323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038639876352395673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53040/60000][Iteration 7942][Wall Clock 359.807159372s] Trained 120 records in 0.041104028 seconds. Throughput is 2919.422 records/second. Loss is 0.12966429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038636890503052313. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53160/60000][Iteration 7943][Wall Clock 359.848112438s] Trained 120 records in 0.040953066 seconds. Throughput is 2930.1836 records/second. Loss is 0.16888009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038633905115129036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53280/60000][Iteration 7944][Wall Clock 359.888968898s] Trained 120 records in 0.04085646 seconds. Throughput is 2937.112 records/second. Loss is 0.20936528. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003863092018851889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53400/60000][Iteration 7945][Wall Clock 359.930187573s] Trained 120 records in 0.041218675 seconds. Throughput is 2911.3018 records/second. Loss is 0.1002552. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038627935723114957. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53520/60000][Iteration 7946][Wall Clock 359.970902785s] Trained 120 records in 0.040715212 seconds. Throughput is 2947.3015 records/second. Loss is 0.24723884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003862495171881035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53640/60000][Iteration 7947][Wall Clock 360.021377626s] Trained 120 records in 0.050474841 seconds. Throughput is 2377.422 records/second. Loss is 0.13116813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038621968175498226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53760/60000][Iteration 7948][Wall Clock 360.068468571s] Trained 120 records in 0.047090945 seconds. Throughput is 2548.2607 records/second. Loss is 0.13682765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003861898509307175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 53880/60000][Iteration 7949][Wall Clock 360.115297632s] Trained 120 records in 0.046829061 seconds. Throughput is 2562.5115 records/second. Loss is 0.122708835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003861600247142416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54000/60000][Iteration 7950][Wall Clock 360.155895916s] Trained 120 records in 0.040598284 seconds. Throughput is 2955.79 records/second. Loss is 0.13917276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003861302031044868. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54120/60000][Iteration 7951][Wall Clock 360.199635028s] Trained 120 records in 0.043739112 seconds. Throughput is 2743.54 records/second. Loss is 0.15665399. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003861003861003861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54240/60000][Iteration 7952][Wall Clock 360.241170158s] Trained 120 records in 0.04153513 seconds. Throughput is 2889.1206 records/second. Loss is 0.17121056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038607057370087247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54360/60000][Iteration 7953][Wall Clock 360.282003239s] Trained 120 records in 0.040833081 seconds. Throughput is 2938.7937 records/second. Loss is 0.14677685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038604076590487957. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54480/60000][Iteration 7954][Wall Clock 360.321549585s] Trained 120 records in 0.039546346 seconds. Throughput is 3034.4146 records/second. Loss is 0.11775632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00386010962711341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54600/60000][Iteration 7955][Wall Clock 360.361528826s] Trained 120 records in 0.039979241 seconds. Throughput is 3001.5576 records/second. Loss is 0.15846378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00385981164119191. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54720/60000][Iteration 7956][Wall Clock 360.401945716s] Trained 120 records in 0.04041689 seconds. Throughput is 2969.056 records/second. Loss is 0.18797101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003859513701273639. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54840/60000][Iteration 7957][Wall Clock 360.442513762s] Trained 120 records in 0.040568046 seconds. Throughput is 2957.9932 records/second. Loss is 0.16371769. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003859215807347947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 54960/60000][Iteration 7958][Wall Clock 360.482528606s] Trained 120 records in 0.040014844 seconds. Throughput is 2998.887 records/second. Loss is 0.23799767. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038589179594041827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:06 INFO  DistriOptimizer$:406 - [Epoch 16 55080/60000][Iteration 7959][Wall Clock 360.522815212s] Trained 120 records in 0.040286606 seconds. Throughput is 2978.6577 records/second. Loss is 0.16902487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038586201574317023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 55200/60000][Iteration 7960][Wall Clock 360.562921534s] Trained 120 records in 0.040106322 seconds. Throughput is 2992.0469 records/second. Loss is 0.12998317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038583224014198626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 55320/60000][Iteration 7961][Wall Clock 360.602852072s] Trained 120 records in 0.039930538 seconds. Throughput is 3005.2188 records/second. Loss is 0.1311698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038580246913580245. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 55440/60000][Iteration 7962][Wall Clock 360.655866004s] Trained 120 records in 0.053013932 seconds. Throughput is 2263.556 records/second. Loss is 0.20662619. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003857727027235553. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 55560/60000][Iteration 7963][Wall Clock 360.697646998s] Trained 120 records in 0.041780994 seconds. Throughput is 2872.1194 records/second. Loss is 0.16989978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038574294090418146. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 55680/60000][Iteration 7964][Wall Clock 360.737481299s] Trained 120 records in 0.039834301 seconds. Throughput is 3012.479 records/second. Loss is 0.17820075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003857131836766181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 55800/60000][Iteration 7965][Wall Clock 360.77790168s] Trained 120 records in 0.040420381 seconds. Throughput is 2968.7996 records/second. Loss is 0.23940477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038568343103980254. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 55920/60000][Iteration 7966][Wall Clock 360.818292132s] Trained 120 records in 0.040390452 seconds. Throughput is 2970.9993 records/second. Loss is 0.12197255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003856536829926726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56040/60000][Iteration 7967][Wall Clock 360.858059386s] Trained 120 records in 0.039767254 seconds. Throughput is 3017.558 records/second. Loss is 0.15574779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003856239395341662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56160/60000][Iteration 7968][Wall Clock 360.89778878s] Trained 120 records in 0.039729394 seconds. Throughput is 3020.4336 records/second. Loss is 0.17290205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038559420066322206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56280/60000][Iteration 7969][Wall Clock 360.938295785s] Trained 120 records in 0.040507005 seconds. Throughput is 2962.4507 records/second. Loss is 0.18721646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003855644663787785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56400/60000][Iteration 7970][Wall Clock 360.98220105s] Trained 120 records in 0.043905265 seconds. Throughput is 2733.1575 records/second. Loss is 0.11217726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038553473667977487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56520/60000][Iteration 7971][Wall Clock 361.023372338s] Trained 120 records in 0.041171288 seconds. Throughput is 2914.6526 records/second. Loss is 0.1296543. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003855050115651503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56640/60000][Iteration 7972][Wall Clock 361.066680365s] Trained 120 records in 0.043308027 seconds. Throughput is 2770.8489 records/second. Loss is 0.16438754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038547529103384478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56760/60000][Iteration 7973][Wall Clock 361.115470437s] Trained 120 records in 0.048790072 seconds. Throughput is 2459.5168 records/second. Loss is 0.12309265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00385445575084798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 56880/60000][Iteration 7974][Wall Clock 361.160161488s] Trained 120 records in 0.044691051 seconds. Throughput is 2685.1013 records/second. Loss is 0.26404005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038541586371695063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57000/60000][Iteration 7975][Wall Clock 361.201122257s] Trained 120 records in 0.040960769 seconds. Throughput is 2929.6323 records/second. Loss is 0.2743646. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038538615692924306. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57120/60000][Iteration 7976][Wall Clock 361.241689821s] Trained 120 records in 0.040567564 seconds. Throughput is 2958.028 records/second. Loss is 0.17012669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003853564547206166. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57240/60000][Iteration 7977][Wall Clock 361.282759577s] Trained 120 records in 0.041069756 seconds. Throughput is 2921.8582 records/second. Loss is 0.20412563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038532675709001232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57360/60000][Iteration 7978][Wall Clock 361.323513017s] Trained 120 records in 0.04075344 seconds. Throughput is 2944.5369 records/second. Loss is 0.13480592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00385297064036372. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57480/60000][Iteration 7979][Wall Clock 361.364198096s] Trained 120 records in 0.040685079 seconds. Throughput is 2949.4841 records/second. Loss is 0.183781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003852673755586377. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57600/60000][Iteration 7980][Wall Clock 361.404881421s] Trained 120 records in 0.040683325 seconds. Throughput is 2949.6113 records/second. Loss is 0.16936812. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003852376916557516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57720/60000][Iteration 7981][Wall Clock 361.446140383s] Trained 120 records in 0.041258962 seconds. Throughput is 2908.459 records/second. Loss is 0.15163971. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003852080123266564. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:07 INFO  DistriOptimizer$:406 - [Epoch 16 57840/60000][Iteration 7982][Wall Clock 361.486785782s] Trained 120 records in 0.040645399 seconds. Throughput is 2952.3638 records/second. Loss is 0.15152124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038517833757029506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 57960/60000][Iteration 7983][Wall Clock 361.527346804s] Trained 120 records in 0.040561022 seconds. Throughput is 2958.5054 records/second. Loss is 0.18453802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038514866738561084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58080/60000][Iteration 7984][Wall Clock 361.568236709s] Trained 120 records in 0.040889905 seconds. Throughput is 2934.7097 records/second. Loss is 0.23490328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003851190017715474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58200/60000][Iteration 7985][Wall Clock 361.60909595s] Trained 120 records in 0.040859241 seconds. Throughput is 2936.912 records/second. Loss is 0.1785048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038508934072704866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58320/60000][Iteration 7986][Wall Clock 361.649355995s] Trained 120 records in 0.040260045 seconds. Throughput is 2980.6226 records/second. Loss is 0.1189532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038505968425105895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58440/60000][Iteration 7987][Wall Clock 361.690651752s] Trained 120 records in 0.041295757 seconds. Throughput is 2905.8677 records/second. Loss is 0.19253461. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003850300323425227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58560/60000][Iteration 7988][Wall Clock 361.731261246s] Trained 120 records in 0.040609494 seconds. Throughput is 2954.974 records/second. Loss is 0.19317916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038500038500038497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58680/60000][Iteration 7989][Wall Clock 361.788393605s] Trained 120 records in 0.057132359 seconds. Throughput is 2100.3857 records/second. Loss is 0.19221026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038497074222359103. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58800/60000][Iteration 7990][Wall Clock 361.830859312s] Trained 120 records in 0.042465707 seconds. Throughput is 2825.8096 records/second. Loss is 0.09530242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038494110401108626. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 58920/60000][Iteration 7991][Wall Clock 361.871138154s] Trained 120 records in 0.040278842 seconds. Throughput is 2979.2317 records/second. Loss is 0.2198331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003849114703618168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59040/60000][Iteration 7992][Wall Clock 361.911147486s] Trained 120 records in 0.040009332 seconds. Throughput is 2999.3003 records/second. Loss is 0.15309006. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038488184127472864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59160/60000][Iteration 7993][Wall Clock 361.951763442s] Trained 120 records in 0.040615956 seconds. Throughput is 2954.504 records/second. Loss is 0.16436973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038485221674876852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59280/60000][Iteration 7994][Wall Clock 361.992102379s] Trained 120 records in 0.040338937 seconds. Throughput is 2974.7932 records/second. Loss is 0.20298018. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003848225967828831. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59400/60000][Iteration 7995][Wall Clock 362.032638558s] Trained 120 records in 0.040536179 seconds. Throughput is 2960.3184 records/second. Loss is 0.17102356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038479298137601976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59520/60000][Iteration 7996][Wall Clock 362.072987334s] Trained 120 records in 0.040348776 seconds. Throughput is 2974.0679 records/second. Loss is 0.22964929. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003847633705271258. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59640/60000][Iteration 7997][Wall Clock 362.123423568s] Trained 120 records in 0.050436234 seconds. Throughput is 2379.242 records/second. Loss is 0.24344172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038473376423514925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59760/60000][Iteration 7998][Wall Clock 362.171237601s] Trained 120 records in 0.047814033 seconds. Throughput is 2509.7234 records/second. Loss is 0.1583664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003847041624990382. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 59880/60000][Iteration 7999][Wall Clock 362.218219084s] Trained 120 records in 0.046981483 seconds. Throughput is 2554.1978 records/second. Loss is 0.14886436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003846745653177412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:406 - [Epoch 16 60000/60000][Iteration 8000][Wall Clock 362.257974007s] Trained 120 records in 0.039754923 seconds. Throughput is 3018.4941 records/second. Loss is 0.23428227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038464497269020694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:08 INFO  DistriOptimizer$:451 - [Epoch 16 60000/60000][Iteration 8000][Wall Clock 362.257974007s] Epoch finished. Wall clock time is 363055.411101 ms
2019-10-23 15:59:08 INFO  DistriOptimizer$:111 - [Epoch 16 60000/60000][Iteration 8000][Wall Clock 362.257974007s] Validate model...
2019-10-23 15:59:09 INFO  DistriOptimizer$:177 - [Epoch 16 60000/60000][Iteration 8000][Wall Clock 362.257974007s] validate model throughput is 14984.397 records/second
2019-10-23 15:59:09 INFO  DistriOptimizer$:180 - [Epoch 16 60000/60000][Iteration 8000][Wall Clock 362.257974007s] Top1Accuracy is Accuracy(correct: 9544, count: 10000, accuracy: 0.9544)
2019-10-23 15:59:09 INFO  DistriOptimizer$:220 - [Wall Clock 363.055411101s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:59:09 INFO  DistriOptimizer$:225 - [Wall Clock 363.055411101s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 120/60000][Iteration 8001][Wall Clock 363.1014521s] Trained 120 records in 0.046040999 seconds. Throughput is 2606.3726 records/second. Loss is 0.16478492. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003846153846153846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 240/60000][Iteration 8002][Wall Clock 363.142223668s] Trained 120 records in 0.040771568 seconds. Throughput is 2943.2275 records/second. Loss is 0.21402083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003845858010922237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 360/60000][Iteration 8003][Wall Clock 363.182986473s] Trained 120 records in 0.040762805 seconds. Throughput is 2943.8604 records/second. Loss is 0.2270515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003845562221196739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 480/60000][Iteration 8004][Wall Clock 363.223261928s] Trained 120 records in 0.040275455 seconds. Throughput is 2979.4822 records/second. Loss is 0.12033224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003845266476966854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 600/60000][Iteration 8005][Wall Clock 363.263094237s] Trained 120 records in 0.039832309 seconds. Throughput is 3012.63 records/second. Loss is 0.18920489. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003844970778222086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 720/60000][Iteration 8006][Wall Clock 363.307072932s] Trained 120 records in 0.043978695 seconds. Throughput is 2728.594 records/second. Loss is 0.13980158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038446751249519417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 840/60000][Iteration 8007][Wall Clock 363.347360418s] Trained 120 records in 0.040287486 seconds. Throughput is 2978.5923 records/second. Loss is 0.17965235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003844379517145932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 960/60000][Iteration 8008][Wall Clock 363.387680507s] Trained 120 records in 0.040320089 seconds. Throughput is 2976.184 records/second. Loss is 0.17037268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003844083954793573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 1080/60000][Iteration 8009][Wall Clock 363.427847335s] Trained 120 records in 0.040166828 seconds. Throughput is 2987.5398 records/second. Loss is 0.19304469. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038437884378843784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 1200/60000][Iteration 8010][Wall Clock 363.467871037s] Trained 120 records in 0.040023702 seconds. Throughput is 2998.2234 records/second. Loss is 0.13819663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038434929664078717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 1320/60000][Iteration 8011][Wall Clock 363.508593287s] Trained 120 records in 0.04072225 seconds. Throughput is 2946.792 records/second. Loss is 0.18519768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003843197540353574. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 1440/60000][Iteration 8012][Wall Clock 363.549009298s] Trained 120 records in 0.040416011 seconds. Throughput is 2969.1204 records/second. Loss is 0.17477576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003842902159711014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:09 INFO  DistriOptimizer$:406 - [Epoch 17 1560/60000][Iteration 8013][Wall Clock 363.588603973s] Trained 120 records in 0.039594675 seconds. Throughput is 3030.7104 records/second. Loss is 0.19850305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00384260682446972. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 1680/60000][Iteration 8014][Wall Clock 363.639100387s] Trained 120 records in 0.050496414 seconds. Throughput is 2376.4062 records/second. Loss is 0.10505741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003842311534619227. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 1800/60000][Iteration 8015][Wall Clock 363.686511638s] Trained 120 records in 0.047411251 seconds. Throughput is 2531.0447 records/second. Loss is 0.21248741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00384201629014907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 1920/60000][Iteration 8016][Wall Clock 363.729034789s] Trained 120 records in 0.042523151 seconds. Throughput is 2821.9922 records/second. Loss is 0.13262282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038417210910487902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2040/60000][Iteration 8017][Wall Clock 363.769587804s] Trained 120 records in 0.040553015 seconds. Throughput is 2959.0896 records/second. Loss is 0.18338785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038414259373079286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2160/60000][Iteration 8018][Wall Clock 363.810045027s] Trained 120 records in 0.040457223 seconds. Throughput is 2966.096 records/second. Loss is 0.1698018. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003841130828916033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2280/60000][Iteration 8019][Wall Clock 363.850125871s] Trained 120 records in 0.040080844 seconds. Throughput is 2993.9487 records/second. Loss is 0.13069747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038408357658626514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2400/60000][Iteration 8020][Wall Clock 363.890457106s] Trained 120 records in 0.040331235 seconds. Throughput is 2975.3616 records/second. Loss is 0.1488544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038405407481373376. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2520/60000][Iteration 8021][Wall Clock 363.931897035s] Trained 120 records in 0.041439929 seconds. Throughput is 2895.7578 records/second. Loss is 0.19092442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038402457757296467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2640/60000][Iteration 8022][Wall Clock 363.97362369s] Trained 120 records in 0.041726655 seconds. Throughput is 2875.8594 records/second. Loss is 0.14519559. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038399508486291374. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2760/60000][Iteration 8023][Wall Clock 364.0243803s] Trained 120 records in 0.05075661 seconds. Throughput is 2364.224 records/second. Loss is 0.104004875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038396559668253723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 2880/60000][Iteration 8024][Wall Clock 364.065068418s] Trained 120 records in 0.040688118 seconds. Throughput is 2949.264 records/second. Loss is 0.13782425. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038393611303079167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3000/60000][Iteration 8025][Wall Clock 364.109047319s] Trained 120 records in 0.043978901 seconds. Throughput is 2728.5813 records/second. Loss is 0.20971337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003839066339066339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3120/60000][Iteration 8026][Wall Clock 364.149415178s] Trained 120 records in 0.040367859 seconds. Throughput is 2972.6619 records/second. Loss is 0.25764754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038387715930902114. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3240/60000][Iteration 8027][Wall Clock 364.18976826s] Trained 120 records in 0.040353082 seconds. Throughput is 2973.7505 records/second. Loss is 0.2384601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038384768923691082. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3360/60000][Iteration 8028][Wall Clock 364.229806236s] Trained 120 records in 0.040037976 seconds. Throughput is 2997.1545 records/second. Loss is 0.10954582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003838182236892607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3480/60000][Iteration 8029][Wall Clock 364.270272156s] Trained 120 records in 0.04046592 seconds. Throughput is 2965.4583 records/second. Loss is 0.29256323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003837887626650292. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3600/60000][Iteration 8030][Wall Clock 364.311487504s] Trained 120 records in 0.041215348 seconds. Throughput is 2911.5366 records/second. Loss is 0.16931601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038375930616317442. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3720/60000][Iteration 8031][Wall Clock 364.351992795s] Trained 120 records in 0.040505291 seconds. Throughput is 2962.576 records/second. Loss is 0.10622743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038372985418265544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3840/60000][Iteration 8032][Wall Clock 364.392250596s] Trained 120 records in 0.040257801 seconds. Throughput is 2980.7888 records/second. Loss is 0.2585152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003837004067224311. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 3960/60000][Iteration 8033][Wall Clock 364.432225926s] Trained 120 records in 0.03997533 seconds. Throughput is 3001.8513 records/second. Loss is 0.156118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038367096378146104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 4080/60000][Iteration 8034][Wall Clock 364.473199593s] Trained 120 records in 0.040973667 seconds. Throughput is 2928.7102 records/second. Loss is 0.17503431. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038364152535870478. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 4200/60000][Iteration 8035][Wall Clock 364.514508157s] Trained 120 records in 0.041308564 seconds. Throughput is 2904.9668 records/second. Loss is 0.17931966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038361209145312265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 4320/60000][Iteration 8036][Wall Clock 364.555404602s] Trained 120 records in 0.040896445 seconds. Throughput is 2934.2402 records/second. Loss is 0.10663808. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003835826620636747. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:10 INFO  DistriOptimizer$:406 - [Epoch 17 4440/60000][Iteration 8037][Wall Clock 364.595474875s] Trained 120 records in 0.040070273 seconds. Throughput is 2994.7388 records/second. Loss is 0.15514353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038355323718932185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 4560/60000][Iteration 8038][Wall Clock 364.635842745s] Trained 120 records in 0.04036787 seconds. Throughput is 2972.6611 records/second. Loss is 0.20885046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038352381682902506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 4680/60000][Iteration 8039][Wall Clock 364.675883366s] Trained 120 records in 0.040040621 seconds. Throughput is 2996.9565 records/second. Loss is 0.10793727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038349440098174566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 4800/60000][Iteration 8040][Wall Clock 364.715644228s] Trained 120 records in 0.039760862 seconds. Throughput is 3018.0432 records/second. Loss is 0.10650536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003834649896464453. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 4920/60000][Iteration 8041][Wall Clock 364.765313931s] Trained 120 records in 0.049669703 seconds. Throughput is 2415.9597 records/second. Loss is 0.29894075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003834355828220859. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5040/60000][Iteration 8042][Wall Clock 364.812911215s] Trained 120 records in 0.047597284 seconds. Throughput is 2521.152 records/second. Loss is 0.18772991. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003834061805076298. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5160/60000][Iteration 8043][Wall Clock 364.857912009s] Trained 120 records in 0.045000794 seconds. Throughput is 2666.6196 records/second. Loss is 0.17388685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003833767827020396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5280/60000][Iteration 8044][Wall Clock 364.89846511s] Trained 120 records in 0.040553101 seconds. Throughput is 2959.0833 records/second. Loss is 0.083875984. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038334738940427816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5400/60000][Iteration 8045][Wall Clock 364.938966847s] Trained 120 records in 0.040501737 seconds. Throughput is 2962.836 records/second. Loss is 0.1729816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038331800061330882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5520/60000][Iteration 8046][Wall Clock 364.980225689s] Trained 120 records in 0.041258842 seconds. Throughput is 2908.4675 records/second. Loss is 0.25939417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038328861632809506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5640/60000][Iteration 8047][Wall Clock 365.022256504s] Trained 120 records in 0.042030815 seconds. Throughput is 2855.048 records/second. Loss is 0.2095546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038325923654760076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5760/60000][Iteration 8048][Wall Clock 365.063105425s] Trained 120 records in 0.040848921 seconds. Throughput is 2937.654 records/second. Loss is 0.18783544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038322986127079023. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 5880/60000][Iteration 8049][Wall Clock 365.110635156s] Trained 120 records in 0.047529731 seconds. Throughput is 2524.7356 records/second. Loss is 0.14684144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003832004904966278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6000/60000][Iteration 8050][Wall Clock 365.154349523s] Trained 120 records in 0.043714367 seconds. Throughput is 2745.093 records/second. Loss is 0.18032683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003831711242240785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6120/60000][Iteration 8051][Wall Clock 365.195614863s] Trained 120 records in 0.04126534 seconds. Throughput is 2908.0095 records/second. Loss is 0.26109108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038314176245210726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6240/60000][Iteration 8052][Wall Clock 365.235761154s] Trained 120 records in 0.040146291 seconds. Throughput is 2989.068 records/second. Loss is 0.13860449. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038311240517967973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6360/60000][Iteration 8053][Wall Clock 365.277893422s] Trained 120 records in 0.042132268 seconds. Throughput is 2848.173 records/second. Loss is 0.1372225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038308305240576154. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6480/60000][Iteration 8054][Wall Clock 365.318885663s] Trained 120 records in 0.040992241 seconds. Throughput is 2927.3833 records/second. Loss is 0.32131004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038305370412931895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6600/60000][Iteration 8055][Wall Clock 365.359854974s] Trained 120 records in 0.040969311 seconds. Throughput is 2929.0215 records/second. Loss is 0.19644633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038302436034931817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6720/60000][Iteration 8056][Wall Clock 365.400147124s] Trained 120 records in 0.04029215 seconds. Throughput is 2978.2476 records/second. Loss is 0.104439616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003829950210647262. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6840/60000][Iteration 8057][Wall Clock 365.439543794s] Trained 120 records in 0.03939667 seconds. Throughput is 3045.9426 records/second. Loss is 0.16532053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003829656862745098. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 6960/60000][Iteration 8058][Wall Clock 365.480214198s] Trained 120 records in 0.040670404 seconds. Throughput is 2950.5486 records/second. Loss is 0.16700204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003829363559776365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 7080/60000][Iteration 8059][Wall Clock 365.52177402s] Trained 120 records in 0.041559822 seconds. Throughput is 2887.404 records/second. Loss is 0.16279024. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038290703017307397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:11 INFO  DistriOptimizer$:406 - [Epoch 17 7200/60000][Iteration 8060][Wall Clock 365.562322143s] Trained 120 records in 0.040548123 seconds. Throughput is 2959.4465 records/second. Loss is 0.20438229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003828777088597902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 7320/60000][Iteration 8061][Wall Clock 365.602985666s] Trained 120 records in 0.040663523 seconds. Throughput is 2951.0479 records/second. Loss is 0.1268362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038284839203675345. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 7440/60000][Iteration 8062][Wall Clock 365.646140259s] Trained 120 records in 0.043154593 seconds. Throughput is 2780.7004 records/second. Loss is 0.20687284. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003828190797029324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 7560/60000][Iteration 8063][Wall Clock 365.686481132s] Trained 120 records in 0.040340873 seconds. Throughput is 2974.6504 records/second. Loss is 0.15324952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038278977185729596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 7680/60000][Iteration 8064][Wall Clock 365.726778982s] Trained 120 records in 0.04029785 seconds. Throughput is 2977.8262 records/second. Loss is 0.16716406. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038276046849881344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 7800/60000][Iteration 8065][Wall Clock 365.767261613s] Trained 120 records in 0.040482631 seconds. Throughput is 2964.2341 records/second. Loss is 0.111637615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038273116962645438. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 7920/60000][Iteration 8066][Wall Clock 365.807377105s] Trained 120 records in 0.040115492 seconds. Throughput is 2991.363 records/second. Loss is 0.13452438. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003827018752391887. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8040/60000][Iteration 8067][Wall Clock 365.847104436s] Trained 120 records in 0.039727331 seconds. Throughput is 3020.5906 records/second. Loss is 0.18104272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038267258533598654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8160/60000][Iteration 8068][Wall Clock 365.901394762s] Trained 120 records in 0.054290326 seconds. Throughput is 2210.3386 records/second. Loss is 0.17641574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038264329991581844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8280/60000][Iteration 8069][Wall Clock 365.943982945s] Trained 120 records in 0.042588183 seconds. Throughput is 2817.683 records/second. Loss is 0.18352292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038261401897765534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8400/60000][Iteration 8070][Wall Clock 365.984526969s] Trained 120 records in 0.040544024 seconds. Throughput is 2959.7456 records/second. Loss is 0.10947631. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038258474252046825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8520/60000][Iteration 8071][Wall Clock 366.025553279s] Trained 120 records in 0.04102631 seconds. Throughput is 2924.9524 records/second. Loss is 0.15249887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038255547054322878. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8640/60000][Iteration 8072][Wall Clock 366.066621652s] Trained 120 records in 0.041068373 seconds. Throughput is 2921.9565 records/second. Loss is 0.13683847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038252620304490854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8760/60000][Iteration 8073][Wall Clock 366.107454618s] Trained 120 records in 0.040832966 seconds. Throughput is 2938.802 records/second. Loss is 0.13431285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038249694002447984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 8880/60000][Iteration 8074][Wall Clock 366.147604505s] Trained 120 records in 0.040149887 seconds. Throughput is 2988.8005 records/second. Loss is 0.17337307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038246768148091485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9000/60000][Iteration 8075][Wall Clock 366.187756037s] Trained 120 records in 0.040151532 seconds. Throughput is 2988.678 records/second. Loss is 0.1451838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038243842741318653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9120/60000][Iteration 8076][Wall Clock 366.237572037s] Trained 120 records in 0.049816 seconds. Throughput is 2408.8645 records/second. Loss is 0.15753396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038240917782026767. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9240/60000][Iteration 8077][Wall Clock 366.282001771s] Trained 120 records in 0.044429734 seconds. Throughput is 2700.894 records/second. Loss is 0.19207294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038237993270113188. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9360/60000][Iteration 8078][Wall Clock 366.322750482s] Trained 120 records in 0.040748711 seconds. Throughput is 2944.8784 records/second. Loss is 0.16896683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003823506920547526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9480/60000][Iteration 8079][Wall Clock 366.364484314s] Trained 120 records in 0.041733832 seconds. Throughput is 2875.365 records/second. Loss is 0.16678597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00382321455880104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9600/60000][Iteration 8080][Wall Clock 366.405944266s] Trained 120 records in 0.041459952 seconds. Throughput is 2894.3594 records/second. Loss is 0.23879912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038229222417616024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9720/60000][Iteration 8081][Wall Clock 366.44993976s] Trained 120 records in 0.043995494 seconds. Throughput is 2727.5522 records/second. Loss is 0.21770772. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00382262996941896. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9840/60000][Iteration 8082][Wall Clock 366.490240826s] Trained 120 records in 0.040301066 seconds. Throughput is 2977.5886 records/second. Loss is 0.2529143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003822337741762862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 9960/60000][Iteration 8083][Wall Clock 366.529956756s] Trained 120 records in 0.03971593 seconds. Throughput is 3021.4575 records/second. Loss is 0.14095299. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038220455587830607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:12 INFO  DistriOptimizer$:406 - [Epoch 17 10080/60000][Iteration 8084][Wall Clock 366.5695227s] Trained 120 records in 0.039565944 seconds. Throughput is 3032.9114 records/second. Loss is 0.20135318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038217534204693115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 10200/60000][Iteration 8085][Wall Clock 366.610211647s] Trained 120 records in 0.040688947 seconds. Throughput is 2949.2039 records/second. Loss is 0.2505985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038214613268113726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 10320/60000][Iteration 8086][Wall Clock 366.650804437s] Trained 120 records in 0.04059279 seconds. Throughput is 2956.19 records/second. Loss is 0.1712389. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038211692777990066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 10440/60000][Iteration 8087][Wall Clock 366.691334659s] Trained 120 records in 0.040530222 seconds. Throughput is 2960.7534 records/second. Loss is 0.16012545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038208772734219776. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 10560/60000][Iteration 8088][Wall Clock 366.73108493s] Trained 120 records in 0.039750271 seconds. Throughput is 3018.8474 records/second. Loss is 0.12654497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038205853136700544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 10680/60000][Iteration 8089][Wall Clock 366.771496197s] Trained 120 records in 0.040411267 seconds. Throughput is 2969.4688 records/second. Loss is 0.1676852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038202933985330067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 10800/60000][Iteration 8090][Wall Clock 366.81205575s] Trained 120 records in 0.040559553 seconds. Throughput is 2958.6125 records/second. Loss is 0.16219097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038200015280006115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 10920/60000][Iteration 8091][Wall Clock 366.852854751s] Trained 120 records in 0.040799001 seconds. Throughput is 2941.2485 records/second. Loss is 0.08514083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003819709702062643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11040/60000][Iteration 8092][Wall Clock 366.8937842s] Trained 120 records in 0.040929449 seconds. Throughput is 2931.8745 records/second. Loss is 0.21696354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038194179207088844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11160/60000][Iteration 8093][Wall Clock 366.934280917s] Trained 120 records in 0.040496717 seconds. Throughput is 2963.2031 records/second. Loss is 0.1419862. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038191261839291167. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11280/60000][Iteration 8094][Wall Clock 366.982622367s] Trained 120 records in 0.04834145 seconds. Throughput is 2482.3418 records/second. Loss is 0.28099033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038188344917131295. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11400/60000][Iteration 8095][Wall Clock 367.030701604s] Trained 120 records in 0.048079237 seconds. Throughput is 2495.88 records/second. Loss is 0.20303743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00381854284405071. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11520/60000][Iteration 8096][Wall Clock 367.074923344s] Trained 120 records in 0.04422174 seconds. Throughput is 2713.5974 records/second. Loss is 0.07110584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003818251240931654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11640/60000][Iteration 8097][Wall Clock 367.116470498s] Trained 120 records in 0.041547154 seconds. Throughput is 2888.2844 records/second. Loss is 0.15492721. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038179596823457542. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11760/60000][Iteration 8098][Wall Clock 367.156643917s] Trained 120 records in 0.040173419 seconds. Throughput is 2987.0498 records/second. Loss is 0.18871011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003817668168282813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 11880/60000][Iteration 8099][Wall Clock 367.197412945s] Trained 120 records in 0.040769028 seconds. Throughput is 2943.4106 records/second. Loss is 0.19114451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038173766987326307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12000/60000][Iteration 8100][Wall Clock 367.241426085s] Trained 120 records in 0.04401314 seconds. Throughput is 2726.4585 records/second. Loss is 0.17804174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003817085273685014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12120/60000][Iteration 8101][Wall Clock 367.282997807s] Trained 120 records in 0.041571722 seconds. Throughput is 2886.5776 records/second. Loss is 0.12965783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003816793893129771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12240/60000][Iteration 8102][Wall Clock 367.33100679s] Trained 120 records in 0.048008983 seconds. Throughput is 2499.5322 records/second. Loss is 0.23692162. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003816502557056713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12360/60000][Iteration 8103][Wall Clock 367.37492169s] Trained 120 records in 0.0439149 seconds. Throughput is 2732.5579 records/second. Loss is 0.19272304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038162112654556556. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12480/60000][Iteration 8104][Wall Clock 367.415711392s] Trained 120 records in 0.040789702 seconds. Throughput is 2941.9192 records/second. Loss is 0.17345904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003815920018316416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12600/60000][Iteration 8105][Wall Clock 367.456890432s] Trained 120 records in 0.04117904 seconds. Throughput is 2914.104 records/second. Loss is 0.15199961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038156288156288155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12720/60000][Iteration 8106][Wall Clock 367.49834749s] Trained 120 records in 0.041457058 seconds. Throughput is 2894.5615 records/second. Loss is 0.12315621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038153376573826785. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12840/60000][Iteration 8107][Wall Clock 367.539113708s] Trained 120 records in 0.040766218 seconds. Throughput is 2943.6138 records/second. Loss is 0.25127178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038150465435678317. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:13 INFO  DistriOptimizer$:406 - [Epoch 17 12960/60000][Iteration 8108][Wall Clock 367.579607942s] Trained 120 records in 0.040494234 seconds. Throughput is 2963.385 records/second. Loss is 0.1717536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003814755474174105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13080/60000][Iteration 8109][Wall Clock 367.620657569s] Trained 120 records in 0.041049627 seconds. Throughput is 2923.291 records/second. Loss is 0.11704586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003814464449191334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13200/60000][Iteration 8110][Wall Clock 367.661027081s] Trained 120 records in 0.040369512 seconds. Throughput is 2972.5403 records/second. Loss is 0.12887937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003814173468609352. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13320/60000][Iteration 8111][Wall Clock 367.701558595s] Trained 120 records in 0.040531514 seconds. Throughput is 2960.6594 records/second. Loss is 0.058903202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003813882532418002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13440/60000][Iteration 8112][Wall Clock 367.741808642s] Trained 120 records in 0.040250047 seconds. Throughput is 2981.3628 records/second. Loss is 0.17982732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038135916406071236. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13560/60000][Iteration 8113][Wall Clock 367.782772501s] Trained 120 records in 0.040963859 seconds. Throughput is 2929.4116 records/second. Loss is 0.10227171. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038133007931665653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13680/60000][Iteration 8114][Wall Clock 367.823440767s] Trained 120 records in 0.040668266 seconds. Throughput is 2950.7036 records/second. Loss is 0.15295956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038130099900861737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13800/60000][Iteration 8115][Wall Clock 367.864062161s] Trained 120 records in 0.040621394 seconds. Throughput is 2954.1084 records/second. Loss is 0.13259082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038127192313558034. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 13920/60000][Iteration 8116][Wall Clock 367.904997705s] Trained 120 records in 0.040935544 seconds. Throughput is 2931.438 records/second. Loss is 0.16661087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038124285169653066. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14040/60000][Iteration 8117][Wall Clock 367.945684076s] Trained 120 records in 0.040686371 seconds. Throughput is 2949.3904 records/second. Loss is 0.13114873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038121378469045445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14160/60000][Iteration 8118][Wall Clock 367.98826872s] Trained 120 records in 0.042584644 seconds. Throughput is 2817.9172 records/second. Loss is 0.18386477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038118472211633755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14280/60000][Iteration 8119][Wall Clock 368.028274561s] Trained 120 records in 0.040005841 seconds. Throughput is 2999.562 records/second. Loss is 0.13272698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038115566397316663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14400/60000][Iteration 8120][Wall Clock 368.076070458s] Trained 120 records in 0.047795897 seconds. Throughput is 2510.6758 records/second. Loss is 0.17611557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038112661025992835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14520/60000][Iteration 8121][Wall Clock 368.123846291s] Trained 120 records in 0.047775833 seconds. Throughput is 2511.73 records/second. Loss is 0.1619059. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038109756097560975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14640/60000][Iteration 8122][Wall Clock 368.169982611s] Trained 120 records in 0.04613632 seconds. Throughput is 2600.9878 records/second. Loss is 0.2424626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038106851611919824. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14760/60000][Iteration 8123][Wall Clock 368.211579563s] Trained 120 records in 0.041596952 seconds. Throughput is 2884.8267 records/second. Loss is 0.06487965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038103947568968147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 14880/60000][Iteration 8124][Wall Clock 368.252300897s] Trained 120 records in 0.040721334 seconds. Throughput is 2946.8582 records/second. Loss is 0.26235545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003810104396860474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15000/60000][Iteration 8125][Wall Clock 368.292459684s] Trained 120 records in 0.040158787 seconds. Throughput is 2988.1382 records/second. Loss is 0.18578418. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038098140810728437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15120/60000][Iteration 8126][Wall Clock 368.332064409s] Trained 120 records in 0.039604725 seconds. Throughput is 3029.9417 records/second. Loss is 0.15310852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038095238095238095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15240/60000][Iteration 8127][Wall Clock 368.371256713s] Trained 120 records in 0.039192304 seconds. Throughput is 3061.8257 records/second. Loss is 0.19720343. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003809233582203261. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15360/60000][Iteration 8128][Wall Clock 368.410437102s] Trained 120 records in 0.039180389 seconds. Throughput is 3062.7566 records/second. Loss is 0.19405094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038089433991010894. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15480/60000][Iteration 8129][Wall Clock 368.457406705s] Trained 120 records in 0.046969603 seconds. Throughput is 2554.8438 records/second. Loss is 0.15169665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038086532602071904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15600/60000][Iteration 8130][Wall Clock 368.501146774s] Trained 120 records in 0.043740069 seconds. Throughput is 2743.48 records/second. Loss is 0.16394529. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038083631655114634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15720/60000][Iteration 8131][Wall Clock 368.54158998s] Trained 120 records in 0.040443206 seconds. Throughput is 2967.124 records/second. Loss is 0.11277011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038080731150038076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:14 INFO  DistriOptimizer$:406 - [Epoch 17 15840/60000][Iteration 8132][Wall Clock 368.581000749s] Trained 120 records in 0.039410769 seconds. Throughput is 3044.853 records/second. Loss is 0.077798344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038077831086741304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 15960/60000][Iteration 8133][Wall Clock 368.620836722s] Trained 120 records in 0.039835973 seconds. Throughput is 3012.3525 records/second. Loss is 0.17229548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003807493146512336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16080/60000][Iteration 8134][Wall Clock 368.660626747s] Trained 120 records in 0.039790025 seconds. Throughput is 3015.831 records/second. Loss is 0.12147072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003807203228508338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16200/60000][Iteration 8135][Wall Clock 368.700580763s] Trained 120 records in 0.039954016 seconds. Throughput is 3003.4526 records/second. Loss is 0.14451234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003806913354652048. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16320/60000][Iteration 8136][Wall Clock 368.740967508s] Trained 120 records in 0.040386745 seconds. Throughput is 2971.272 records/second. Loss is 0.1733934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038066235249333844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16440/60000][Iteration 8137][Wall Clock 368.78424051s] Trained 120 records in 0.043273002 seconds. Throughput is 2773.0916 records/second. Loss is 0.14629017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003806333739342265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16560/60000][Iteration 8138][Wall Clock 368.824035768s] Trained 120 records in 0.039795258 seconds. Throughput is 3015.4348 records/second. Loss is 0.19022755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038060439978686153. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16680/60000][Iteration 8139][Wall Clock 368.864401225s] Trained 120 records in 0.040365457 seconds. Throughput is 2972.8389 records/second. Loss is 0.16024013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038057543005023593. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16800/60000][Iteration 8140][Wall Clock 368.90515322s] Trained 120 records in 0.040751995 seconds. Throughput is 2944.641 records/second. Loss is 0.16908003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003805464647233427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 16920/60000][Iteration 8141][Wall Clock 368.945851969s] Trained 120 records in 0.040698749 seconds. Throughput is 2948.4937 records/second. Loss is 0.11165739. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00380517503805175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17040/60000][Iteration 8142][Wall Clock 368.985727483s] Trained 120 records in 0.039875514 seconds. Throughput is 3009.3655 records/second. Loss is 0.15862037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038048854729472643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17160/60000][Iteration 8143][Wall Clock 369.025786109s] Trained 120 records in 0.040058626 seconds. Throughput is 2995.6094 records/second. Loss is 0.31618103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038045959519099073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17280/60000][Iteration 8144][Wall Clock 369.066328043s] Trained 120 records in 0.040541934 seconds. Throughput is 2959.8982 records/second. Loss is 0.14520867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038043064749296203. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17400/60000][Iteration 8145][Wall Clock 369.107817627s] Trained 120 records in 0.041489584 seconds. Throughput is 2892.2922 records/second. Loss is 0.11453107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003804017041996348. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17520/60000][Iteration 8146][Wall Clock 369.162384562s] Trained 120 records in 0.054566935 seconds. Throughput is 2199.134 records/second. Loss is 0.20237859. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038037276531000383. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17640/60000][Iteration 8147][Wall Clock 369.20921283s] Trained 120 records in 0.046828268 seconds. Throughput is 2562.555 records/second. Loss is 0.19136521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003803438308230641. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17760/60000][Iteration 8148][Wall Clock 369.249356333s] Trained 120 records in 0.040143503 seconds. Throughput is 2989.2756 records/second. Loss is 0.1705303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038031490073781086. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 17880/60000][Iteration 8149][Wall Clock 369.289313373s] Trained 120 records in 0.03995704 seconds. Throughput is 3003.2256 records/second. Loss is 0.09363235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038028597505324006. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 18000/60000][Iteration 8150][Wall Clock 369.329679756s] Trained 120 records in 0.040366383 seconds. Throughput is 2972.7708 records/second. Loss is 0.15820579. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038025705376834736. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 18120/60000][Iteration 8151][Wall Clock 369.370053183s] Trained 120 records in 0.040373427 seconds. Throughput is 2972.2522 records/second. Loss is 0.07291993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003802281368821293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 18240/60000][Iteration 8152][Wall Clock 369.411490982s] Trained 120 records in 0.041437799 seconds. Throughput is 2895.9067 records/second. Loss is 0.14766932. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003801992243935822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 18360/60000][Iteration 8153][Wall Clock 369.452834896s] Trained 120 records in 0.041343914 seconds. Throughput is 2902.483 records/second. Loss is 0.19012947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038017031630170318. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 18480/60000][Iteration 8154][Wall Clock 369.494118024s] Trained 120 records in 0.041283128 seconds. Throughput is 2906.7566 records/second. Loss is 0.18423091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003801414126054892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:15 INFO  DistriOptimizer$:406 - [Epoch 17 18600/60000][Iteration 8155][Wall Clock 369.542178016s] Trained 120 records in 0.048059992 seconds. Throughput is 2496.8794 records/second. Loss is 0.22789165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00380112513303938. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 18720/60000][Iteration 8156][Wall Clock 369.587906382s] Trained 120 records in 0.045728366 seconds. Throughput is 2624.1917 records/second. Loss is 0.294034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003800836183960471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 18840/60000][Iteration 8157][Wall Clock 369.627450335s] Trained 120 records in 0.039543953 seconds. Throughput is 3034.598 records/second. Loss is 0.19029832. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003800547278808149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 18960/60000][Iteration 8158][Wall Clock 369.66724792s] Trained 120 records in 0.039797585 seconds. Throughput is 3015.2583 records/second. Loss is 0.14628379. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0038002584175723946. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19080/60000][Iteration 8159][Wall Clock 369.706834019s] Trained 120 records in 0.039586099 seconds. Throughput is 3031.367 records/second. Loss is 0.15635188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003799969600243198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19200/60000][Iteration 8160][Wall Clock 369.746779366s] Trained 120 records in 0.039945347 seconds. Throughput is 3004.1047 records/second. Loss is 0.21091086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037996808268105477. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19320/60000][Iteration 8161][Wall Clock 369.786951504s] Trained 120 records in 0.040172138 seconds. Throughput is 2987.145 records/second. Loss is 0.14447328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003799392097264438. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19440/60000][Iteration 8162][Wall Clock 369.82756896s] Trained 120 records in 0.040617456 seconds. Throughput is 2954.3948 records/second. Loss is 0.16240497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037991034115948635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19560/60000][Iteration 8163][Wall Clock 369.867827549s] Trained 120 records in 0.040258589 seconds. Throughput is 2980.7302 records/second. Loss is 0.22525387. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003798814769791825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19680/60000][Iteration 8164][Wall Clock 369.90785773s] Trained 120 records in 0.040030181 seconds. Throughput is 2997.738 records/second. Loss is 0.1318926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003798526171845324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19800/60000][Iteration 8165][Wall Clock 369.947862669s] Trained 120 records in 0.040004939 seconds. Throughput is 2999.6296 records/second. Loss is 0.15837362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003798237617745366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 19920/60000][Iteration 8166][Wall Clock 369.988568461s] Trained 120 records in 0.040705792 seconds. Throughput is 2947.9834 records/second. Loss is 0.0855718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037979491074819596. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20040/60000][Iteration 8167][Wall Clock 370.029655534s] Trained 120 records in 0.041087073 seconds. Throughput is 2920.6267 records/second. Loss is 0.20441152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037976606410451163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20160/60000][Iteration 8168][Wall Clock 370.070523197s] Trained 120 records in 0.040867663 seconds. Throughput is 2936.307 records/second. Loss is 0.16836312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00379737221842485. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20280/60000][Iteration 8169][Wall Clock 370.111088634s] Trained 120 records in 0.040565437 seconds. Throughput is 2958.1833 records/second. Loss is 0.22215265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003797083839611178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20400/60000][Iteration 8170][Wall Clock 370.152352096s] Trained 120 records in 0.041263462 seconds. Throughput is 2908.1418 records/second. Loss is 0.23168953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003796795504594123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20520/60000][Iteration 8171][Wall Clock 370.197688718s] Trained 120 records in 0.045336622 seconds. Throughput is 2646.8667 records/second. Loss is 0.2003185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003796507213363705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20640/60000][Iteration 8172][Wall Clock 370.247311787s] Trained 120 records in 0.049623069 seconds. Throughput is 2418.2302 records/second. Loss is 0.1331625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003796218965909954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20760/60000][Iteration 8173][Wall Clock 370.287944398s] Trained 120 records in 0.040632611 seconds. Throughput is 2953.293 records/second. Loss is 0.14294186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037959307622228967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 20880/60000][Iteration 8174][Wall Clock 370.331926331s] Trained 120 records in 0.043981933 seconds. Throughput is 2728.393 records/second. Loss is 0.1943814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037956426022925684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 21000/60000][Iteration 8175][Wall Clock 370.371913797s] Trained 120 records in 0.039987466 seconds. Throughput is 3000.9402 records/second. Loss is 0.21155515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037953544861090024. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 21120/60000][Iteration 8176][Wall Clock 370.412772287s] Trained 120 records in 0.04085849 seconds. Throughput is 2936.9663 records/second. Loss is 0.2301887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037950664136622396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 21240/60000][Iteration 8177][Wall Clock 370.453964866s] Trained 120 records in 0.041192579 seconds. Throughput is 2913.146 records/second. Loss is 0.19956939. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037947783849423193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 21360/60000][Iteration 8178][Wall Clock 370.495855964s] Trained 120 records in 0.041891098 seconds. Throughput is 2864.5703 records/second. Loss is 0.18099603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003794490399939288. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:16 INFO  DistriOptimizer$:406 - [Epoch 17 21480/60000][Iteration 8179][Wall Clock 370.537533847s] Trained 120 records in 0.041677883 seconds. Throughput is 2879.2249 records/second. Loss is 0.14163163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003794202458643193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 21600/60000][Iteration 8180][Wall Clock 370.578274079s] Trained 120 records in 0.040740232 seconds. Throughput is 2945.4912 records/second. Loss is 0.117852576. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003793914561044085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 21720/60000][Iteration 8181][Wall Clock 370.619336396s] Trained 120 records in 0.041062317 seconds. Throughput is 2922.3875 records/second. Loss is 0.15809917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003793626707132018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 21840/60000][Iteration 8182][Wall Clock 370.66837691s] Trained 120 records in 0.049040514 seconds. Throughput is 2446.9563 records/second. Loss is 0.23901793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037933388968970486. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 21960/60000][Iteration 8183][Wall Clock 370.713404892s] Trained 120 records in 0.045027982 seconds. Throughput is 2665.0095 records/second. Loss is 0.12808351. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003793051130329237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22080/60000][Iteration 8184][Wall Clock 370.753962471s] Trained 120 records in 0.040557579 seconds. Throughput is 2958.7566 records/second. Loss is 0.18421894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003792763407418645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22200/60000][Iteration 8185][Wall Clock 370.794197587s] Trained 120 records in 0.040235116 seconds. Throughput is 2982.4692 records/second. Loss is 0.16747138. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00379247572815534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22320/60000][Iteration 8186][Wall Clock 370.834615893s] Trained 120 records in 0.040418306 seconds. Throughput is 2968.952 records/second. Loss is 0.16125481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037921880925293897. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22440/60000][Iteration 8187][Wall Clock 370.875265733s] Trained 120 records in 0.04064984 seconds. Throughput is 2952.0413 records/second. Loss is 0.15594524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037919005005308663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22560/60000][Iteration 8188][Wall Clock 370.915465746s] Trained 120 records in 0.040200013 seconds. Throughput is 2985.0737 records/second. Loss is 0.1549759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003791612952149844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22680/60000][Iteration 8189][Wall Clock 370.955774619s] Trained 120 records in 0.040308873 seconds. Throughput is 2977.012 records/second. Loss is 0.26406488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037913254473764028. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22800/60000][Iteration 8190][Wall Clock 370.99585713s] Trained 120 records in 0.040082511 seconds. Throughput is 2993.8245 records/second. Loss is 0.17153096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037910379862006213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 22920/60000][Iteration 8191][Wall Clock 371.036320736s] Trained 120 records in 0.040463606 seconds. Throughput is 2965.6277 records/second. Loss is 0.17440161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037907505686125857. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23040/60000][Iteration 8192][Wall Clock 371.07757821s] Trained 120 records in 0.041257474 seconds. Throughput is 2908.564 records/second. Loss is 0.18077144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00379046319460238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23160/60000][Iteration 8193][Wall Clock 371.122172456s] Trained 120 records in 0.044594246 seconds. Throughput is 2690.9302 records/second. Loss is 0.2258578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037901758641600974. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23280/60000][Iteration 8194][Wall Clock 371.163485476s] Trained 120 records in 0.04131302 seconds. Throughput is 2904.6533 records/second. Loss is 0.12490531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037898885772758278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23400/60000][Iteration 8195][Wall Clock 371.203665586s] Trained 120 records in 0.04018011 seconds. Throughput is 2986.5522 records/second. Loss is 0.2030545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00378960133393967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23520/60000][Iteration 8196][Wall Clock 371.255319476s] Trained 120 records in 0.05165389 seconds. Throughput is 2323.155 records/second. Loss is 0.17532034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00378931413414172. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23640/60000][Iteration 8197][Wall Clock 371.304699958s] Trained 120 records in 0.049380482 seconds. Throughput is 2430.1099 records/second. Loss is 0.2084318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003789026977872083. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23760/60000][Iteration 8198][Wall Clock 371.346178412s] Trained 120 records in 0.041478454 seconds. Throughput is 2893.068 records/second. Loss is 0.1469263. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037887398651208605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 23880/60000][Iteration 8199][Wall Clock 371.38774765s] Trained 120 records in 0.041569238 seconds. Throughput is 2886.7502 records/second. Loss is 0.18643059. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003788452795878163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 24000/60000][Iteration 8200][Wall Clock 371.429046841s] Trained 120 records in 0.041299191 seconds. Throughput is 2905.626 records/second. Loss is 0.09047521. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003788165770134101. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 24120/60000][Iteration 8201][Wall Clock 371.469317344s] Trained 120 records in 0.040270503 seconds. Throughput is 2979.8484 records/second. Loss is 0.18520983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003787878787878788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 24240/60000][Iteration 8202][Wall Clock 371.509260734s] Trained 120 records in 0.03994339 seconds. Throughput is 3004.2517 records/second. Loss is 0.17889023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003787591849102341. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:17 INFO  DistriOptimizer$:406 - [Epoch 17 24360/60000][Iteration 8203][Wall Clock 371.550442671s] Trained 120 records in 0.041181937 seconds. Throughput is 2913.899 records/second. Loss is 0.14903064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037873049537948795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 24480/60000][Iteration 8204][Wall Clock 371.591787577s] Trained 120 records in 0.041344906 seconds. Throughput is 2902.413 records/second. Loss is 0.1812508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037870181019465272. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 24600/60000][Iteration 8205][Wall Clock 371.632984339s] Trained 120 records in 0.041196762 seconds. Throughput is 2912.85 records/second. Loss is 0.2004625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00378673129354741. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 24720/60000][Iteration 8206][Wall Clock 371.673079056s] Trained 120 records in 0.040094717 seconds. Throughput is 2992.9128 records/second. Loss is 0.23046465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003786444528587656. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 24840/60000][Iteration 8207][Wall Clock 371.713047899s] Trained 120 records in 0.039968843 seconds. Throughput is 3002.3384 records/second. Loss is 0.2937702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037861578070573984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 24960/60000][Iteration 8208][Wall Clock 371.753606265s] Trained 120 records in 0.040558366 seconds. Throughput is 2958.6992 records/second. Loss is 0.13951014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003785871128946771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25080/60000][Iteration 8209][Wall Clock 371.805125663s] Trained 120 records in 0.051519398 seconds. Throughput is 2329.2197 records/second. Loss is 0.07124791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003785584494245911. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25200/60000][Iteration 8210][Wall Clock 371.847303706s] Trained 120 records in 0.042178043 seconds. Throughput is 2845.0823 records/second. Loss is 0.1539174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003785297902944962. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25320/60000][Iteration 8211][Wall Clock 371.891684181s] Trained 120 records in 0.044380475 seconds. Throughput is 2703.8918 records/second. Loss is 0.15910287. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037850113550340647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25440/60000][Iteration 8212][Wall Clock 371.932352663s] Trained 120 records in 0.040668482 seconds. Throughput is 2950.6877 records/second. Loss is 0.1958135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003784724850503369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25560/60000][Iteration 8213][Wall Clock 371.972693458s] Trained 120 records in 0.040340795 seconds. Throughput is 2974.6562 records/second. Loss is 0.13765253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003784438389343021. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25680/60000][Iteration 8214][Wall Clock 372.013039405s] Trained 120 records in 0.040345947 seconds. Throughput is 2974.2764 records/second. Loss is 0.13809195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037841519715431774. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25800/60000][Iteration 8215][Wall Clock 372.053238905s] Trained 120 records in 0.0401995 seconds. Throughput is 2985.1118 records/second. Loss is 0.18174532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003783865597093991. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 25920/60000][Iteration 8216][Wall Clock 372.094244711s] Trained 120 records in 0.041005806 seconds. Throughput is 2926.415 records/second. Loss is 0.20868124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003783579265985623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26040/60000][Iteration 8217][Wall Clock 372.134763893s] Trained 120 records in 0.040519182 seconds. Throughput is 2961.5603 records/second. Loss is 0.22994243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003783292978208232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26160/60000][Iteration 8218][Wall Clock 372.175046315s] Trained 120 records in 0.040282422 seconds. Throughput is 2978.967 records/second. Loss is 0.16325802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037830067337519865. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26280/60000][Iteration 8219][Wall Clock 372.215612052s] Trained 120 records in 0.040565737 seconds. Throughput is 2958.1614 records/second. Loss is 0.17947888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037827205326070507. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26400/60000][Iteration 8220][Wall Clock 372.256223572s] Trained 120 records in 0.04061152 seconds. Throughput is 2954.8267 records/second. Loss is 0.21699952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037824343747635976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26520/60000][Iteration 8221][Wall Clock 372.304696333s] Trained 120 records in 0.048472761 seconds. Throughput is 2475.6172 records/second. Loss is 0.10505722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037821482602118004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26640/60000][Iteration 8222][Wall Clock 372.356900655s] Trained 120 records in 0.052204322 seconds. Throughput is 2298.6602 records/second. Loss is 0.16910891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003781862188941835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26760/60000][Iteration 8223][Wall Clock 372.397788965s] Trained 120 records in 0.04088831 seconds. Throughput is 2934.8242 records/second. Loss is 0.11884187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037815761609438815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 26880/60000][Iteration 8224][Wall Clock 372.439122693s] Trained 120 records in 0.041333728 seconds. Throughput is 2903.198 records/second. Loss is 0.24045043. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037812901762081224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 27000/60000][Iteration 8225][Wall Clock 372.479532503s] Trained 120 records in 0.04040981 seconds. Throughput is 2969.576 records/second. Loss is 0.25121778. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003781004234724743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 27120/60000][Iteration 8226][Wall Clock 372.520430411s] Trained 120 records in 0.040897908 seconds. Throughput is 2934.1353 records/second. Loss is 0.16277616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003780718336483932. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:18 INFO  DistriOptimizer$:406 - [Epoch 17 27240/60000][Iteration 8227][Wall Clock 372.560678456s] Trained 120 records in 0.040248045 seconds. Throughput is 2981.5115 records/second. Loss is 0.1416583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003780432481475881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 27360/60000][Iteration 8228][Wall Clock 372.60075423s] Trained 120 records in 0.040075774 seconds. Throughput is 2994.3276 records/second. Loss is 0.163411. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003780146669690784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 27480/60000][Iteration 8229][Wall Clock 372.641280707s] Trained 120 records in 0.040526477 seconds. Throughput is 2961.0273 records/second. Loss is 0.15248819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003779860901118839. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 27600/60000][Iteration 8230][Wall Clock 372.68468304s] Trained 120 records in 0.043402333 seconds. Throughput is 2764.8284 records/second. Loss is 0.22604275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037795751757502454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 27720/60000][Iteration 8231][Wall Clock 372.725220069s] Trained 120 records in 0.040537029 seconds. Throughput is 2960.2563 records/second. Loss is 0.17060089. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003779289493575208. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 27840/60000][Iteration 8232][Wall Clock 372.765925223s] Trained 120 records in 0.040705154 seconds. Throughput is 2948.0295 records/second. Loss is 0.14527304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037790038545839314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 27960/60000][Iteration 8233][Wall Clock 372.806539906s] Trained 120 records in 0.040614683 seconds. Throughput is 2954.5964 records/second. Loss is 0.17438915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037787182587666265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28080/60000][Iteration 8234][Wall Clock 372.847169476s] Trained 120 records in 0.04062957 seconds. Throughput is 2953.514 records/second. Loss is 0.20592466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037784327061135036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28200/60000][Iteration 8235][Wall Clock 372.894896445s] Trained 120 records in 0.047726969 seconds. Throughput is 2514.3018 records/second. Loss is 0.14846462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037781471966147804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28320/60000][Iteration 8236][Wall Clock 372.94234534s] Trained 120 records in 0.047448895 seconds. Throughput is 2529.0366 records/second. Loss is 0.22308289. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037778617302606722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28440/60000][Iteration 8237][Wall Clock 372.982844088s] Trained 120 records in 0.040498748 seconds. Throughput is 2963.0544 records/second. Loss is 0.15773119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037775763070414027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28560/60000][Iteration 8238][Wall Clock 373.023816094s] Trained 120 records in 0.040972006 seconds. Throughput is 2928.829 records/second. Loss is 0.19041078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037772909269471935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28680/60000][Iteration 8239][Wall Clock 373.0646038s] Trained 120 records in 0.040787706 seconds. Throughput is 2942.063 records/second. Loss is 0.19904901. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003777005589968273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28800/60000][Iteration 8240][Wall Clock 373.1053727s] Trained 120 records in 0.0407689 seconds. Throughput is 2943.4202 records/second. Loss is 0.07996798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003776720296094871. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 28920/60000][Iteration 8241][Wall Clock 373.14676956s] Trained 120 records in 0.04139686 seconds. Throughput is 2898.7705 records/second. Loss is 0.16893254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037764350453172203. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29040/60000][Iteration 8242][Wall Clock 373.186966858s] Trained 120 records in 0.040197298 seconds. Throughput is 2985.2754 records/second. Loss is 0.08899183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003776149837625557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29160/60000][Iteration 8243][Wall Clock 373.227127259s] Trained 120 records in 0.040160401 seconds. Throughput is 2988.0178 records/second. Loss is 0.1758754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037758646730101193. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29280/60000][Iteration 8244][Wall Clock 373.268149099s] Trained 120 records in 0.04102184 seconds. Throughput is 2925.271 records/second. Loss is 0.27328837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003775579551461149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29400/60000][Iteration 8245][Wall Clock 373.308160486s] Trained 120 records in 0.040011387 seconds. Throughput is 2999.1462 records/second. Loss is 0.18255195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037752944729688917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29520/60000][Iteration 8246][Wall Clock 373.349229547s] Trained 120 records in 0.041069061 seconds. Throughput is 2921.9077 records/second. Loss is 0.13100477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003775009437523594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29640/60000][Iteration 8247][Wall Clock 373.396527861s] Trained 120 records in 0.047298314 seconds. Throughput is 2537.0884 records/second. Loss is 0.14526968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037747244451155067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29760/60000][Iteration 8248][Wall Clock 373.440209569s] Trained 120 records in 0.043681708 seconds. Throughput is 2747.1453 records/second. Loss is 0.20569627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037744394957348834. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 29880/60000][Iteration 8249][Wall Clock 373.484688239s] Trained 120 records in 0.04447867 seconds. Throughput is 2697.9224 records/second. Loss is 0.09748181. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00377415458937198. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:19 INFO  DistriOptimizer$:406 - [Epoch 17 30000/60000][Iteration 8250][Wall Clock 373.524852491s] Trained 120 records in 0.040164252 seconds. Throughput is 2987.7314 records/second. Loss is 0.14292732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003773869726017058. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30120/60000][Iteration 8251][Wall Clock 373.566192958s] Trained 120 records in 0.041340467 seconds. Throughput is 2902.7249 records/second. Loss is 0.15718266. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003773584905660377. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30240/60000][Iteration 8252][Wall Clock 373.607382916s] Trained 120 records in 0.041189958 seconds. Throughput is 2913.3315 records/second. Loss is 0.22138792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037733001282922044. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30360/60000][Iteration 8253][Wall Clock 373.649100213s] Trained 120 records in 0.041717297 seconds. Throughput is 2876.5046 records/second. Loss is 0.18826456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003773015393902807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30480/60000][Iteration 8254][Wall Clock 373.691998278s] Trained 120 records in 0.042898065 seconds. Throughput is 2797.3289 records/second. Loss is 0.19914025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003772730702482457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30600/60000][Iteration 8255][Wall Clock 373.733872485s] Trained 120 records in 0.041874207 seconds. Throughput is 2865.7258 records/second. Loss is 0.28352755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003772446054021427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30720/60000][Iteration 8256][Wall Clock 373.775423962s] Trained 120 records in 0.041551477 seconds. Throughput is 2887.984 records/second. Loss is 0.29109535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037721614485099965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30840/60000][Iteration 8257][Wall Clock 373.81660976s] Trained 120 records in 0.041185798 seconds. Throughput is 2913.6257 records/second. Loss is 0.10762671. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003771876885938443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 30960/60000][Iteration 8258][Wall Clock 373.857970127s] Trained 120 records in 0.041360367 seconds. Throughput is 2901.3281 records/second. Loss is 0.14923503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003771592366297051. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31080/60000][Iteration 8259][Wall Clock 373.899059379s] Trained 120 records in 0.041089252 seconds. Throughput is 2920.4717 records/second. Loss is 0.12354307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003771307889576105. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31200/60000][Iteration 8260][Wall Clock 373.940882355s] Trained 120 records in 0.041822976 seconds. Throughput is 2869.236 records/second. Loss is 0.09003624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037710234557658947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31320/60000][Iteration 8261][Wall Clock 373.982122871s] Trained 120 records in 0.041240516 seconds. Throughput is 2909.7598 records/second. Loss is 0.17869562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003770739064856712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31440/60000][Iteration 8262][Wall Clock 374.034614266s] Trained 120 records in 0.052491395 seconds. Throughput is 2286.0889 records/second. Loss is 0.1608759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037704547168388508. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31560/60000][Iteration 8263][Wall Clock 374.082498994s] Trained 120 records in 0.047884728 seconds. Throughput is 2506.018 records/second. Loss is 0.14342538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003770170411702609. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31680/60000][Iteration 8264][Wall Clock 374.124603026s] Trained 120 records in 0.042104032 seconds. Throughput is 2850.0833 records/second. Loss is 0.10832799. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003769886149438287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31800/60000][Iteration 8265][Wall Clock 374.165594331s] Trained 120 records in 0.040991305 seconds. Throughput is 2927.45 records/second. Loss is 0.14304513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037696019300361883. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 31920/60000][Iteration 8266][Wall Clock 374.206398171s] Trained 120 records in 0.04080384 seconds. Throughput is 2940.9 records/second. Loss is 0.09520647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003769317753486619. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32040/60000][Iteration 8267][Wall Clock 374.247551472s] Trained 120 records in 0.041153301 seconds. Throughput is 2915.9265 records/second. Loss is 0.15509282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037690336197798886. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32160/60000][Iteration 8268][Wall Clock 374.291880198s] Trained 120 records in 0.044328726 seconds. Throughput is 2707.048 records/second. Loss is 0.19884875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003768749528906309. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32280/60000][Iteration 8269][Wall Clock 374.332012976s] Trained 120 records in 0.040132778 seconds. Throughput is 2990.0745 records/second. Loss is 0.19663252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037684654808561955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32400/60000][Iteration 8270][Wall Clock 374.372625043s] Trained 120 records in 0.040612067 seconds. Throughput is 2954.7866 records/second. Loss is 0.22333466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037681814756198653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32520/60000][Iteration 8271][Wall Clock 374.41460106s] Trained 120 records in 0.041976017 seconds. Throughput is 2858.7754 records/second. Loss is 0.17279202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037678975131876413. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32640/60000][Iteration 8272][Wall Clock 374.46058838s] Trained 120 records in 0.04598732 seconds. Throughput is 2609.415 records/second. Loss is 0.08407251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003767613593549845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32760/60000][Iteration 8273][Wall Clock 374.503805686s] Trained 120 records in 0.043217306 seconds. Throughput is 2776.6655 records/second. Loss is 0.15172526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037673297166968055. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:20 INFO  DistriOptimizer$:406 - [Epoch 17 32880/60000][Iteration 8274][Wall Clock 374.544123119s] Trained 120 records in 0.040317433 seconds. Throughput is 2976.38 records/second. Loss is 0.15108906. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00376704588261885. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33000/60000][Iteration 8275][Wall Clock 374.58476386s] Trained 120 records in 0.040640741 seconds. Throughput is 2952.702 records/second. Loss is 0.11323662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037667620913063135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33120/60000][Iteration 8276][Wall Clock 374.625014128s] Trained 120 records in 0.040250268 seconds. Throughput is 2981.3467 records/second. Loss is 0.1471561. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003766478342749529. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33240/60000][Iteration 8277][Wall Clock 374.665042468s] Trained 120 records in 0.04002834 seconds. Throughput is 2997.876 records/second. Loss is 0.15857247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037661946369388372. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33360/60000][Iteration 8278][Wall Clock 374.70522222s] Trained 120 records in 0.040179752 seconds. Throughput is 2986.5789 records/second. Loss is 0.33493248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037659109738645774. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33480/60000][Iteration 8279][Wall Clock 374.745106831s] Trained 120 records in 0.039884611 seconds. Throughput is 3008.6792 records/second. Loss is 0.2438125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003765627353517096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33600/60000][Iteration 8280][Wall Clock 374.785471881s] Trained 120 records in 0.04036505 seconds. Throughput is 2972.8687 records/second. Loss is 0.12201785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003765343775886738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33720/60000][Iteration 8281][Wall Clock 374.825458236s] Trained 120 records in 0.039986355 seconds. Throughput is 3001.024 records/second. Loss is 0.097419724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037650602409638554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33840/60000][Iteration 8282][Wall Clock 374.865586061s] Trained 120 records in 0.040127825 seconds. Throughput is 2990.4436 records/second. Loss is 0.07116294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037647767487387998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 33960/60000][Iteration 8283][Wall Clock 374.905966246s] Trained 120 records in 0.040380185 seconds. Throughput is 2971.7546 records/second. Loss is 0.17064257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037644932992019274. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34080/60000][Iteration 8284][Wall Clock 374.946589159s] Trained 120 records in 0.040622913 seconds. Throughput is 2953.998 records/second. Loss is 0.17166582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003764209892343597. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34200/60000][Iteration 8285][Wall Clock 374.987253699s] Trained 120 records in 0.04066454 seconds. Throughput is 2950.974 records/second. Loss is 0.123763815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037639265281541705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34320/60000][Iteration 8286][Wall Clock 375.027777608s] Trained 120 records in 0.040523909 seconds. Throughput is 2961.2148 records/second. Loss is 0.19293658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037636432066240123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34440/60000][Iteration 8287][Wall Clock 375.072171131s] Trained 120 records in 0.044393523 seconds. Throughput is 2703.097 records/second. Loss is 0.21090987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037633599277434896. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34560/60000][Iteration 8288][Wall Clock 375.1127698s] Trained 120 records in 0.040598669 seconds. Throughput is 2955.762 records/second. Loss is 0.12340387. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003763076691502973. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34680/60000][Iteration 8289][Wall Clock 375.163988042s] Trained 120 records in 0.051218242 seconds. Throughput is 2342.9153 records/second. Loss is 0.124200836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003762793497892835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34800/60000][Iteration 8290][Wall Clock 375.206805636s] Trained 120 records in 0.042817594 seconds. Throughput is 2802.5864 records/second. Loss is 0.21316358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003762510346903454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 34920/60000][Iteration 8291][Wall Clock 375.247628914s] Trained 120 records in 0.040823278 seconds. Throughput is 2939.4995 records/second. Loss is 0.17571852. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037622272385252065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 35040/60000][Iteration 8292][Wall Clock 375.287741683s] Trained 120 records in 0.040112769 seconds. Throughput is 2991.5662 records/second. Loss is 0.14292057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037619441727484767. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 35160/60000][Iteration 8293][Wall Clock 375.327771116s] Trained 120 records in 0.040029433 seconds. Throughput is 2997.7942 records/second. Loss is 0.16797394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003761661149563647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 35280/60000][Iteration 8294][Wall Clock 375.368251321s] Trained 120 records in 0.040480205 seconds. Throughput is 2964.4119 records/second. Loss is 0.19200014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003761378168961108. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 35400/60000][Iteration 8295][Wall Clock 375.409371126s] Trained 120 records in 0.041119805 seconds. Throughput is 2918.3018 records/second. Loss is 0.19769053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037610952309312467. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 35520/60000][Iteration 8296][Wall Clock 375.451506788s] Trained 120 records in 0.042135662 seconds. Throughput is 2847.9438 records/second. Loss is 0.25095168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037608123354644606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 35640/60000][Iteration 8297][Wall Clock 375.506424165s] Trained 120 records in 0.054917377 seconds. Throughput is 2185.1008 records/second. Loss is 0.19626336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003760529482551143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:21 INFO  DistriOptimizer$:406 - [Epoch 17 35760/60000][Iteration 8298][Wall Clock 375.55162774s] Trained 120 records in 0.045203575 seconds. Throughput is 2654.6575 records/second. Loss is 0.21381824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037602466721816954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 35880/60000][Iteration 8299][Wall Clock 375.591673304s] Trained 120 records in 0.040045564 seconds. Throughput is 2996.5867 records/second. Loss is 0.1803462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003759963904346518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36000/60000][Iteration 8300][Wall Clock 375.631660628s] Trained 120 records in 0.039987324 seconds. Throughput is 3000.951 records/second. Loss is 0.14436969. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037596811790360177. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36120/60000][Iteration 8301][Wall Clock 375.671460738s] Trained 120 records in 0.03980011 seconds. Throughput is 3015.067 records/second. Loss is 0.09384222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037593984962406013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36240/60000][Iteration 8302][Wall Clock 375.711025954s] Trained 120 records in 0.039565216 seconds. Throughput is 3032.967 records/second. Loss is 0.17038043. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037591158559506805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36360/60000][Iteration 8303][Wall Clock 375.750871513s] Trained 120 records in 0.039845559 seconds. Throughput is 3011.628 records/second. Loss is 0.121635534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003758833258156668. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36480/60000][Iteration 8304][Wall Clock 375.790714461s] Trained 120 records in 0.039842948 seconds. Throughput is 3011.8252 records/second. Loss is 0.13948908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037585507028489815. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36600/60000][Iteration 8305][Wall Clock 375.833299945s] Trained 120 records in 0.042585484 seconds. Throughput is 2817.8616 records/second. Loss is 0.15566285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00375826819001804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36720/60000][Iteration 8306][Wall Clock 375.873714586s] Trained 120 records in 0.040414641 seconds. Throughput is 2969.221 records/second. Loss is 0.19941534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003757985719654265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36840/60000][Iteration 8307][Wall Clock 375.913197769s] Trained 120 records in 0.039483183 seconds. Throughput is 3039.2688 records/second. Loss is 0.18387571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003757703291748084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 36960/60000][Iteration 8308][Wall Clock 375.952865959s] Trained 120 records in 0.03966819 seconds. Throughput is 3025.0938 records/second. Loss is 0.13511582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037574209062899225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37080/60000][Iteration 8309][Wall Clock 375.992459093s] Trained 120 records in 0.039593134 seconds. Throughput is 3030.8286 records/second. Loss is 0.14784692. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037571385632702136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37200/60000][Iteration 8310][Wall Clock 376.032181111s] Trained 120 records in 0.039722018 seconds. Throughput is 3020.9946 records/second. Loss is 0.17612696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037568562626793893. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37320/60000][Iteration 8311][Wall Clock 376.072018285s] Trained 120 records in 0.039837174 seconds. Throughput is 3012.262 records/second. Loss is 0.09292198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003756574004507889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37440/60000][Iteration 8312][Wall Clock 376.112514359s] Trained 120 records in 0.040496074 seconds. Throughput is 2963.2502 records/second. Loss is 0.19718748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037562917887461493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37560/60000][Iteration 8313][Wall Clock 376.152971503s] Trained 120 records in 0.040457144 seconds. Throughput is 2966.1016 records/second. Loss is 0.23291855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037560096153846155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37680/60000][Iteration 8314][Wall Clock 376.192116643s] Trained 120 records in 0.03914514 seconds. Throughput is 3065.5144 records/second. Loss is 0.14557253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037557274844137304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37800/60000][Iteration 8315][Wall Clock 376.239985516s] Trained 120 records in 0.047868873 seconds. Throughput is 2506.8481 records/second. Loss is 0.14528233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003755445395823945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 37920/60000][Iteration 8316][Wall Clock 376.286548852s] Trained 120 records in 0.046563336 seconds. Throughput is 2577.135 records/second. Loss is 0.19951563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037551633496057074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 38040/60000][Iteration 8317][Wall Clock 376.330558469s] Trained 120 records in 0.044009617 seconds. Throughput is 2726.6768 records/second. Loss is 0.1809813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003754881345749475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 38160/60000][Iteration 8318][Wall Clock 376.372449576s] Trained 120 records in 0.041891107 seconds. Throughput is 2864.5698 records/second. Loss is 0.1693953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037545993842457008. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 38280/60000][Iteration 8319][Wall Clock 376.412932051s] Trained 120 records in 0.040482475 seconds. Throughput is 2964.2456 records/second. Loss is 0.18355213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037543174650848474. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 38400/60000][Iteration 8320][Wall Clock 376.453410738s] Trained 120 records in 0.040478687 seconds. Throughput is 2964.523 records/second. Loss is 0.12681548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037540355882573766. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 38520/60000][Iteration 8321][Wall Clock 376.503517866s] Trained 120 records in 0.050107128 seconds. Throughput is 2394.869 records/second. Loss is 0.1577156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037537537537537537. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:22 INFO  DistriOptimizer$:406 - [Epoch 17 38640/60000][Iteration 8322][Wall Clock 376.54615163s] Trained 120 records in 0.042633764 seconds. Throughput is 2814.6704 records/second. Loss is 0.12004587. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003753471961564447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 38760/60000][Iteration 8323][Wall Clock 376.586519651s] Trained 120 records in 0.040368021 seconds. Throughput is 2972.6501 records/second. Loss is 0.24829267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003753190211679928. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 38880/60000][Iteration 8324][Wall Clock 376.641347658s] Trained 120 records in 0.054828007 seconds. Throughput is 2188.6624 records/second. Loss is 0.1648161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037529085040906704. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39000/60000][Iteration 8325][Wall Clock 376.682368457s] Trained 120 records in 0.041020799 seconds. Throughput is 2925.3452 records/second. Loss is 0.2102094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003752626838787151. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39120/60000][Iteration 8326][Wall Clock 376.722678373s] Trained 120 records in 0.040309916 seconds. Throughput is 2976.9348 records/second. Loss is 0.17885676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00375234521575985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39240/60000][Iteration 8327][Wall Clock 376.762381463s] Trained 120 records in 0.03970309 seconds. Throughput is 3022.4348 records/second. Loss is 0.13710634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037520636349992497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39360/60000][Iteration 8328][Wall Clock 376.801953621s] Trained 120 records in 0.039572158 seconds. Throughput is 3032.435 records/second. Loss is 0.091788135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037517820964958356. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39480/60000][Iteration 8329][Wall Clock 376.841244325s] Trained 120 records in 0.039290704 seconds. Throughput is 3054.1575 records/second. Loss is 0.0882758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003751500600240096. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39600/60000][Iteration 8330][Wall Clock 376.8810757s] Trained 120 records in 0.039831375 seconds. Throughput is 3012.7004 records/second. Loss is 0.09590822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037512191462225225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39720/60000][Iteration 8331][Wall Clock 376.920965113s] Trained 120 records in 0.039889413 seconds. Throughput is 3008.317 records/second. Loss is 0.21066257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003750937734433608. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39840/60000][Iteration 8332][Wall Clock 376.961279066s] Trained 120 records in 0.040313953 seconds. Throughput is 2976.637 records/second. Loss is 0.17549983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037506563648638516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 39960/60000][Iteration 8333][Wall Clock 377.001540877s] Trained 120 records in 0.040261811 seconds. Throughput is 2980.4917 records/second. Loss is 0.32864085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00375037503750375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40080/60000][Iteration 8334][Wall Clock 377.042188081s] Trained 120 records in 0.040647204 seconds. Throughput is 2952.2324 records/second. Loss is 0.20503858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037500937523438087. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40200/60000][Iteration 8335][Wall Clock 377.08248145s] Trained 120 records in 0.040293369 seconds. Throughput is 2978.1575 records/second. Loss is 0.18736997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037498125093745308. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40320/60000][Iteration 8336][Wall Clock 377.122177207s] Trained 120 records in 0.039695757 seconds. Throughput is 3022.993 records/second. Loss is 0.2306343. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003749531308586427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40440/60000][Iteration 8337][Wall Clock 377.16259377s] Trained 120 records in 0.040416563 seconds. Throughput is 2969.0796 records/second. Loss is 0.12787192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037492501499700056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40560/60000][Iteration 8338][Wall Clock 377.202096864s] Trained 120 records in 0.039503094 seconds. Throughput is 3037.7368 records/second. Loss is 0.14453085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037489690335157835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40680/60000][Iteration 8339][Wall Clock 377.241981352s] Trained 120 records in 0.039884488 seconds. Throughput is 3008.6885 records/second. Loss is 0.12217726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003748687959214275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40800/60000][Iteration 8340][Wall Clock 377.283054297s] Trained 120 records in 0.041072945 seconds. Throughput is 2921.631 records/second. Loss is 0.19298996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003748406927056001. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 40920/60000][Iteration 8341][Wall Clock 377.323881457s] Trained 120 records in 0.04082716 seconds. Throughput is 2939.22 records/second. Loss is 0.11750247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037481259370314842. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 41040/60000][Iteration 8342][Wall Clock 377.37543521s] Trained 120 records in 0.051553753 seconds. Throughput is 2327.6677 records/second. Loss is 0.18643548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037478449891312493. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 41160/60000][Iteration 8343][Wall Clock 377.427163232s] Trained 120 records in 0.051728022 seconds. Throughput is 2319.826 records/second. Loss is 0.24319312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003747564083345825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 41280/60000][Iteration 8344][Wall Clock 377.470550766s] Trained 120 records in 0.043387534 seconds. Throughput is 2765.7715 records/second. Loss is 0.14088804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037472832196657423. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:23 INFO  DistriOptimizer$:406 - [Epoch 17 41400/60000][Iteration 8345][Wall Clock 377.511172709s] Trained 120 records in 0.040621943 seconds. Throughput is 2954.0684 records/second. Loss is 0.20491128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003747002398081535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 41520/60000][Iteration 8346][Wall Clock 377.552987615s] Trained 120 records in 0.041814906 seconds. Throughput is 2869.79 records/second. Loss is 0.123858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003746721618583739. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 41640/60000][Iteration 8347][Wall Clock 377.595457444s] Trained 120 records in 0.042469829 seconds. Throughput is 2825.5352 records/second. Loss is 0.16235727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037464408811628954. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 41760/60000][Iteration 8348][Wall Clock 377.634811411s] Trained 120 records in 0.039353967 seconds. Throughput is 3049.2478 records/second. Loss is 0.17083724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037461601858095454. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 41880/60000][Iteration 8349][Wall Clock 377.67489562s] Trained 120 records in 0.040084209 seconds. Throughput is 2993.6975 records/second. Loss is 0.2292627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037458795325142347. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42000/60000][Iteration 8350][Wall Clock 377.721588584s] Trained 120 records in 0.046692964 seconds. Throughput is 2569.9805 records/second. Loss is 0.23878542. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037455989212675104. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42120/60000][Iteration 8351][Wall Clock 377.768512486s] Trained 120 records in 0.046923902 seconds. Throughput is 2557.332 records/second. Loss is 0.20224114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003745318352059925. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42240/60000][Iteration 8352][Wall Clock 377.808762428s] Trained 120 records in 0.040249942 seconds. Throughput is 2981.3706 records/second. Loss is 0.21340464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003745037824882031. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42360/60000][Iteration 8353][Wall Clock 377.848924155s] Trained 120 records in 0.040161727 seconds. Throughput is 2987.9192 records/second. Loss is 0.19338655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037447573397243862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42480/60000][Iteration 8354][Wall Clock 377.889125103s] Trained 120 records in 0.040200948 seconds. Throughput is 2985.0042 records/second. Loss is 0.20640334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003744476896577548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42600/60000][Iteration 8355][Wall Clock 377.929587056s] Trained 120 records in 0.040461953 seconds. Throughput is 2965.749 records/second. Loss is 0.1500595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037441964954320808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42720/60000][Iteration 8356][Wall Clock 377.969256934s] Trained 120 records in 0.039669878 seconds. Throughput is 3024.965 records/second. Loss is 0.11794675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003743916136278547. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42840/60000][Iteration 8357][Wall Clock 378.009243067s] Trained 120 records in 0.039986133 seconds. Throughput is 3001.0403 records/second. Loss is 0.20285973. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037436358191075174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 42960/60000][Iteration 8358][Wall Clock 378.050282275s] Trained 120 records in 0.041039208 seconds. Throughput is 2924.033 records/second. Loss is 0.18528143. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037433555439095605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43080/60000][Iteration 8359][Wall Clock 378.091405731s] Trained 120 records in 0.041123456 seconds. Throughput is 2918.0425 records/second. Loss is 0.16258983. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037430753106752514. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43200/60000][Iteration 8360][Wall Clock 378.132472478s] Trained 120 records in 0.041066747 seconds. Throughput is 2922.0723 records/second. Loss is 0.1885696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003742795119395164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43320/60000][Iteration 8361][Wall Clock 378.177124664s] Trained 120 records in 0.044652186 seconds. Throughput is 2687.4385 records/second. Loss is 0.0996178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037425149700598802. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43440/60000][Iteration 8362][Wall Clock 378.217432724s] Trained 120 records in 0.04030806 seconds. Throughput is 2977.0723 records/second. Loss is 0.17919718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037422348626599804. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43560/60000][Iteration 8363][Wall Clock 378.25811456s] Trained 120 records in 0.040681836 seconds. Throughput is 2949.7195 records/second. Loss is 0.15888214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00374195479718605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43680/60000][Iteration 8364][Wall Clock 378.298501683s] Trained 120 records in 0.040387123 seconds. Throughput is 2971.244 records/second. Loss is 0.13662767. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037416747736286763. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43800/60000][Iteration 8365][Wall Clock 378.338321609s] Trained 120 records in 0.039819926 seconds. Throughput is 3013.5667 records/second. Loss is 0.2859868. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037413947919784497. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 43920/60000][Iteration 8366][Wall Clock 378.377901377s] Trained 120 records in 0.039579768 seconds. Throughput is 3031.852 records/second. Loss is 0.13134621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037411148522259632. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 44040/60000][Iteration 8367][Wall Clock 378.418747039s] Trained 120 records in 0.040845662 seconds. Throughput is 2937.8884 records/second. Loss is 0.18646976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037408349543618137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 44160/60000][Iteration 8368][Wall Clock 378.459327471s] Trained 120 records in 0.040580432 seconds. Throughput is 2957.09 records/second. Loss is 0.11774122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003740555098376599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:24 INFO  DistriOptimizer$:406 - [Epoch 17 44280/60000][Iteration 8369][Wall Clock 378.515761571s] Trained 120 records in 0.0564341 seconds. Throughput is 2126.374 records/second. Loss is 0.13434884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037402752842609216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 44400/60000][Iteration 8370][Wall Clock 378.560225095s] Trained 120 records in 0.044463524 seconds. Throughput is 2698.8416 records/second. Loss is 0.2239068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003739995512005386. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 44520/60000][Iteration 8371][Wall Clock 378.601623981s] Trained 120 records in 0.041398886 seconds. Throughput is 2898.6287 records/second. Loss is 0.18240616. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003739715781600598. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 44640/60000][Iteration 8372][Wall Clock 378.642463993s] Trained 120 records in 0.040840012 seconds. Throughput is 2938.295 records/second. Loss is 0.20039612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00373943609303717. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 44760/60000][Iteration 8373][Wall Clock 378.682276215s] Trained 120 records in 0.039812222 seconds. Throughput is 3014.1497 records/second. Loss is 0.13331644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003739156446305713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 44880/60000][Iteration 8374][Wall Clock 378.722400466s] Trained 120 records in 0.040124251 seconds. Throughput is 2990.71 records/second. Loss is 0.16843042. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037388768413968445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45000/60000][Iteration 8375][Wall Clock 378.762425812s] Trained 120 records in 0.040025346 seconds. Throughput is 2998.1003 records/second. Loss is 0.20296647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003738597278301181. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45120/60000][Iteration 8376][Wall Clock 378.803033112s] Trained 120 records in 0.0406073 seconds. Throughput is 2955.1338 records/second. Loss is 0.16443269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003738317757009346. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45240/60000][Iteration 8377][Wall Clock 378.85144994s] Trained 120 records in 0.048416828 seconds. Throughput is 2478.477 records/second. Loss is 0.13353111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037380382775119613. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45360/60000][Iteration 8378][Wall Clock 378.89673659s] Trained 120 records in 0.04528665 seconds. Throughput is 2649.7874 records/second. Loss is 0.14412941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037377588397996563. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45480/60000][Iteration 8379][Wall Clock 378.936792524s] Trained 120 records in 0.040055934 seconds. Throughput is 2995.8108 records/second. Loss is 0.07235021. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037374794438630584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45600/60000][Iteration 8380][Wall Clock 378.981087851s] Trained 120 records in 0.044295327 seconds. Throughput is 2709.0894 records/second. Loss is 0.1933782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037372000896928018. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45720/60000][Iteration 8381][Wall Clock 379.022608253s] Trained 120 records in 0.041520402 seconds. Throughput is 2890.1455 records/second. Loss is 0.20313497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037369207772795215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45840/60000][Iteration 8382][Wall Clock 379.064371461s] Trained 120 records in 0.041763208 seconds. Throughput is 2873.3425 records/second. Loss is 0.16704288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003736641506613855. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 45960/60000][Iteration 8383][Wall Clock 379.105215764s] Trained 120 records in 0.040844303 seconds. Throughput is 2937.9863 records/second. Loss is 0.23529392. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037363622776864446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46080/60000][Iteration 8384][Wall Clock 379.146372011s] Trained 120 records in 0.041156247 seconds. Throughput is 2915.7178 records/second. Loss is 0.19368188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037360830904879325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46200/60000][Iteration 8385][Wall Clock 379.187233575s] Trained 120 records in 0.040861564 seconds. Throughput is 2936.745 records/second. Loss is 0.10405677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003735803945008966. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46320/60000][Iteration 8386][Wall Clock 379.227996139s] Trained 120 records in 0.040762564 seconds. Throughput is 2943.8777 records/second. Loss is 0.08836819. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037355248412401943. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46440/60000][Iteration 8387][Wall Clock 379.268799878s] Trained 120 records in 0.040803739 seconds. Throughput is 2940.907 records/second. Loss is 0.16952565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037352457791722696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46560/60000][Iteration 8388][Wall Clock 379.308848992s] Trained 120 records in 0.040049114 seconds. Throughput is 2996.321 records/second. Loss is 0.3518823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037349667587958466. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46680/60000][Iteration 8389][Wall Clock 379.349346744s] Trained 120 records in 0.040497752 seconds. Throughput is 2963.1272 records/second. Loss is 0.17669652. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037346877801015836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46800/60000][Iteration 8390][Wall Clock 379.389365559s] Trained 120 records in 0.040018815 seconds. Throughput is 2998.5896 records/second. Loss is 0.1743527. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00373440884308014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 46920/60000][Iteration 8391][Wall Clock 379.430237629s] Trained 120 records in 0.04087207 seconds. Throughput is 2935.9902 records/second. Loss is 0.18653956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037341299477221808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 47040/60000][Iteration 8392][Wall Clock 379.470840542s] Trained 120 records in 0.040602913 seconds. Throughput is 2955.4531 records/second. Loss is 0.1215526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00373385109401837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:25 INFO  DistriOptimizer$:406 - [Epoch 17 47160/60000][Iteration 8393][Wall Clock 379.511356532s] Trained 120 records in 0.04051599 seconds. Throughput is 2961.7937 records/second. Loss is 0.1900853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003733572281959379. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 47280/60000][Iteration 8394][Wall Clock 379.551965551s] Trained 120 records in 0.040609019 seconds. Throughput is 2955.0085 records/second. Loss is 0.12281038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037332935115358765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 47400/60000][Iteration 8395][Wall Clock 379.601796895s] Trained 120 records in 0.049831344 seconds. Throughput is 2408.1228 records/second. Loss is 0.16143201. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00373301478273854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 47520/60000][Iteration 8396][Wall Clock 379.650205771s] Trained 120 records in 0.048408876 seconds. Throughput is 2478.8843 records/second. Loss is 0.16947891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037327360955580436. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 47640/60000][Iteration 8397][Wall Clock 379.694180709s] Trained 120 records in 0.043974938 seconds. Throughput is 2728.827 records/second. Loss is 0.23434547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037324574499850707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 47760/60000][Iteration 8398][Wall Clock 379.735756857s] Trained 120 records in 0.041576148 seconds. Throughput is 2886.2703 records/second. Loss is 0.121014304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037321788460103005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 47880/60000][Iteration 8399][Wall Clock 379.780342066s] Trained 120 records in 0.044585209 seconds. Throughput is 2691.4756 records/second. Loss is 0.09170843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003731900283624422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48000/60000][Iteration 8400][Wall Clock 379.82102343s] Trained 120 records in 0.040681364 seconds. Throughput is 2949.7537 records/second. Loss is 0.17205568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037316217628181204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48120/60000][Iteration 8401][Wall Clock 379.861287836s] Trained 120 records in 0.040264406 seconds. Throughput is 2980.2998 records/second. Loss is 0.14804417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037313432835820895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48240/60000][Iteration 8402][Wall Clock 379.901626231s] Trained 120 records in 0.040338395 seconds. Throughput is 2974.8335 records/second. Loss is 0.17601171. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037310648459070216. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48360/60000][Iteration 8403][Wall Clock 379.949589723s] Trained 120 records in 0.047963492 seconds. Throughput is 2501.9028 records/second. Loss is 0.20043096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037307864497836143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48480/60000][Iteration 8404][Wall Clock 379.994156164s] Trained 120 records in 0.044566441 seconds. Throughput is 2692.609 records/second. Loss is 0.17435153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037305080952025668. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48600/60000][Iteration 8405][Wall Clock 380.03500051s] Trained 120 records in 0.040844346 seconds. Throughput is 2937.9832 records/second. Loss is 0.117638946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037302297821545805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48720/60000][Iteration 8406][Wall Clock 380.075194269s] Trained 120 records in 0.040193759 seconds. Throughput is 2985.538 records/second. Loss is 0.2134671. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003729951510630362. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48840/60000][Iteration 8407][Wall Clock 380.116138871s] Trained 120 records in 0.040944602 seconds. Throughput is 2930.7893 records/second. Loss is 0.34001604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037296732806206176. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 48960/60000][Iteration 8408][Wall Clock 380.156268159s] Trained 120 records in 0.040129288 seconds. Throughput is 2990.3345 records/second. Loss is 0.21272488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037293950921160586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49080/60000][Iteration 8409][Wall Clock 380.195930176s] Trained 120 records in 0.039662017 seconds. Throughput is 3025.5647 records/second. Loss is 0.18226555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003729116945107399. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49200/60000][Iteration 8410][Wall Clock 380.236000583s] Trained 120 records in 0.040070407 seconds. Throughput is 2994.7288 records/second. Loss is 0.09646987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037288388395853534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49320/60000][Iteration 8411][Wall Clock 380.276585975s] Trained 120 records in 0.040585392 seconds. Throughput is 2956.729 records/second. Loss is 0.16262549. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003728560775540641. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49440/60000][Iteration 8412][Wall Clock 380.316890752s] Trained 120 records in 0.040304777 seconds. Throughput is 2977.3147 records/second. Loss is 0.075608276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003728282752963985. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49560/60000][Iteration 8413][Wall Clock 380.357438041s] Trained 120 records in 0.040547289 seconds. Throughput is 2959.5073 records/second. Loss is 0.15204304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037280047718461075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49680/60000][Iteration 8414][Wall Clock 380.398586471s] Trained 120 records in 0.04114843 seconds. Throughput is 2916.2715 records/second. Loss is 0.13490915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037277268321777384. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49800/60000][Iteration 8415][Wall Clock 380.439751796s] Trained 120 records in 0.041165325 seconds. Throughput is 2915.0747 records/second. Loss is 0.20894179. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037274489339496047. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 49920/60000][Iteration 8416][Wall Clock 380.480254868s] Trained 120 records in 0.040503072 seconds. Throughput is 2962.738 records/second. Loss is 0.175253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037271710771524416. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:26 INFO  DistriOptimizer$:406 - [Epoch 17 50040/60000][Iteration 8417][Wall Clock 380.520324389s] Trained 120 records in 0.040069521 seconds. Throughput is 2994.795 records/second. Loss is 0.17244317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037268932617769823. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 50160/60000][Iteration 8418][Wall Clock 380.563751531s] Trained 120 records in 0.043427142 seconds. Throughput is 2763.2488 records/second. Loss is 0.1491856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037266154878139676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 50280/60000][Iteration 8419][Wall Clock 380.603910781s] Trained 120 records in 0.04015925 seconds. Throughput is 2988.1035 records/second. Loss is 0.1922419. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003726337755254136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 50400/60000][Iteration 8420][Wall Clock 380.644159578s] Trained 120 records in 0.040248797 seconds. Throughput is 2981.4556 records/second. Loss is 0.13549921. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037260600640882328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 50520/60000][Iteration 8421][Wall Clock 380.703366674s] Trained 120 records in 0.059207096 seconds. Throughput is 2026.784 records/second. Loss is 0.15430753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037257824143070045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 50640/60000][Iteration 8422][Wall Clock 380.75581093s] Trained 120 records in 0.052444256 seconds. Throughput is 2288.1438 records/second. Loss is 0.12699454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037255048059011996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 50760/60000][Iteration 8423][Wall Clock 380.795964216s] Trained 120 records in 0.040153286 seconds. Throughput is 2988.5474 records/second. Loss is 0.11148815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037252272388615705. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 50880/60000][Iteration 8424][Wall Clock 380.83588359s] Trained 120 records in 0.039919374 seconds. Throughput is 3006.0593 records/second. Loss is 0.2002326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003724949713178872. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51000/60000][Iteration 8425][Wall Clock 380.876656074s] Trained 120 records in 0.040772484 seconds. Throughput is 2943.1614 records/second. Loss is 0.18564035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003724672228843862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51120/60000][Iteration 8426][Wall Clock 380.916783089s] Trained 120 records in 0.040127015 seconds. Throughput is 2990.504 records/second. Loss is 0.14627565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037243947858473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51240/60000][Iteration 8427][Wall Clock 380.956885989s] Trained 120 records in 0.0401029 seconds. Throughput is 2992.3025 records/second. Loss is 0.2406711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037241173841799495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51360/60000][Iteration 8428][Wall Clock 380.997600094s] Trained 120 records in 0.040714105 seconds. Throughput is 2947.3816 records/second. Loss is 0.11476304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003723840023832576. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51480/60000][Iteration 8429][Wall Clock 381.038453159s] Trained 120 records in 0.040853065 seconds. Throughput is 2937.3562 records/second. Loss is 0.09051444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037235627047959487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51600/60000][Iteration 8430][Wall Clock 381.0887779s] Trained 120 records in 0.050324741 seconds. Throughput is 2384.513 records/second. Loss is 0.2233626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003723285427060838. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51720/60000][Iteration 8431][Wall Clock 381.131996873s] Trained 120 records in 0.043218973 seconds. Throughput is 2776.5583 records/second. Loss is 0.106115974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037230081906180195. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51840/60000][Iteration 8432][Wall Clock 381.172542632s] Trained 120 records in 0.040545759 seconds. Throughput is 2959.6191 records/second. Loss is 0.1298835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003722730995458268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 51960/60000][Iteration 8433][Wall Clock 381.214480629s] Trained 120 records in 0.041937997 seconds. Throughput is 2861.3672 records/second. Loss is 0.10536055. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003722453841572365. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 52080/60000][Iteration 8434][Wall Clock 381.256877426s] Trained 120 records in 0.042396797 seconds. Throughput is 2830.4023 records/second. Loss is 0.1563807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037221767289510902. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 52200/60000][Iteration 8435][Wall Clock 381.298512334s] Trained 120 records in 0.041634908 seconds. Throughput is 2882.1968 records/second. Loss is 0.16465397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003721899657585232. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 52320/60000][Iteration 8436][Wall Clock 381.341463112s] Trained 120 records in 0.042950778 seconds. Throughput is 2793.8958 records/second. Loss is 0.20583655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037216226274655747. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 52440/60000][Iteration 8437][Wall Clock 381.381393404s] Trained 120 records in 0.039930292 seconds. Throughput is 3005.2373 records/second. Loss is 0.12408026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003721345638582912. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 52560/60000][Iteration 8438][Wall Clock 381.420995935s] Trained 120 records in 0.039602531 seconds. Throughput is 3030.1094 records/second. Loss is 0.17952423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003721068690928034. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 52680/60000][Iteration 8439][Wall Clock 381.460558694s] Trained 120 records in 0.039562759 seconds. Throughput is 3033.1555 records/second. Loss is 0.21153316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037207917844917404. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:27 INFO  DistriOptimizer$:406 - [Epoch 17 52800/60000][Iteration 8440][Wall Clock 381.501085917s] Trained 120 records in 0.040527223 seconds. Throughput is 2960.9727 records/second. Loss is 0.12827578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003720514919264826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 52920/60000][Iteration 8441][Wall Clock 381.541098143s] Trained 120 records in 0.040012226 seconds. Throughput is 2999.0833 records/second. Loss is 0.20219609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003720238095238095. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53040/60000][Iteration 8442][Wall Clock 381.582788537s] Trained 120 records in 0.041690394 seconds. Throughput is 2878.3608 records/second. Loss is 0.16333215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003719961312402351. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53160/60000][Iteration 8443][Wall Clock 381.624214658s] Trained 120 records in 0.041426121 seconds. Throughput is 2896.723 records/second. Loss is 0.19543754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037196845707484004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53280/60000][Iteration 8444][Wall Clock 381.663674218s] Trained 120 records in 0.03945956 seconds. Throughput is 3041.0881 records/second. Loss is 0.2680942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037194078702670534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53400/60000][Iteration 8445][Wall Clock 381.703863398s] Trained 120 records in 0.04018918 seconds. Throughput is 2985.8782 records/second. Loss is 0.24392599. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037191312109491224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53520/60000][Iteration 8446][Wall Clock 381.749245863s] Trained 120 records in 0.045382465 seconds. Throughput is 2644.193 records/second. Loss is 0.09069328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003718854592785422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53640/60000][Iteration 8447][Wall Clock 381.798221204s] Trained 120 records in 0.048975341 seconds. Throughput is 2450.2126 records/second. Loss is 0.24181794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003718578015766771. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53760/60000][Iteration 8448][Wall Clock 381.837845964s] Trained 120 records in 0.03962476 seconds. Throughput is 3028.4094 records/second. Loss is 0.09602524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003718301479883989. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 53880/60000][Iteration 8449][Wall Clock 381.877363153s] Trained 120 records in 0.039517189 seconds. Throughput is 3036.653 records/second. Loss is 0.14394751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037180249851279. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54000/60000][Iteration 8450][Wall Clock 381.918053454s] Trained 120 records in 0.040690301 seconds. Throughput is 2949.1057 records/second. Loss is 0.09386948. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037177485314893303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54120/60000][Iteration 8451][Wall Clock 381.958303922s] Trained 120 records in 0.040250468 seconds. Throughput is 2981.3318 records/second. Loss is 0.11261811. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003717472118959107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54240/60000][Iteration 8452][Wall Clock 381.999563799s] Trained 120 records in 0.041259877 seconds. Throughput is 2908.3945 records/second. Loss is 0.16166736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003717195747528065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54360/60000][Iteration 8453][Wall Clock 382.041742573s] Trained 120 records in 0.042178774 seconds. Throughput is 2845.033 records/second. Loss is 0.19454248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003716919417187035. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54480/60000][Iteration 8454][Wall Clock 382.082900675s] Trained 120 records in 0.041158102 seconds. Throughput is 2915.5864 records/second. Loss is 0.25535473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037166431279268566. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54600/60000][Iteration 8455][Wall Clock 382.127557579s] Trained 120 records in 0.044656904 seconds. Throughput is 2687.1545 records/second. Loss is 0.13543923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037163668797383673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54720/60000][Iteration 8456][Wall Clock 382.168564797s] Trained 120 records in 0.041007218 seconds. Throughput is 2926.3142 records/second. Loss is 0.0752688. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003716090672612412. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54840/60000][Iteration 8457][Wall Clock 382.22086613s] Trained 120 records in 0.052301333 seconds. Throughput is 2294.3967 records/second. Loss is 0.08895139. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003715814506539833. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 54960/60000][Iteration 8458][Wall Clock 382.262409168s] Trained 120 records in 0.041543038 seconds. Throughput is 2888.5708 records/second. Loss is 0.23693825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037155383815114813. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 55080/60000][Iteration 8459][Wall Clock 382.303032779s] Trained 120 records in 0.040623611 seconds. Throughput is 2953.947 records/second. Loss is 0.21210513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037152622975182045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 55200/60000][Iteration 8460][Wall Clock 382.342794023s] Trained 120 records in 0.039761244 seconds. Throughput is 3018.0142 records/second. Loss is 0.10708416. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037149862545508587. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 55320/60000][Iteration 8461][Wall Clock 382.382821887s] Trained 120 records in 0.040027864 seconds. Throughput is 2997.9116 records/second. Loss is 0.14492339. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003714710252600297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 55440/60000][Iteration 8462][Wall Clock 382.42360603s] Trained 120 records in 0.040784143 seconds. Throughput is 2942.32 records/second. Loss is 0.113045566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037144342916573805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 55560/60000][Iteration 8463][Wall Clock 382.464014536s] Trained 120 records in 0.040408506 seconds. Throughput is 2969.6716 records/second. Loss is 0.20289475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00371415837171297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:28 INFO  DistriOptimizer$:406 - [Epoch 17 55680/60000][Iteration 8464][Wall Clock 382.503972492s] Trained 120 records in 0.039957956 seconds. Throughput is 3003.1567 records/second. Loss is 0.24216957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003713882492757929. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 55800/60000][Iteration 8465][Wall Clock 382.54441627s] Trained 120 records in 0.040443778 seconds. Throughput is 2967.0818 records/second. Loss is 0.25265834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037136066547831252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 55920/60000][Iteration 8466][Wall Clock 382.58430438s] Trained 120 records in 0.03988811 seconds. Throughput is 3008.4153 records/second. Loss is 0.18334794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003713330857779428. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56040/60000][Iteration 8467][Wall Clock 382.624129928s] Trained 120 records in 0.039825548 seconds. Throughput is 3013.1414 records/second. Loss is 0.18064547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037130551017377097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56160/60000][Iteration 8468][Wall Clock 382.664255384s] Trained 120 records in 0.040125456 seconds. Throughput is 2990.6204 records/second. Loss is 0.13051078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037127793866488456. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56280/60000][Iteration 8469][Wall Clock 382.704307808s] Trained 120 records in 0.040052424 seconds. Throughput is 2996.0732 records/second. Loss is 0.2631629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037125037125037125. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56400/60000][Iteration 8470][Wall Clock 382.745512701s] Trained 120 records in 0.041204893 seconds. Throughput is 2912.2756 records/second. Loss is 0.24316737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003712228079293192. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56520/60000][Iteration 8471][Wall Clock 382.795375344s] Trained 120 records in 0.049862643 seconds. Throughput is 2406.6113 records/second. Loss is 0.13902324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037119524870081666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56640/60000][Iteration 8472][Wall Clock 382.848046089s] Trained 120 records in 0.052670745 seconds. Throughput is 2278.3047 records/second. Loss is 0.15575498. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037116769356395217. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56760/60000][Iteration 8473][Wall Clock 382.892309627s] Trained 120 records in 0.044263538 seconds. Throughput is 2711.035 records/second. Loss is 0.17412177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037114014251781475. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 56880/60000][Iteration 8474][Wall Clock 382.933299168s] Trained 120 records in 0.040989541 seconds. Throughput is 2927.5762 records/second. Loss is 0.12888032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003711125955614933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57000/60000][Iteration 8475][Wall Clock 382.974438629s] Trained 120 records in 0.041139461 seconds. Throughput is 2916.9075 records/second. Loss is 0.1559837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003710850526940775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57120/60000][Iteration 8476][Wall Clock 383.015524957s] Trained 120 records in 0.041086328 seconds. Throughput is 2920.6797 records/second. Loss is 0.12378068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037105751391465673. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57240/60000][Iteration 8477][Wall Clock 383.056293091s] Trained 120 records in 0.040768134 seconds. Throughput is 2943.4753 records/second. Loss is 0.12036748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037102997922232117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57360/60000][Iteration 8478][Wall Clock 383.098180351s] Trained 120 records in 0.04188726 seconds. Throughput is 2864.8328 records/second. Loss is 0.14693505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037100244861616085. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57480/60000][Iteration 8479][Wall Clock 383.139850885s] Trained 120 records in 0.041670534 seconds. Throughput is 2879.7327 records/second. Loss is 0.16286689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003709749220952664. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57600/60000][Iteration 8480][Wall Clock 383.180224822s] Trained 120 records in 0.040373937 seconds. Throughput is 2972.2146 records/second. Loss is 0.10487394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037094739965872836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57720/60000][Iteration 8481][Wall Clock 383.220409907s] Trained 120 records in 0.040185085 seconds. Throughput is 2986.1824 records/second. Loss is 0.157605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037091988130563795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57840/60000][Iteration 8482][Wall Clock 383.26056375s] Trained 120 records in 0.040153843 seconds. Throughput is 2988.506 records/second. Loss is 0.21467295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003708923670350864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 57960/60000][Iteration 8483][Wall Clock 383.30732484s] Trained 120 records in 0.04676109 seconds. Throughput is 2566.236 records/second. Loss is 0.15303947. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037086485684616525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 58080/60000][Iteration 8484][Wall Clock 383.355718354s] Trained 120 records in 0.048393514 seconds. Throughput is 2479.6711 records/second. Loss is 0.114601254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003708373507379663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 58200/60000][Iteration 8485][Wall Clock 383.395611489s] Trained 120 records in 0.039893135 seconds. Throughput is 3008.0364 records/second. Loss is 0.17495674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003708098487095817. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 58320/60000][Iteration 8486][Wall Clock 383.436157475s] Trained 120 records in 0.040545986 seconds. Throughput is 2959.6025 records/second. Loss is 0.19120121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037078235076010383. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 58440/60000][Iteration 8487][Wall Clock 383.475920151s] Trained 120 records in 0.039762676 seconds. Throughput is 3017.9055 records/second. Loss is 0.13282603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037075485688862525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:29 INFO  DistriOptimizer$:406 - [Epoch 17 58560/60000][Iteration 8488][Wall Clock 383.515777635s] Trained 120 records in 0.039857484 seconds. Throughput is 3010.7268 records/second. Loss is 0.18730594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003707273670942389. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 58680/60000][Iteration 8489][Wall Clock 383.556195973s] Trained 120 records in 0.040418338 seconds. Throughput is 2968.9495 records/second. Loss is 0.13763933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00370699881376038. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 58800/60000][Iteration 8490][Wall Clock 383.595587599s] Trained 120 records in 0.039391626 seconds. Throughput is 3046.3328 records/second. Loss is 0.1284644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003706723997331159. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 58920/60000][Iteration 8491][Wall Clock 383.63494375s] Trained 120 records in 0.039356151 seconds. Throughput is 3049.0789 records/second. Loss is 0.16640505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003706449221645663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59040/60000][Iteration 8492][Wall Clock 383.676935408s] Trained 120 records in 0.041991658 seconds. Throughput is 2857.7104 records/second. Loss is 0.12537985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037061744866948338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59160/60000][Iteration 8493][Wall Clock 383.715918863s] Trained 120 records in 0.038983455 seconds. Throughput is 3078.2288 records/second. Loss is 0.2662174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003705899792469611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59280/60000][Iteration 8494][Wall Clock 383.757647462s] Trained 120 records in 0.041728599 seconds. Throughput is 2875.7253 records/second. Loss is 0.13905473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037056251389609427. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59400/60000][Iteration 8495][Wall Clock 383.798685026s] Trained 120 records in 0.041037564 seconds. Throughput is 2924.1501 records/second. Loss is 0.12758979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037053505261597742. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59520/60000][Iteration 8496][Wall Clock 383.846705748s] Trained 120 records in 0.048020722 seconds. Throughput is 2498.9214 records/second. Loss is 0.13657342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037050759540570586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59640/60000][Iteration 8497][Wall Clock 383.896470913s] Trained 120 records in 0.049765165 seconds. Throughput is 2411.3252 records/second. Loss is 0.16792694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003704801422643746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59760/60000][Iteration 8498][Wall Clock 383.938217644s] Trained 120 records in 0.041746731 seconds. Throughput is 2874.4766 records/second. Loss is 0.13358368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003704526931910795. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 59880/60000][Iteration 8499][Wall Clock 383.978305094s] Trained 120 records in 0.04008745 seconds. Throughput is 2993.4556 records/second. Loss is 0.08373196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037042524818491625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:406 - [Epoch 17 60000/60000][Iteration 8500][Wall Clock 384.018436414s] Trained 120 records in 0.04013132 seconds. Throughput is 2990.1833 records/second. Loss is 0.12652192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037039780724498115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:30 INFO  DistriOptimizer$:451 - [Epoch 17 60000/60000][Iteration 8500][Wall Clock 384.018436414s] Epoch finished. Wall clock time is 384812.495815 ms
2019-10-23 15:59:30 INFO  DistriOptimizer$:111 - [Epoch 17 60000/60000][Iteration 8500][Wall Clock 384.018436414s] Validate model...
2019-10-23 15:59:31 INFO  DistriOptimizer$:177 - [Epoch 17 60000/60000][Iteration 8500][Wall Clock 384.018436414s] validate model throughput is 14984.713 records/second
2019-10-23 15:59:31 INFO  DistriOptimizer$:180 - [Epoch 17 60000/60000][Iteration 8500][Wall Clock 384.018436414s] Top1Accuracy is Accuracy(correct: 9555, count: 10000, accuracy: 0.9555)
2019-10-23 15:59:31 INFO  DistriOptimizer$:220 - [Wall Clock 384.812495815s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:59:31 INFO  DistriOptimizer$:225 - [Wall Clock 384.812495815s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 120/60000][Iteration 8501][Wall Clock 384.858831762s] Trained 120 records in 0.046335947 seconds. Throughput is 2589.782 records/second. Loss is 0.15969849. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037037037037037034. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 240/60000][Iteration 8502][Wall Clock 384.899470039s] Trained 120 records in 0.040638277 seconds. Throughput is 2952.881 records/second. Loss is 0.21370097. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037034293756018073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 360/60000][Iteration 8503][Wall Clock 384.939642657s] Trained 120 records in 0.040172618 seconds. Throughput is 2987.1094 records/second. Loss is 0.21331094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003703155088135091. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 480/60000][Iteration 8504][Wall Clock 384.979467284s] Trained 120 records in 0.039824627 seconds. Throughput is 3013.211 records/second. Loss is 0.24819025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003702880841294527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 600/60000][Iteration 8505][Wall Clock 385.020389051s] Trained 120 records in 0.040921767 seconds. Throughput is 2932.4248 records/second. Loss is 0.17596559. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00370260663507109. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 720/60000][Iteration 8506][Wall Clock 385.061755925s] Trained 120 records in 0.041366874 seconds. Throughput is 2900.8718 records/second. Loss is 0.17310622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037023324694557573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 840/60000][Iteration 8507][Wall Clock 385.103243677s] Trained 120 records in 0.041487752 seconds. Throughput is 2892.42 records/second. Loss is 0.14809817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037020583444395084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 960/60000][Iteration 8508][Wall Clock 385.145253019s] Trained 120 records in 0.042009342 seconds. Throughput is 2856.5076 records/second. Loss is 0.19201173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037017842600133265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1080/60000][Iteration 8509][Wall Clock 385.20297453s] Trained 120 records in 0.057721511 seconds. Throughput is 2078.9478 records/second. Loss is 0.13609192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037015102161681965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1200/60000][Iteration 8510][Wall Clock 385.245404151s] Trained 120 records in 0.042429621 seconds. Throughput is 2828.213 records/second. Loss is 0.31876895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003701236212895107. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1320/60000][Iteration 8511][Wall Clock 385.286454219s] Trained 120 records in 0.041050068 seconds. Throughput is 2923.2593 records/second. Loss is 0.2797508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037009622501850484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1440/60000][Iteration 8512][Wall Clock 385.327037127s] Trained 120 records in 0.040582908 seconds. Throughput is 2956.91 records/second. Loss is 0.09410908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003700688328029013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1560/60000][Iteration 8513][Wall Clock 385.367912671s] Trained 120 records in 0.040875544 seconds. Throughput is 2935.7407 records/second. Loss is 0.20568341. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003700414446417999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1680/60000][Iteration 8514][Wall Clock 385.408368921s] Trained 120 records in 0.04045625 seconds. Throughput is 2966.1672 records/second. Loss is 0.2552148. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0037001406053430025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1800/60000][Iteration 8515][Wall Clock 385.448846202s] Trained 120 records in 0.040477281 seconds. Throughput is 2964.6262 records/second. Loss is 0.16102953. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036998668047950275. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 1920/60000][Iteration 8516][Wall Clock 385.489546817s] Trained 120 records in 0.040700615 seconds. Throughput is 2948.3584 records/second. Loss is 0.1333858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036995930447650755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 2040/60000][Iteration 8517][Wall Clock 385.530240286s] Trained 120 records in 0.040693469 seconds. Throughput is 2948.8762 records/second. Loss is 0.1465612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036993193252441554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:31 INFO  DistriOptimizer$:406 - [Epoch 18 2160/60000][Iteration 8518][Wall Clock 385.571756907s] Trained 120 records in 0.041516621 seconds. Throughput is 2890.4087 records/second. Loss is 0.15406065. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036990456462232743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 2280/60000][Iteration 8519][Wall Clock 385.613565385s] Trained 120 records in 0.041808478 seconds. Throughput is 2870.2312 records/second. Loss is 0.13477913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003698772007693446. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 2400/60000][Iteration 8520][Wall Clock 385.663625139s] Trained 120 records in 0.050059754 seconds. Throughput is 2397.1353 records/second. Loss is 0.2127333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003698498409645684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 2520/60000][Iteration 8521][Wall Clock 385.707733272s] Trained 120 records in 0.044108133 seconds. Throughput is 2720.5867 records/second. Loss is 0.09595442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036982248520710057. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 2640/60000][Iteration 8522][Wall Clock 385.747801029s] Trained 120 records in 0.040067757 seconds. Throughput is 2994.9268 records/second. Loss is 0.08435103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003697951334960432. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 2760/60000][Iteration 8523][Wall Clock 385.788160854s] Trained 120 records in 0.040359825 seconds. Throughput is 2973.2537 records/second. Loss is 0.16147034. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036976778583049843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 2880/60000][Iteration 8524][Wall Clock 385.827944363s] Trained 120 records in 0.039783509 seconds. Throughput is 3016.3252 records/second. Loss is 0.15689203. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036974044220956888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3000/60000][Iteration 8525][Wall Clock 385.867604985s] Trained 120 records in 0.039660622 seconds. Throughput is 3025.6711 records/second. Loss is 0.15965857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003697131026323573. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3120/60000][Iteration 8526][Wall Clock 385.907752103s] Trained 120 records in 0.040147118 seconds. Throughput is 2989.0066 records/second. Loss is 0.24119745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036968576709796672. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3240/60000][Iteration 8527][Wall Clock 385.947973597s] Trained 120 records in 0.040221494 seconds. Throughput is 2983.4795 records/second. Loss is 0.17680788. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003696584356055005. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3360/60000][Iteration 8528][Wall Clock 385.992597466s] Trained 120 records in 0.044623869 seconds. Throughput is 2689.1438 records/second. Loss is 0.14716668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036963110815406226. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3480/60000][Iteration 8529][Wall Clock 386.03412719s] Trained 120 records in 0.041529724 seconds. Throughput is 2889.4968 records/second. Loss is 0.07813371. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003696037847427558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3600/60000][Iteration 8530][Wall Clock 386.074520951s] Trained 120 records in 0.040393761 seconds. Throughput is 2970.7556 records/second. Loss is 0.23318727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003695764653706852. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3720/60000][Iteration 8531][Wall Clock 386.115405928s] Trained 120 records in 0.040884977 seconds. Throughput is 2935.0635 records/second. Loss is 0.1807631. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036954915003695487. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3840/60000][Iteration 8532][Wall Clock 386.155282222s] Trained 120 records in 0.039876294 seconds. Throughput is 3009.307 records/second. Loss is 0.14486001. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003695218387406696. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 3960/60000][Iteration 8533][Wall Clock 386.195705748s] Trained 120 records in 0.040423526 seconds. Throughput is 2968.5684 records/second. Loss is 0.09554946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036949453148093403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4080/60000][Iteration 8534][Wall Clock 386.235168942s] Trained 120 records in 0.039463194 seconds. Throughput is 3040.8083 records/second. Loss is 0.23885657. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036946722825685363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4200/60000][Iteration 8535][Wall Clock 386.285268645s] Trained 120 records in 0.050099703 seconds. Throughput is 2395.2236 records/second. Loss is 0.09952608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003694399290675336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4320/60000][Iteration 8536][Wall Clock 386.328450746s] Trained 120 records in 0.043182101 seconds. Throughput is 2778.9292 records/second. Loss is 0.1248897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003694126339120798. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4440/60000][Iteration 8537][Wall Clock 386.369959398s] Trained 120 records in 0.041508652 seconds. Throughput is 2890.9636 records/second. Loss is 0.13065967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036938534278959808. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4560/60000][Iteration 8538][Wall Clock 386.411178923s] Trained 120 records in 0.041219525 seconds. Throughput is 2911.2417 records/second. Loss is 0.078320734. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036935805569919484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4680/60000][Iteration 8539][Wall Clock 386.451545288s] Trained 120 records in 0.040366365 seconds. Throughput is 2972.772 records/second. Loss is 0.28704727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036933077263997635. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4800/60000][Iteration 8540][Wall Clock 386.491788078s] Trained 120 records in 0.04024279 seconds. Throughput is 2981.9006 records/second. Loss is 0.1477011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003693034936110496. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 4920/60000][Iteration 8541][Wall Clock 386.531419181s] Trained 120 records in 0.039631103 seconds. Throughput is 3027.9248 records/second. Loss is 0.2698529. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003692762186115214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:32 INFO  DistriOptimizer$:406 - [Epoch 18 5040/60000][Iteration 8542][Wall Clock 386.570714141s] Trained 120 records in 0.03929496 seconds. Throughput is 3053.8267 records/second. Loss is 0.19801378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003692489476404992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 5160/60000][Iteration 8543][Wall Clock 386.611124667s] Trained 120 records in 0.040410526 seconds. Throughput is 2969.5234 records/second. Loss is 0.12509285. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036922168069709054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 5280/60000][Iteration 8544][Wall Clock 386.652984733s] Trained 120 records in 0.041860066 seconds. Throughput is 2866.694 records/second. Loss is 0.15070206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036919441778040314. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 5400/60000][Iteration 8545][Wall Clock 386.697735535s] Trained 120 records in 0.044750802 seconds. Throughput is 2681.516 records/second. Loss is 0.1390509. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036916715888954516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 5520/60000][Iteration 8546][Wall Clock 386.742597825s] Trained 120 records in 0.04486229 seconds. Throughput is 2674.8523 records/second. Loss is 0.13661891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036913990402362494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 5640/60000][Iteration 8547][Wall Clock 386.786333799s] Trained 120 records in 0.043735974 seconds. Throughput is 2743.7368 records/second. Loss is 0.21237567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003691126531817511. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 5760/60000][Iteration 8548][Wall Clock 386.826053179s] Trained 120 records in 0.03971938 seconds. Throughput is 3021.195 records/second. Loss is 0.097167775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003690854063630324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 5880/60000][Iteration 8549][Wall Clock 386.865786849s] Trained 120 records in 0.03973367 seconds. Throughput is 3020.1086 records/second. Loss is 0.115918204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003690581635665781. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6000/60000][Iteration 8550][Wall Clock 386.906082057s] Trained 120 records in 0.040295208 seconds. Throughput is 2978.0215 records/second. Loss is 0.20364484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036903092479149756. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6120/60000][Iteration 8551][Wall Clock 386.946237477s] Trained 120 records in 0.04015542 seconds. Throughput is 2988.3887 records/second. Loss is 0.15132158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003690036900369004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6240/60000][Iteration 8552][Wall Clock 386.986515049s] Trained 120 records in 0.040277572 seconds. Throughput is 2979.3257 records/second. Loss is 0.14134258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003689764593018965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6360/60000][Iteration 8553][Wall Clock 387.026985265s] Trained 120 records in 0.040470216 seconds. Throughput is 2965.1436 records/second. Loss is 0.20026432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036894923258559624. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6480/60000][Iteration 8554][Wall Clock 387.066872538s] Trained 120 records in 0.039887273 seconds. Throughput is 3008.4785 records/second. Loss is 0.16261497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036892200988710984. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6600/60000][Iteration 8555][Wall Clock 387.107926197s] Trained 120 records in 0.041053659 seconds. Throughput is 2923.0037 records/second. Loss is 0.06706977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003688947912055482. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6720/60000][Iteration 8556][Wall Clock 387.14861702s] Trained 120 records in 0.040690823 seconds. Throughput is 2949.0679 records/second. Loss is 0.22766879. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003688675765400221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6840/60000][Iteration 8557][Wall Clock 387.188583124s] Trained 120 records in 0.039966104 seconds. Throughput is 3002.5444 records/second. Loss is 0.19983393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00368840365889643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 6960/60000][Iteration 8558][Wall Clock 387.22920377s] Trained 120 records in 0.040620646 seconds. Throughput is 2954.1626 records/second. Loss is 0.19729568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036881315925352213. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7080/60000][Iteration 8559][Wall Clock 387.269270898s] Trained 120 records in 0.040067128 seconds. Throughput is 2994.9739 records/second. Loss is 0.21674104. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036878595663077155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7200/60000][Iteration 8560][Wall Clock 387.309689471s] Trained 120 records in 0.040418573 seconds. Throughput is 2968.9321 records/second. Loss is 0.12652637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00368758758020503. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7320/60000][Iteration 8561][Wall Clock 387.350766721s] Trained 120 records in 0.04107725 seconds. Throughput is 2921.3252 records/second. Loss is 0.24809235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003687315634218289. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7440/60000][Iteration 8562][Wall Clock 387.406646299s] Trained 120 records in 0.055879578 seconds. Throughput is 2147.475 records/second. Loss is 0.19991086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003687043728338618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7560/60000][Iteration 8563][Wall Clock 387.450493005s] Trained 120 records in 0.043846706 seconds. Throughput is 2736.8076 records/second. Loss is 0.15077437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036867718625571448. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7680/60000][Iteration 8564][Wall Clock 387.491196546s] Trained 120 records in 0.040703541 seconds. Throughput is 2948.1462 records/second. Loss is 0.12638703. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036865000368650003. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7800/60000][Iteration 8565][Wall Clock 387.534631716s] Trained 120 records in 0.04343517 seconds. Throughput is 2762.738 records/second. Loss is 0.099994294. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036862282512533174. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:33 INFO  DistriOptimizer$:406 - [Epoch 18 7920/60000][Iteration 8566][Wall Clock 387.575164944s] Trained 120 records in 0.040533228 seconds. Throughput is 2960.534 records/second. Loss is 0.15145697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036859565057132324. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8040/60000][Iteration 8567][Wall Clock 387.615107257s] Trained 120 records in 0.039942313 seconds. Throughput is 3004.3328 records/second. Loss is 0.22554325. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003685684800235884. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8160/60000][Iteration 8568][Wall Clock 387.656026214s] Trained 120 records in 0.040918957 seconds. Throughput is 2932.626 records/second. Loss is 0.16370386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036854131348124123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8280/60000][Iteration 8569][Wall Clock 387.697369911s] Trained 120 records in 0.041343697 seconds. Throughput is 2902.498 records/second. Loss is 0.16257162. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036851415094339623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8400/60000][Iteration 8570][Wall Clock 387.746193859s] Trained 120 records in 0.048823948 seconds. Throughput is 2457.8103 records/second. Loss is 0.2067511. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00368486992409168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8520/60000][Iteration 8571][Wall Clock 387.789107556s] Trained 120 records in 0.042913697 seconds. Throughput is 2796.31 records/second. Loss is 0.14224236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003684598378776713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8640/60000][Iteration 8572][Wall Clock 387.82889868s] Trained 120 records in 0.039791124 seconds. Throughput is 3015.7478 records/second. Loss is 0.23168217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003684326873480215. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8760/60000][Iteration 8573][Wall Clock 387.868537911s] Trained 120 records in 0.039639231 seconds. Throughput is 3027.304 records/second. Loss is 0.18862864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003684055408193339. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 8880/60000][Iteration 8574][Wall Clock 387.908517019s] Trained 120 records in 0.039979108 seconds. Throughput is 3001.5676 records/second. Loss is 0.2298085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036837839829072425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9000/60000][Iteration 8575][Wall Clock 387.949087983s] Trained 120 records in 0.040570964 seconds. Throughput is 2957.7805 records/second. Loss is 0.1810161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036835125976130835. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9120/60000][Iteration 8576][Wall Clock 387.989609442s] Trained 120 records in 0.040521459 seconds. Throughput is 2961.394 records/second. Loss is 0.1811635. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003683241252302026. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9240/60000][Iteration 8577][Wall Clock 388.030797296s] Trained 120 records in 0.041187854 seconds. Throughput is 2913.4805 records/second. Loss is 0.22911228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036829699469652323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9360/60000][Iteration 8578][Wall Clock 388.071719814s] Trained 120 records in 0.040922518 seconds. Throughput is 2932.3708 records/second. Loss is 0.20766462. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036826986815938724. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9480/60000][Iteration 8579][Wall Clock 388.113410984s] Trained 120 records in 0.04169117 seconds. Throughput is 2878.3074 records/second. Loss is 0.3399202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003682427456179113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9600/60000][Iteration 8580][Wall Clock 388.155625769s] Trained 120 records in 0.042214785 seconds. Throughput is 2842.606 records/second. Loss is 0.15052673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036821562707121296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9720/60000][Iteration 8581][Wall Clock 388.197070228s] Trained 120 records in 0.041444459 seconds. Throughput is 2895.4414 records/second. Loss is 0.12477962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003681885125184094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9840/60000][Iteration 8582][Wall Clock 388.237868756s] Trained 120 records in 0.040798528 seconds. Throughput is 2941.2827 records/second. Loss is 0.13024785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036816140195861866. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 9960/60000][Iteration 8583][Wall Clock 388.277471634s] Trained 120 records in 0.039602878 seconds. Throughput is 3030.0828 records/second. Loss is 0.12490842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003681342953909586. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 10080/60000][Iteration 8584][Wall Clock 388.320352362s] Trained 120 records in 0.042880728 seconds. Throughput is 2798.46 records/second. Loss is 0.12085005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003681071928145476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 10200/60000][Iteration 8585][Wall Clock 388.361260375s] Trained 120 records in 0.040908013 seconds. Throughput is 2933.4106 records/second. Loss is 0.20652089. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036808009422850414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 10320/60000][Iteration 8586][Wall Clock 388.401969925s] Trained 120 records in 0.04070955 seconds. Throughput is 2947.7112 records/second. Loss is 0.1733498. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00368052999631947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 10440/60000][Iteration 8587][Wall Clock 388.442009944s] Trained 120 records in 0.040040019 seconds. Throughput is 2997.0015 records/second. Loss is 0.13352206. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003680259090239953. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 10560/60000][Iteration 8588][Wall Clock 388.482280871s] Trained 120 records in 0.040270927 seconds. Throughput is 2979.8171 records/second. Loss is 0.19350383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036799882240376833. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 10680/60000][Iteration 8589][Wall Clock 388.53545487s] Trained 120 records in 0.053173999 seconds. Throughput is 2256.742 records/second. Loss is 0.16788197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036797173977038563. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:34 INFO  DistriOptimizer$:406 - [Epoch 18 10800/60000][Iteration 8590][Wall Clock 388.580985766s] Trained 120 records in 0.045530896 seconds. Throughput is 2635.573 records/second. Loss is 0.13903166. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036794466112296713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 10920/60000][Iteration 8591][Wall Clock 388.621419314s] Trained 120 records in 0.040433548 seconds. Throughput is 2967.8325 records/second. Loss is 0.11122667. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003679175864606328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11040/60000][Iteration 8592][Wall Clock 388.662232931s] Trained 120 records in 0.040813617 seconds. Throughput is 2940.195 records/second. Loss is 0.15150848. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003678905157825031. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11160/60000][Iteration 8593][Wall Clock 388.70328436s] Trained 120 records in 0.041051429 seconds. Throughput is 2923.1626 records/second. Loss is 0.1852421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036786344908769867. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11280/60000][Iteration 8594][Wall Clock 388.744925225s] Trained 120 records in 0.041640865 seconds. Throughput is 2881.7844 records/second. Loss is 0.14395231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003678363863753402. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11400/60000][Iteration 8595][Wall Clock 388.786051946s] Trained 120 records in 0.041126721 seconds. Throughput is 2917.811 records/second. Loss is 0.15216824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003678093276445491. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11520/60000][Iteration 8596][Wall Clock 388.826158897s] Trained 120 records in 0.040106951 seconds. Throughput is 2992.0 records/second. Loss is 0.10041534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036778227289444645. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11640/60000][Iteration 8597][Wall Clock 388.872704793s] Trained 120 records in 0.046545896 seconds. Throughput is 2578.1006 records/second. Loss is 0.13936569. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036775522212415417. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11760/60000][Iteration 8598][Wall Clock 388.917586552s] Trained 120 records in 0.044881759 seconds. Throughput is 2673.6921 records/second. Loss is 0.16089569. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036772817533279397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 11880/60000][Iteration 8599][Wall Clock 388.957478217s] Trained 120 records in 0.039891665 seconds. Throughput is 3008.1472 records/second. Loss is 0.15366085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003677011325194882. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12000/60000][Iteration 8600][Wall Clock 388.997175574s] Trained 120 records in 0.039697357 seconds. Throughput is 3022.8713 records/second. Loss is 0.1653841. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036767409368335907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12120/60000][Iteration 8601][Wall Clock 389.036846518s] Trained 120 records in 0.039670944 seconds. Throughput is 3024.8838 records/second. Loss is 0.15519282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036764705882352945. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12240/60000][Iteration 8602][Wall Clock 389.076409257s] Trained 120 records in 0.039562739 seconds. Throughput is 3033.157 records/second. Loss is 0.12961783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036762002793912212. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12360/60000][Iteration 8603][Wall Clock 389.119730898s] Trained 120 records in 0.043321641 seconds. Throughput is 2769.9783 records/second. Loss is 0.12998538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003675930010292604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12480/60000][Iteration 8604][Wall Clock 389.160169644s] Trained 120 records in 0.040438746 seconds. Throughput is 2967.4512 records/second. Loss is 0.20014372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003675659780930677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12600/60000][Iteration 8605][Wall Clock 389.200268963s] Trained 120 records in 0.040099319 seconds. Throughput is 2992.5696 records/second. Loss is 0.15462658. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036753895912966772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12720/60000][Iteration 8606][Wall Clock 389.239935755s] Trained 120 records in 0.039666792 seconds. Throughput is 3025.2007 records/second. Loss is 0.119075455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003675119441381845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12840/60000][Iteration 8607][Wall Clock 389.279484738s] Trained 120 records in 0.039548983 seconds. Throughput is 3034.2122 records/second. Loss is 0.12716995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003674849331177422. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 12960/60000][Iteration 8608][Wall Clock 389.319802446s] Trained 120 records in 0.040317708 seconds. Throughput is 2976.3599 records/second. Loss is 0.12938459. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036745792606746527. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 13080/60000][Iteration 8609][Wall Clock 389.359395809s] Trained 120 records in 0.039593363 seconds. Throughput is 3030.811 records/second. Loss is 0.18170759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036743092298647854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 13200/60000][Iteration 8610][Wall Clock 389.398991338s] Trained 120 records in 0.039595529 seconds. Throughput is 3030.6453 records/second. Loss is 0.16363025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00367403923873907. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 13320/60000][Iteration 8611][Wall Clock 389.439047021s] Trained 120 records in 0.040055683 seconds. Throughput is 2995.8293 records/second. Loss is 0.13983731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036737692872887582. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 13440/60000][Iteration 8612][Wall Clock 389.479498758s] Trained 120 records in 0.040451737 seconds. Throughput is 2966.4983 records/second. Loss is 0.08846245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036734993755051064. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 13560/60000][Iteration 8613][Wall Clock 389.52006933s] Trained 120 records in 0.040570572 seconds. Throughput is 2957.8088 records/second. Loss is 0.13594116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003673229503379371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:35 INFO  DistriOptimizer$:406 - [Epoch 18 13680/60000][Iteration 8614][Wall Clock 389.560447984s] Trained 120 records in 0.040378654 seconds. Throughput is 2971.8674 records/second. Loss is 0.1432402. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036729596709028137. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 13800/60000][Iteration 8615][Wall Clock 389.608534502s] Trained 120 records in 0.048086518 seconds. Throughput is 2495.502 records/second. Loss is 0.107826136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036726898780666956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 13920/60000][Iteration 8616][Wall Clock 389.657333038s] Trained 120 records in 0.048798536 seconds. Throughput is 2459.0903 records/second. Loss is 0.1421589. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036724201248622846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14040/60000][Iteration 8617][Wall Clock 389.699544587s] Trained 120 records in 0.042211549 seconds. Throughput is 2842.824 records/second. Loss is 0.14402188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036721504112808456. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14160/60000][Iteration 8618][Wall Clock 389.740197913s] Trained 120 records in 0.040653326 seconds. Throughput is 2951.788 records/second. Loss is 0.21165912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003671880737313652. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14280/60000][Iteration 8619][Wall Clock 389.781375473s] Trained 120 records in 0.04117756 seconds. Throughput is 2914.2087 records/second. Loss is 0.110918745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003671611102951975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14400/60000][Iteration 8620][Wall Clock 389.823530464s] Trained 120 records in 0.042154991 seconds. Throughput is 2846.6382 records/second. Loss is 0.09168336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003671341508187092. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14520/60000][Iteration 8621][Wall Clock 389.864441033s] Trained 120 records in 0.040910569 seconds. Throughput is 2933.2275 records/second. Loss is 0.12557714. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003671071953010279. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14640/60000][Iteration 8622][Wall Clock 389.908355418s] Trained 120 records in 0.043914385 seconds. Throughput is 2732.5898 records/second. Loss is 0.18501829. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003670802437412818. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14760/60000][Iteration 8623][Wall Clock 389.948704986s] Trained 120 records in 0.040349568 seconds. Throughput is 2974.0095 records/second. Loss is 0.14387324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003670532961385993. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 14880/60000][Iteration 8624][Wall Clock 389.998451069s] Trained 120 records in 0.049746083 seconds. Throughput is 2412.2502 records/second. Loss is 0.15655969. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036702635249210892. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15000/60000][Iteration 8625][Wall Clock 390.03922353s] Trained 120 records in 0.040772461 seconds. Throughput is 2943.163 records/second. Loss is 0.14777158. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003669994128009395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15120/60000][Iteration 8626][Wall Clock 390.080187635s] Trained 120 records in 0.040964105 seconds. Throughput is 2929.394 records/second. Loss is 0.12709858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036697247706422016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15240/60000][Iteration 8627][Wall Clock 390.120868487s] Trained 120 records in 0.040680852 seconds. Throughput is 2949.7908 records/second. Loss is 0.12038231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003669455452810803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15360/60000][Iteration 8628][Wall Clock 390.161639904s] Trained 120 records in 0.040771417 seconds. Throughput is 2943.2383 records/second. Loss is 0.16855523. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036691861745064944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15480/60000][Iteration 8629][Wall Clock 390.202094953s] Trained 120 records in 0.040455049 seconds. Throughput is 2966.2551 records/second. Loss is 0.10736642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003668916935720575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15600/60000][Iteration 8630][Wall Clock 390.242681126s] Trained 120 records in 0.040586173 seconds. Throughput is 2956.6719 records/second. Loss is 0.14800765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036686477364443466. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15720/60000][Iteration 8631][Wall Clock 390.283082181s] Trained 120 records in 0.040401055 seconds. Throughput is 2970.2195 records/second. Loss is 0.10786112. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036683785766691126. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15840/60000][Iteration 8632][Wall Clock 390.323435503s] Trained 120 records in 0.040353322 seconds. Throughput is 2973.733 records/second. Loss is 0.18078615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003668109456386178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 15960/60000][Iteration 8633][Wall Clock 390.363567512s] Trained 120 records in 0.040132009 seconds. Throughput is 2990.1318 records/second. Loss is 0.10287526. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036678403755868545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 16080/60000][Iteration 8634][Wall Clock 390.403912829s] Trained 120 records in 0.040345317 seconds. Throughput is 2974.3228 records/second. Loss is 0.13855547. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003667571334262451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 16200/60000][Iteration 8635][Wall Clock 390.444389393s] Trained 120 records in 0.040476564 seconds. Throughput is 2964.6785 records/second. Loss is 0.10799733. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036673023324042837. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 16320/60000][Iteration 8636][Wall Clock 390.485298493s] Trained 120 records in 0.0409091 seconds. Throughput is 2933.3328 records/second. Loss is 0.21997085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036670333700036667. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 16440/60000][Iteration 8637][Wall Clock 390.526031492s] Trained 120 records in 0.040732999 seconds. Throughput is 2946.0144 records/second. Loss is 0.16520604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003666764447051922. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:36 INFO  DistriOptimizer$:406 - [Epoch 18 16560/60000][Iteration 8638][Wall Clock 390.566153772s] Trained 120 records in 0.04012228 seconds. Throughput is 2990.857 records/second. Loss is 0.10675664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036664955635403677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 16680/60000][Iteration 8639][Wall Clock 390.606743827s] Trained 120 records in 0.040590055 seconds. Throughput is 2956.3892 records/second. Loss is 0.1702605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003666226719460332. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 16800/60000][Iteration 8640][Wall Clock 390.647193373s] Trained 120 records in 0.040449546 seconds. Throughput is 2966.659 records/second. Loss is 0.1759231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003665957914803138. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 16920/60000][Iteration 8641][Wall Clock 390.691434654s] Trained 120 records in 0.044241281 seconds. Throughput is 2712.399 records/second. Loss is 0.174997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036656891495601175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17040/60000][Iteration 8642][Wall Clock 390.74123151s] Trained 120 records in 0.049796856 seconds. Throughput is 2409.7905 records/second. Loss is 0.11558817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003665420423722601. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17160/60000][Iteration 8643][Wall Clock 390.790965803s] Trained 120 records in 0.049734293 seconds. Throughput is 2412.822 records/second. Loss is 0.08186187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003665151737281923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17280/60000][Iteration 8644][Wall Clock 390.835313207s] Trained 120 records in 0.044347404 seconds. Throughput is 2705.908 records/second. Loss is 0.14839949. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036648830902294214. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17400/60000][Iteration 8645][Wall Clock 390.877399298s] Trained 120 records in 0.042086091 seconds. Throughput is 2851.2983 records/second. Loss is 0.14541847. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003664614482556435. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17520/60000][Iteration 8646][Wall Clock 390.917177833s] Trained 120 records in 0.039778535 seconds. Throughput is 3016.7024 records/second. Loss is 0.14177844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036643459142543054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17640/60000][Iteration 8647][Wall Clock 390.957022024s] Trained 120 records in 0.039844191 seconds. Throughput is 3011.7312 records/second. Loss is 0.11075222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003664077385314378. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17760/60000][Iteration 8648][Wall Clock 390.99841529s] Trained 120 records in 0.041393266 seconds. Throughput is 2899.0222 records/second. Loss is 0.20696259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003663808895727999. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 17880/60000][Iteration 8649][Wall Clock 391.039876484s] Trained 120 records in 0.041461194 seconds. Throughput is 2894.2725 records/second. Loss is 0.19956213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003663540445486518. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18000/60000][Iteration 8650][Wall Clock 391.087506431s] Trained 120 records in 0.047629947 seconds. Throughput is 2519.4233 records/second. Loss is 0.14951807. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003663272034581288. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18120/60000][Iteration 8651][Wall Clock 391.131569651s] Trained 120 records in 0.04406322 seconds. Throughput is 2723.3596 records/second. Loss is 0.17199768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003663003663003663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18240/60000][Iteration 8652][Wall Clock 391.172534037s] Trained 120 records in 0.040964386 seconds. Throughput is 2929.3738 records/second. Loss is 0.1848611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036627353307450007. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18360/60000][Iteration 8653][Wall Clock 391.213011028s] Trained 120 records in 0.040476991 seconds. Throughput is 2964.6472 records/second. Loss is 0.21072985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036624670377966594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18480/60000][Iteration 8654][Wall Clock 391.253495375s] Trained 120 records in 0.040484347 seconds. Throughput is 2964.1086 records/second. Loss is 0.1660972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003662198784150004. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18600/60000][Iteration 8655][Wall Clock 391.294583821s] Trained 120 records in 0.041088446 seconds. Throughput is 2920.529 records/second. Loss is 0.3010767. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003661930569796396. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18720/60000][Iteration 8656][Wall Clock 391.335987706s] Trained 120 records in 0.041403885 seconds. Throughput is 2898.2786 records/second. Loss is 0.13559318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003661662394727206. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18840/60000][Iteration 8657][Wall Clock 391.376682871s] Trained 120 records in 0.040695165 seconds. Throughput is 2948.7532 records/second. Loss is 0.1344045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036613942589338016. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 18960/60000][Iteration 8658][Wall Clock 391.417121588s] Trained 120 records in 0.040438717 seconds. Throughput is 2967.4534 records/second. Loss is 0.16754441. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003661126162407557. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 19080/60000][Iteration 8659][Wall Clock 391.461190878s] Trained 120 records in 0.04406929 seconds. Throughput is 2722.9846 records/second. Loss is 0.12414315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036608581051398447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 19200/60000][Iteration 8660][Wall Clock 391.502290817s] Trained 120 records in 0.041099939 seconds. Throughput is 2919.7124 records/second. Loss is 0.14694653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036605900871220444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:37 INFO  DistriOptimizer$:406 - [Epoch 18 19320/60000][Iteration 8661][Wall Clock 391.542622849s] Trained 120 records in 0.040332032 seconds. Throughput is 2975.3027 records/second. Loss is 0.18540414. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003660322108345534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 19440/60000][Iteration 8662][Wall Clock 391.582810182s] Trained 120 records in 0.040187333 seconds. Throughput is 2986.0156 records/second. Loss is 0.15633358. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003660054168801698. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 19560/60000][Iteration 8663][Wall Clock 391.623725366s] Trained 120 records in 0.040915184 seconds. Throughput is 2932.8965 records/second. Loss is 0.1542531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036597862684819207. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 19680/60000][Iteration 8664][Wall Clock 391.664137337s] Trained 120 records in 0.040411971 seconds. Throughput is 2969.4172 records/second. Loss is 0.22212788. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003659518407377589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 19800/60000][Iteration 8665][Wall Clock 391.705737875s] Trained 120 records in 0.041600538 seconds. Throughput is 2884.5781 records/second. Loss is 0.2342569. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036592505854800934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 19920/60000][Iteration 8666][Wall Clock 391.74687799s] Trained 120 records in 0.041140115 seconds. Throughput is 2916.8608 records/second. Loss is 0.2104974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003658982802780827. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20040/60000][Iteration 8667][Wall Clock 391.788039856s] Trained 120 records in 0.041161866 seconds. Throughput is 2915.3198 records/second. Loss is 0.27368802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036587150592711838. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20160/60000][Iteration 8668][Wall Clock 391.835726554s] Trained 120 records in 0.047686698 seconds. Throughput is 2516.425 records/second. Loss is 0.08975708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036584473549425623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20280/60000][Iteration 8669][Wall Clock 391.888218248s] Trained 120 records in 0.052491694 seconds. Throughput is 2286.076 records/second. Loss is 0.16661312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036581796897863623. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20400/60000][Iteration 8670][Wall Clock 391.931041307s] Trained 120 records in 0.042823059 seconds. Throughput is 2802.2288 records/second. Loss is 0.18788598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036579120637939863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20520/60000][Iteration 8671][Wall Clock 391.970942408s] Trained 120 records in 0.039901101 seconds. Throughput is 3007.4358 records/second. Loss is 0.14395407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036576444769568397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20640/60000][Iteration 8672][Wall Clock 392.01096661s] Trained 120 records in 0.040024202 seconds. Throughput is 2998.186 records/second. Loss is 0.14904836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036573769292663296. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20760/60000][Iteration 8673][Wall Clock 392.051046757s] Trained 120 records in 0.040080147 seconds. Throughput is 2994.001 records/second. Loss is 0.17862056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003657109420713868. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 20880/60000][Iteration 8674][Wall Clock 392.091485871s] Trained 120 records in 0.040439114 seconds. Throughput is 2967.424 records/second. Loss is 0.09152187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036568419512908647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21000/60000][Iteration 8675][Wall Clock 392.132077163s] Trained 120 records in 0.040591292 seconds. Throughput is 2956.299 records/second. Loss is 0.19732167. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003656574520988738. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21120/60000][Iteration 8676][Wall Clock 392.171929353s] Trained 120 records in 0.03985219 seconds. Throughput is 3011.1267 records/second. Loss is 0.10131226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036563071297989027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21240/60000][Iteration 8677][Wall Clock 392.220294102s] Trained 120 records in 0.048364749 seconds. Throughput is 2481.146 records/second. Loss is 0.09335502. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036560397777127816. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21360/60000][Iteration 8678][Wall Clock 392.267724324s] Trained 120 records in 0.047430222 seconds. Throughput is 2530.0325 records/second. Loss is 0.10871674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036557724647217956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21480/60000][Iteration 8679][Wall Clock 392.308676308s] Trained 120 records in 0.040951984 seconds. Throughput is 2930.261 records/second. Loss is 0.13309918. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036555051908173713. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21600/60000][Iteration 8680][Wall Clock 392.349253024s] Trained 120 records in 0.040576716 seconds. Throughput is 2957.361 records/second. Loss is 0.12633924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003655237955990935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21720/60000][Iteration 8681][Wall Clock 392.389219768s] Trained 120 records in 0.039966744 seconds. Throughput is 3002.4963 records/second. Loss is 0.11696298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036549707602339184. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21840/60000][Iteration 8682][Wall Clock 392.429112606s] Trained 120 records in 0.039892838 seconds. Throughput is 3008.0588 records/second. Loss is 0.17569622. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003654703603537753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 21960/60000][Iteration 8683][Wall Clock 392.468945786s] Trained 120 records in 0.03983318 seconds. Throughput is 3012.564 records/second. Loss is 0.20230238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003654436485893875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 22080/60000][Iteration 8684][Wall Clock 392.508792722s] Trained 120 records in 0.039846936 seconds. Throughput is 3011.524 records/second. Loss is 0.2157022. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003654169407293722. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:38 INFO  DistriOptimizer$:406 - [Epoch 18 22200/60000][Iteration 8685][Wall Clock 392.548300094s] Trained 120 records in 0.039507372 seconds. Throughput is 3037.408 records/second. Loss is 0.22467703. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036539023677287343. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 22320/60000][Iteration 8686][Wall Clock 392.587836977s] Trained 120 records in 0.039536883 seconds. Throughput is 3035.1406 records/second. Loss is 0.112545766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003653635367190354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 22440/60000][Iteration 8687][Wall Clock 392.62679508s] Trained 120 records in 0.038958103 seconds. Throughput is 3080.2322 records/second. Loss is 0.13473348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036533684056700277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 22560/60000][Iteration 8688][Wall Clock 392.665604476s] Trained 120 records in 0.038809396 seconds. Throughput is 3092.0347 records/second. Loss is 0.16859373. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003653101483159202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 22680/60000][Iteration 8689][Wall Clock 392.705145899s] Trained 120 records in 0.039541423 seconds. Throughput is 3034.7922 records/second. Loss is 0.111469746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003652834599649328. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 22800/60000][Iteration 8690][Wall Clock 392.744949207s] Trained 120 records in 0.039803308 seconds. Throughput is 3014.825 records/second. Loss is 0.16742703. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003652567755131858. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 22920/60000][Iteration 8691][Wall Clock 392.784739567s] Trained 120 records in 0.03979036 seconds. Throughput is 3015.806 records/second. Loss is 0.20284902. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003652300949598247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23040/60000][Iteration 8692][Wall Clock 392.826123832s] Trained 120 records in 0.041384265 seconds. Throughput is 2899.6528 records/second. Loss is 0.21946435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003652034183039953. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23160/60000][Iteration 8693][Wall Clock 392.867120714s] Trained 120 records in 0.040996882 seconds. Throughput is 2927.0518 records/second. Loss is 0.23769578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036517674554484366. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23280/60000][Iteration 8694][Wall Clock 392.921664645s] Trained 120 records in 0.054543931 seconds. Throughput is 2200.0615 records/second. Loss is 0.24196962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003651500766815161. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23400/60000][Iteration 8695][Wall Clock 392.966943909s] Trained 120 records in 0.045279264 seconds. Throughput is 2650.2197 records/second. Loss is 0.16478467. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00365123411713159. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23520/60000][Iteration 8696][Wall Clock 393.010894341s] Trained 120 records in 0.043950432 seconds. Throughput is 2730.3486 records/second. Loss is 0.1767481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036509675063891934. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23640/60000][Iteration 8697][Wall Clock 393.051777288s] Trained 120 records in 0.040882947 seconds. Throughput is 2935.209 records/second. Loss is 0.11978872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003650700934579439. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23760/60000][Iteration 8698][Wall Clock 393.093063544s] Trained 120 records in 0.041286256 seconds. Throughput is 2906.5361 records/second. Loss is 0.08136114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003650434401693802. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 23880/60000][Iteration 8699][Wall Clock 393.134223646s] Trained 120 records in 0.041160102 seconds. Throughput is 2915.4446 records/second. Loss is 0.14829722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003650167907723755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24000/60000][Iteration 8700][Wall Clock 393.175050718s] Trained 120 records in 0.040827072 seconds. Throughput is 2939.226 records/second. Loss is 0.1190236. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036499014526607783. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24120/60000][Iteration 8701][Wall Clock 393.214943612s] Trained 120 records in 0.039892894 seconds. Throughput is 3008.0547 records/second. Loss is 0.12996627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036496350364963502. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24240/60000][Iteration 8702][Wall Clock 393.254894073s] Trained 120 records in 0.039950461 seconds. Throughput is 3003.72 records/second. Loss is 0.13009067. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036493686592219544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24360/60000][Iteration 8703][Wall Clock 393.294941047s] Trained 120 records in 0.040046974 seconds. Throughput is 2996.481 records/second. Loss is 0.19143598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003649102320829076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24480/60000][Iteration 8704][Wall Clock 393.348477241s] Trained 120 records in 0.053536194 seconds. Throughput is 2241.474 records/second. Loss is 0.1535183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003648836021309202. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24600/60000][Iteration 8705][Wall Clock 393.389319449s] Trained 120 records in 0.040842208 seconds. Throughput is 2938.137 records/second. Loss is 0.104226135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036485697606538237. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24720/60000][Iteration 8706][Wall Clock 393.429408573s] Trained 120 records in 0.040089124 seconds. Throughput is 2993.3306 records/second. Loss is 0.12575078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036483035388544327. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24840/60000][Iteration 8707][Wall Clock 393.469434742s] Trained 120 records in 0.040026169 seconds. Throughput is 2998.0386 records/second. Loss is 0.13878962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036480373559025243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 24960/60000][Iteration 8708][Wall Clock 393.509059646s] Trained 120 records in 0.039624904 seconds. Throughput is 3028.3984 records/second. Loss is 0.18157394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036477712117895965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:39 INFO  DistriOptimizer$:406 - [Epoch 18 25080/60000][Iteration 8709][Wall Clock 393.549076818s] Trained 120 records in 0.040017172 seconds. Throughput is 2998.7126 records/second. Loss is 0.1721204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003647505106507149. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 25200/60000][Iteration 8710][Wall Clock 393.589740566s] Trained 120 records in 0.040663748 seconds. Throughput is 2951.0315 records/second. Loss is 0.101762466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036472390400466848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 25320/60000][Iteration 8711][Wall Clock 393.630562304s] Trained 120 records in 0.040821738 seconds. Throughput is 2939.61 records/second. Loss is 0.27550215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036469730123997084. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 25440/60000][Iteration 8712][Wall Clock 393.670892916s] Trained 120 records in 0.040330612 seconds. Throughput is 2975.4075 records/second. Loss is 0.17492814. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003646707023557727. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 25560/60000][Iteration 8713][Wall Clock 393.711562682s] Trained 120 records in 0.040669766 seconds. Throughput is 2950.5947 records/second. Loss is 0.17388694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003646441073512252. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 25680/60000][Iteration 8714][Wall Clock 393.751884598s] Trained 120 records in 0.040321916 seconds. Throughput is 2976.049 records/second. Loss is 0.1645052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036461751622547944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 25800/60000][Iteration 8715][Wall Clock 393.795169896s] Trained 120 records in 0.043285298 seconds. Throughput is 2772.3037 records/second. Loss is 0.1205594. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036459092897768706. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 25920/60000][Iteration 8716][Wall Clock 393.835780367s] Trained 120 records in 0.040610471 seconds. Throughput is 2954.903 records/second. Loss is 0.22456875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003645643456069996. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26040/60000][Iteration 8717][Wall Clock 393.876312873s] Trained 120 records in 0.040532506 seconds. Throughput is 2960.5867 records/second. Loss is 0.21394663. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003645377661125693. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26160/60000][Iteration 8718][Wall Clock 393.916498758s] Trained 120 records in 0.040185885 seconds. Throughput is 2986.1233 records/second. Loss is 0.1503782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003645111904935481. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26280/60000][Iteration 8719][Wall Clock 393.974934394s] Trained 120 records in 0.058435636 seconds. Throughput is 2053.5415 records/second. Loss is 0.16557612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003644846187490888. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26400/60000][Iteration 8720][Wall Clock 394.024608869s] Trained 120 records in 0.049674475 seconds. Throughput is 2415.7275 records/second. Loss is 0.18781014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036445805087834387. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26520/60000][Iteration 8721][Wall Clock 394.065633139s] Trained 120 records in 0.04102427 seconds. Throughput is 2925.0977 records/second. Loss is 0.17603561. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003644314868804665. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26640/60000][Iteration 8722][Wall Clock 394.106248473s] Trained 120 records in 0.040615334 seconds. Throughput is 2954.549 records/second. Loss is 0.117241584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003644049267546097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26760/60000][Iteration 8723][Wall Clock 394.146581745s] Trained 120 records in 0.040333272 seconds. Throughput is 2975.2112 records/second. Loss is 0.16422288. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003643783704999271. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 26880/60000][Iteration 8724][Wall Clock 394.187347331s] Trained 120 records in 0.040765586 seconds. Throughput is 2943.6592 records/second. Loss is 0.16274823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036435181811557238. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27000/60000][Iteration 8725][Wall Clock 394.227370918s] Trained 120 records in 0.040023587 seconds. Throughput is 2998.232 records/second. Loss is 0.15100583. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003643252696006995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27120/60000][Iteration 8726][Wall Clock 394.267310442s] Trained 120 records in 0.039939524 seconds. Throughput is 3004.5427 records/second. Loss is 0.16296403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036429872495446266. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27240/60000][Iteration 8727][Wall Clock 394.306918351s] Trained 120 records in 0.039607909 seconds. Throughput is 3029.698 records/second. Loss is 0.08283356. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003642721841760163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27360/60000][Iteration 8728][Wall Clock 394.346833346s] Trained 120 records in 0.039914995 seconds. Throughput is 3006.389 records/second. Loss is 0.11864748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003642456472645152. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27480/60000][Iteration 8729][Wall Clock 394.386655722s] Trained 120 records in 0.039822376 seconds. Throughput is 3013.381 records/second. Loss is 0.20839596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003642191142191142. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27600/60000][Iteration 8730][Wall Clock 394.434942105s] Trained 120 records in 0.048286383 seconds. Throughput is 2485.1726 records/second. Loss is 0.18561214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003641925850389686. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27720/60000][Iteration 8731][Wall Clock 394.480370859s] Trained 120 records in 0.045428754 seconds. Throughput is 2641.4988 records/second. Loss is 0.25403818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003641660597232338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27840/60000][Iteration 8732][Wall Clock 394.520903827s] Trained 120 records in 0.040532968 seconds. Throughput is 2960.553 records/second. Loss is 0.15995458. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003641395382710655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:40 INFO  DistriOptimizer$:406 - [Epoch 18 27960/60000][Iteration 8733][Wall Clock 394.560609117s] Trained 120 records in 0.03970529 seconds. Throughput is 3022.267 records/second. Loss is 0.11435798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036411302068161955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28080/60000][Iteration 8734][Wall Clock 394.603855717s] Trained 120 records in 0.0432466 seconds. Throughput is 2774.7847 records/second. Loss is 0.15927444. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003640865069540523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28200/60000][Iteration 8735][Wall Clock 394.644036803s] Trained 120 records in 0.040181086 seconds. Throughput is 2986.4797 records/second. Loss is 0.14155434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036405999708751997. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28320/60000][Iteration 8736][Wall Clock 394.683699088s] Trained 120 records in 0.039662285 seconds. Throughput is 3025.5442 records/second. Loss is 0.1658464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036403349108117948. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28440/60000][Iteration 8737][Wall Clock 394.7240807s] Trained 120 records in 0.040381612 seconds. Throughput is 2971.6497 records/second. Loss is 0.17429182. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003640069889341875. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28560/60000][Iteration 8738][Wall Clock 394.764307517s] Trained 120 records in 0.040226817 seconds. Throughput is 2983.0847 records/second. Loss is 0.11417647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003639804906457014. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28680/60000][Iteration 8739][Wall Clock 394.803927037s] Trained 120 records in 0.03961952 seconds. Throughput is 3028.81 records/second. Loss is 0.15917997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003639539962148784. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28800/60000][Iteration 8740][Wall Clock 394.844628728s] Trained 120 records in 0.040701691 seconds. Throughput is 2948.2805 records/second. Loss is 0.1575671. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003639275056408764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 28920/60000][Iteration 8741][Wall Clock 394.884918635s] Trained 120 records in 0.040289907 seconds. Throughput is 2978.4133 records/second. Loss is 0.14643821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00363901018922853. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29040/60000][Iteration 8742][Wall Clock 394.925014646s] Trained 120 records in 0.040096011 seconds. Throughput is 2992.8164 records/second. Loss is 0.15706977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036387453605996657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29160/60000][Iteration 8743][Wall Clock 394.965762729s] Trained 120 records in 0.040748083 seconds. Throughput is 2944.9238 records/second. Loss is 0.11976374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036384805705137534. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29280/60000][Iteration 8744][Wall Clock 395.0151495s] Trained 120 records in 0.049386771 seconds. Throughput is 2429.8005 records/second. Loss is 0.21794875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036382158189623807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29400/60000][Iteration 8745][Wall Clock 395.066562903s] Trained 120 records in 0.051413403 seconds. Throughput is 2334.0217 records/second. Loss is 0.18159303. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003637951105937136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29520/60000][Iteration 8746][Wall Clock 395.107774285s] Trained 120 records in 0.041211382 seconds. Throughput is 2911.817 records/second. Loss is 0.15030476. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036376864314296106. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29640/60000][Iteration 8747][Wall Clock 395.148388692s] Trained 120 records in 0.040614407 seconds. Throughput is 2954.6165 records/second. Loss is 0.2683575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036374217954313983. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29760/60000][Iteration 8748][Wall Clock 395.189536215s] Trained 120 records in 0.041147523 seconds. Throughput is 2916.336 records/second. Loss is 0.19083175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036371571979340947. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 29880/60000][Iteration 8749][Wall Clock 395.228971428s] Trained 120 records in 0.039435213 seconds. Throughput is 3042.9658 records/second. Loss is 0.13251567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003636892638929299. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30000/60000][Iteration 8750][Wall Clock 395.268747811s] Trained 120 records in 0.039776383 seconds. Throughput is 3016.8655 records/second. Loss is 0.20600921. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036366281184086117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30120/60000][Iteration 8751][Wall Clock 395.30850382s] Trained 120 records in 0.039756009 seconds. Throughput is 3018.4119 records/second. Loss is 0.13312383. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036363636363636364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30240/60000][Iteration 8752][Wall Clock 395.348656714s] Trained 120 records in 0.040152894 seconds. Throughput is 2988.5767 records/second. Loss is 0.17128737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036360991927859793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30360/60000][Iteration 8753][Wall Clock 395.391953391s] Trained 120 records in 0.043296677 seconds. Throughput is 2771.5754 records/second. Loss is 0.13113475. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036358347876672484. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30480/60000][Iteration 8754][Wall Clock 395.432517417s] Trained 120 records in 0.040564026 seconds. Throughput is 2958.2861 records/second. Loss is 0.27063912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036355704209990545. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30600/60000][Iteration 8755][Wall Clock 395.472932327s] Trained 120 records in 0.04041491 seconds. Throughput is 2969.2012 records/second. Loss is 0.2231337. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036353060927730115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30720/60000][Iteration 8756][Wall Clock 395.5120719s] Trained 120 records in 0.039139573 seconds. Throughput is 3065.9507 records/second. Loss is 0.14514348. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003635041802980734. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:41 INFO  DistriOptimizer$:406 - [Epoch 18 30840/60000][Iteration 8757][Wall Clock 395.560760842s] Trained 120 records in 0.048688942 seconds. Throughput is 2464.6255 records/second. Loss is 0.17349611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036347775516138415. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 30960/60000][Iteration 8758][Wall Clock 395.606454889s] Trained 120 records in 0.045694047 seconds. Throughput is 2626.1628 records/second. Loss is 0.20371944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036345133386639526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31080/60000][Iteration 8759][Wall Clock 395.645814993s] Trained 120 records in 0.039360104 seconds. Throughput is 3048.7725 records/second. Loss is 0.19489746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036342491641226924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31200/60000][Iteration 8760][Wall Clock 395.685231274s] Trained 120 records in 0.039416281 seconds. Throughput is 3044.4272 records/second. Loss is 0.085617825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036339850279816844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31320/60000][Iteration 8761][Wall Clock 395.725490828s] Trained 120 records in 0.040259554 seconds. Throughput is 2980.659 records/second. Loss is 0.20467086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036337209302325585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31440/60000][Iteration 8762][Wall Clock 395.765725415s] Trained 120 records in 0.040234587 seconds. Throughput is 2982.5085 records/second. Loss is 0.12788513. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036334568708669425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31560/60000][Iteration 8763][Wall Clock 395.805451906s] Trained 120 records in 0.039726491 seconds. Throughput is 3020.6543 records/second. Loss is 0.15882036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003633192849876471. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31680/60000][Iteration 8764][Wall Clock 395.845423845s] Trained 120 records in 0.039971939 seconds. Throughput is 3002.106 records/second. Loss is 0.16951914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036329288672527793. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31800/60000][Iteration 8765][Wall Clock 395.885288596s] Trained 120 records in 0.039864751 seconds. Throughput is 3010.178 records/second. Loss is 0.2018114. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036326649229875036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 31920/60000][Iteration 8766][Wall Clock 395.925389572s] Trained 120 records in 0.040100976 seconds. Throughput is 2992.4458 records/second. Loss is 0.166473. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036324010170722845. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32040/60000][Iteration 8767][Wall Clock 395.965378203s] Trained 120 records in 0.039988631 seconds. Throughput is 3000.853 records/second. Loss is 0.12170208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003632137149498765. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32160/60000][Iteration 8768][Wall Clock 396.006140457s] Trained 120 records in 0.040762254 seconds. Throughput is 2943.9001 records/second. Loss is 0.104172565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036318733202585895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32280/60000][Iteration 8769][Wall Clock 396.047523488s] Trained 120 records in 0.041383031 seconds. Throughput is 2899.7393 records/second. Loss is 0.16023903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003631609529343405. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32400/60000][Iteration 8770][Wall Clock 396.103340621s] Trained 120 records in 0.055817133 seconds. Throughput is 2149.8774 records/second. Loss is 0.095489696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003631345776744862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32520/60000][Iteration 8771][Wall Clock 396.149988444s] Trained 120 records in 0.046647823 seconds. Throughput is 2572.4673 records/second. Loss is 0.19954062. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036310820624546117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32640/60000][Iteration 8772][Wall Clock 396.191201983s] Trained 120 records in 0.041213539 seconds. Throughput is 2911.6646 records/second. Loss is 0.14028151. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003630818386464309. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32760/60000][Iteration 8773][Wall Clock 396.231600595s] Trained 120 records in 0.040398612 seconds. Throughput is 2970.399 records/second. Loss is 0.17350443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003630554748765611. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 32880/60000][Iteration 8774][Wall Clock 396.272949413s] Trained 120 records in 0.041348818 seconds. Throughput is 2902.1384 records/second. Loss is 0.096607275. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003630291149350178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 33000/60000][Iteration 8775][Wall Clock 396.314506532s] Trained 120 records in 0.041557119 seconds. Throughput is 2887.592 records/second. Loss is 0.13168365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00363002758820967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 33120/60000][Iteration 8776][Wall Clock 396.355494233s] Trained 120 records in 0.040987701 seconds. Throughput is 2927.7075 records/second. Loss is 0.22748905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036297640653357535. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 33240/60000][Iteration 8777][Wall Clock 396.397220215s] Trained 120 records in 0.041725982 seconds. Throughput is 2875.906 records/second. Loss is 0.079957716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036295005807200926. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 33360/60000][Iteration 8778][Wall Clock 396.438821625s] Trained 120 records in 0.04160141 seconds. Throughput is 2884.5178 records/second. Loss is 0.14835422. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003629237134354359. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 33480/60000][Iteration 8779][Wall Clock 396.4800797s] Trained 120 records in 0.041258075 seconds. Throughput is 2908.5215 records/second. Loss is 0.17884818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003628973726230222. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:42 INFO  DistriOptimizer$:406 - [Epoch 18 33600/60000][Iteration 8780][Wall Clock 396.520280449s] Trained 120 records in 0.040200749 seconds. Throughput is 2985.019 records/second. Loss is 0.2734165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003628710356339357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 33720/60000][Iteration 8781][Wall Clock 396.560118312s] Trained 120 records in 0.039837863 seconds. Throughput is 3012.2097 records/second. Loss is 0.10558111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036284470246734394. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 33840/60000][Iteration 8782][Wall Clock 396.600243341s] Trained 120 records in 0.040125029 seconds. Throughput is 2990.652 records/second. Loss is 0.14909405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036281837312241495. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 33960/60000][Iteration 8783][Wall Clock 396.640872536s] Trained 120 records in 0.040629195 seconds. Throughput is 2953.5413 records/second. Loss is 0.17594372. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036279204759831663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34080/60000][Iteration 8784][Wall Clock 396.694437217s] Trained 120 records in 0.053564681 seconds. Throughput is 2240.2822 records/second. Loss is 0.1574665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003627657258942175. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34200/60000][Iteration 8785][Wall Clock 396.741086565s] Trained 120 records in 0.046649348 seconds. Throughput is 2572.3833 records/second. Loss is 0.13719684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003627394080092861. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34320/60000][Iteration 8786][Wall Clock 396.781282938s] Trained 120 records in 0.040196373 seconds. Throughput is 2985.344 records/second. Loss is 0.08443936. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003627130939426913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34440/60000][Iteration 8787][Wall Clock 396.821215073s] Trained 120 records in 0.039932135 seconds. Throughput is 3005.0984 records/second. Loss is 0.076862656. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003626867836936022. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34560/60000][Iteration 8788][Wall Clock 396.86090275s] Trained 120 records in 0.039687677 seconds. Throughput is 3023.6084 records/second. Loss is 0.10388119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036266047726118806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34680/60000][Iteration 8789][Wall Clock 396.901078048s] Trained 120 records in 0.040175298 seconds. Throughput is 2986.9102 records/second. Loss is 0.096706636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003626341746446185. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34800/60000][Iteration 8790][Wall Clock 396.944777901s] Trained 120 records in 0.043699853 seconds. Throughput is 2746.0046 records/second. Loss is 0.20776515. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003626078758430633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 34920/60000][Iteration 8791][Wall Clock 396.98567708s] Trained 120 records in 0.040899179 seconds. Throughput is 2934.0442 records/second. Loss is 0.11114642. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036258158085569255. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35040/60000][Iteration 8792][Wall Clock 397.025924205s] Trained 120 records in 0.040247125 seconds. Throughput is 2981.5796 records/second. Loss is 0.17447281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036255528968167647. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35160/60000][Iteration 8793][Wall Clock 397.068276359s] Trained 120 records in 0.042352154 seconds. Throughput is 2833.386 records/second. Loss is 0.23421049. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036252900232018564. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35280/60000][Iteration 8794][Wall Clock 397.111079942s] Trained 120 records in 0.042803583 seconds. Throughput is 2803.5037 records/second. Loss is 0.13082759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036250271877039074. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35400/60000][Iteration 8795][Wall Clock 397.157428287s] Trained 120 records in 0.046348345 seconds. Throughput is 2589.0894 records/second. Loss is 0.16998205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00362476439031463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35520/60000][Iteration 8796][Wall Clock 397.202879066s] Trained 120 records in 0.045450779 seconds. Throughput is 2640.2188 records/second. Loss is 0.1524534. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036245016310257334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35640/60000][Iteration 8797][Wall Clock 397.243329161s] Trained 120 records in 0.040450095 seconds. Throughput is 2966.6184 records/second. Loss is 0.20171086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036242389098289363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35760/60000][Iteration 8798][Wall Clock 397.283643635s] Trained 120 records in 0.040314474 seconds. Throughput is 2976.5984 records/second. Loss is 0.17484966. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036239762267159525. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 35880/60000][Iteration 8799][Wall Clock 397.323650637s] Trained 120 records in 0.040007002 seconds. Throughput is 2999.4749 records/second. Loss is 0.20138483. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036237135816785046. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 36000/60000][Iteration 8800][Wall Clock 397.363761069s] Trained 120 records in 0.040110432 seconds. Throughput is 2991.7405 records/second. Loss is 0.12807457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036234509747083117. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 36120/60000][Iteration 8801][Wall Clock 397.405211539s] Trained 120 records in 0.04145047 seconds. Throughput is 2895.0215 records/second. Loss is 0.0643009. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003623188405797102. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 36240/60000][Iteration 8802][Wall Clock 397.446612863s] Trained 120 records in 0.041401324 seconds. Throughput is 2898.458 records/second. Loss is 0.16998993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003622925874936599. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 36360/60000][Iteration 8803][Wall Clock 397.487074716s] Trained 120 records in 0.040461853 seconds. Throughput is 2965.7563 records/second. Loss is 0.11123653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036226633821185334. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:43 INFO  DistriOptimizer$:406 - [Epoch 18 36480/60000][Iteration 8804][Wall Clock 397.527078883s] Trained 120 records in 0.040004167 seconds. Throughput is 2999.6875 records/second. Loss is 0.1449574. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003622400927334637. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 36600/60000][Iteration 8805][Wall Clock 397.567096352s] Trained 120 records in 0.040017469 seconds. Throughput is 2998.6902 records/second. Loss is 0.104380265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036221385105766443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 36720/60000][Iteration 8806][Wall Clock 397.607361831s] Trained 120 records in 0.040265479 seconds. Throughput is 2980.2205 records/second. Loss is 0.117062904. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003621876131836291. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 36840/60000][Iteration 8807][Wall Clock 397.647946147s] Trained 120 records in 0.040584316 seconds. Throughput is 2956.8074 records/second. Loss is 0.10014544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036216137911053163. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 36960/60000][Iteration 8808][Wall Clock 397.688253813s] Trained 120 records in 0.040307666 seconds. Throughput is 2977.101 records/second. Loss is 0.12719853. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036213514883754617. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37080/60000][Iteration 8809][Wall Clock 397.732314449s] Trained 120 records in 0.044060636 seconds. Throughput is 2723.5195 records/second. Loss is 0.13679431. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036210892236384707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37200/60000][Iteration 8810][Wall Clock 397.772332952s] Trained 120 records in 0.040018503 seconds. Throughput is 2998.613 records/second. Loss is 0.09202138. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036208269968860886. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37320/60000][Iteration 8811][Wall Clock 397.824728326s] Trained 120 records in 0.052395374 seconds. Throughput is 2290.2786 records/second. Loss is 0.09632412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003620564808110065. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37440/60000][Iteration 8812][Wall Clock 397.872328139s] Trained 120 records in 0.047599813 seconds. Throughput is 2521.0183 records/second. Loss is 0.2673768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036203026573021504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37560/60000][Iteration 8813][Wall Clock 397.913857158s] Trained 120 records in 0.041529019 seconds. Throughput is 2889.546 records/second. Loss is 0.15880196. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036200405444540974. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37680/60000][Iteration 8814][Wall Clock 397.954812975s] Trained 120 records in 0.040955817 seconds. Throughput is 2929.9868 records/second. Loss is 0.1785774. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036197784695576633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37800/60000][Iteration 8815][Wall Clock 397.996528803s] Trained 120 records in 0.041715828 seconds. Throughput is 2876.606 records/second. Loss is 0.13220353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036195164326046038. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 37920/60000][Iteration 8816][Wall Clock 398.037921046s] Trained 120 records in 0.041392243 seconds. Throughput is 2899.0938 records/second. Loss is 0.09570854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036192544335866814. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38040/60000][Iteration 8817][Wall Clock 398.079913374s] Trained 120 records in 0.041992328 seconds. Throughput is 2857.6648 records/second. Loss is 0.28016913. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003618992472495657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38160/60000][Iteration 8818][Wall Clock 398.122622597s] Trained 120 records in 0.042709223 seconds. Throughput is 2809.6975 records/second. Loss is 0.098733276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036187305493232975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38280/60000][Iteration 8819][Wall Clock 398.166003028s] Trained 120 records in 0.043380431 seconds. Throughput is 2766.224 records/second. Loss is 0.18914598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003618468664061369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38400/60000][Iteration 8820][Wall Clock 398.223359419s] Trained 120 records in 0.057356391 seconds. Throughput is 2092.182 records/second. Loss is 0.15176985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003618206816701643. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38520/60000][Iteration 8821][Wall Clock 398.267894497s] Trained 120 records in 0.044535078 seconds. Throughput is 2694.5051 records/second. Loss is 0.1575328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00361794500723589. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38640/60000][Iteration 8822][Wall Clock 398.308835504s] Trained 120 records in 0.040941007 seconds. Throughput is 2931.0466 records/second. Loss is 0.10121735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036176832356558863. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38760/60000][Iteration 8823][Wall Clock 398.349244554s] Trained 120 records in 0.04040905 seconds. Throughput is 2969.6318 records/second. Loss is 0.17401911. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036174215019534072. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 38880/60000][Iteration 8824][Wall Clock 398.390003443s] Trained 120 records in 0.040758889 seconds. Throughput is 2944.143 records/second. Loss is 0.15292892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036171598061202344. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 39000/60000][Iteration 8825][Wall Clock 398.430335926s] Trained 120 records in 0.040332483 seconds. Throughput is 2975.2695 records/second. Loss is 0.16349538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003616898148148148. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 39120/60000][Iteration 8826][Wall Clock 398.470633903s] Trained 120 records in 0.040297977 seconds. Throughput is 2977.817 records/second. Loss is 0.16218962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003616636528028933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:44 INFO  DistriOptimizer$:406 - [Epoch 18 39240/60000][Iteration 8827][Wall Clock 398.513945544s] Trained 120 records in 0.043311641 seconds. Throughput is 2770.6177 records/second. Loss is 0.17946914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036163749457543757. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 39360/60000][Iteration 8828][Wall Clock 398.553980281s] Trained 120 records in 0.040034737 seconds. Throughput is 2997.397 records/second. Loss is 0.15109546. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003616113401316265. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 39480/60000][Iteration 8829][Wall Clock 398.594576602s] Trained 120 records in 0.040596321 seconds. Throughput is 2955.9329 records/second. Loss is 0.105978265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003615851894706393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 39600/60000][Iteration 8830][Wall Clock 398.635160178s] Trained 120 records in 0.040583576 seconds. Throughput is 2956.861 records/second. Loss is 0.12945198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003615590425916552. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 39720/60000][Iteration 8831][Wall Clock 398.675184682s] Trained 120 records in 0.040024504 seconds. Throughput is 2998.1633 records/second. Loss is 0.067393735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036153289949385397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 39840/60000][Iteration 8832][Wall Clock 398.714943064s] Trained 120 records in 0.039758382 seconds. Throughput is 3018.2317 records/second. Loss is 0.18843707. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036150676017641533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 39960/60000][Iteration 8833][Wall Clock 398.755561139s] Trained 120 records in 0.040618075 seconds. Throughput is 2954.3499 records/second. Loss is 0.20349838. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003614806246385194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40080/60000][Iteration 8834][Wall Clock 398.796082369s] Trained 120 records in 0.04052123 seconds. Throughput is 2961.4106 records/second. Loss is 0.16962093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036145449287934644. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40200/60000][Iteration 8835][Wall Clock 398.8368443s] Trained 120 records in 0.040761931 seconds. Throughput is 2943.923 records/second. Loss is 0.11949727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003614283648980772. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40320/60000][Iteration 8836][Wall Clock 398.877741128s] Trained 120 records in 0.040896828 seconds. Throughput is 2934.213 records/second. Loss is 0.22424951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003614022406938923. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40440/60000][Iteration 8837][Wall Clock 398.918112854s] Trained 120 records in 0.040371726 seconds. Throughput is 2972.3772 records/second. Loss is 0.25183254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036137612026597285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40560/60000][Iteration 8838][Wall Clock 398.969363388s] Trained 120 records in 0.051250534 seconds. Throughput is 2341.4392 records/second. Loss is 0.23987731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003613500036135. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40680/60000][Iteration 8839][Wall Clock 399.017531602s] Trained 120 records in 0.048168214 seconds. Throughput is 2491.2695 records/second. Loss is 0.13320039. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003613238907356555. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40800/60000][Iteration 8840][Wall Clock 399.060844481s] Trained 120 records in 0.043312879 seconds. Throughput is 2770.5386 records/second. Loss is 0.1266586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036129778163162076. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 40920/60000][Iteration 8841][Wall Clock 399.10162547s] Trained 120 records in 0.040780989 seconds. Throughput is 2942.5476 records/second. Loss is 0.23855175. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036127167630057807. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41040/60000][Iteration 8842][Wall Clock 399.142604138s] Trained 120 records in 0.040978668 seconds. Throughput is 2928.353 records/second. Loss is 0.23114873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003612455747417094. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41160/60000][Iteration 8843][Wall Clock 399.183916561s] Trained 120 records in 0.041312423 seconds. Throughput is 2904.6953 records/second. Loss is 0.10589238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036121947695419735. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41280/60000][Iteration 8844][Wall Clock 399.225820219s] Trained 120 records in 0.041903658 seconds. Throughput is 2863.7117 records/second. Loss is 0.08186173. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036119338293722457. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41400/60000][Iteration 8845][Wall Clock 399.275958954s] Trained 120 records in 0.050138735 seconds. Throughput is 2393.3591 records/second. Loss is 0.11322479. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00361167292689974. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41520/60000][Iteration 8846][Wall Clock 399.325993633s] Trained 120 records in 0.050034679 seconds. Throughput is 2398.3364 records/second. Loss is 0.22947595. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036114120621162874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41640/60000][Iteration 8847][Wall Clock 399.369397489s] Trained 120 records in 0.043403856 seconds. Throughput is 2764.7312 records/second. Loss is 0.13978443. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036111512350137224. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41760/60000][Iteration 8848][Wall Clock 399.409942175s] Trained 120 records in 0.040544686 seconds. Throughput is 2959.6975 records/second. Loss is 0.13467216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003610890445583881. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 41880/60000][Iteration 8849][Wall Clock 399.450817166s] Trained 120 records in 0.040874991 seconds. Throughput is 2935.7805 records/second. Loss is 0.114197716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003610629693818602. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 42000/60000][Iteration 8850][Wall Clock 399.491370765s] Trained 120 records in 0.040553599 seconds. Throughput is 2959.0469 records/second. Loss is 0.22082183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003610368979709726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:45 INFO  DistriOptimizer$:406 - [Epoch 18 42120/60000][Iteration 8851][Wall Clock 399.53204875s] Trained 120 records in 0.040677985 seconds. Throughput is 2949.9988 records/second. Loss is 0.22581945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036101083032490976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 42240/60000][Iteration 8852][Wall Clock 399.573691926s] Trained 120 records in 0.041643176 seconds. Throughput is 2881.6245 records/second. Loss is 0.11883155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003609847664428561. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 42360/60000][Iteration 8853][Wall Clock 399.614702655s] Trained 120 records in 0.041010729 seconds. Throughput is 2926.0635 records/second. Loss is 0.19045463. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003609587063239965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 42480/60000][Iteration 8854][Wall Clock 399.654979049s] Trained 120 records in 0.040276394 seconds. Throughput is 2979.4128 records/second. Loss is 0.17004903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036093264996751606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 42600/60000][Iteration 8855][Wall Clock 399.695143323s] Trained 120 records in 0.040164274 seconds. Throughput is 2987.73 records/second. Loss is 0.2321229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036090659737259994. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 42720/60000][Iteration 8856][Wall Clock 399.73636471s] Trained 120 records in 0.041221387 seconds. Throughput is 2911.11 records/second. Loss is 0.13177903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003608805485384338. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 42840/60000][Iteration 8857][Wall Clock 399.776618857s] Trained 120 records in 0.040254147 seconds. Throughput is 2981.0593 records/second. Loss is 0.2102191. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003608545034642032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 42960/60000][Iteration 8858][Wall Clock 399.817582064s] Trained 120 records in 0.040963207 seconds. Throughput is 2929.4583 records/second. Loss is 0.12667729. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036082846214909436. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43080/60000][Iteration 8859][Wall Clock 399.857583484s] Trained 120 records in 0.04000142 seconds. Throughput is 2999.8936 records/second. Loss is 0.21489993. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036080242459229322. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43200/60000][Iteration 8860][Wall Clock 399.897805276s] Trained 120 records in 0.040221792 seconds. Throughput is 2983.4573 records/second. Loss is 0.14639106. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036077639079298653. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43320/60000][Iteration 8861][Wall Clock 399.937500446s] Trained 120 records in 0.03969517 seconds. Throughput is 3023.0378 records/second. Loss is 0.3609535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003607503607503607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43440/60000][Iteration 8862][Wall Clock 399.977803648s] Trained 120 records in 0.040303202 seconds. Throughput is 2977.4312 records/second. Loss is 0.13894926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036072433446360293. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43560/60000][Iteration 8863][Wall Clock 400.018252919s] Trained 120 records in 0.040449271 seconds. Throughput is 2966.6787 records/second. Loss is 0.09419698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036069831193190015. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43680/60000][Iteration 8864][Wall Clock 400.059365567s] Trained 120 records in 0.041112648 seconds. Throughput is 2918.8098 records/second. Loss is 0.13169071. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036067229315443986. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43800/60000][Iteration 8865][Wall Clock 400.116188467s] Trained 120 records in 0.0568229 seconds. Throughput is 2111.8247 records/second. Loss is 0.18839999. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003606462781304097. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 43920/60000][Iteration 8866][Wall Clock 400.16043824s] Trained 120 records in 0.044249773 seconds. Throughput is 2711.8784 records/second. Loss is 0.11393344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003606202668589975. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44040/60000][Iteration 8867][Wall Clock 400.201151648s] Trained 120 records in 0.040713408 seconds. Throughput is 2947.4321 records/second. Loss is 0.13388892. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003605942593393913. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44160/60000][Iteration 8868][Wall Clock 400.242192756s] Trained 120 records in 0.041041108 seconds. Throughput is 2923.8975 records/second. Loss is 0.1544539. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036056825557077956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44280/60000][Iteration 8869][Wall Clock 400.283782304s] Trained 120 records in 0.041589548 seconds. Throughput is 2885.3403 records/second. Loss is 0.12798212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036054225555235075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44400/60000][Iteration 8870][Wall Clock 400.324714178s] Trained 120 records in 0.040931874 seconds. Throughput is 2931.7007 records/second. Loss is 0.15590008. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036051625928329367. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44520/60000][Iteration 8871][Wall Clock 400.364528106s] Trained 120 records in 0.039813928 seconds. Throughput is 3014.0205 records/second. Loss is 0.16159138. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036049026676279743. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44640/60000][Iteration 8872][Wall Clock 400.404876242s] Trained 120 records in 0.040348136 seconds. Throughput is 2974.1152 records/second. Loss is 0.13436152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003604642779900512. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44760/60000][Iteration 8873][Wall Clock 400.454673306s] Trained 120 records in 0.049797064 seconds. Throughput is 2409.7805 records/second. Loss is 0.21755368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003604382929642445. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 44880/60000][Iteration 8874][Wall Clock 400.498542701s] Trained 120 records in 0.043869395 seconds. Throughput is 2735.392 records/second. Loss is 0.2092532. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003604123116845671. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:46 INFO  DistriOptimizer$:406 - [Epoch 18 45000/60000][Iteration 8875][Wall Clock 400.538604307s] Trained 120 records in 0.040061606 seconds. Throughput is 2995.3867 records/second. Loss is 0.15902995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036038633415020906. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45120/60000][Iteration 8876][Wall Clock 400.579065448s] Trained 120 records in 0.040461141 seconds. Throughput is 2965.8086 records/second. Loss is 0.101058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036036036036036032. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45240/60000][Iteration 8877][Wall Clock 400.619462106s] Trained 120 records in 0.040396658 seconds. Throughput is 2970.5427 records/second. Loss is 0.18941268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003603343903142116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45360/60000][Iteration 8878][Wall Clock 400.659765564s] Trained 120 records in 0.040303458 seconds. Throughput is 2977.412 records/second. Loss is 0.1996064. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036030842401095333. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45480/60000][Iteration 8879][Wall Clock 400.700231252s] Trained 120 records in 0.040465688 seconds. Throughput is 2965.4753 records/second. Loss is 0.12065185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036028246144977666. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45600/60000][Iteration 8880][Wall Clock 400.740620416s] Trained 120 records in 0.040389164 seconds. Throughput is 2971.0938 records/second. Loss is 0.08355943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036025650262987243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45720/60000][Iteration 8881][Wall Clock 400.780818987s] Trained 120 records in 0.040198571 seconds. Throughput is 2985.1807 records/second. Loss is 0.16651507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003602305475504323. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45840/60000][Iteration 8882][Wall Clock 400.820344175s] Trained 120 records in 0.039525188 seconds. Throughput is 3036.0386 records/second. Loss is 0.14350629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036020459621064764. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 45960/60000][Iteration 8883][Wall Clock 400.862954335s] Trained 120 records in 0.04261016 seconds. Throughput is 2816.2297 records/second. Loss is 0.14191155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036017864860971045. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46080/60000][Iteration 8884][Wall Clock 400.903443874s] Trained 120 records in 0.040489539 seconds. Throughput is 2963.7285 records/second. Loss is 0.112706654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036015270474681264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46200/60000][Iteration 8885][Wall Clock 400.943911313s] Trained 120 records in 0.040467439 seconds. Throughput is 2965.3472 records/second. Loss is 0.13757764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036012676462114663. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46320/60000][Iteration 8886][Wall Clock 400.983589225s] Trained 120 records in 0.039677912 seconds. Throughput is 3024.3528 records/second. Loss is 0.15610269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036010082823190494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46440/60000][Iteration 8887][Wall Clock 401.023319952s] Trained 120 records in 0.039730727 seconds. Throughput is 3020.3323 records/second. Loss is 0.139643. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036007489557828027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46560/60000][Iteration 8888][Wall Clock 401.064265441s] Trained 120 records in 0.040945489 seconds. Throughput is 2930.7258 records/second. Loss is 0.22438082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0036004896665946568. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46680/60000][Iteration 8889][Wall Clock 401.105587905s] Trained 120 records in 0.041322464 seconds. Throughput is 2903.9895 records/second. Loss is 0.10385353. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003600230414746544. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46800/60000][Iteration 8890][Wall Clock 401.146520412s] Trained 120 records in 0.040932507 seconds. Throughput is 2931.6553 records/second. Loss is 0.0707555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035999712002303982. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 46920/60000][Iteration 8891][Wall Clock 401.197205156s] Trained 120 records in 0.050684744 seconds. Throughput is 2367.5764 records/second. Loss is 0.21797694. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003599712023038157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47040/60000][Iteration 8892][Wall Clock 401.244139324s] Trained 120 records in 0.046934168 seconds. Throughput is 2556.7727 records/second. Loss is 0.13060717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035994528831617594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47160/60000][Iteration 8893][Wall Clock 401.287997446s] Trained 120 records in 0.043858122 seconds. Throughput is 2736.0952 records/second. Loss is 0.21716627. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003599193780593147. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47280/60000][Iteration 8894][Wall Clock 401.330314322s] Trained 120 records in 0.042316876 seconds. Throughput is 2835.748 records/second. Loss is 0.1602301. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003598934715324264. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47400/60000][Iteration 8895][Wall Clock 401.371103093s] Trained 120 records in 0.040788771 seconds. Throughput is 2941.9863 records/second. Loss is 0.17018054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003598675687347056. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47520/60000][Iteration 8896][Wall Clock 401.411044092s] Trained 120 records in 0.039940999 seconds. Throughput is 3004.4316 records/second. Loss is 0.17036289. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003598416696653473. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47640/60000][Iteration 8897][Wall Clock 401.451438145s] Trained 120 records in 0.040394053 seconds. Throughput is 2970.7344 records/second. Loss is 0.20735857. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003598157743235463. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47760/60000][Iteration 8898][Wall Clock 401.490897881s] Trained 120 records in 0.039459736 seconds. Throughput is 3041.0747 records/second. Loss is 0.11089968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035978988270849825. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:47 INFO  DistriOptimizer$:406 - [Epoch 18 47880/60000][Iteration 8899][Wall Clock 401.531505404s] Trained 120 records in 0.040607523 seconds. Throughput is 2955.1174 records/second. Loss is 0.12774397. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035976399481939844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48000/60000][Iteration 8900][Wall Clock 401.581935452s] Trained 120 records in 0.050430048 seconds. Throughput is 2379.5337 records/second. Loss is 0.23828751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035973811065544287. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48120/60000][Iteration 8901][Wall Clock 401.623335111s] Trained 120 records in 0.041399659 seconds. Throughput is 2898.5747 records/second. Loss is 0.14049824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003597122302158273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48240/60000][Iteration 8902][Wall Clock 401.667918328s] Trained 120 records in 0.044583217 seconds. Throughput is 2691.596 records/second. Loss is 0.10601152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035968635349974826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48360/60000][Iteration 8903][Wall Clock 401.709065871s] Trained 120 records in 0.041147543 seconds. Throughput is 2916.3347 records/second. Loss is 0.15972696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035966048050640196. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48480/60000][Iteration 8904][Wall Clock 401.750931035s] Trained 120 records in 0.041865164 seconds. Throughput is 2866.345 records/second. Loss is 0.14173415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035963461123498523. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48600/60000][Iteration 8905][Wall Clock 401.793309631s] Trained 120 records in 0.042378596 seconds. Throughput is 2831.6182 records/second. Loss is 0.101365246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035960874568469504. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48720/60000][Iteration 8906][Wall Clock 401.834971494s] Trained 120 records in 0.041661863 seconds. Throughput is 2880.332 records/second. Loss is 0.1566743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003595828838547285. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48840/60000][Iteration 8907][Wall Clock 401.876438677s] Trained 120 records in 0.041467183 seconds. Throughput is 2893.8547 records/second. Loss is 0.139403. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035955702574428303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 48960/60000][Iteration 8908][Wall Clock 401.917983842s] Trained 120 records in 0.041545165 seconds. Throughput is 2888.4229 records/second. Loss is 0.0817032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035953117135255628. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49080/60000][Iteration 8909][Wall Clock 401.959073929s] Trained 120 records in 0.041090087 seconds. Throughput is 2920.4124 records/second. Loss is 0.13337895. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035950532067874604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49200/60000][Iteration 8910][Wall Clock 402.000783991s] Trained 120 records in 0.041710062 seconds. Throughput is 2877.0034 records/second. Loss is 0.30236685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003594794737220505. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49320/60000][Iteration 8911][Wall Clock 402.042746533s] Trained 120 records in 0.041962542 seconds. Throughput is 2859.6934 records/second. Loss is 0.07756268. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035945363048166786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49440/60000][Iteration 8912][Wall Clock 402.084408403s] Trained 120 records in 0.04166187 seconds. Throughput is 2880.3315 records/second. Loss is 0.16180184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035942779095679677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49560/60000][Iteration 8913][Wall Clock 402.126359138s] Trained 120 records in 0.041950735 seconds. Throughput is 2860.498 records/second. Loss is 0.10654121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00359401955146636. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49680/60000][Iteration 8914][Wall Clock 402.167850099s] Trained 120 records in 0.041490961 seconds. Throughput is 2892.1963 records/second. Loss is 0.22452281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035937612305038447. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49800/60000][Iteration 8915][Wall Clock 402.209781964s] Trained 120 records in 0.041931865 seconds. Throughput is 2861.7854 records/second. Loss is 0.14485976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035935029466724164. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 49920/60000][Iteration 8916][Wall Clock 402.250672879s] Trained 120 records in 0.040890915 seconds. Throughput is 2934.6372 records/second. Loss is 0.13578428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003593244699964067. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 50040/60000][Iteration 8917][Wall Clock 402.291413421s] Trained 120 records in 0.040740542 seconds. Throughput is 2945.469 records/second. Loss is 0.123109296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035929864903707963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 50160/60000][Iteration 8918][Wall Clock 402.340199393s] Trained 120 records in 0.048785972 seconds. Throughput is 2459.7234 records/second. Loss is 0.17837177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035927283178846013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 50280/60000][Iteration 8919][Wall Clock 402.390772767s] Trained 120 records in 0.050573374 seconds. Throughput is 2372.79 records/second. Loss is 0.29832432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035924701824974854. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 50400/60000][Iteration 8920][Wall Clock 402.436711005s] Trained 120 records in 0.045938238 seconds. Throughput is 2612.203 records/second. Loss is 0.19153912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003592212084201451. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 50520/60000][Iteration 8921][Wall Clock 402.480331882s] Trained 120 records in 0.043620877 seconds. Throughput is 2750.9763 records/second. Loss is 0.195846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003591954022988506. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:48 INFO  DistriOptimizer$:406 - [Epoch 18 50640/60000][Iteration 8922][Wall Clock 402.520305347s] Trained 120 records in 0.039973465 seconds. Throughput is 3001.9915 records/second. Loss is 0.17235228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003591695998850657. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 50760/60000][Iteration 8923][Wall Clock 402.560950697s] Trained 120 records in 0.04064535 seconds. Throughput is 2952.3672 records/second. Loss is 0.14507316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003591438011779917. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 50880/60000][Iteration 8924][Wall Clock 402.601463608s] Trained 120 records in 0.040512911 seconds. Throughput is 2962.0186 records/second. Loss is 0.15921466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003591180061768297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51000/60000][Iteration 8925][Wall Clock 402.641751267s] Trained 120 records in 0.040287659 seconds. Throughput is 2978.5796 records/second. Loss is 0.19152069. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035909221488078136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51120/60000][Iteration 8926][Wall Clock 402.688278114s] Trained 120 records in 0.046526847 seconds. Throughput is 2579.1562 records/second. Loss is 0.2649469. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035906642728904844. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51240/60000][Iteration 8927][Wall Clock 402.731073391s] Trained 120 records in 0.042795277 seconds. Throughput is 2804.0476 records/second. Loss is 0.17919654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035904064340083297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51360/60000][Iteration 8928][Wall Clock 402.771887492s] Trained 120 records in 0.040814101 seconds. Throughput is 2940.1602 records/second. Loss is 0.11194308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003590148632153371. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51480/60000][Iteration 8929][Wall Clock 402.812051512s] Trained 120 records in 0.04016402 seconds. Throughput is 2987.7488 records/second. Loss is 0.120410874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035898908673176336. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51600/60000][Iteration 8930][Wall Clock 402.8528671s] Trained 120 records in 0.040815588 seconds. Throughput is 2940.0532 records/second. Loss is 0.14780222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035896331394931437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51720/60000][Iteration 8931][Wall Clock 402.893207313s] Trained 120 records in 0.040340213 seconds. Throughput is 2974.6995 records/second. Loss is 0.19779176. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035893754486719313. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51840/60000][Iteration 8932][Wall Clock 402.933128159s] Trained 120 records in 0.039920846 seconds. Throughput is 3005.9485 records/second. Loss is 0.12607169. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003589117794846027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 51960/60000][Iteration 8933][Wall Clock 402.973510441s] Trained 120 records in 0.040382282 seconds. Throughput is 2971.6003 records/second. Loss is 0.16197874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003588860178007465. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52080/60000][Iteration 8934][Wall Clock 403.013648882s] Trained 120 records in 0.040138441 seconds. Throughput is 2989.6526 records/second. Loss is 0.13656794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003588602598148281. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52200/60000][Iteration 8935][Wall Clock 403.054819282s] Trained 120 records in 0.0411704 seconds. Throughput is 2914.7153 records/second. Loss is 0.09027128. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035883450552605133. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52320/60000][Iteration 8936][Wall Clock 403.095701284s] Trained 120 records in 0.040882002 seconds. Throughput is 2935.2769 records/second. Loss is 0.15989421. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003588087549336204. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52440/60000][Iteration 8937][Wall Clock 403.136555213s] Trained 120 records in 0.040853929 seconds. Throughput is 2937.294 records/second. Loss is 0.13310908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035878300803673935. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52560/60000][Iteration 8938][Wall Clock 403.177468128s] Trained 120 records in 0.040912915 seconds. Throughput is 2933.059 records/second. Loss is 0.17023446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003587572648346129. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52680/60000][Iteration 8939][Wall Clock 403.217541887s] Trained 120 records in 0.040073759 seconds. Throughput is 2994.4783 records/second. Loss is 0.19855861. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035873152532644565. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52800/60000][Iteration 8940][Wall Clock 403.260745167s] Trained 120 records in 0.04320328 seconds. Throughput is 2777.567 records/second. Loss is 0.119525045. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035870578951144273. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 52920/60000][Iteration 8941][Wall Clock 403.300748077s] Trained 120 records in 0.04000291 seconds. Throughput is 2999.782 records/second. Loss is 0.21502668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035868005738880914. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 53040/60000][Iteration 8942][Wall Clock 403.341494504s] Trained 120 records in 0.040746427 seconds. Throughput is 2945.0435 records/second. Loss is 0.20741557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035865432895775054. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 53160/60000][Iteration 8943][Wall Clock 403.38358289s] Trained 120 records in 0.042088386 seconds. Throughput is 2851.1428 records/second. Loss is 0.13243914. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035862860421747235. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 53280/60000][Iteration 8944][Wall Clock 403.440629176s] Trained 120 records in 0.057046286 seconds. Throughput is 2103.555 records/second. Loss is 0.22497334. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035860288316718063. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 53400/60000][Iteration 8945][Wall Clock 403.485131044s] Trained 120 records in 0.044501868 seconds. Throughput is 2696.516 records/second. Loss is 0.09414261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035857716580608144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:49 INFO  DistriOptimizer$:406 - [Epoch 18 53520/60000][Iteration 8946][Wall Clock 403.525287504s] Trained 120 records in 0.04015646 seconds. Throughput is 2988.311 records/second. Loss is 0.14267354. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035855145213338113. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 53640/60000][Iteration 8947][Wall Clock 403.565739368s] Trained 120 records in 0.040451864 seconds. Throughput is 2966.4885 records/second. Loss is 0.1738836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003585257421482862. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 53760/60000][Iteration 8948][Wall Clock 403.605844453s] Trained 120 records in 0.040105085 seconds. Throughput is 2992.1392 records/second. Loss is 0.1824952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035850003585000357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 53880/60000][Iteration 8949][Wall Clock 403.646173214s] Trained 120 records in 0.040328761 seconds. Throughput is 2975.544 records/second. Loss is 0.12458708. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035847433323774017. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54000/60000][Iteration 8950][Wall Clock 403.686807786s] Trained 120 records in 0.040634572 seconds. Throughput is 2953.1504 records/second. Loss is 0.21521798. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003584486343107033. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54120/60000][Iteration 8951][Wall Clock 403.727151493s] Trained 120 records in 0.040343707 seconds. Throughput is 2974.4417 records/second. Loss is 0.14261362. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035842293906810036. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54240/60000][Iteration 8952][Wall Clock 403.767219584s] Trained 120 records in 0.040068091 seconds. Throughput is 2994.9019 records/second. Loss is 0.22215019. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035839724750913915. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54360/60000][Iteration 8953][Wall Clock 403.816112574s] Trained 120 records in 0.04889299 seconds. Throughput is 2454.3396 records/second. Loss is 0.09139781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035837155963302754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54480/60000][Iteration 8954][Wall Clock 403.859300643s] Trained 120 records in 0.043188069 seconds. Throughput is 2778.5452 records/second. Loss is 0.17348507. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035834587543897363. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54600/60000][Iteration 8955][Wall Clock 403.899890198s] Trained 120 records in 0.040589555 seconds. Throughput is 2956.4255 records/second. Loss is 0.098549604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035832019492618604. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54720/60000][Iteration 8956][Wall Clock 403.940239982s] Trained 120 records in 0.040349784 seconds. Throughput is 2973.9934 records/second. Loss is 0.07715017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003582945180938731. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54840/60000][Iteration 8957][Wall Clock 403.981082106s] Trained 120 records in 0.040842124 seconds. Throughput is 2938.143 records/second. Loss is 0.11550457. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035826884494124392. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 54960/60000][Iteration 8958][Wall Clock 404.025181057s] Trained 120 records in 0.044098951 seconds. Throughput is 2721.153 records/second. Loss is 0.20667101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003582431754675073. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55080/60000][Iteration 8959][Wall Clock 404.065311801s] Trained 120 records in 0.040130744 seconds. Throughput is 2990.226 records/second. Loss is 0.21219856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003582175096718728. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55200/60000][Iteration 8960][Wall Clock 404.106291834s] Trained 120 records in 0.040980033 seconds. Throughput is 2928.2554 records/second. Loss is 0.099377625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035819184755354967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55320/60000][Iteration 8961][Wall Clock 404.146443647s] Trained 120 records in 0.040151813 seconds. Throughput is 2988.6572 records/second. Loss is 0.21943955. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035816618911174787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55440/60000][Iteration 8962][Wall Clock 404.187542337s] Trained 120 records in 0.04109869 seconds. Throughput is 2919.801 records/second. Loss is 0.19836754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035814053434567723. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55560/60000][Iteration 8963][Wall Clock 404.228561692s] Trained 120 records in 0.041019355 seconds. Throughput is 2925.4482 records/second. Loss is 0.12934309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003581148832545481. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55680/60000][Iteration 8964][Wall Clock 404.269652948s] Trained 120 records in 0.041091256 seconds. Throughput is 2920.3293 records/second. Loss is 0.1389152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003580892358375707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55800/60000][Iteration 8965][Wall Clock 404.310864235s] Trained 120 records in 0.041211287 seconds. Throughput is 2911.8235 records/second. Loss is 0.1524717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035806359209395585. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 55920/60000][Iteration 8966][Wall Clock 404.351675479s] Trained 120 records in 0.040811244 seconds. Throughput is 2940.3662 records/second. Loss is 0.17989637. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035803795202291443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 56040/60000][Iteration 8967][Wall Clock 404.392080379s] Trained 120 records in 0.0404049 seconds. Throughput is 2969.9368 records/second. Loss is 0.20638779. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035801231562365746. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 56160/60000][Iteration 8968][Wall Clock 404.434713077s] Trained 120 records in 0.042632698 seconds. Throughput is 2814.741 records/second. Loss is 0.22260998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003579866828953963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:50 INFO  DistriOptimizer$:406 - [Epoch 18 56280/60000][Iteration 8969][Wall Clock 404.482803406s] Trained 120 records in 0.048090329 seconds. Throughput is 2495.3042 records/second. Loss is 0.13114756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003579610538373425. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 56400/60000][Iteration 8970][Wall Clock 404.531471597s] Trained 120 records in 0.048668191 seconds. Throughput is 2465.6763 records/second. Loss is 0.12095544. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035793542844870787. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 56520/60000][Iteration 8971][Wall Clock 404.572216997s] Trained 120 records in 0.0407454 seconds. Throughput is 2945.1177 records/second. Loss is 0.20517558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035790980672870437. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 56640/60000][Iteration 8972][Wall Clock 404.612625283s] Trained 120 records in 0.040408286 seconds. Throughput is 2969.6877 records/second. Loss is 0.2046033. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003578841886765443. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 56760/60000][Iteration 8973][Wall Clock 404.653466754s] Trained 120 records in 0.040841471 seconds. Throughput is 2938.19 records/second. Loss is 0.08802677. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035785857429144. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 56880/60000][Iteration 8974][Wall Clock 404.694115862s] Trained 120 records in 0.040649108 seconds. Throughput is 2952.0942 records/second. Loss is 0.12460306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035783296357260433. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57000/60000][Iteration 8975][Wall Clock 404.735427402s] Trained 120 records in 0.04131154 seconds. Throughput is 2904.7573 records/second. Loss is 0.14852254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035780735651924998. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57120/60000][Iteration 8976][Wall Clock 404.775370496s] Trained 120 records in 0.039943094 seconds. Throughput is 3004.274 records/second. Loss is 0.16379428. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035778175313059034. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57240/60000][Iteration 8977][Wall Clock 404.819675913s] Trained 120 records in 0.044305417 seconds. Throughput is 2708.4724 records/second. Loss is 0.14449231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035775615340583856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57360/60000][Iteration 8978][Wall Clock 404.860279824s] Trained 120 records in 0.040603911 seconds. Throughput is 2955.3804 records/second. Loss is 0.19104597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035773055734420836. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57480/60000][Iteration 8979][Wall Clock 404.900897724s] Trained 120 records in 0.0406179 seconds. Throughput is 2954.3623 records/second. Loss is 0.10515126. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003577049649449134. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57600/60000][Iteration 8980][Wall Clock 404.953698811s] Trained 120 records in 0.052801087 seconds. Throughput is 2272.6804 records/second. Loss is 0.111950256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003576793762071679. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57720/60000][Iteration 8981][Wall Clock 404.99503358s] Trained 120 records in 0.041334769 seconds. Throughput is 2903.1248 records/second. Loss is 0.08830048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035765379113018594. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57840/60000][Iteration 8982][Wall Clock 405.036442861s] Trained 120 records in 0.041409281 seconds. Throughput is 2897.9011 records/second. Loss is 0.09732866. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003576282097131822. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 57960/60000][Iteration 8983][Wall Clock 405.077325045s] Trained 120 records in 0.040882184 seconds. Throughput is 2935.264 records/second. Loss is 0.17949265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035760263195537116. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58080/60000][Iteration 8984][Wall Clock 405.118074164s] Trained 120 records in 0.040749119 seconds. Throughput is 2944.849 records/second. Loss is 0.27538246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035757705785596796. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58200/60000][Iteration 8985][Wall Clock 405.158599714s] Trained 120 records in 0.04052555 seconds. Throughput is 2961.095 records/second. Loss is 0.1260715. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003575514874141876. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58320/60000][Iteration 8986][Wall Clock 405.19867269s] Trained 120 records in 0.040072976 seconds. Throughput is 2994.5366 records/second. Loss is 0.13037054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003575259206292456. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58440/60000][Iteration 8987][Wall Clock 405.239010798s] Trained 120 records in 0.040338108 seconds. Throughput is 2974.8545 records/second. Loss is 0.13754101. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003575003575003575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58560/60000][Iteration 8988][Wall Clock 405.279391689s] Trained 120 records in 0.040380891 seconds. Throughput is 2971.7026 records/second. Loss is 0.19536732. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003574747980267391. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58680/60000][Iteration 8989][Wall Clock 405.319828071s] Trained 120 records in 0.040436382 seconds. Throughput is 2967.6245 records/second. Loss is 0.16272691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035744924220760654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58800/60000][Iteration 8990][Wall Clock 405.359315835s] Trained 120 records in 0.039487764 seconds. Throughput is 3038.916 records/second. Loss is 0.14249305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00357423690042176. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 58920/60000][Iteration 8991][Wall Clock 405.401145479s] Trained 120 records in 0.041829644 seconds. Throughput is 2868.7788 records/second. Loss is 0.14205958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035739814152966403. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 59040/60000][Iteration 8992][Wall Clock 405.442607655s] Trained 120 records in 0.041462176 seconds. Throughput is 2894.204 records/second. Loss is 0.12676199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003573725966692874. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:51 INFO  DistriOptimizer$:406 - [Epoch 18 59160/60000][Iteration 8993][Wall Clock 405.483471611s] Trained 120 records in 0.040863956 seconds. Throughput is 2936.5732 records/second. Loss is 0.06978091. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035734705546026303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:406 - [Epoch 18 59280/60000][Iteration 8994][Wall Clock 405.535816362s] Trained 120 records in 0.052344751 seconds. Throughput is 2292.4934 records/second. Loss is 0.15549164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035732151790180806. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:406 - [Epoch 18 59400/60000][Iteration 8995][Wall Clock 405.588494016s] Trained 120 records in 0.052677654 seconds. Throughput is 2278.0059 records/second. Loss is 0.20785919. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035729598399313993. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:406 - [Epoch 18 59520/60000][Iteration 8996][Wall Clock 405.630057806s] Trained 120 records in 0.04156379 seconds. Throughput is 2887.1284 records/second. Loss is 0.25334382. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003572704537334762. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:406 - [Epoch 18 59640/60000][Iteration 8997][Wall Clock 405.670332394s] Trained 120 records in 0.040274588 seconds. Throughput is 2979.5464 records/second. Loss is 0.13917258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003572449271220349. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:406 - [Epoch 18 59760/60000][Iteration 8998][Wall Clock 405.709867277s] Trained 120 records in 0.039534883 seconds. Throughput is 3035.2942 records/second. Loss is 0.17400716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035721940415803385. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:406 - [Epoch 18 59880/60000][Iteration 8999][Wall Clock 405.750093922s] Trained 120 records in 0.040226645 seconds. Throughput is 2983.0974 records/second. Loss is 0.18061785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035719388484069157. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:406 - [Epoch 18 60000/60000][Iteration 9000][Wall Clock 405.789437919s] Trained 120 records in 0.039343997 seconds. Throughput is 3050.0205 records/second. Loss is 0.092626825. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035716836916922633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:52 INFO  DistriOptimizer$:451 - [Epoch 18 60000/60000][Iteration 9000][Wall Clock 405.789437919s] Epoch finished. Wall clock time is 406583.011759 ms
2019-10-23 15:59:52 INFO  DistriOptimizer$:111 - [Epoch 18 60000/60000][Iteration 9000][Wall Clock 405.789437919s] Validate model...
2019-10-23 15:59:52 INFO  DistriOptimizer$:177 - [Epoch 18 60000/60000][Iteration 9000][Wall Clock 405.789437919s] validate model throughput is 15078.131 records/second
2019-10-23 15:59:52 INFO  DistriOptimizer$:180 - [Epoch 18 60000/60000][Iteration 9000][Wall Clock 405.789437919s] Top1Accuracy is Accuracy(correct: 9573, count: 10000, accuracy: 0.9573)
2019-10-23 15:59:52 INFO  DistriOptimizer$:220 - [Wall Clock 406.583011759s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 15:59:52 INFO  DistriOptimizer$:225 - [Wall Clock 406.583011759s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 120/60000][Iteration 9001][Wall Clock 406.629515777s] Trained 120 records in 0.046504018 seconds. Throughput is 2580.4224 records/second. Loss is 0.15454452. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035714285714285718. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 240/60000][Iteration 9002][Wall Clock 406.669827218s] Trained 120 records in 0.040311441 seconds. Throughput is 2976.8225 records/second. Loss is 0.17087121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035711734876080277. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 360/60000][Iteration 9003][Wall Clock 406.710651685s] Trained 120 records in 0.040824467 seconds. Throughput is 2939.4138 records/second. Loss is 0.13449723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003570918440222826. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 480/60000][Iteration 9004][Wall Clock 406.751876066s] Trained 120 records in 0.041224381 seconds. Throughput is 2910.8987 records/second. Loss is 0.28119653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035706634292651572. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 600/60000][Iteration 9005][Wall Clock 406.802184159s] Trained 120 records in 0.050308093 seconds. Throughput is 2385.302 records/second. Loss is 0.12797855. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035704084547272205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 720/60000][Iteration 9006][Wall Clock 406.848363109s] Trained 120 records in 0.04617895 seconds. Throughput is 2598.5864 records/second. Loss is 0.12503423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035701535166012136. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 840/60000][Iteration 9007][Wall Clock 406.889018242s] Trained 120 records in 0.040655133 seconds. Throughput is 2951.6567 records/second. Loss is 0.12632923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035698986148793373. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 960/60000][Iteration 9008][Wall Clock 406.929383189s] Trained 120 records in 0.040364947 seconds. Throughput is 2972.8765 records/second. Loss is 0.1251759. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035696437495537944. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1080/60000][Iteration 9009][Wall Clock 406.969388528s] Trained 120 records in 0.040005339 seconds. Throughput is 2999.5999 records/second. Loss is 0.19671606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035693889206167904. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1200/60000][Iteration 9010][Wall Clock 407.010469828s] Trained 120 records in 0.0410813 seconds. Throughput is 2921.037 records/second. Loss is 0.17342152. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035691341280605325. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1320/60000][Iteration 9011][Wall Clock 407.051492272s] Trained 120 records in 0.041022444 seconds. Throughput is 2925.228 records/second. Loss is 0.12419432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035688793718772305. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1440/60000][Iteration 9012][Wall Clock 407.092235872s] Trained 120 records in 0.0407436 seconds. Throughput is 2945.2478 records/second. Loss is 0.19957255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035686246520590967. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1560/60000][Iteration 9013][Wall Clock 407.136637042s] Trained 120 records in 0.04440117 seconds. Throughput is 2702.6316 records/second. Loss is 0.13137957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035683699685983444. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1680/60000][Iteration 9014][Wall Clock 407.17743219s] Trained 120 records in 0.040795148 seconds. Throughput is 2941.5264 records/second. Loss is 0.062575705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035681153214871908. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1800/60000][Iteration 9015][Wall Clock 407.218087546s] Trained 120 records in 0.040655356 seconds. Throughput is 2951.6406 records/second. Loss is 0.148752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003567860710717853. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 1920/60000][Iteration 9016][Wall Clock 407.257928835s] Trained 120 records in 0.039841289 seconds. Throughput is 3011.9507 records/second. Loss is 0.17529777. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035676061362825548. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2040/60000][Iteration 9017][Wall Clock 407.298097046s] Trained 120 records in 0.040168211 seconds. Throughput is 2987.437 records/second. Loss is 0.17074156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003567351598173516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2160/60000][Iteration 9018][Wall Clock 407.344089314s] Trained 120 records in 0.045992268 seconds. Throughput is 2609.1343 records/second. Loss is 0.252553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035670970963829637. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2280/60000][Iteration 9019][Wall Clock 407.387085779s] Trained 120 records in 0.042996465 seconds. Throughput is 2790.927 records/second. Loss is 0.15742305. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003566842630903124. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2400/60000][Iteration 9020][Wall Clock 407.427638018s] Trained 120 records in 0.040552239 seconds. Throughput is 2959.146 records/second. Loss is 0.2323496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003566588201726229. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2520/60000][Iteration 9021][Wall Clock 407.467801568s] Trained 120 records in 0.04016355 seconds. Throughput is 2987.7837 records/second. Loss is 0.20728451. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035663338088445075. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2640/60000][Iteration 9022][Wall Clock 407.509706384s] Trained 120 records in 0.041904816 seconds. Throughput is 2863.6328 records/second. Loss is 0.18575197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035660794522501963. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2760/60000][Iteration 9023][Wall Clock 407.55034365s] Trained 120 records in 0.040637266 seconds. Throughput is 2952.9546 records/second. Loss is 0.15499204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035658251319355297. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:53 INFO  DistriOptimizer$:406 - [Epoch 19 2880/60000][Iteration 9024][Wall Clock 407.590745229s] Trained 120 records in 0.040401579 seconds. Throughput is 2970.181 records/second. Loss is 0.22118886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003565570847892748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3000/60000][Iteration 9025][Wall Clock 407.630910809s] Trained 120 records in 0.04016558 seconds. Throughput is 2987.6326 records/second. Loss is 0.26453346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00356531660011409. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3120/60000][Iteration 9026][Wall Clock 407.670417852s] Trained 120 records in 0.039507043 seconds. Throughput is 3037.433 records/second. Loss is 0.12251046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035650623885918. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3240/60000][Iteration 9027][Wall Clock 407.71043364s] Trained 120 records in 0.040015788 seconds. Throughput is 2998.8164 records/second. Loss is 0.22210293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003564808213318123. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3360/60000][Iteration 9028][Wall Clock 407.750643522s] Trained 120 records in 0.040209882 seconds. Throughput is 2984.341 records/second. Loss is 0.29683304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003564554074285307. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3480/60000][Iteration 9029][Wall Clock 407.791301195s] Trained 120 records in 0.040657673 seconds. Throughput is 2951.4724 records/second. Loss is 0.19564666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035642999714856002. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3600/60000][Iteration 9030][Wall Clock 407.831445843s] Trained 120 records in 0.040144648 seconds. Throughput is 2989.1904 records/second. Loss is 0.110716246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035640459049112554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3720/60000][Iteration 9031][Wall Clock 407.87130882s] Trained 120 records in 0.039862977 seconds. Throughput is 3010.3123 records/second. Loss is 0.11712321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003563791874554526. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3840/60000][Iteration 9032][Wall Clock 407.928541467s] Trained 120 records in 0.057232647 seconds. Throughput is 2096.7053 records/second. Loss is 0.17122386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003563537880407669. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 3960/60000][Iteration 9033][Wall Clock 407.971393849s] Trained 120 records in 0.042852382 seconds. Throughput is 2800.311 records/second. Loss is 0.13220538. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003563283922462942. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4080/60000][Iteration 9034][Wall Clock 408.011946311s] Trained 120 records in 0.040552462 seconds. Throughput is 2959.1296 records/second. Loss is 0.19970815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003563030000712606. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4200/60000][Iteration 9035][Wall Clock 408.052975024s] Trained 120 records in 0.041028713 seconds. Throughput is 2924.781 records/second. Loss is 0.18324395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003562776115148924. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4320/60000][Iteration 9036][Wall Clock 408.093561938s] Trained 120 records in 0.040586914 seconds. Throughput is 2956.618 records/second. Loss is 0.18177585. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035625222657641605. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4440/60000][Iteration 9037][Wall Clock 408.134973965s] Trained 120 records in 0.041412027 seconds. Throughput is 2897.709 records/second. Loss is 0.15051565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003562268452550584. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4560/60000][Iteration 9038][Wall Clock 408.177057801s] Trained 120 records in 0.042083836 seconds. Throughput is 2851.451 records/second. Loss is 0.11202041. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035620146755004625. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4680/60000][Iteration 9039][Wall Clock 408.218570067s] Trained 120 records in 0.041512266 seconds. Throughput is 2890.712 records/second. Loss is 0.163108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035617609346060694. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4800/60000][Iteration 9040][Wall Clock 408.259337444s] Trained 120 records in 0.040767377 seconds. Throughput is 2943.5303 records/second. Loss is 0.15395625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003561507229859676. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 4920/60000][Iteration 9041][Wall Clock 408.299559442s] Trained 120 records in 0.040221998 seconds. Throughput is 2983.4421 records/second. Loss is 0.07393477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035612535612535618. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 5040/60000][Iteration 9042][Wall Clock 408.341196551s] Trained 120 records in 0.041637109 seconds. Throughput is 2882.0447 records/second. Loss is 0.14839837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035609999287800013. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 5160/60000][Iteration 9043][Wall Clock 408.386996884s] Trained 120 records in 0.045800333 seconds. Throughput is 2620.0684 records/second. Loss is 0.11147077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003560746332431278. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 5280/60000][Iteration 9044][Wall Clock 408.432490337s] Trained 120 records in 0.045493453 seconds. Throughput is 2637.7422 records/second. Loss is 0.16156705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035604927721996724. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 5400/60000][Iteration 9045][Wall Clock 408.473473397s] Trained 120 records in 0.04098306 seconds. Throughput is 2928.039 records/second. Loss is 0.17711726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035602392480774707. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 5520/60000][Iteration 9046][Wall Clock 408.514119056s] Trained 120 records in 0.040645659 seconds. Throughput is 2952.3447 records/second. Loss is 0.14210747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035599857600569595. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 5640/60000][Iteration 9047][Wall Clock 408.554452722s] Trained 120 records in 0.040333666 seconds. Throughput is 2975.1821 records/second. Loss is 0.08589557. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035597323081304286. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:54 INFO  DistriOptimizer$:406 - [Epoch 19 5760/60000][Iteration 9048][Wall Clock 408.594357029s] Trained 120 records in 0.039904307 seconds. Throughput is 3007.194 records/second. Loss is 0.120609485. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035594788922901684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 5880/60000][Iteration 9049][Wall Clock 408.634754809s] Trained 120 records in 0.04039778 seconds. Throughput is 2970.4604 records/second. Loss is 0.15531178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035592255125284737. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6000/60000][Iteration 9050][Wall Clock 408.678621441s] Trained 120 records in 0.043866632 seconds. Throughput is 2735.5645 records/second. Loss is 0.18133958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035589721688376397. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6120/60000][Iteration 9051][Wall Clock 408.718906977s] Trained 120 records in 0.040285536 seconds. Throughput is 2978.7366 records/second. Loss is 0.1312235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035587188612099642. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6240/60000][Iteration 9052][Wall Clock 408.758856779s] Trained 120 records in 0.039949802 seconds. Throughput is 3003.7698 records/second. Loss is 0.17389235. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003558465589637748. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6360/60000][Iteration 9053][Wall Clock 408.798476273s] Trained 120 records in 0.039619494 seconds. Throughput is 3028.812 records/second. Loss is 0.13619226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035582123541132936. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6480/60000][Iteration 9054][Wall Clock 408.838279017s] Trained 120 records in 0.039802744 seconds. Throughput is 3014.8674 records/second. Loss is 0.11344813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003557959154628905. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6600/60000][Iteration 9055][Wall Clock 408.877976641s] Trained 120 records in 0.039697624 seconds. Throughput is 3022.8508 records/second. Loss is 0.14858824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003557705991176889. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6720/60000][Iteration 9056][Wall Clock 408.917785904s] Trained 120 records in 0.039809263 seconds. Throughput is 3014.3738 records/second. Loss is 0.11122306. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035574528637495554. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6840/60000][Iteration 9057][Wall Clock 408.957332862s] Trained 120 records in 0.039546958 seconds. Throughput is 3034.3674 records/second. Loss is 0.28043804. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035571997723392143. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 6960/60000][Iteration 9058][Wall Clock 409.005336542s] Trained 120 records in 0.04800368 seconds. Throughput is 2499.8083 records/second. Loss is 0.18610255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035569467169381803. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7080/60000][Iteration 9059][Wall Clock 409.053842327s] Trained 120 records in 0.048505785 seconds. Throughput is 2473.9316 records/second. Loss is 0.16027837. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035566936975387677. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7200/60000][Iteration 9060][Wall Clock 409.095584276s] Trained 120 records in 0.041741949 seconds. Throughput is 2874.806 records/second. Loss is 0.21422109. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035564407141332956. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7320/60000][Iteration 9061][Wall Clock 409.136581917s] Trained 120 records in 0.040997641 seconds. Throughput is 2926.9978 records/second. Loss is 0.23709223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003556187766714082. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7440/60000][Iteration 9062][Wall Clock 409.177776151s] Trained 120 records in 0.041194234 seconds. Throughput is 2913.029 records/second. Loss is 0.13035052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035559348552734516. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7560/60000][Iteration 9063][Wall Clock 409.218547424s] Trained 120 records in 0.040771273 seconds. Throughput is 2943.2488 records/second. Loss is 0.20176719. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003555681979803726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7680/60000][Iteration 9064][Wall Clock 409.258922837s] Trained 120 records in 0.040375413 seconds. Throughput is 2972.106 records/second. Loss is 0.11116796. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003555429140297234. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7800/60000][Iteration 9065][Wall Clock 409.299750141s] Trained 120 records in 0.040827304 seconds. Throughput is 2939.2095 records/second. Loss is 0.2437753. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035551763367463025. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 7920/60000][Iteration 9066][Wall Clock 409.340968951s] Trained 120 records in 0.04121881 seconds. Throughput is 2911.2922 records/second. Loss is 0.1419081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003554923569143263. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 8040/60000][Iteration 9067][Wall Clock 409.391436877s] Trained 120 records in 0.050467926 seconds. Throughput is 2377.7478 records/second. Loss is 0.11771219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035546708374804494. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 8160/60000][Iteration 9068][Wall Clock 409.439335037s] Trained 120 records in 0.04789816 seconds. Throughput is 2505.3154 records/second. Loss is 0.2406212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035544181417501955. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 8280/60000][Iteration 9069][Wall Clock 409.490588128s] Trained 120 records in 0.051253091 seconds. Throughput is 2341.3223 records/second. Loss is 0.1303295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035541654819448393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 8400/60000][Iteration 9070][Wall Clock 409.530722471s] Trained 120 records in 0.040134343 seconds. Throughput is 2989.958 records/second. Loss is 0.16135605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035539128580567205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:55 INFO  DistriOptimizer$:406 - [Epoch 19 8520/60000][Iteration 9071][Wall Clock 409.570781831s] Trained 120 records in 0.04005936 seconds. Throughput is 2995.5544 records/second. Loss is 0.105088905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035536602700781805. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 8640/60000][Iteration 9072][Wall Clock 409.610660794s] Trained 120 records in 0.039878963 seconds. Throughput is 3009.1052 records/second. Loss is 0.13005717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035534077180015633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 8760/60000][Iteration 9073][Wall Clock 409.650532102s] Trained 120 records in 0.039871308 seconds. Throughput is 3009.6829 records/second. Loss is 0.15307942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035531552018192155. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 8880/60000][Iteration 9074][Wall Clock 409.69041785s] Trained 120 records in 0.039885748 seconds. Throughput is 3008.5935 records/second. Loss is 0.15257764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035529027215234848. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9000/60000][Iteration 9075][Wall Clock 409.730215644s] Trained 120 records in 0.039797794 seconds. Throughput is 3015.2424 records/second. Loss is 0.08585229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035526502771067218. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9120/60000][Iteration 9076][Wall Clock 409.770916928s] Trained 120 records in 0.040701284 seconds. Throughput is 2948.3098 records/second. Loss is 0.20690873. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035523978685612786. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9240/60000][Iteration 9077][Wall Clock 409.811325749s] Trained 120 records in 0.040408821 seconds. Throughput is 2969.6487 records/second. Loss is 0.16000296. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035521454958795115. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9360/60000][Iteration 9078][Wall Clock 409.850816618s] Trained 120 records in 0.039490869 seconds. Throughput is 3038.6772 records/second. Loss is 0.13599056. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035518931590537753. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9480/60000][Iteration 9079][Wall Clock 409.891041762s] Trained 120 records in 0.040225144 seconds. Throughput is 2983.2087 records/second. Loss is 0.16157724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035516408580764315. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9600/60000][Iteration 9080][Wall Clock 409.931468023s] Trained 120 records in 0.040426261 seconds. Throughput is 2968.3674 records/second. Loss is 0.14510255. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003551388592939839. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9720/60000][Iteration 9081][Wall Clock 409.97333079s] Trained 120 records in 0.041862767 seconds. Throughput is 2866.509 records/second. Loss is 0.13358511. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003551136363636364. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9840/60000][Iteration 9082][Wall Clock 410.014578282s] Trained 120 records in 0.041247492 seconds. Throughput is 2909.2678 records/second. Loss is 0.1510315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003550884170158369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 9960/60000][Iteration 9083][Wall Clock 410.055124435s] Trained 120 records in 0.040546153 seconds. Throughput is 2959.5903 records/second. Loss is 0.119204976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003550632012498225. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10080/60000][Iteration 9084][Wall Clock 410.096065089s] Trained 120 records in 0.040940654 seconds. Throughput is 2931.072 records/second. Loss is 0.10229948. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035503798906482992. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10200/60000][Iteration 9085][Wall Clock 410.146059602s] Trained 120 records in 0.049994513 seconds. Throughput is 2400.2634 records/second. Loss is 0.18111119. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035501278046009654. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10320/60000][Iteration 9086][Wall Clock 410.193774849s] Trained 120 records in 0.047715247 seconds. Throughput is 2514.9194 records/second. Loss is 0.15237124. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035498757543485976. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10440/60000][Iteration 9087][Wall Clock 410.240364194s] Trained 120 records in 0.046589345 seconds. Throughput is 2575.6963 records/second. Loss is 0.18342076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035496237398835724. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10560/60000][Iteration 9088][Wall Clock 410.280803384s] Trained 120 records in 0.04043919 seconds. Throughput is 2967.4187 records/second. Loss is 0.21195272. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003549371761198268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10680/60000][Iteration 9089][Wall Clock 410.321742045s] Trained 120 records in 0.040938661 seconds. Throughput is 2931.2146 records/second. Loss is 0.17740844. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035491198182850655. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10800/60000][Iteration 9090][Wall Clock 410.362769977s] Trained 120 records in 0.041027932 seconds. Throughput is 2924.8367 records/second. Loss is 0.18508711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035488679111363476. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 10920/60000][Iteration 9091][Wall Clock 410.403163338s] Trained 120 records in 0.040393361 seconds. Throughput is 2970.7854 records/second. Loss is 0.20541446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035486160397444995. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 11040/60000][Iteration 9092][Wall Clock 410.445501987s] Trained 120 records in 0.042338649 seconds. Throughput is 2834.2896 records/second. Loss is 0.2376046. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003548364204101909. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 11160/60000][Iteration 9093][Wall Clock 410.488206966s] Trained 120 records in 0.042704979 seconds. Throughput is 2809.9766 records/second. Loss is 0.1485437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003548112404200965. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 11280/60000][Iteration 9094][Wall Clock 410.539587835s] Trained 120 records in 0.051380869 seconds. Throughput is 2335.4995 records/second. Loss is 0.15476435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035478606400340595. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:56 INFO  DistriOptimizer$:406 - [Epoch 19 11400/60000][Iteration 9095][Wall Clock 410.58015812s] Trained 120 records in 0.040570285 seconds. Throughput is 2957.8298 records/second. Loss is 0.17801644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035476089115935856. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 11520/60000][Iteration 9096][Wall Clock 410.62066448s] Trained 120 records in 0.04050636 seconds. Throughput is 2962.4978 records/second. Loss is 0.17538245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035473572188719407. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 11640/60000][Iteration 9097][Wall Clock 410.660815372s] Trained 120 records in 0.040150892 seconds. Throughput is 2988.7256 records/second. Loss is 0.11724588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035471055618615205. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 11760/60000][Iteration 9098][Wall Clock 410.701210145s] Trained 120 records in 0.040394773 seconds. Throughput is 2970.6814 records/second. Loss is 0.11550958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035468539405547283. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 11880/60000][Iteration 9099][Wall Clock 410.741610633s] Trained 120 records in 0.040400488 seconds. Throughput is 2970.2612 records/second. Loss is 0.17015359. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035466023549439634. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12000/60000][Iteration 9100][Wall Clock 410.781214965s] Trained 120 records in 0.039604332 seconds. Throughput is 3029.9714 records/second. Loss is 0.15026504. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003546350805021633. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12120/60000][Iteration 9101][Wall Clock 410.822111918s] Trained 120 records in 0.040896953 seconds. Throughput is 2934.204 records/second. Loss is 0.15525068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035460992907801418. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12240/60000][Iteration 9102][Wall Clock 410.863049502s] Trained 120 records in 0.040937584 seconds. Throughput is 2931.2917 records/second. Loss is 0.23012705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035458478122119. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12360/60000][Iteration 9103][Wall Clock 410.903407304s] Trained 120 records in 0.040357802 seconds. Throughput is 2973.4028 records/second. Loss is 0.20547925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035455963693093178. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12480/60000][Iteration 9104][Wall Clock 410.944406683s] Trained 120 records in 0.040999379 seconds. Throughput is 2926.8735 records/second. Loss is 0.16419977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003545344962064809. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12600/60000][Iteration 9105][Wall Clock 410.985360146s] Trained 120 records in 0.040953463 seconds. Throughput is 2930.155 records/second. Loss is 0.06551503. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003545093590470788. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12720/60000][Iteration 9106][Wall Clock 411.029263033s] Trained 120 records in 0.043902887 seconds. Throughput is 2733.3057 records/second. Loss is 0.13259344. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003544842254519674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12840/60000][Iteration 9107][Wall Clock 411.070095521s] Trained 120 records in 0.040832488 seconds. Throughput is 2938.8362 records/second. Loss is 0.09116364. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035445909542038846. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 12960/60000][Iteration 9108][Wall Clock 411.110921909s] Trained 120 records in 0.040826388 seconds. Throughput is 2939.2754 records/second. Loss is 0.17613289. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003544339689515843. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13080/60000][Iteration 9109][Wall Clock 411.15230365s] Trained 120 records in 0.041381741 seconds. Throughput is 2899.8296 records/second. Loss is 0.23997487. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035440884604479726. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13200/60000][Iteration 9110][Wall Clock 411.192292088s] Trained 120 records in 0.039988438 seconds. Throughput is 3000.8672 records/second. Loss is 0.12124659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035438372669927. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13320/60000][Iteration 9111][Wall Clock 411.232729362s] Trained 120 records in 0.040437274 seconds. Throughput is 2967.559 records/second. Loss is 0.19652057. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003543586109142452. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13440/60000][Iteration 9112][Wall Clock 411.284993013s] Trained 120 records in 0.052263651 seconds. Throughput is 2296.0508 records/second. Loss is 0.08845781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035433349868896607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13560/60000][Iteration 9113][Wall Clock 411.330470603s] Trained 120 records in 0.04547759 seconds. Throughput is 2638.662 records/second. Loss is 0.14640231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035430839002267575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13680/60000][Iteration 9114][Wall Clock 411.370469018s] Trained 120 records in 0.039998415 seconds. Throughput is 3000.119 records/second. Loss is 0.21700928. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035428328491461775. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13800/60000][Iteration 9115][Wall Clock 411.410264248s] Trained 120 records in 0.03979523 seconds. Throughput is 3015.4368 records/second. Loss is 0.114998974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003542581833640357. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 13920/60000][Iteration 9116][Wall Clock 411.450093437s] Trained 120 records in 0.039829189 seconds. Throughput is 3012.8657 records/second. Loss is 0.16752376. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035423308537017354. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 14040/60000][Iteration 9117][Wall Clock 411.49940093s] Trained 120 records in 0.049307493 seconds. Throughput is 2433.7073 records/second. Loss is 0.1343324. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035420799093227543. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 14160/60000][Iteration 9118][Wall Clock 411.549930375s] Trained 120 records in 0.050529445 seconds. Throughput is 2374.8528 records/second. Loss is 0.15582578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035418290004958558. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:57 INFO  DistriOptimizer$:406 - [Epoch 19 14280/60000][Iteration 9119][Wall Clock 411.590204642s] Trained 120 records in 0.040274267 seconds. Throughput is 2979.57 records/second. Loss is 0.16246729. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035415781272134864. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 14400/60000][Iteration 9120][Wall Clock 411.641241127s] Trained 120 records in 0.051036485 seconds. Throughput is 2351.259 records/second. Loss is 0.10534571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035413272894680922. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 14520/60000][Iteration 9121][Wall Clock 411.684339769s] Trained 120 records in 0.043098642 seconds. Throughput is 2784.3103 records/second. Loss is 0.12718011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035410764872521247. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 14640/60000][Iteration 9122][Wall Clock 411.724806249s] Trained 120 records in 0.04046648 seconds. Throughput is 2965.4172 records/second. Loss is 0.11708644. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003540825720558034. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 14760/60000][Iteration 9123][Wall Clock 411.765450854s] Trained 120 records in 0.040644605 seconds. Throughput is 2952.4214 records/second. Loss is 0.15675436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035405749893782754. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 14880/60000][Iteration 9124][Wall Clock 411.806137703s] Trained 120 records in 0.040686849 seconds. Throughput is 2949.356 records/second. Loss is 0.13886228. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003540324293705303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15000/60000][Iteration 9125][Wall Clock 411.850296613s] Trained 120 records in 0.04415891 seconds. Throughput is 2717.4585 records/second. Loss is 0.12451822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003540073633531578. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15120/60000][Iteration 9126][Wall Clock 411.891254393s] Trained 120 records in 0.04095778 seconds. Throughput is 2929.8464 records/second. Loss is 0.18662602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035398230088495575. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15240/60000][Iteration 9127][Wall Clock 411.932261305s] Trained 120 records in 0.041006912 seconds. Throughput is 2926.336 records/second. Loss is 0.10992823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003539572419651706. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15360/60000][Iteration 9128][Wall Clock 411.972559381s] Trained 120 records in 0.040298076 seconds. Throughput is 2977.8098 records/second. Loss is 0.10638764. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035393218659304877. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15480/60000][Iteration 9129][Wall Clock 412.013178399s] Trained 120 records in 0.040619018 seconds. Throughput is 2954.281 records/second. Loss is 0.13030598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003539071347678369. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15600/60000][Iteration 9130][Wall Clock 412.053072071s] Trained 120 records in 0.039893672 seconds. Throughput is 3007.9958 records/second. Loss is 0.10610961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003538820864887819. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15720/60000][Iteration 9131][Wall Clock 412.09351398s] Trained 120 records in 0.040441909 seconds. Throughput is 2967.219 records/second. Loss is 0.17038171. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003538570417551309. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15840/60000][Iteration 9132][Wall Clock 412.134366179s] Trained 120 records in 0.040852199 seconds. Throughput is 2937.4182 records/second. Loss is 0.14603685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003538320005661312. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 15960/60000][Iteration 9133][Wall Clock 412.174866405s] Trained 120 records in 0.040500226 seconds. Throughput is 2962.9463 records/second. Loss is 0.1495183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003538069629210303. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16080/60000][Iteration 9134][Wall Clock 412.215772395s] Trained 120 records in 0.04090599 seconds. Throughput is 2933.5557 records/second. Loss is 0.14580946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035378192881907592. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16200/60000][Iteration 9135][Wall Clock 412.255842609s] Trained 120 records in 0.040070214 seconds. Throughput is 2994.7432 records/second. Loss is 0.1349548. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035375689825951607. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16320/60000][Iteration 9136][Wall Clock 412.29529909s] Trained 120 records in 0.039456481 seconds. Throughput is 3041.3257 records/second. Loss is 0.15566327. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003537318712415989. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16440/60000][Iteration 9137][Wall Clock 412.335255751s] Trained 120 records in 0.039956661 seconds. Throughput is 3003.254 records/second. Loss is 0.13576569. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035370684776457268. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16560/60000][Iteration 9138][Wall Clock 412.38540532s] Trained 120 records in 0.050149569 seconds. Throughput is 2392.8423 records/second. Loss is 0.18255481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035368182782768622. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16680/60000][Iteration 9139][Wall Clock 412.435824977s] Trained 120 records in 0.050419657 seconds. Throughput is 2380.0242 records/second. Loss is 0.2715944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035365681143018812. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16800/60000][Iteration 9140][Wall Clock 412.478729922s] Trained 120 records in 0.042904945 seconds. Throughput is 2796.8806 records/second. Loss is 0.16716. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035363179857132755. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 16920/60000][Iteration 9141][Wall Clock 412.518527844s] Trained 120 records in 0.039797922 seconds. Throughput is 3015.233 records/second. Loss is 0.1364643. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003536067892503536. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:58 INFO  DistriOptimizer$:406 - [Epoch 19 17040/60000][Iteration 9142][Wall Clock 412.559232863s] Trained 120 records in 0.040705019 seconds. Throughput is 2948.0396 records/second. Loss is 0.14773437. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035358178346651583. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 17160/60000][Iteration 9143][Wall Clock 412.603807656s] Trained 120 records in 0.044574793 seconds. Throughput is 2692.1045 records/second. Loss is 0.15592326. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035355678121906375. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 17280/60000][Iteration 9144][Wall Clock 412.645050308s] Trained 120 records in 0.041242652 seconds. Throughput is 2909.6091 records/second. Loss is 0.15173867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035353178250724744. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 17400/60000][Iteration 9145][Wall Clock 412.685420414s] Trained 120 records in 0.040370106 seconds. Throughput is 2972.4966 records/second. Loss is 0.19590934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035350678733031674. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 17520/60000][Iteration 9146][Wall Clock 412.725301184s] Trained 120 records in 0.03988077 seconds. Throughput is 3008.969 records/second. Loss is 0.18042864. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003534817956875221. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 17640/60000][Iteration 9147][Wall Clock 412.776092286s] Trained 120 records in 0.050791102 seconds. Throughput is 2362.6184 records/second. Loss is 0.21628214. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035345680757811393. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 17760/60000][Iteration 9148][Wall Clock 412.816565285s] Trained 120 records in 0.040472999 seconds. Throughput is 2964.9397 records/second. Loss is 0.13963026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035343182300134304. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 17880/60000][Iteration 9149][Wall Clock 412.856222962s] Trained 120 records in 0.039657677 seconds. Throughput is 3025.8958 records/second. Loss is 0.09328612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035340684195646027. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18000/60000][Iteration 9150][Wall Clock 412.896378806s] Trained 120 records in 0.040155844 seconds. Throughput is 2988.3572 records/second. Loss is 0.19653195. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003533818644427168. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18120/60000][Iteration 9151][Wall Clock 412.936760155s] Trained 120 records in 0.040381349 seconds. Throughput is 2971.669 records/second. Loss is 0.15724333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035335689045936395. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18240/60000][Iteration 9152][Wall Clock 412.977156753s] Trained 120 records in 0.040396598 seconds. Throughput is 2970.547 records/second. Loss is 0.10993522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003533319200056533. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18360/60000][Iteration 9153][Wall Clock 413.018056691s] Trained 120 records in 0.040899938 seconds. Throughput is 2933.9897 records/second. Loss is 0.17210934. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035330695308083662. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18480/60000][Iteration 9154][Wall Clock 413.058622346s] Trained 120 records in 0.040565655 seconds. Throughput is 2958.1675 records/second. Loss is 0.14440636. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003532819896841659. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18600/60000][Iteration 9155][Wall Clock 413.099187913s] Trained 120 records in 0.040565567 seconds. Throughput is 2958.174 records/second. Loss is 0.09895872. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003532570298148933. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18720/60000][Iteration 9156][Wall Clock 413.139477475s] Trained 120 records in 0.040289562 seconds. Throughput is 2978.439 records/second. Loss is 0.10661413. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003532320734722712. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18840/60000][Iteration 9157][Wall Clock 413.180950224s] Trained 120 records in 0.041472749 seconds. Throughput is 2893.4663 records/second. Loss is 0.16255522. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035320712065555243. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 18960/60000][Iteration 9158][Wall Clock 413.22169338s] Trained 120 records in 0.040743156 seconds. Throughput is 2945.2798 records/second. Loss is 0.097617164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003531821713639895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19080/60000][Iteration 9159][Wall Clock 413.262655021s] Trained 120 records in 0.040961641 seconds. Throughput is 2929.57 records/second. Loss is 0.08136606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035315722559683574. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19200/60000][Iteration 9160][Wall Clock 413.302464292s] Trained 120 records in 0.039809271 seconds. Throughput is 3014.373 records/second. Loss is 0.181005. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035313228335334414. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19320/60000][Iteration 9161][Wall Clock 413.342904226s] Trained 120 records in 0.040439934 seconds. Throughput is 2967.364 records/second. Loss is 0.19067915. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003531073446327684. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19440/60000][Iteration 9162][Wall Clock 413.382951194s] Trained 120 records in 0.040046968 seconds. Throughput is 2996.4814 records/second. Loss is 0.17106766. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035308240943436194. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19560/60000][Iteration 9163][Wall Clock 413.425777641s] Trained 120 records in 0.042826447 seconds. Throughput is 2802.0068 records/second. Loss is 0.1853413. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035305747775737895. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19680/60000][Iteration 9164][Wall Clock 413.465873254s] Trained 120 records in 0.040095613 seconds. Throughput is 2992.8462 records/second. Loss is 0.14626946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003530325496010732. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19800/60000][Iteration 9165][Wall Clock 413.515645819s] Trained 120 records in 0.049772565 seconds. Throughput is 2410.9668 records/second. Loss is 0.15205517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003530076249646993. Current dampening is 1.7976931348623157E308.  
2019-10-23 15:59:59 INFO  DistriOptimizer$:406 - [Epoch 19 19920/60000][Iteration 9166][Wall Clock 413.561977506s] Trained 120 records in 0.046331687 seconds. Throughput is 2590.02 records/second. Loss is 0.1667939. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035298270384751147. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20040/60000][Iteration 9167][Wall Clock 413.60604788s] Trained 120 records in 0.044070374 seconds. Throughput is 2722.9177 records/second. Loss is 0.152159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035295778624876463. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20160/60000][Iteration 9168][Wall Clock 413.655108791s] Trained 120 records in 0.049060911 seconds. Throughput is 2445.9392 records/second. Loss is 0.2841298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003529328721677137. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20280/60000][Iteration 9169][Wall Clock 413.695132234s] Trained 120 records in 0.040023443 seconds. Throughput is 2998.243 records/second. Loss is 0.14061198. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035290796160361375. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20400/60000][Iteration 9170][Wall Clock 413.734970336s] Trained 120 records in 0.039838102 seconds. Throughput is 3012.1917 records/second. Loss is 0.20862699. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035288305455572024. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20520/60000][Iteration 9171][Wall Clock 413.775456363s] Trained 120 records in 0.040486027 seconds. Throughput is 2963.9856 records/second. Loss is 0.13443612. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035285815102328866. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20640/60000][Iteration 9172][Wall Clock 413.814968664s] Trained 120 records in 0.039512301 seconds. Throughput is 3037.0288 records/second. Loss is 0.12316742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035283325100557475. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20760/60000][Iteration 9173][Wall Clock 413.860938148s] Trained 120 records in 0.045969484 seconds. Throughput is 2610.4275 records/second. Loss is 0.19562824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003528083545018346. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 20880/60000][Iteration 9174][Wall Clock 413.906068579s] Trained 120 records in 0.045130431 seconds. Throughput is 2658.9597 records/second. Loss is 0.15313242. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035278346151132434. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21000/60000][Iteration 9175][Wall Clock 413.946912409s] Trained 120 records in 0.04084383 seconds. Throughput is 2938.0203 records/second. Loss is 0.103654556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035275857203330044. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21120/60000][Iteration 9176][Wall Clock 413.988701991s] Trained 120 records in 0.041789582 seconds. Throughput is 2871.529 records/second. Loss is 0.21238445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035273368606701942. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21240/60000][Iteration 9177][Wall Clock 414.029011123s] Trained 120 records in 0.040309132 seconds. Throughput is 2976.993 records/second. Loss is 0.111719824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003527088036117381. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21360/60000][Iteration 9178][Wall Clock 414.068626258s] Trained 120 records in 0.039615135 seconds. Throughput is 3029.1453 records/second. Loss is 0.15316477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003526839246667137. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21480/60000][Iteration 9179][Wall Clock 414.108756932s] Trained 120 records in 0.040130674 seconds. Throughput is 2990.2312 records/second. Loss is 0.16039848. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035265904923120323. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21600/60000][Iteration 9180][Wall Clock 414.148771728s] Trained 120 records in 0.040014796 seconds. Throughput is 2998.8906 records/second. Loss is 0.14460231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035263417730446436. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21720/60000][Iteration 9181][Wall Clock 414.192634198s] Trained 120 records in 0.04386247 seconds. Throughput is 2735.824 records/second. Loss is 0.21003243. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035260930888575456. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21840/60000][Iteration 9182][Wall Clock 414.232382458s] Trained 120 records in 0.03974826 seconds. Throughput is 3019.0002 records/second. Loss is 0.14096066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035258444397433188. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 21960/60000][Iteration 9183][Wall Clock 414.271799076s] Trained 120 records in 0.039416618 seconds. Throughput is 3044.4011 records/second. Loss is 0.08233059. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003525595825694542. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 22080/60000][Iteration 9184][Wall Clock 414.311243331s] Trained 120 records in 0.039444255 seconds. Throughput is 3042.268 records/second. Loss is 0.12552787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035253472467038005. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 22200/60000][Iteration 9185][Wall Clock 414.35070302s] Trained 120 records in 0.039459689 seconds. Throughput is 3041.0781 records/second. Loss is 0.15722638. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003525098702763677. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 22320/60000][Iteration 9186][Wall Clock 414.390157816s] Trained 120 records in 0.039454796 seconds. Throughput is 3041.4553 records/second. Loss is 0.14853178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035248501938667607. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 22440/60000][Iteration 9187][Wall Clock 414.430250007s] Trained 120 records in 0.040092191 seconds. Throughput is 2993.1016 records/second. Loss is 0.11437074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035246017200056393. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 22560/60000][Iteration 9188][Wall Clock 414.469904993s] Trained 120 records in 0.039654986 seconds. Throughput is 3026.1013 records/second. Loss is 0.15971133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003524353281172905. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 22680/60000][Iteration 9189][Wall Clock 414.509902014s] Trained 120 records in 0.039997021 seconds. Throughput is 3000.2234 records/second. Loss is 0.24163014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00352410487736115. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:00 INFO  DistriOptimizer$:406 - [Epoch 19 22800/60000][Iteration 9190][Wall Clock 414.549818902s] Trained 120 records in 0.039916888 seconds. Throughput is 3006.2463 records/second. Loss is 0.10036137. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035238565085629714. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 22920/60000][Iteration 9191][Wall Clock 414.589920447s] Trained 120 records in 0.040101545 seconds. Throughput is 2992.4033 records/second. Loss is 0.14285359. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035236081747709656. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23040/60000][Iteration 9192][Wall Clock 414.646807761s] Trained 120 records in 0.056887314 seconds. Throughput is 2109.4333 records/second. Loss is 0.15748964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035233598759777324. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23160/60000][Iteration 9193][Wall Clock 414.691328439s] Trained 120 records in 0.044520678 seconds. Throughput is 2695.3767 records/second. Loss is 0.14049481. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035231116121758736. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23280/60000][Iteration 9194][Wall Clock 414.732237061s] Trained 120 records in 0.040908622 seconds. Throughput is 2933.367 records/second. Loss is 0.21067269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035228633833579936. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23400/60000][Iteration 9195][Wall Clock 414.771397116s] Trained 120 records in 0.039160055 seconds. Throughput is 3064.3472 records/second. Loss is 0.15359831. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035226151895166972. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23520/60000][Iteration 9196][Wall Clock 414.811417238s] Trained 120 records in 0.040020122 seconds. Throughput is 2998.4915 records/second. Loss is 0.11538061. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035223670306445925. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23640/60000][Iteration 9197][Wall Clock 414.850590814s] Trained 120 records in 0.039173576 seconds. Throughput is 3063.2893 records/second. Loss is 0.1742958. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035221189067342917. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23760/60000][Iteration 9198][Wall Clock 414.889820072s] Trained 120 records in 0.039229258 seconds. Throughput is 3058.9414 records/second. Loss is 0.119132295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035218708177784035. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 23880/60000][Iteration 9199][Wall Clock 414.929155198s] Trained 120 records in 0.039335126 seconds. Throughput is 3050.7085 records/second. Loss is 0.09524535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035216227637695453. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24000/60000][Iteration 9200][Wall Clock 414.987186834s] Trained 120 records in 0.058031636 seconds. Throughput is 2067.8376 records/second. Loss is 0.11321926. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035213747447003308. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24120/60000][Iteration 9201][Wall Clock 415.02918453s] Trained 120 records in 0.041997696 seconds. Throughput is 2857.2996 records/second. Loss is 0.1096898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035211267605633804. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24240/60000][Iteration 9202][Wall Clock 415.070555288s] Trained 120 records in 0.041370758 seconds. Throughput is 2900.5996 records/second. Loss is 0.2098123. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003520878811351313. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24360/60000][Iteration 9203][Wall Clock 415.11157036s] Trained 120 records in 0.041015072 seconds. Throughput is 2925.7537 records/second. Loss is 0.1648247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003520630897056753. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24480/60000][Iteration 9204][Wall Clock 415.151900629s] Trained 120 records in 0.040330269 seconds. Throughput is 2975.4326 records/second. Loss is 0.2066845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035203830176723226. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24600/60000][Iteration 9205][Wall Clock 415.193069782s] Trained 120 records in 0.041169153 seconds. Throughput is 2914.8037 records/second. Loss is 0.16723321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003520135173190651. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24720/60000][Iteration 9206][Wall Clock 415.233504902s] Trained 120 records in 0.04043512 seconds. Throughput is 2967.717 records/second. Loss is 0.17916808. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035198873636043647. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24840/60000][Iteration 9207][Wall Clock 415.273876085s] Trained 120 records in 0.040371183 seconds. Throughput is 2972.4172 records/second. Loss is 0.1290208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003519639588906096. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 24960/60000][Iteration 9208][Wall Clock 415.313624857s] Trained 120 records in 0.039748772 seconds. Throughput is 3018.9612 records/second. Loss is 0.17138349. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035193918490884772. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 25080/60000][Iteration 9209][Wall Clock 415.353604741s] Trained 120 records in 0.039979884 seconds. Throughput is 3001.5095 records/second. Loss is 0.18808746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003519144144144144. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 25200/60000][Iteration 9210][Wall Clock 415.393025158s] Trained 120 records in 0.039420417 seconds. Throughput is 3044.1077 records/second. Loss is 0.14378497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003518896474065733. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 25320/60000][Iteration 9211][Wall Clock 415.433249103s] Trained 120 records in 0.040223945 seconds. Throughput is 2983.2976 records/second. Loss is 0.1570735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003518648838845883. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 25440/60000][Iteration 9212][Wall Clock 415.47326085s] Trained 120 records in 0.040011747 seconds. Throughput is 2999.1191 records/second. Loss is 0.11379139. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035184012384772358. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 25560/60000][Iteration 9213][Wall Clock 415.512896877s] Trained 120 records in 0.039636027 seconds. Throughput is 3027.5486 records/second. Loss is 0.14018866. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035181536729524347. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:01 INFO  DistriOptimizer$:406 - [Epoch 19 25680/60000][Iteration 9214][Wall Clock 415.552787228s] Trained 120 records in 0.039890351 seconds. Throughput is 3008.246 records/second. Loss is 0.18228514. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035179061422641244. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 25800/60000][Iteration 9215][Wall Clock 415.592755545s] Trained 120 records in 0.039968317 seconds. Throughput is 3002.3782 records/second. Loss is 0.13185617. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003517658646404953. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 25920/60000][Iteration 9216][Wall Clock 415.632537214s] Trained 120 records in 0.039781669 seconds. Throughput is 3016.4648 records/second. Loss is 0.10377664. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035174111853675696. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26040/60000][Iteration 9217][Wall Clock 415.681659057s] Trained 120 records in 0.049121843 seconds. Throughput is 2442.905 records/second. Loss is 0.16238597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035171637591446254. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26160/60000][Iteration 9218][Wall Clock 415.735779017s] Trained 120 records in 0.05411996 seconds. Throughput is 2217.2966 records/second. Loss is 0.06928758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035169163677287755. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26280/60000][Iteration 9219][Wall Clock 415.77644401s] Trained 120 records in 0.040664993 seconds. Throughput is 2950.9412 records/second. Loss is 0.09591039. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035166690111126738. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26400/60000][Iteration 9220][Wall Clock 415.815703771s] Trained 120 records in 0.039259761 seconds. Throughput is 3056.5647 records/second. Loss is 0.11590361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035164216892889797. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26520/60000][Iteration 9221][Wall Clock 415.855323859s] Trained 120 records in 0.039620088 seconds. Throughput is 3028.7668 records/second. Loss is 0.14298747. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035161744022503515. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26640/60000][Iteration 9222][Wall Clock 415.89494335s] Trained 120 records in 0.039619491 seconds. Throughput is 3028.8123 records/second. Loss is 0.15718491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035159271499894526. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26760/60000][Iteration 9223][Wall Clock 415.934757878s] Trained 120 records in 0.039814528 seconds. Throughput is 3013.975 records/second. Loss is 0.21677408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003515679932498945. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 26880/60000][Iteration 9224][Wall Clock 415.974849401s] Trained 120 records in 0.040091523 seconds. Throughput is 2993.1516 records/second. Loss is 0.20468237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035154327497714973. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27000/60000][Iteration 9225][Wall Clock 416.014704599s] Trained 120 records in 0.039855198 seconds. Throughput is 3010.8997 records/second. Loss is 0.10267942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003515185601799775. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27120/60000][Iteration 9226][Wall Clock 416.061510696s] Trained 120 records in 0.046806097 seconds. Throughput is 2563.7686 records/second. Loss is 0.1701215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035149384885764497. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27240/60000][Iteration 9227][Wall Clock 416.104175983s] Trained 120 records in 0.042665287 seconds. Throughput is 2812.5908 records/second. Loss is 0.108443566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035146914100941938. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27360/60000][Iteration 9228][Wall Clock 416.145046666s] Trained 120 records in 0.040870683 seconds. Throughput is 2936.09 records/second. Loss is 0.1205248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035144443663456806. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27480/60000][Iteration 9229][Wall Clock 416.185577985s] Trained 120 records in 0.040531319 seconds. Throughput is 2960.6736 records/second. Loss is 0.21219791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003514197357323587. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27600/60000][Iteration 9230][Wall Clock 416.225169717s] Trained 120 records in 0.039591732 seconds. Throughput is 3030.9358 records/second. Loss is 0.15707824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003513950383020592. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27720/60000][Iteration 9231][Wall Clock 416.26515508s] Trained 120 records in 0.039985363 seconds. Throughput is 3001.0981 records/second. Loss is 0.2201956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035137034434293743. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27840/60000][Iteration 9232][Wall Clock 416.305912354s] Trained 120 records in 0.040757274 seconds. Throughput is 2944.2598 records/second. Loss is 0.12016199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035134565385426184. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 27960/60000][Iteration 9233][Wall Clock 416.348141887s] Trained 120 records in 0.042229533 seconds. Throughput is 2841.6133 records/second. Loss is 0.16149592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035132096683530073. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 28080/60000][Iteration 9234][Wall Clock 416.389416923s] Trained 120 records in 0.041275036 seconds. Throughput is 2907.3264 records/second. Loss is 0.22695093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035129628328532283. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 28200/60000][Iteration 9235][Wall Clock 416.430107305s] Trained 120 records in 0.040690382 seconds. Throughput is 2949.0999 records/second. Loss is 0.16899695. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00351271603203597. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 28320/60000][Iteration 9236][Wall Clock 416.470191411s] Trained 120 records in 0.040084106 seconds. Throughput is 2993.7053 records/second. Loss is 0.106438994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003512469265893923. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 28440/60000][Iteration 9237][Wall Clock 416.513186378s] Trained 120 records in 0.042994967 seconds. Throughput is 2791.0242 records/second. Loss is 0.1715791. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003512222534419781. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:02 INFO  DistriOptimizer$:406 - [Epoch 19 28560/60000][Iteration 9238][Wall Clock 416.552846809s] Trained 120 records in 0.039660431 seconds. Throughput is 3025.6858 records/second. Loss is 0.2636593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003511975837606237. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 28680/60000][Iteration 9239][Wall Clock 416.593220304s] Trained 120 records in 0.040373495 seconds. Throughput is 2972.2468 records/second. Loss is 0.129021. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035117291754459897. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 28800/60000][Iteration 9240][Wall Clock 416.63346236s] Trained 120 records in 0.040242056 seconds. Throughput is 2981.9548 records/second. Loss is 0.16255258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035114825479317362. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 28920/60000][Iteration 9241][Wall Clock 416.673587916s] Trained 120 records in 0.040125556 seconds. Throughput is 2990.6128 records/second. Loss is 0.15866846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00351123595505618. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29040/60000][Iteration 9242][Wall Clock 416.72266365s] Trained 120 records in 0.049075734 seconds. Throughput is 2445.2002 records/second. Loss is 0.18683082. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035109893968120216. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29160/60000][Iteration 9243][Wall Clock 416.771486674s] Trained 120 records in 0.048823024 seconds. Throughput is 2457.8567 records/second. Loss is 0.09144298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003510742873191968. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29280/60000][Iteration 9244][Wall Clock 416.811707225s] Trained 120 records in 0.040220551 seconds. Throughput is 2983.5493 records/second. Loss is 0.16516215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003510496384188724. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29400/60000][Iteration 9245][Wall Clock 416.851444608s] Trained 120 records in 0.039737383 seconds. Throughput is 3019.8264 records/second. Loss is 0.20099282. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003510249929795002. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29520/60000][Iteration 9246][Wall Clock 416.891075757s] Trained 120 records in 0.039631149 seconds. Throughput is 3027.9211 records/second. Loss is 0.14416417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035100035100035097. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29640/60000][Iteration 9247][Wall Clock 416.931130381s] Trained 120 records in 0.040054624 seconds. Throughput is 2995.909 records/second. Loss is 0.11722641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003509757124806963. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29760/60000][Iteration 9248][Wall Clock 416.971577781s] Trained 120 records in 0.0404474 seconds. Throughput is 2966.8162 records/second. Loss is 0.12649491. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035095107741980767. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 29880/60000][Iteration 9249][Wall Clock 417.012853516s] Trained 120 records in 0.041275735 seconds. Throughput is 2907.277 records/second. Loss is 0.15378846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035092644581695676. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30000/60000][Iteration 9250][Wall Clock 417.053802122s] Trained 120 records in 0.040948606 seconds. Throughput is 2930.5027 records/second. Loss is 0.14851598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035090181767141555. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30120/60000][Iteration 9251][Wall Clock 417.094626631s] Trained 120 records in 0.040824509 seconds. Throughput is 2939.4106 records/second. Loss is 0.20645241. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035087719298245615. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30240/60000][Iteration 9252][Wall Clock 417.134686624s] Trained 120 records in 0.040059993 seconds. Throughput is 2995.5073 records/second. Loss is 0.19035338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035085257174935092. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30360/60000][Iteration 9253][Wall Clock 417.187266298s] Trained 120 records in 0.052579674 seconds. Throughput is 2282.2507 records/second. Loss is 0.10968863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035082795397137242. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30480/60000][Iteration 9254][Wall Clock 417.229325224s] Trained 120 records in 0.042058926 seconds. Throughput is 2853.14 records/second. Loss is 0.11099896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035080333964779345. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30600/60000][Iteration 9255][Wall Clock 417.270132553s] Trained 120 records in 0.040807329 seconds. Throughput is 2940.6482 records/second. Loss is 0.15840752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035077872877788694. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30720/60000][Iteration 9256][Wall Clock 417.314494242s] Trained 120 records in 0.044361689 seconds. Throughput is 2705.0369 records/second. Loss is 0.2193232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00350754121360926. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30840/60000][Iteration 9257][Wall Clock 417.355282407s] Trained 120 records in 0.040788165 seconds. Throughput is 2942.0298 records/second. Loss is 0.1639969. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035072951739618403. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 30960/60000][Iteration 9258][Wall Clock 417.395265148s] Trained 120 records in 0.039982741 seconds. Throughput is 3001.2952 records/second. Loss is 0.20297833. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003507049168829347. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 31080/60000][Iteration 9259][Wall Clock 417.434965077s] Trained 120 records in 0.039699929 seconds. Throughput is 3022.6753 records/second. Loss is 0.119304225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035068031982045163. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 31200/60000][Iteration 9260][Wall Clock 417.475122783s] Trained 120 records in 0.040157706 seconds. Throughput is 2988.2185 records/second. Loss is 0.25677603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00350655726208009. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 31320/60000][Iteration 9261][Wall Clock 417.516285734s] Trained 120 records in 0.041162951 seconds. Throughput is 2915.2427 records/second. Loss is 0.3067185. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035063113604488078. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:03 INFO  DistriOptimizer$:406 - [Epoch 19 31440/60000][Iteration 9262][Wall Clock 417.557137505s] Trained 120 records in 0.040851771 seconds. Throughput is 2937.449 records/second. Loss is 0.122281484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003506065493303415. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 31560/60000][Iteration 9263][Wall Clock 417.597298958s] Trained 120 records in 0.040161453 seconds. Throughput is 2987.9397 records/second. Loss is 0.15638836. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003505819660636657. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 31680/60000][Iteration 9264][Wall Clock 417.636645359s] Trained 120 records in 0.039346401 seconds. Throughput is 3049.8342 records/second. Loss is 0.16880727. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003505573862441282. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 31800/60000][Iteration 9265][Wall Clock 417.676229598s] Trained 120 records in 0.039584239 seconds. Throughput is 3031.5098 records/second. Loss is 0.11299619. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003505328098710039. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 31920/60000][Iteration 9266][Wall Clock 417.71605619s] Trained 120 records in 0.039826592 seconds. Throughput is 3013.0623 records/second. Loss is 0.1603269. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003505082369435682. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32040/60000][Iteration 9267][Wall Clock 417.765801516s] Trained 120 records in 0.049745326 seconds. Throughput is 2412.2869 records/second. Loss is 0.058691923. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003504836674610963. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32160/60000][Iteration 9268][Wall Clock 417.819187062s] Trained 120 records in 0.053385546 seconds. Throughput is 2247.7996 records/second. Loss is 0.13344333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035045910142286396. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32280/60000][Iteration 9269][Wall Clock 417.860173395s] Trained 120 records in 0.040986333 seconds. Throughput is 2927.8052 records/second. Loss is 0.19423278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003504345388281469. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32400/60000][Iteration 9270][Wall Clock 417.899731987s] Trained 120 records in 0.039558592 seconds. Throughput is 3033.4749 records/second. Loss is 0.18680446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003504099796762212. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32520/60000][Iteration 9271][Wall Clock 417.939377524s] Trained 120 records in 0.039645537 seconds. Throughput is 3026.8223 records/second. Loss is 0.12398606. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00350385423966363. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32640/60000][Iteration 9272][Wall Clock 417.979866084s] Trained 120 records in 0.04048856 seconds. Throughput is 2963.8 records/second. Loss is 0.24298628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003503608716978488. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32760/60000][Iteration 9273][Wall Clock 418.021539149s] Trained 120 records in 0.041673065 seconds. Throughput is 2879.5579 records/second. Loss is 0.17882691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035033632286995517. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 32880/60000][Iteration 9274][Wall Clock 418.063290764s] Trained 120 records in 0.041751615 seconds. Throughput is 2874.1404 records/second. Loss is 0.18237978. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035031177748195896. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33000/60000][Iteration 9275][Wall Clock 418.108241333s] Trained 120 records in 0.044950569 seconds. Throughput is 2669.599 records/second. Loss is 0.14473942. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035028723553313717. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33120/60000][Iteration 9276][Wall Clock 418.150823515s] Trained 120 records in 0.042582182 seconds. Throughput is 2818.0803 records/second. Loss is 0.067330316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035026269702276708. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33240/60000][Iteration 9277][Wall Clock 418.19223576s] Trained 120 records in 0.041412245 seconds. Throughput is 2897.6936 records/second. Loss is 0.26133907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035023816195012608. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33360/60000][Iteration 9278][Wall Clock 418.232861785s] Trained 120 records in 0.040626025 seconds. Throughput is 2953.7715 records/second. Loss is 0.18096338. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003502136303144918. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33480/60000][Iteration 9279][Wall Clock 418.281198977s] Trained 120 records in 0.048337192 seconds. Throughput is 2482.5605 records/second. Loss is 0.23958845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003501891021151422. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33600/60000][Iteration 9280][Wall Clock 418.327255931s] Trained 120 records in 0.046056954 seconds. Throughput is 2605.4697 records/second. Loss is 0.10515582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035016457735135512. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33720/60000][Iteration 9281][Wall Clock 418.3674374s] Trained 120 records in 0.040181469 seconds. Throughput is 2986.4512 records/second. Loss is 0.06650499. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035014005602240898. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33840/60000][Iteration 9282][Wall Clock 418.408595133s] Trained 120 records in 0.041157733 seconds. Throughput is 2915.6125 records/second. Loss is 0.17388669. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035011553812758205. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 33960/60000][Iteration 9283][Wall Clock 418.450359033s] Trained 120 records in 0.0417639 seconds. Throughput is 2873.2947 records/second. Loss is 0.22778083. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035009102366615323. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 34080/60000][Iteration 9284][Wall Clock 418.491378749s] Trained 120 records in 0.041019716 seconds. Throughput is 2925.4226 records/second. Loss is 0.18940505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035006651263740107. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:04 INFO  DistriOptimizer$:406 - [Epoch 19 34200/60000][Iteration 9285][Wall Clock 418.532344106s] Trained 120 records in 0.040965357 seconds. Throughput is 2929.3044 records/second. Loss is 0.06414208. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003500420050406049. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 34320/60000][Iteration 9286][Wall Clock 418.573057997s] Trained 120 records in 0.040713891 seconds. Throughput is 2947.397 records/second. Loss is 0.16278066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0035001750087504373. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 34440/60000][Iteration 9287][Wall Clock 418.61644342s] Trained 120 records in 0.043385423 seconds. Throughput is 2765.906 records/second. Loss is 0.1630598. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034999300013999718. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 34560/60000][Iteration 9288][Wall Clock 418.660580432s] Trained 120 records in 0.044137012 seconds. Throughput is 2718.8066 records/second. Loss is 0.18619107. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034996850283474487. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 34680/60000][Iteration 9289][Wall Clock 418.704473371s] Trained 120 records in 0.043892939 seconds. Throughput is 2733.925 records/second. Loss is 0.15157813. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003499440089585666. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 34800/60000][Iteration 9290][Wall Clock 418.747799231s] Trained 120 records in 0.04332586 seconds. Throughput is 2769.7085 records/second. Loss is 0.10848429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003499195185107425. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 34920/60000][Iteration 9291][Wall Clock 418.789115749s] Trained 120 records in 0.041316518 seconds. Throughput is 2904.4075 records/second. Loss is 0.2032108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003498950314905528. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35040/60000][Iteration 9292][Wall Clock 418.83039265s] Trained 120 records in 0.041276901 seconds. Throughput is 2907.1948 records/second. Loss is 0.14861758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034987054789727802. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35160/60000][Iteration 9293][Wall Clock 418.888999025s] Trained 120 records in 0.058606375 seconds. Throughput is 2047.5588 records/second. Loss is 0.18130232. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003498460677301987. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35280/60000][Iteration 9294][Wall Clock 418.931775269s] Trained 120 records in 0.042776244 seconds. Throughput is 2805.2952 records/second. Loss is 0.13398854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003498215909885958. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35400/60000][Iteration 9295][Wall Clock 418.972614506s] Trained 120 records in 0.040839237 seconds. Throughput is 2938.3508 records/second. Loss is 0.1849257. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003497971176717504. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35520/60000][Iteration 9296][Wall Clock 419.012945514s] Trained 120 records in 0.040331008 seconds. Throughput is 2975.378 records/second. Loss is 0.18541136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003497726477789437. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35640/60000][Iteration 9297][Wall Clock 419.053607484s] Trained 120 records in 0.04066197 seconds. Throughput is 2951.1606 records/second. Loss is 0.16972074. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034974818130945715. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35760/60000][Iteration 9298][Wall Clock 419.094751173s] Trained 120 records in 0.041143689 seconds. Throughput is 2916.6077 records/second. Loss is 0.22261882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003497237182625726. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 35880/60000][Iteration 9299][Wall Clock 419.135589921s] Trained 120 records in 0.040838748 seconds. Throughput is 2938.3857 records/second. Loss is 0.27635878. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034969925863757166. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36000/60000][Iteration 9300][Wall Clock 419.176474508s] Trained 120 records in 0.040884587 seconds. Throughput is 2935.0913 records/second. Loss is 0.1989682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034967480243373664. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36120/60000][Iteration 9301][Wall Clock 419.216814768s] Trained 120 records in 0.04034026 seconds. Throughput is 2974.6958 records/second. Loss is 0.1379505. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003496503496503496. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36240/60000][Iteration 9302][Wall Clock 419.256889923s] Trained 120 records in 0.040075155 seconds. Throughput is 2994.3738 records/second. Loss is 0.1568316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034962590028669326. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36360/60000][Iteration 9303][Wall Clock 419.297065617s] Trained 120 records in 0.040175694 seconds. Throughput is 2986.8806 records/second. Loss is 0.12938641. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034960145434205004. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36480/60000][Iteration 9304][Wall Clock 419.336451773s] Trained 120 records in 0.039386156 seconds. Throughput is 3046.7559 records/second. Loss is 0.087906905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00349577011815703. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36600/60000][Iteration 9305][Wall Clock 419.375341031s] Trained 120 records in 0.038889258 seconds. Throughput is 3085.6848 records/second. Loss is 0.30796987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003495525727069351. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36720/60000][Iteration 9306][Wall Clock 419.422863582s] Trained 120 records in 0.047522551 seconds. Throughput is 2525.117 records/second. Loss is 0.13118725. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034952813701502974. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36840/60000][Iteration 9307][Wall Clock 419.470022128s] Trained 120 records in 0.047158546 seconds. Throughput is 2544.6077 records/second. Loss is 0.19249673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003495037047392702. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 36960/60000][Iteration 9308][Wall Clock 419.510478978s] Trained 120 records in 0.04045685 seconds. Throughput is 2966.123 records/second. Loss is 0.1736468. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034947927587894037. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:05 INFO  DistriOptimizer$:406 - [Epoch 19 37080/60000][Iteration 9309][Wall Clock 419.550515518s] Trained 120 records in 0.04003654 seconds. Throughput is 2997.262 records/second. Loss is 0.11179412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00349454850433324. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 37200/60000][Iteration 9310][Wall Clock 419.590736003s] Trained 120 records in 0.040220485 seconds. Throughput is 2983.5544 records/second. Loss is 0.12130795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034943042840170522. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 37320/60000][Iteration 9311][Wall Clock 419.63056536s] Trained 120 records in 0.039829357 seconds. Throughput is 3012.853 records/second. Loss is 0.117975086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034940600978336828. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 37440/60000][Iteration 9312][Wall Clock 419.673923607s] Trained 120 records in 0.043358247 seconds. Throughput is 2767.6394 records/second. Loss is 0.21272996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034938159457759766. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 37560/60000][Iteration 9313][Wall Clock 419.714064624s] Trained 120 records in 0.040141017 seconds. Throughput is 2989.461 records/second. Loss is 0.17181908. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034935718278367805. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 37680/60000][Iteration 9314][Wall Clock 419.753918475s] Trained 120 records in 0.039853851 seconds. Throughput is 3011.0012 records/second. Loss is 0.1631815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003493327744008943. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 37800/60000][Iteration 9315][Wall Clock 419.795482767s] Trained 120 records in 0.041564292 seconds. Throughput is 2887.0935 records/second. Loss is 0.17922132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003493083694285315. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 37920/60000][Iteration 9316][Wall Clock 419.835127391s] Trained 120 records in 0.039644624 seconds. Throughput is 3026.892 records/second. Loss is 0.16671261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034928396786587496. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38040/60000][Iteration 9317][Wall Clock 419.875948308s] Trained 120 records in 0.040820917 seconds. Throughput is 2939.6694 records/second. Loss is 0.12233054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003492595697122101. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38160/60000][Iteration 9318][Wall Clock 419.922823552s] Trained 120 records in 0.046875244 seconds. Throughput is 2559.9868 records/second. Loss is 0.12409581. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034923517496682262. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38280/60000][Iteration 9319][Wall Clock 419.967672617s] Trained 120 records in 0.044849065 seconds. Throughput is 2675.641 records/second. Loss is 0.1655453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034921078362899847. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38400/60000][Iteration 9320][Wall Clock 420.007675364s] Trained 120 records in 0.040002747 seconds. Throughput is 2999.794 records/second. Loss is 0.1589605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034918639569802355. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38520/60000][Iteration 9321][Wall Clock 420.048227679s] Trained 120 records in 0.040552315 seconds. Throughput is 2959.1406 records/second. Loss is 0.13953567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003491620111731844. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38640/60000][Iteration 9322][Wall Clock 420.089166393s] Trained 120 records in 0.040938714 seconds. Throughput is 2931.211 records/second. Loss is 0.18856545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034913763005376716. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38760/60000][Iteration 9323][Wall Clock 420.129254037s] Trained 120 records in 0.040087644 seconds. Throughput is 2993.4412 records/second. Loss is 0.22078994. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034911325233905883. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 38880/60000][Iteration 9324][Wall Clock 420.168885541s] Trained 120 records in 0.039631504 seconds. Throughput is 3027.894 records/second. Loss is 0.20713192. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00349088878028346. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39000/60000][Iteration 9325][Wall Clock 420.208179757s] Trained 120 records in 0.039294216 seconds. Throughput is 3053.8845 records/second. Loss is 0.18617398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034906450712091598. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39120/60000][Iteration 9326][Wall Clock 420.248500803s] Trained 120 records in 0.040321046 seconds. Throughput is 2976.1133 records/second. Loss is 0.07212996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003490401396160558. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39240/60000][Iteration 9327][Wall Clock 420.28896056s] Trained 120 records in 0.040459757 seconds. Throughput is 2965.9102 records/second. Loss is 0.113037415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034901577551305317. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39360/60000][Iteration 9328][Wall Clock 420.328937994s] Trained 120 records in 0.039977434 seconds. Throughput is 3001.6934 records/second. Loss is 0.18258756. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034899141481119565. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39480/60000][Iteration 9329][Wall Clock 420.368901489s] Trained 120 records in 0.039963495 seconds. Throughput is 3002.7405 records/second. Loss is 0.12068423. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034896705750977106. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39600/60000][Iteration 9330][Wall Clock 420.409234264s] Trained 120 records in 0.040332775 seconds. Throughput is 2975.2478 records/second. Loss is 0.116779976. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034894270360806756. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39720/60000][Iteration 9331][Wall Clock 420.45329905s] Trained 120 records in 0.044064786 seconds. Throughput is 2723.263 records/second. Loss is 0.13529219. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034891835310537334. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39840/60000][Iteration 9332][Wall Clock 420.492991011s] Trained 120 records in 0.039691961 seconds. Throughput is 3023.2822 records/second. Loss is 0.08900165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003488940060009769. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:06 INFO  DistriOptimizer$:406 - [Epoch 19 39960/60000][Iteration 9333][Wall Clock 420.545841474s] Trained 120 records in 0.052850463 seconds. Throughput is 2270.5571 records/second. Loss is 0.10663125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003488696622941669. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40080/60000][Iteration 9334][Wall Clock 420.589790486s] Trained 120 records in 0.043949012 seconds. Throughput is 2730.4368 records/second. Loss is 0.15302724. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034884532198423217. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40200/60000][Iteration 9335][Wall Clock 420.630443463s] Trained 120 records in 0.040652977 seconds. Throughput is 2951.8135 records/second. Loss is 0.1299649. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034882098507046187. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40320/60000][Iteration 9336][Wall Clock 420.67027504s] Trained 120 records in 0.039831577 seconds. Throughput is 3012.685 records/second. Loss is 0.09430591. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003487966515521451. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40440/60000][Iteration 9337][Wall Clock 420.709858973s] Trained 120 records in 0.039583933 seconds. Throughput is 3031.533 records/second. Loss is 0.20061676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003487723214285714. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40560/60000][Iteration 9338][Wall Clock 420.749836924s] Trained 120 records in 0.039977951 seconds. Throughput is 3001.6545 records/second. Loss is 0.28315464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003487479946990305. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40680/60000][Iteration 9339][Wall Clock 420.790237162s] Trained 120 records in 0.040400238 seconds. Throughput is 2970.2795 records/second. Loss is 0.11853047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003487236713628121. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40800/60000][Iteration 9340][Wall Clock 420.830579955s] Trained 120 records in 0.040342793 seconds. Throughput is 2974.509 records/second. Loss is 0.17160723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003486993514192064. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 40920/60000][Iteration 9341][Wall Clock 420.871082768s] Trained 120 records in 0.040502813 seconds. Throughput is 2962.757 records/second. Loss is 0.15344511. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034867503486750344. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41040/60000][Iteration 9342][Wall Clock 420.913134645s] Trained 120 records in 0.042051877 seconds. Throughput is 2853.6182 records/second. Loss is 0.117826276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034865072170699395. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41160/60000][Iteration 9343][Wall Clock 420.973366142s] Trained 120 records in 0.060231497 seconds. Throughput is 1992.3131 records/second. Loss is 0.12015556. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003486264119369683. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41280/60000][Iteration 9344][Wall Clock 421.020427008s] Trained 120 records in 0.047060866 seconds. Throughput is 2549.8894 records/second. Loss is 0.15467212. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003486021055567176. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41400/60000][Iteration 9345][Wall Clock 421.062274221s] Trained 120 records in 0.041847213 seconds. Throughput is 2867.5745 records/second. Loss is 0.14226246. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003485778025655326. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41520/60000][Iteration 9346][Wall Clock 421.103591401s] Trained 120 records in 0.04131718 seconds. Throughput is 2904.3608 records/second. Loss is 0.25305545. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003485535029627048. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41640/60000][Iteration 9347][Wall Clock 421.144257259s] Trained 120 records in 0.040665858 seconds. Throughput is 2950.8784 records/second. Loss is 0.18116446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003485292067475254. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41760/60000][Iteration 9348][Wall Clock 421.184656833s] Trained 120 records in 0.040399574 seconds. Throughput is 2970.3284 records/second. Loss is 0.08564227. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034850491391928626. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 41880/60000][Iteration 9349][Wall Clock 421.228449273s] Trained 120 records in 0.04379244 seconds. Throughput is 2740.199 records/second. Loss is 0.20614077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034848062447727906. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42000/60000][Iteration 9350][Wall Clock 421.268519909s] Trained 120 records in 0.040070636 seconds. Throughput is 2994.7117 records/second. Loss is 0.14750385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003484563384207959. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42120/60000][Iteration 9351][Wall Clock 421.308490047s] Trained 120 records in 0.039970138 seconds. Throughput is 3002.2415 records/second. Loss is 0.23714797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003484320557491289. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42240/60000][Iteration 9352][Wall Clock 421.348118452s] Trained 120 records in 0.039628405 seconds. Throughput is 3028.1309 records/second. Loss is 0.23703401. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003484077764615706. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42360/60000][Iteration 9353][Wall Clock 421.387766209s] Trained 120 records in 0.039647757 seconds. Throughput is 3026.6528 records/second. Loss is 0.15711662. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003483835005574136. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42480/60000][Iteration 9354][Wall Clock 421.427660533s] Trained 120 records in 0.039894324 seconds. Throughput is 3007.9468 records/second. Loss is 0.16475824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034835922803595066. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42600/60000][Iteration 9355][Wall Clock 421.467843255s] Trained 120 records in 0.040182722 seconds. Throughput is 2986.3582 records/second. Loss is 0.12645856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034833495889647487. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42720/60000][Iteration 9356][Wall Clock 421.508131164s] Trained 120 records in 0.040287909 seconds. Throughput is 2978.5613 records/second. Loss is 0.09233609. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034831069313827935. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:07 INFO  DistriOptimizer$:406 - [Epoch 19 42840/60000][Iteration 9357][Wall Clock 421.547999278s] Trained 120 records in 0.039868114 seconds. Throughput is 3009.9243 records/second. Loss is 0.17081684. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034828643076065756. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 42960/60000][Iteration 9358][Wall Clock 421.58780241s] Trained 120 records in 0.039803132 seconds. Throughput is 3014.8381 records/second. Loss is 0.14473946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003482621717629031. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43080/60000][Iteration 9359][Wall Clock 421.636350994s] Trained 120 records in 0.048548584 seconds. Throughput is 2471.7507 records/second. Loss is 0.0754368. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003482379161443098. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43200/60000][Iteration 9360][Wall Clock 421.68427756s] Trained 120 records in 0.047926566 seconds. Throughput is 2503.8306 records/second. Loss is 0.17909704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034821366390417156. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43320/60000][Iteration 9361][Wall Clock 421.72745418s] Trained 120 records in 0.04317662 seconds. Throughput is 2779.2817 records/second. Loss is 0.18970712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034818941504178276. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43440/60000][Iteration 9362][Wall Clock 421.767615939s] Trained 120 records in 0.040161759 seconds. Throughput is 2987.917 records/second. Loss is 0.20636149. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034816516955643753. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43560/60000][Iteration 9363][Wall Clock 421.807668325s] Trained 120 records in 0.040052386 seconds. Throughput is 2996.0764 records/second. Loss is 0.2464933. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034814092744743074. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43680/60000][Iteration 9364][Wall Clock 421.847200729s] Trained 120 records in 0.039532404 seconds. Throughput is 3035.4844 records/second. Loss is 0.12984629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034811668871405693. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43800/60000][Iteration 9365][Wall Clock 421.887821599s] Trained 120 records in 0.04062087 seconds. Throughput is 2954.1465 records/second. Loss is 0.13547249. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034809245335561127. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 43920/60000][Iteration 9366][Wall Clock 421.929428995s] Trained 120 records in 0.041607396 seconds. Throughput is 2884.1028 records/second. Loss is 0.1521184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003480682213713888. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44040/60000][Iteration 9367][Wall Clock 421.972509294s] Trained 120 records in 0.043080299 seconds. Throughput is 2785.4958 records/second. Loss is 0.21690705. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034804399276068495. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44160/60000][Iteration 9368][Wall Clock 422.024424518s] Trained 120 records in 0.051915224 seconds. Throughput is 2311.4607 records/second. Loss is 0.07941217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003480197675227953. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44280/60000][Iteration 9369][Wall Clock 422.069300144s] Trained 120 records in 0.044875626 seconds. Throughput is 2674.0574 records/second. Loss is 0.14738944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034799554565701557. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44400/60000][Iteration 9370][Wall Clock 422.110494728s] Trained 120 records in 0.041194584 seconds. Throughput is 2913.0044 records/second. Loss is 0.120222524. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034797132716264177. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44520/60000][Iteration 9371][Wall Clock 422.151262298s] Trained 120 records in 0.04076757 seconds. Throughput is 2943.516 records/second. Loss is 0.16984452. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003479471120389701. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44640/60000][Iteration 9372][Wall Clock 422.191434346s] Trained 120 records in 0.040172048 seconds. Throughput is 2987.1516 records/second. Loss is 0.19898039. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034792290028529678. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44760/60000][Iteration 9373][Wall Clock 422.230990667s] Trained 120 records in 0.039556321 seconds. Throughput is 3033.6492 records/second. Loss is 0.1454011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034789869190091846. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 44880/60000][Iteration 9374][Wall Clock 422.271505793s] Trained 120 records in 0.040515126 seconds. Throughput is 2961.857 records/second. Loss is 0.07455369. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034787448688513183. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 45000/60000][Iteration 9375][Wall Clock 422.312292539s] Trained 120 records in 0.040786746 seconds. Throughput is 2942.132 records/second. Loss is 0.16929676. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003478502852372339. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 45120/60000][Iteration 9376][Wall Clock 422.353934425s] Trained 120 records in 0.041641886 seconds. Throughput is 2881.7139 records/second. Loss is 0.13450608. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034782608695652175. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 45240/60000][Iteration 9377][Wall Clock 422.394334413s] Trained 120 records in 0.040399988 seconds. Throughput is 2970.2979 records/second. Loss is 0.11201964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034780189204229265. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 45360/60000][Iteration 9378][Wall Clock 422.434517215s] Trained 120 records in 0.040182802 seconds. Throughput is 2986.352 records/second. Loss is 0.10156975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034777770049384434. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 45480/60000][Iteration 9379][Wall Clock 422.474917086s] Trained 120 records in 0.040399871 seconds. Throughput is 2970.3064 records/second. Loss is 0.25012907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003477535123104743. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:08 INFO  DistriOptimizer$:406 - [Epoch 19 45600/60000][Iteration 9380][Wall Clock 422.514990405s] Trained 120 records in 0.040073319 seconds. Throughput is 2994.511 records/second. Loss is 0.2097096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034772932749148064. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 45720/60000][Iteration 9381][Wall Clock 422.55463998s] Trained 120 records in 0.039649575 seconds. Throughput is 3026.5142 records/second. Loss is 0.14373843. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003477051460361613. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 45840/60000][Iteration 9382][Wall Clock 422.594330287s] Trained 120 records in 0.039690307 seconds. Throughput is 3023.4082 records/second. Loss is 0.24696146. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034768096794381476. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 45960/60000][Iteration 9383][Wall Clock 422.633741512s] Trained 120 records in 0.039411225 seconds. Throughput is 3044.8179 records/second. Loss is 0.12506647. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034765679321373936. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46080/60000][Iteration 9384][Wall Clock 422.674407729s] Trained 120 records in 0.040666217 seconds. Throughput is 2950.852 records/second. Loss is 0.091043144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00347632621845234. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46200/60000][Iteration 9385][Wall Clock 422.714152385s] Trained 120 records in 0.039744656 seconds. Throughput is 3019.2737 records/second. Loss is 0.1452925. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003476084538375973. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46320/60000][Iteration 9386][Wall Clock 422.762240269s] Trained 120 records in 0.048087884 seconds. Throughput is 2495.4312 records/second. Loss is 0.17238604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034758428919012866. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46440/60000][Iteration 9387][Wall Clock 422.81292015s] Trained 120 records in 0.050679881 seconds. Throughput is 2367.8035 records/second. Loss is 0.117919095. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034756012790212705. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46560/60000][Iteration 9388][Wall Clock 422.85723831s] Trained 120 records in 0.04431816 seconds. Throughput is 2707.6938 records/second. Loss is 0.16258834. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003475359699728922. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46680/60000][Iteration 9389][Wall Clock 422.897585698s] Trained 120 records in 0.040347388 seconds. Throughput is 2974.1704 records/second. Loss is 0.107156165. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034751181540172366. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46800/60000][Iteration 9390][Wall Clock 422.93795895s] Trained 120 records in 0.040373252 seconds. Throughput is 2972.265 records/second. Loss is 0.13560037. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003474876641879213. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 46920/60000][Iteration 9391][Wall Clock 422.978467931s] Trained 120 records in 0.040508981 seconds. Throughput is 2962.306 records/second. Loss is 0.20454253. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034746351633078527. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47040/60000][Iteration 9392][Wall Clock 423.019437812s] Trained 120 records in 0.040969881 seconds. Throughput is 2928.981 records/second. Loss is 0.19659136. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034743937182961575. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47160/60000][Iteration 9393][Wall Clock 423.061497852s] Trained 120 records in 0.04206004 seconds. Throughput is 2853.0645 records/second. Loss is 0.22674035. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034741523068371315. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47280/60000][Iteration 9394][Wall Clock 423.102578686s] Trained 120 records in 0.041080834 seconds. Throughput is 2921.0703 records/second. Loss is 0.0752072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034739109289237823. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47400/60000][Iteration 9395][Wall Clock 423.154553175s] Trained 120 records in 0.051974489 seconds. Throughput is 2308.825 records/second. Loss is 0.13448174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003473669584549118. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47520/60000][Iteration 9396][Wall Clock 423.19500015s] Trained 120 records in 0.040446975 seconds. Throughput is 2966.8474 records/second. Loss is 0.10773689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003473428273706148. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47640/60000][Iteration 9397][Wall Clock 423.23506261s] Trained 120 records in 0.04006246 seconds. Throughput is 2995.3228 records/second. Loss is 0.13490625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034731869963878855. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47760/60000][Iteration 9398][Wall Clock 423.275866288s] Trained 120 records in 0.040803678 seconds. Throughput is 2940.9114 records/second. Loss is 0.09472558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034729457525873443. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 47880/60000][Iteration 9399][Wall Clock 423.316331086s] Trained 120 records in 0.040464798 seconds. Throughput is 2965.5405 records/second. Loss is 0.15549216. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034727045422975416. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 48000/60000][Iteration 9400][Wall Clock 423.356366804s] Trained 120 records in 0.040035718 seconds. Throughput is 2997.3235 records/second. Loss is 0.17485741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034724633655114933. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 48120/60000][Iteration 9401][Wall Clock 423.396390865s] Trained 120 records in 0.040024061 seconds. Throughput is 2998.1965 records/second. Loss is 0.20148785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034722222222222225. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 48240/60000][Iteration 9402][Wall Clock 423.435976143s] Trained 120 records in 0.039585278 seconds. Throughput is 3031.4302 records/second. Loss is 0.14216907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003471981112422748. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 48360/60000][Iteration 9403][Wall Clock 423.475943165s] Trained 120 records in 0.039967022 seconds. Throughput is 3002.4753 records/second. Loss is 0.18285145. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034717400361060965. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:09 INFO  DistriOptimizer$:406 - [Epoch 19 48480/60000][Iteration 9404][Wall Clock 423.516002499s] Trained 120 records in 0.040059334 seconds. Throughput is 2995.5564 records/second. Loss is 0.17027047. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034714989932652916. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 48600/60000][Iteration 9405][Wall Clock 423.55947285s] Trained 120 records in 0.043470351 seconds. Throughput is 2760.5024 records/second. Loss is 0.08663573. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003471257983893363. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 48720/60000][Iteration 9406][Wall Clock 423.599808378s] Trained 120 records in 0.040335528 seconds. Throughput is 2975.0447 records/second. Loss is 0.1878321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003471017007983339. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 48840/60000][Iteration 9407][Wall Clock 423.639168331s] Trained 120 records in 0.039359953 seconds. Throughput is 3048.7842 records/second. Loss is 0.06325943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034707760655282526. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 48960/60000][Iteration 9408][Wall Clock 423.678675328s] Trained 120 records in 0.039506997 seconds. Throughput is 3037.4365 records/second. Loss is 0.16987103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034705351565211353. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49080/60000][Iteration 9409][Wall Clock 423.718862113s] Trained 120 records in 0.040186785 seconds. Throughput is 2986.0562 records/second. Loss is 0.17172028. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003470294280955025. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49200/60000][Iteration 9410][Wall Clock 423.758586472s] Trained 120 records in 0.039724359 seconds. Throughput is 3020.8167 records/second. Loss is 0.18842751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003470053438822958. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49320/60000][Iteration 9411][Wall Clock 423.798106269s] Trained 120 records in 0.039519797 seconds. Throughput is 3036.453 records/second. Loss is 0.17379276. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034698126301179735. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49440/60000][Iteration 9412][Wall Clock 423.837940854s] Trained 120 records in 0.039834585 seconds. Throughput is 3012.4575 records/second. Loss is 0.17921495. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034695718548331134. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49560/60000][Iteration 9413][Wall Clock 423.886919167s] Trained 120 records in 0.048978313 seconds. Throughput is 2450.064 records/second. Loss is 0.083008036. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003469331112961421. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49680/60000][Iteration 9414][Wall Clock 423.934845238s] Trained 120 records in 0.047926071 seconds. Throughput is 2503.8564 records/second. Loss is 0.14249153. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034690904044959413. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49800/60000][Iteration 9415][Wall Clock 423.976800737s] Trained 120 records in 0.041955499 seconds. Throughput is 2860.1733 records/second. Loss is 0.12738308. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003468849729429721. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 49920/60000][Iteration 9416][Wall Clock 424.016934395s] Trained 120 records in 0.040133658 seconds. Throughput is 2990.009 records/second. Loss is 0.1499863. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00346860908775581. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50040/60000][Iteration 9417][Wall Clock 424.058364316s] Trained 120 records in 0.041429921 seconds. Throughput is 2896.4573 records/second. Loss is 0.13468535. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034683684794672587. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50160/60000][Iteration 9418][Wall Clock 424.09943965s] Trained 120 records in 0.041075334 seconds. Throughput is 2921.4614 records/second. Loss is 0.117740974. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034681279045571203. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50280/60000][Iteration 9419][Wall Clock 424.14005932s] Trained 120 records in 0.04061967 seconds. Throughput is 2954.2336 records/second. Loss is 0.15967792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003467887363018449. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50400/60000][Iteration 9420][Wall Clock 424.17958614s] Trained 120 records in 0.03952682 seconds. Throughput is 3035.9133 records/second. Loss is 0.20583722. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003467646854844303. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50520/60000][Iteration 9421][Wall Clock 424.227471238s] Trained 120 records in 0.047885098 seconds. Throughput is 2505.9988 records/second. Loss is 0.120859995. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003467406380027739. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50640/60000][Iteration 9422][Wall Clock 424.27266624s] Trained 120 records in 0.045195002 seconds. Throughput is 2655.161 records/second. Loss is 0.17427553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034671659385618198. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50760/60000][Iteration 9423][Wall Clock 424.312763562s] Trained 120 records in 0.040097322 seconds. Throughput is 2992.7185 records/second. Loss is 0.14922816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003466925530439606. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 50880/60000][Iteration 9424][Wall Clock 424.35602183s] Trained 120 records in 0.043258268 seconds. Throughput is 2774.0361 records/second. Loss is 0.14694233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034666851556541638. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 51000/60000][Iteration 9425][Wall Clock 424.396250665s] Trained 120 records in 0.040228835 seconds. Throughput is 2982.9348 records/second. Loss is 0.09071482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003466444814198558. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 51120/60000][Iteration 9426][Wall Clock 424.43646809s] Trained 120 records in 0.040217425 seconds. Throughput is 2983.7812 records/second. Loss is 0.20583023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003466204506065858. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 51240/60000][Iteration 9427][Wall Clock 424.476659003s] Trained 120 records in 0.040190913 seconds. Throughput is 2985.7495 records/second. Loss is 0.104966395. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034659642312491333. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:10 INFO  DistriOptimizer$:406 - [Epoch 19 51360/60000][Iteration 9428][Wall Clock 424.517161303s] Trained 120 records in 0.0405023 seconds. Throughput is 2962.795 records/second. Loss is 0.20543508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034657239897414567. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 51480/60000][Iteration 9429][Wall Clock 424.557303647s] Trained 120 records in 0.040142344 seconds. Throughput is 2989.362 records/second. Loss is 0.16166554. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003465483781535902. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 51600/60000][Iteration 9430][Wall Clock 424.597247402s] Trained 120 records in 0.039943755 seconds. Throughput is 3004.2244 records/second. Loss is 0.1202433. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034652436066255456. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 51720/60000][Iteration 9431][Wall Clock 424.637633953s] Trained 120 records in 0.040386551 seconds. Throughput is 2971.2861 records/second. Loss is 0.22330017. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003465003465003465. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 51840/60000][Iteration 9432][Wall Clock 424.677372748s] Trained 120 records in 0.039738795 seconds. Throughput is 3019.719 records/second. Loss is 0.16914979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034647633566627398. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 51960/60000][Iteration 9433][Wall Clock 424.71789189s] Trained 120 records in 0.040519142 seconds. Throughput is 2961.5632 records/second. Loss is 0.11120738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034645232815964525. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52080/60000][Iteration 9434][Wall Clock 424.759325378s] Trained 120 records in 0.041433488 seconds. Throughput is 2896.208 records/second. Loss is 0.18284589. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003464283239797686. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52200/60000][Iteration 9435][Wall Clock 424.799264762s] Trained 120 records in 0.039939384 seconds. Throughput is 3004.553 records/second. Loss is 0.12313519. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034640432312595263. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52320/60000][Iteration 9436][Wall Clock 424.839570936s] Trained 120 records in 0.040306174 seconds. Throughput is 2977.2114 records/second. Loss is 0.14760877. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034638032559750607. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52440/60000][Iteration 9437][Wall Clock 424.879660232s] Trained 120 records in 0.040089296 seconds. Throughput is 2993.3179 records/second. Loss is 0.23150685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003463563313937379. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52560/60000][Iteration 9438][Wall Clock 424.919921876s] Trained 120 records in 0.040261644 seconds. Throughput is 2980.5042 records/second. Loss is 0.15298653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034633234051395716. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52680/60000][Iteration 9439][Wall Clock 424.960818272s] Trained 120 records in 0.040896396 seconds. Throughput is 2934.244 records/second. Loss is 0.18122987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034630835295747335. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52800/60000][Iteration 9440][Wall Clock 425.019734293s] Trained 120 records in 0.058916021 seconds. Throughput is 2036.7974 records/second. Loss is 0.17035723. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003462843687235958. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 52920/60000][Iteration 9441][Wall Clock 425.064595817s] Trained 120 records in 0.044861524 seconds. Throughput is 2674.898 records/second. Loss is 0.14587267. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003462603878116344. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53040/60000][Iteration 9442][Wall Clock 425.10671294s] Trained 120 records in 0.042117123 seconds. Throughput is 2849.1975 records/second. Loss is 0.19575068. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003462364102208988. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53160/60000][Iteration 9443][Wall Clock 425.154284817s] Trained 120 records in 0.047571877 seconds. Throughput is 2522.4988 records/second. Loss is 0.15157096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034621243595069936. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53280/60000][Iteration 9444][Wall Clock 425.195376523s] Trained 120 records in 0.041091706 seconds. Throughput is 2920.2974 records/second. Loss is 0.10256568. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003461884650003462. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53400/60000][Iteration 9445][Wall Clock 425.237790365s] Trained 120 records in 0.042413842 seconds. Throughput is 2829.2651 records/second. Loss is 0.16466407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034616449736914984. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53520/60000][Iteration 9446][Wall Clock 425.279047546s] Trained 120 records in 0.041257181 seconds. Throughput is 2908.5847 records/second. Loss is 0.0923415. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034614053305642087. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53640/60000][Iteration 9447][Wall Clock 425.319382572s] Trained 120 records in 0.040335026 seconds. Throughput is 2975.0818 records/second. Loss is 0.21426632. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034611657206147033. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53760/60000][Iteration 9448][Wall Clock 425.369498119s] Trained 120 records in 0.050115547 seconds. Throughput is 2394.4666 records/second. Loss is 0.1079262. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00346092614383609. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 53880/60000][Iteration 9449][Wall Clock 425.412557889s] Trained 120 records in 0.04305977 seconds. Throughput is 2786.824 records/second. Loss is 0.202517. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034606866002214838. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 54000/60000][Iteration 9450][Wall Clock 425.453904133s] Trained 120 records in 0.041346244 seconds. Throughput is 2902.3193 records/second. Loss is 0.21048237. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003460447089763997. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:11 INFO  DistriOptimizer$:406 - [Epoch 19 54120/60000][Iteration 9451][Wall Clock 425.49495129s] Trained 120 records in 0.041047157 seconds. Throughput is 2923.4668 records/second. Loss is 0.17634436. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034602076124567475. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 54240/60000][Iteration 9452][Wall Clock 425.535166178s] Trained 120 records in 0.040214888 seconds. Throughput is 2983.9695 records/second. Loss is 0.15153809. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034599681682928518. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 54360/60000][Iteration 9453][Wall Clock 425.575486303s] Trained 120 records in 0.040320125 seconds. Throughput is 2976.1814 records/second. Loss is 0.15079975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034597287572654305. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 54480/60000][Iteration 9454][Wall Clock 425.615708627s] Trained 120 records in 0.040222324 seconds. Throughput is 2983.4177 records/second. Loss is 0.1861336. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034594893793676055. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 54600/60000][Iteration 9455][Wall Clock 425.655614722s] Trained 120 records in 0.039906095 seconds. Throughput is 3007.0593 records/second. Loss is 0.09802435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034592500345925004. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 54720/60000][Iteration 9456][Wall Clock 425.695492028s] Trained 120 records in 0.039877306 seconds. Throughput is 3009.2302 records/second. Loss is 0.22350286. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034590107229332413. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 54840/60000][Iteration 9457][Wall Clock 425.73555289s] Trained 120 records in 0.040060862 seconds. Throughput is 2995.4421 records/second. Loss is 0.22804588. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003458771444382955. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 54960/60000][Iteration 9458][Wall Clock 425.775868776s] Trained 120 records in 0.040315886 seconds. Throughput is 2976.4941 records/second. Loss is 0.15809815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003458532198934772. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55080/60000][Iteration 9459][Wall Clock 425.815591926s] Trained 120 records in 0.03972315 seconds. Throughput is 3020.9084 records/second. Loss is 0.19003531. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034582929865818227. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55200/60000][Iteration 9460][Wall Clock 425.854912547s] Trained 120 records in 0.039320621 seconds. Throughput is 3051.8337 records/second. Loss is 0.1607096. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003458053807317242. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55320/60000][Iteration 9461][Wall Clock 425.894495272s] Trained 120 records in 0.039582725 seconds. Throughput is 3031.6255 records/second. Loss is 0.16027711. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003457814661134163. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55440/60000][Iteration 9462][Wall Clock 425.937505236s] Trained 120 records in 0.043009964 seconds. Throughput is 2790.0513 records/second. Loss is 0.11492283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034575755480257247. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55560/60000][Iteration 9463][Wall Clock 425.977951975s] Trained 120 records in 0.040446739 seconds. Throughput is 2966.8645 records/second. Loss is 0.20011213. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003457336467985064. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55680/60000][Iteration 9464][Wall Clock 426.017787498s] Trained 120 records in 0.039835523 seconds. Throughput is 3012.3867 records/second. Loss is 0.0990682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003457097421005324. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55800/60000][Iteration 9465][Wall Clock 426.058335804s] Trained 120 records in 0.040548306 seconds. Throughput is 2959.433 records/second. Loss is 0.20569673. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034568584070796458. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 55920/60000][Iteration 9466][Wall Clock 426.109151721s] Trained 120 records in 0.050815917 seconds. Throughput is 2361.4648 records/second. Loss is 0.1814997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034566194262011757. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56040/60000][Iteration 9467][Wall Clock 426.161746858s] Trained 120 records in 0.052595137 seconds. Throughput is 2281.5796 records/second. Loss is 0.15026835. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003456380478363058. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56160/60000][Iteration 9468][Wall Clock 426.206310788s] Trained 120 records in 0.04456393 seconds. Throughput is 2692.7607 records/second. Loss is 0.19917247. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003456141563558443. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56280/60000][Iteration 9469][Wall Clock 426.24851113s] Trained 120 records in 0.042200342 seconds. Throughput is 2843.5789 records/second. Loss is 0.09415013. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003455902681780481. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56400/60000][Iteration 9470][Wall Clock 426.289493012s] Trained 120 records in 0.040981882 seconds. Throughput is 2928.1233 records/second. Loss is 0.12523665. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034556638330223233. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56520/60000][Iteration 9471][Wall Clock 426.330807441s] Trained 120 records in 0.041314429 seconds. Throughput is 2904.5542 records/second. Loss is 0.12224591. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003455425017277125. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56640/60000][Iteration 9472][Wall Clock 426.372233052s] Trained 120 records in 0.041425611 seconds. Throughput is 2896.7585 records/second. Loss is 0.13455884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034551862345380416. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56760/60000][Iteration 9473][Wall Clock 426.413771672s] Trained 120 records in 0.04153862 seconds. Throughput is 2888.878 records/second. Loss is 0.15721162. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003454947484798231. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 56880/60000][Iteration 9474][Wall Clock 426.461512473s] Trained 120 records in 0.047740801 seconds. Throughput is 2513.5732 records/second. Loss is 0.25698116. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034547087680508533. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:12 INFO  DistriOptimizer$:406 - [Epoch 19 57000/60000][Iteration 9475][Wall Clock 426.505630747s] Trained 120 records in 0.044118274 seconds. Throughput is 2719.9614 records/second. Loss is 0.16853851. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00345447008428907. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57120/60000][Iteration 9476][Wall Clock 426.546038329s] Trained 120 records in 0.040407582 seconds. Throughput is 2969.7395 records/second. Loss is 0.09613851. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034542314335060447. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57240/60000][Iteration 9477][Wall Clock 426.587099159s] Trained 120 records in 0.04106083 seconds. Throughput is 2922.4932 records/second. Loss is 0.1829605. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034539928156949434. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57360/60000][Iteration 9478][Wall Clock 426.628362767s] Trained 120 records in 0.041263608 seconds. Throughput is 2908.1316 records/second. Loss is 0.122904204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034537542308489323. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57480/60000][Iteration 9479][Wall Clock 426.668549455s] Trained 120 records in 0.040186688 seconds. Throughput is 2986.0635 records/second. Loss is 0.14598987. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034535156789611827. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57600/60000][Iteration 9480][Wall Clock 426.712281647s] Trained 120 records in 0.043732192 seconds. Throughput is 2743.974 records/second. Loss is 0.20289832. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034532771600248634. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57720/60000][Iteration 9481][Wall Clock 426.752822235s] Trained 120 records in 0.040540588 seconds. Throughput is 2959.9966 records/second. Loss is 0.1663133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034530386740331495. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57840/60000][Iteration 9482][Wall Clock 426.793043012s] Trained 120 records in 0.040220777 seconds. Throughput is 2983.5325 records/second. Loss is 0.1339496. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003452800220979214. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 57960/60000][Iteration 9483][Wall Clock 426.83268388s] Trained 120 records in 0.039640868 seconds. Throughput is 3027.179 records/second. Loss is 0.089322485. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034525618008562358. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58080/60000][Iteration 9484][Wall Clock 426.872608553s] Trained 120 records in 0.039924673 seconds. Throughput is 3005.6602 records/second. Loss is 0.1687744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003452323413657391. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58200/60000][Iteration 9485][Wall Clock 426.912572979s] Trained 120 records in 0.039964426 seconds. Throughput is 3002.6704 records/second. Loss is 0.15510374. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034520850593758633. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58320/60000][Iteration 9486][Wall Clock 426.953142324s] Trained 120 records in 0.040569345 seconds. Throughput is 2957.8982 records/second. Loss is 0.16258815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034518467380048323. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58440/60000][Iteration 9487][Wall Clock 426.994251812s] Trained 120 records in 0.041109488 seconds. Throughput is 2919.0342 records/second. Loss is 0.1671763. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034516084495374846. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58560/60000][Iteration 9488][Wall Clock 427.035399778s] Trained 120 records in 0.041147966 seconds. Throughput is 2916.3044 records/second. Loss is 0.06075879. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003451370193967005. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58680/60000][Iteration 9489][Wall Clock 427.076269394s] Trained 120 records in 0.040869616 seconds. Throughput is 2936.1665 records/second. Loss is 0.203793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003451131971286582. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58800/60000][Iteration 9490][Wall Clock 427.117706481s] Trained 120 records in 0.041437087 seconds. Throughput is 2895.9565 records/second. Loss is 0.19434783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034508937814894058. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 58920/60000][Iteration 9491][Wall Clock 427.158608748s] Trained 120 records in 0.040902267 seconds. Throughput is 2933.8228 records/second. Loss is 0.1489944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003450655624568668. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59040/60000][Iteration 9492][Wall Clock 427.206808169s] Trained 120 records in 0.048199421 seconds. Throughput is 2489.6565 records/second. Loss is 0.17786191. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034504175005175626. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59160/60000][Iteration 9493][Wall Clock 427.254376197s] Trained 120 records in 0.047568028 seconds. Throughput is 2522.703 records/second. Loss is 0.12524566. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003450179409329285. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59280/60000][Iteration 9494][Wall Clock 427.296539697s] Trained 120 records in 0.0421635 seconds. Throughput is 2846.0637 records/second. Loss is 0.10646054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003449941350997033. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59400/60000][Iteration 9495][Wall Clock 427.336165619s] Trained 120 records in 0.039625922 seconds. Throughput is 3028.3208 records/second. Loss is 0.14014404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034497033255140057. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59520/60000][Iteration 9496][Wall Clock 427.375903342s] Trained 120 records in 0.039737723 seconds. Throughput is 3019.8005 records/second. Loss is 0.17023572. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034494653328734047. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59640/60000][Iteration 9497][Wall Clock 427.416362262s] Trained 120 records in 0.04045892 seconds. Throughput is 2965.9712 records/second. Loss is 0.1593314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003449227373068433. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59760/60000][Iteration 9498][Wall Clock 427.456249443s] Trained 120 records in 0.039887181 seconds. Throughput is 3008.4854 records/second. Loss is 0.21692671. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003448989446092295. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:13 INFO  DistriOptimizer$:406 - [Epoch 19 59880/60000][Iteration 9499][Wall Clock 427.500916331s] Trained 120 records in 0.044666888 seconds. Throughput is 2686.554 records/second. Loss is 0.18240426. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003448751551938198. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:14 INFO  DistriOptimizer$:406 - [Epoch 19 60000/60000][Iteration 9500][Wall Clock 427.542210657s] Trained 120 records in 0.041294326 seconds. Throughput is 2905.9683 records/second. Loss is 0.17377701. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003448513690599352. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:14 INFO  DistriOptimizer$:451 - [Epoch 19 60000/60000][Iteration 9500][Wall Clock 427.542210657s] Epoch finished. Wall clock time is 428331.460368 ms
2019-10-23 16:00:14 INFO  DistriOptimizer$:111 - [Epoch 19 60000/60000][Iteration 9500][Wall Clock 427.542210657s] Validate model...
2019-10-23 16:00:14 INFO  DistriOptimizer$:177 - [Epoch 19 60000/60000][Iteration 9500][Wall Clock 427.542210657s] validate model throughput is 14946.347 records/second
2019-10-23 16:00:14 INFO  DistriOptimizer$:180 - [Epoch 19 60000/60000][Iteration 9500][Wall Clock 427.542210657s] Top1Accuracy is Accuracy(correct: 9582, count: 10000, accuracy: 0.9582)
2019-10-23 16:00:14 INFO  DistriOptimizer$:220 - [Wall Clock 428.331460368s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 16:00:14 INFO  DistriOptimizer$:225 - [Wall Clock 428.331460368s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
2019-10-23 16:00:14 INFO  DistriOptimizer$:406 - [Epoch 20 120/60000][Iteration 9501][Wall Clock 428.380487127s] Trained 120 records in 0.049026759 seconds. Throughput is 2447.643 records/second. Loss is 0.111408964. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003448275862068965. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:14 INFO  DistriOptimizer$:406 - [Epoch 20 240/60000][Iteration 9502][Wall Clock 428.420428475s] Trained 120 records in 0.039941348 seconds. Throughput is 3004.4053 records/second. Loss is 0.21764718. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003448038066340253. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:14 INFO  DistriOptimizer$:406 - [Epoch 20 360/60000][Iteration 9503][Wall Clock 428.461101182s] Trained 120 records in 0.040672707 seconds. Throughput is 2950.3813 records/second. Loss is 0.12572592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034478003034064263. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:14 INFO  DistriOptimizer$:406 - [Epoch 20 480/60000][Iteration 9504][Wall Clock 428.501982637s] Trained 120 records in 0.040881455 seconds. Throughput is 2935.3162 records/second. Loss is 0.19465245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003447562573260705. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:14 INFO  DistriOptimizer$:406 - [Epoch 20 600/60000][Iteration 9505][Wall Clock 428.542118723s] Trained 120 records in 0.040136086 seconds. Throughput is 2989.8281 records/second. Loss is 0.09051408. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003447324875896304. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:14 INFO  DistriOptimizer$:406 - [Epoch 20 720/60000][Iteration 9506][Wall Clock 428.582547668s] Trained 120 records in 0.040428945 seconds. Throughput is 2968.1704 records/second. Loss is 0.14566453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034470872113064465. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 840/60000][Iteration 9507][Wall Clock 428.622693012s] Trained 120 records in 0.040145344 seconds. Throughput is 2989.1387 records/second. Loss is 0.21951455. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034468495794843512. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 960/60000][Iteration 9508][Wall Clock 428.662597102s] Trained 120 records in 0.03990409 seconds. Throughput is 3007.2104 records/second. Loss is 0.14182156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003446611980423244. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1080/60000][Iteration 9509][Wall Clock 428.702435726s] Trained 120 records in 0.039838624 seconds. Throughput is 3012.1523 records/second. Loss is 0.14994283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034463744141163496. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1200/60000][Iteration 9510][Wall Clock 428.743034786s] Trained 120 records in 0.04059906 seconds. Throughput is 2955.7334 records/second. Loss is 0.16243222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034461368805568954. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1320/60000][Iteration 9511][Wall Clock 428.784230352s] Trained 120 records in 0.041195566 seconds. Throughput is 2912.9348 records/second. Loss is 0.1583944. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034458993797381117. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1440/60000][Iteration 9512][Wall Clock 428.825535065s] Trained 120 records in 0.041304713 seconds. Throughput is 2905.2375 records/second. Loss is 0.32475156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034456619116532286. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1560/60000][Iteration 9513][Wall Clock 428.866686038s] Trained 120 records in 0.041150973 seconds. Throughput is 2916.0916 records/second. Loss is 0.17044562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034454244762954795. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1680/60000][Iteration 9514][Wall Clock 428.907314726s] Trained 120 records in 0.040628688 seconds. Throughput is 2953.5781 records/second. Loss is 0.2788202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034451870736580997. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1800/60000][Iteration 9515][Wall Clock 428.95665872s] Trained 120 records in 0.049343994 seconds. Throughput is 2431.9067 records/second. Loss is 0.232615. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034449497037343257. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 1920/60000][Iteration 9516][Wall Clock 429.01153428s] Trained 120 records in 0.05487556 seconds. Throughput is 2186.7659 records/second. Loss is 0.15347865. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003444712366517396. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2040/60000][Iteration 9517][Wall Clock 429.052871641s] Trained 120 records in 0.041337361 seconds. Throughput is 2902.943 records/second. Loss is 0.15475975. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003444475062000551. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2160/60000][Iteration 9518][Wall Clock 429.093845599s] Trained 120 records in 0.040973958 seconds. Throughput is 2928.6895 records/second. Loss is 0.17282394. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034442377901770338. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2280/60000][Iteration 9519][Wall Clock 429.134808438s] Trained 120 records in 0.040962839 seconds. Throughput is 2929.4846 records/second. Loss is 0.26892194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003444000551040088. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2400/60000][Iteration 9520][Wall Clock 429.176136014s] Trained 120 records in 0.041327576 seconds. Throughput is 2903.6301 records/second. Loss is 0.10493407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034437633445829597. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2520/60000][Iteration 9521][Wall Clock 429.216628166s] Trained 120 records in 0.040492152 seconds. Throughput is 2963.5374 records/second. Loss is 0.1641592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003443526170798898. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2640/60000][Iteration 9522][Wall Clock 429.257418515s] Trained 120 records in 0.040790349 seconds. Throughput is 2941.8723 records/second. Loss is 0.14101133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003443289029681151. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2760/60000][Iteration 9523][Wall Clock 429.297825204s] Trained 120 records in 0.040406689 seconds. Throughput is 2969.8054 records/second. Loss is 0.15748562. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034430519212229724. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 2880/60000][Iteration 9524][Wall Clock 429.338266666s] Trained 120 records in 0.040441462 seconds. Throughput is 2967.252 records/second. Loss is 0.17064951. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034428148454176133. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 3000/60000][Iteration 9525][Wall Clock 429.378347447s] Trained 120 records in 0.040080781 seconds. Throughput is 2993.9536 records/second. Loss is 0.20967604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034425778022583314. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 3120/60000][Iteration 9526][Wall Clock 429.428950386s] Trained 120 records in 0.050602939 seconds. Throughput is 2371.4038 records/second. Loss is 0.12218821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003442340791738382. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 3240/60000][Iteration 9527][Wall Clock 429.471181423s] Trained 120 records in 0.042231037 seconds. Throughput is 2841.512 records/second. Loss is 0.21115977. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034421038138510262. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 3360/60000][Iteration 9528][Wall Clock 429.51102954s] Trained 120 records in 0.039848117 seconds. Throughput is 3011.4348 records/second. Loss is 0.18705231. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003441866868589523. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:15 INFO  DistriOptimizer$:406 - [Epoch 20 3480/60000][Iteration 9529][Wall Clock 429.551061366s] Trained 120 records in 0.040031826 seconds. Throughput is 2997.615 records/second. Loss is 0.15681937. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034416299559471364. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 3600/60000][Iteration 9530][Wall Clock 429.591552448s] Trained 120 records in 0.040491082 seconds. Throughput is 2963.6155 records/second. Loss is 0.15865998. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003441393075917131. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 3720/60000][Iteration 9531][Wall Clock 429.63147081s] Trained 120 records in 0.039918362 seconds. Throughput is 3006.1353 records/second. Loss is 0.17589311. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034411562284927736. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 3840/60000][Iteration 9532][Wall Clock 429.671075851s] Trained 120 records in 0.039605041 seconds. Throughput is 3029.9175 records/second. Loss is 0.12562856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003440919413667332. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 3960/60000][Iteration 9533][Wall Clock 429.711582449s] Trained 120 records in 0.040506598 seconds. Throughput is 2962.4805 records/second. Loss is 0.11010309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034406826314340765. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4080/60000][Iteration 9534][Wall Clock 429.751538544s] Trained 120 records in 0.039956095 seconds. Throughput is 3003.2964 records/second. Loss is 0.21827342. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034404458817862793. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4200/60000][Iteration 9535][Wall Clock 429.795040948s] Trained 120 records in 0.043502404 seconds. Throughput is 2758.4683 records/second. Loss is 0.28795597. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034402091647172148. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4320/60000][Iteration 9536][Wall Clock 429.836313876s] Trained 120 records in 0.041272928 seconds. Throughput is 2907.4749 records/second. Loss is 0.099057384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034399724802201583. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4440/60000][Iteration 9537][Wall Clock 429.876171219s] Trained 120 records in 0.039857343 seconds. Throughput is 3010.7375 records/second. Loss is 0.2007593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034397358282883877. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4560/60000][Iteration 9538][Wall Clock 429.916049497s] Trained 120 records in 0.039878278 seconds. Throughput is 3009.157 records/second. Loss is 0.11216581. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003439499208915182. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4680/60000][Iteration 9539][Wall Clock 429.955855938s] Trained 120 records in 0.039806441 seconds. Throughput is 3014.5876 records/second. Loss is 0.08215842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003439262622093823. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4800/60000][Iteration 9540][Wall Clock 430.01453864s] Trained 120 records in 0.058682702 seconds. Throughput is 2044.8956 records/second. Loss is 0.07700621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034390260678175944. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 4920/60000][Iteration 9541][Wall Clock 430.067508955s] Trained 120 records in 0.052970315 seconds. Throughput is 2265.4197 records/second. Loss is 0.15403199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034387895460797797. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5040/60000][Iteration 9542][Wall Clock 430.111125135s] Trained 120 records in 0.04361618 seconds. Throughput is 2751.2727 records/second. Loss is 0.17126921. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034385530568736677. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5160/60000][Iteration 9543][Wall Clock 430.151263541s] Trained 120 records in 0.040138406 seconds. Throughput is 2989.6555 records/second. Loss is 0.3092456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034383166001925453. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5280/60000][Iteration 9544][Wall Clock 430.191588787s] Trained 120 records in 0.040325246 seconds. Throughput is 2975.8032 records/second. Loss is 0.14732572. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003438080176029705. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5400/60000][Iteration 9545][Wall Clock 430.232216256s] Trained 120 records in 0.040627469 seconds. Throughput is 2953.6667 records/second. Loss is 0.16241409. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034378437843784375. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5520/60000][Iteration 9546][Wall Clock 430.272782365s] Trained 120 records in 0.040566109 seconds. Throughput is 2958.1343 records/second. Loss is 0.13145845. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003437607425232039. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5640/60000][Iteration 9547][Wall Clock 430.313460248s] Trained 120 records in 0.040677883 seconds. Throughput is 2950.006 records/second. Loss is 0.23886584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003437371098583803. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5760/60000][Iteration 9548][Wall Clock 430.353401395s] Trained 120 records in 0.039941147 seconds. Throughput is 3004.4204 records/second. Loss is 0.14227384. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00343713480442703. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 5880/60000][Iteration 9549][Wall Clock 430.393017931s] Trained 120 records in 0.039616536 seconds. Throughput is 3029.038 records/second. Loss is 0.18614312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003436898542755018. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 6000/60000][Iteration 9550][Wall Clock 430.433339676s] Trained 120 records in 0.040321745 seconds. Throughput is 2976.0618 records/second. Loss is 0.12987396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034366623135610695. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 6120/60000][Iteration 9551][Wall Clock 430.474360323s] Trained 120 records in 0.041020647 seconds. Throughput is 2925.3562 records/second. Loss is 0.103164874. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003436426116838488. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 6240/60000][Iteration 9552][Wall Clock 430.523453784s] Trained 120 records in 0.049093461 seconds. Throughput is 2444.3174 records/second. Loss is 0.26776972. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034361899525805787. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:16 INFO  DistriOptimizer$:406 - [Epoch 20 6360/60000][Iteration 9553][Wall Clock 430.57071575s] Trained 120 records in 0.047261966 seconds. Throughput is 2539.0396 records/second. Loss is 0.23503248. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034359538207806486. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 6480/60000][Iteration 9554][Wall Clock 430.610801668s] Trained 120 records in 0.040085918 seconds. Throughput is 2993.5698 records/second. Loss is 0.17506784. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003435717721432007. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 6600/60000][Iteration 9555][Wall Clock 430.650730197s] Trained 120 records in 0.039928529 seconds. Throughput is 3005.3699 records/second. Loss is 0.13943318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003435481654527965. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 6720/60000][Iteration 9556][Wall Clock 430.690883353s] Trained 120 records in 0.040153156 seconds. Throughput is 2988.5571 records/second. Loss is 0.17892952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034352456200618343. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 6840/60000][Iteration 9557][Wall Clock 430.731030128s] Trained 120 records in 0.040146775 seconds. Throughput is 2989.032 records/second. Loss is 0.09320442. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034350096180269306. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 6960/60000][Iteration 9558][Wall Clock 430.770892034s] Trained 120 records in 0.039861906 seconds. Throughput is 3010.3928 records/second. Loss is 0.1352427. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034347736484165695. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7080/60000][Iteration 9559][Wall Clock 430.810153647s] Trained 120 records in 0.039261613 seconds. Throughput is 3056.4204 records/second. Loss is 0.11255997. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034345377112240693. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7200/60000][Iteration 9560][Wall Clock 430.849715161s] Trained 120 records in 0.039561514 seconds. Throughput is 3033.251 records/second. Loss is 0.1362218. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034343018064427497. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7320/60000][Iteration 9561][Wall Clock 430.889304773s] Trained 120 records in 0.039589612 seconds. Throughput is 3031.0981 records/second. Loss is 0.07560959. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034340659340659344. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7440/60000][Iteration 9562][Wall Clock 430.929175711s] Trained 120 records in 0.039870938 seconds. Throughput is 3009.7112 records/second. Loss is 0.18817559. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003433830094086944. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7560/60000][Iteration 9563][Wall Clock 430.969232384s] Trained 120 records in 0.040056673 seconds. Throughput is 2995.7556 records/second. Loss is 0.24291946. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034335942864991073. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7680/60000][Iteration 9564][Wall Clock 431.009312043s] Trained 120 records in 0.040079659 seconds. Throughput is 2994.0374 records/second. Loss is 0.20038004. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034333585112957493. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7800/60000][Iteration 9565][Wall Clock 431.05975877s] Trained 120 records in 0.050446727 seconds. Throughput is 2378.747 records/second. Loss is 0.08004905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003433122768470201. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 7920/60000][Iteration 9566][Wall Clock 431.106147668s] Trained 120 records in 0.046388898 seconds. Throughput is 2586.826 records/second. Loss is 0.10701315. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003432887058015791. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8040/60000][Iteration 9567][Wall Clock 431.151765433s] Trained 120 records in 0.045617765 seconds. Throughput is 2630.554 records/second. Loss is 0.15742478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003432651379925855. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8160/60000][Iteration 9568][Wall Clock 431.19232448s] Trained 120 records in 0.040559047 seconds. Throughput is 2958.6494 records/second. Loss is 0.18927482. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003432415734193725. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8280/60000][Iteration 9569][Wall Clock 431.231930649s] Trained 120 records in 0.039606169 seconds. Throughput is 3029.831 records/second. Loss is 0.15588628. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00343218012081274. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8400/60000][Iteration 9570][Wall Clock 431.271892635s] Trained 120 records in 0.039961986 seconds. Throughput is 3002.8538 records/second. Loss is 0.14696404. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034319445397762373. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8520/60000][Iteration 9571][Wall Clock 431.311801235s] Trained 120 records in 0.0399086 seconds. Throughput is 3006.8708 records/second. Loss is 0.20321979. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034317089910775567. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8640/60000][Iteration 9572][Wall Clock 431.355290907s] Trained 120 records in 0.043489672 seconds. Throughput is 2759.276 records/second. Loss is 0.23043361. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034314734747100404. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8760/60000][Iteration 9573][Wall Clock 431.39506705s] Trained 120 records in 0.039776143 seconds. Throughput is 3016.8838 records/second. Loss is 0.17638625. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034312379906670325. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 8880/60000][Iteration 9574][Wall Clock 431.435913139s] Trained 120 records in 0.040846089 seconds. Throughput is 2937.8577 records/second. Loss is 0.19431251. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003431002538941879. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 9000/60000][Iteration 9575][Wall Clock 431.476727228s] Trained 120 records in 0.040814089 seconds. Throughput is 2940.1611 records/second. Loss is 0.17085768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034307671195279266. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 9120/60000][Iteration 9576][Wall Clock 431.518711142s] Trained 120 records in 0.041983914 seconds. Throughput is 2858.2375 records/second. Loss is 0.14109726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003430531732418525. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:17 INFO  DistriOptimizer$:406 - [Epoch 20 9240/60000][Iteration 9577][Wall Clock 431.55919998s] Trained 120 records in 0.040488838 seconds. Throughput is 2963.7798 records/second. Loss is 0.13487558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034302963776070253. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 9360/60000][Iteration 9578][Wall Clock 431.600080888s] Trained 120 records in 0.040880908 seconds. Throughput is 2935.3557 records/second. Loss is 0.15622824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034300610550867805. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 9480/60000][Iteration 9579][Wall Clock 431.650918336s] Trained 120 records in 0.050837448 seconds. Throughput is 2360.4646 records/second. Loss is 0.20471105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003429825764851145. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 9600/60000][Iteration 9580][Wall Clock 431.696891075s] Trained 120 records in 0.045972739 seconds. Throughput is 2610.2427 records/second. Loss is 0.12805584. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003429590506893477. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 9720/60000][Iteration 9581][Wall Clock 431.736970537s] Trained 120 records in 0.040079462 seconds. Throughput is 2994.052 records/second. Loss is 0.13762781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034293552812071325. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 9840/60000][Iteration 9582][Wall Clock 431.777599944s] Trained 120 records in 0.040629407 seconds. Throughput is 2953.526 records/second. Loss is 0.14115025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034291200877854745. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 9960/60000][Iteration 9583][Wall Clock 431.817900746s] Trained 120 records in 0.040300802 seconds. Throughput is 2977.6084 records/second. Loss is 0.15194888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034288849266218622. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10080/60000][Iteration 9584][Wall Clock 431.858361711s] Trained 120 records in 0.040460965 seconds. Throughput is 2965.8213 records/second. Loss is 0.14084396. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003428649797709662. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10200/60000][Iteration 9585][Wall Clock 431.899059598s] Trained 120 records in 0.040697887 seconds. Throughput is 2948.556 records/second. Loss is 0.19112737. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003428414701042238. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10320/60000][Iteration 9586][Wall Clock 431.939539506s] Trained 120 records in 0.040479908 seconds. Throughput is 2964.4336 records/second. Loss is 0.15779252. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003428179636612959. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10440/60000][Iteration 9587][Wall Clock 431.979970532s] Trained 120 records in 0.040431026 seconds. Throughput is 2968.0176 records/second. Loss is 0.12815194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034279446044151924. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10560/60000][Iteration 9588][Wall Clock 432.021783355s] Trained 120 records in 0.041812823 seconds. Throughput is 2869.933 records/second. Loss is 0.11074867. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003427709604442312. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10680/60000][Iteration 9589][Wall Clock 432.063333302s] Trained 120 records in 0.041549947 seconds. Throughput is 2888.0903 records/second. Loss is 0.22112226. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034274746366876885. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10800/60000][Iteration 9590][Wall Clock 432.105274857s] Trained 120 records in 0.041941555 seconds. Throughput is 2861.1243 records/second. Loss is 0.10891386. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034272397011446977. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 10920/60000][Iteration 9591][Wall Clock 432.158710532s] Trained 120 records in 0.053435675 seconds. Throughput is 2245.6907 records/second. Loss is 0.16010761. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003427004797806717. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11040/60000][Iteration 9592][Wall Clock 432.203349803s] Trained 120 records in 0.044639271 seconds. Throughput is 2688.216 records/second. Loss is 0.18260792. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034267699266671233. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11160/60000][Iteration 9593][Wall Clock 432.243958144s] Trained 120 records in 0.040608341 seconds. Throughput is 2955.0579 records/second. Loss is 0.1383304. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003426535087719298. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11280/60000][Iteration 9594][Wall Clock 432.284398304s] Trained 120 records in 0.04044016 seconds. Throughput is 2967.3472 records/second. Loss is 0.19109312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003426300280956623. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11400/60000][Iteration 9595][Wall Clock 432.325043147s] Trained 120 records in 0.040644843 seconds. Throughput is 2952.404 records/second. Loss is 0.23514743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003426065506372482. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11520/60000][Iteration 9596][Wall Clock 432.365250458s] Trained 120 records in 0.040207311 seconds. Throughput is 2984.5317 records/second. Loss is 0.16130728. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034258307639602604. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11640/60000][Iteration 9597][Wall Clock 432.405885965s] Trained 120 records in 0.040635507 seconds. Throughput is 2953.0823 records/second. Loss is 0.21909223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003425596053713346. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11760/60000][Iteration 9598][Wall Clock 432.446509627s] Trained 120 records in 0.040623662 seconds. Throughput is 2953.9436 records/second. Loss is 0.15825297. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034253613756251287. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 11880/60000][Iteration 9599][Wall Clock 432.487342095s] Trained 120 records in 0.040832468 seconds. Throughput is 2938.838 records/second. Loss is 0.12625429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034251267296889986. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 12000/60000][Iteration 9600][Wall Clock 432.528566961s] Trained 120 records in 0.041224866 seconds. Throughput is 2910.8645 records/second. Loss is 0.18886758. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034248921158983488. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:18 INFO  DistriOptimizer$:406 - [Epoch 20 12120/60000][Iteration 9601][Wall Clock 432.56975611s] Trained 120 records in 0.041189149 seconds. Throughput is 2913.3887 records/second. Loss is 0.11490882. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034246575342465756. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 12240/60000][Iteration 9602][Wall Clock 432.610049276s] Trained 120 records in 0.040293166 seconds. Throughput is 2978.1726 records/second. Loss is 0.09895555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003424422984727073. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 12360/60000][Iteration 9603][Wall Clock 432.649728187s] Trained 120 records in 0.039678911 seconds. Throughput is 3024.2764 records/second. Loss is 0.13561298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034241884673332423. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 12480/60000][Iteration 9604][Wall Clock 432.690169265s] Trained 120 records in 0.040441078 seconds. Throughput is 2967.28 records/second. Loss is 0.10890824. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003423953982058481. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 12600/60000][Iteration 9605][Wall Clock 432.730723073s] Trained 120 records in 0.040553808 seconds. Throughput is 2959.0315 records/second. Loss is 0.18981768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003423719528896193. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 12720/60000][Iteration 9606][Wall Clock 432.782393593s] Trained 120 records in 0.05167052 seconds. Throughput is 2322.4075 records/second. Loss is 0.14609309. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034234851078397805. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 12840/60000][Iteration 9607][Wall Clock 432.824911996s] Trained 120 records in 0.042518403 seconds. Throughput is 2822.3074 records/second. Loss is 0.21425703. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034232507188826514. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 12960/60000][Iteration 9608][Wall Clock 432.864841468s] Trained 120 records in 0.039929472 seconds. Throughput is 3005.2988 records/second. Loss is 0.29957142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00342301636201821. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13080/60000][Iteration 9609][Wall Clock 432.908075247s] Trained 120 records in 0.043233779 seconds. Throughput is 2775.6074 records/second. Loss is 0.16106346. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034227820372398684. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13200/60000][Iteration 9610][Wall Clock 432.948067359s] Trained 120 records in 0.039992112 seconds. Throughput is 3000.5916 records/second. Loss is 0.14631087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003422547744541036. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13320/60000][Iteration 9611][Wall Clock 432.988077006s] Trained 120 records in 0.040009647 seconds. Throughput is 2999.2766 records/second. Loss is 0.13975261. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034223134839151265. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13440/60000][Iteration 9612][Wall Clock 433.027954444s] Trained 120 records in 0.039877438 seconds. Throughput is 3009.2205 records/second. Loss is 0.16652076. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003422079255355554. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13560/60000][Iteration 9613][Wall Clock 433.068191765s] Trained 120 records in 0.040237321 seconds. Throughput is 2982.306 records/second. Loss is 0.13109854. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003421845058855735. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13680/60000][Iteration 9614][Wall Clock 433.108904333s] Trained 120 records in 0.040712568 seconds. Throughput is 2947.4927 records/second. Loss is 0.115841016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003421610894409088. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13800/60000][Iteration 9615][Wall Clock 433.151753145s] Trained 120 records in 0.042848812 seconds. Throughput is 2800.5444 records/second. Loss is 0.23122683. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034213767620090325. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 13920/60000][Iteration 9616][Wall Clock 433.202369745s] Trained 120 records in 0.0506166 seconds. Throughput is 2370.7637 records/second. Loss is 0.2286159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034211426616489907. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14040/60000][Iteration 9617][Wall Clock 433.246012217s] Trained 120 records in 0.043642472 seconds. Throughput is 2749.615 records/second. Loss is 0.1654488. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034209085933223863. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14160/60000][Iteration 9618][Wall Clock 433.286448959s] Trained 120 records in 0.040436742 seconds. Throughput is 2967.5981 records/second. Loss is 0.12847038. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003420674557022645. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14280/60000][Iteration 9619][Wall Clock 433.326213677s] Trained 120 records in 0.039764718 seconds. Throughput is 3017.7507 records/second. Loss is 0.13532323. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003420440552743193. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14400/60000][Iteration 9620][Wall Clock 433.366174996s] Trained 120 records in 0.039961319 seconds. Throughput is 3002.9038 records/second. Loss is 0.17485307. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003420206580477461. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14520/60000][Iteration 9621][Wall Clock 433.405887563s] Trained 120 records in 0.039712567 seconds. Throughput is 3021.7136 records/second. Loss is 0.13635893. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034199726402188778. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14640/60000][Iteration 9622][Wall Clock 433.445647426s] Trained 120 records in 0.039759863 seconds. Throughput is 3018.1191 records/second. Loss is 0.13518204. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034197387319608785. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14760/60000][Iteration 9623][Wall Clock 433.487592054s] Trained 120 records in 0.041944628 seconds. Throughput is 2860.9148 records/second. Loss is 0.15044098. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034195048556968947. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 14880/60000][Iteration 9624][Wall Clock 433.528571496s] Trained 120 records in 0.040979442 seconds. Throughput is 2928.2976 records/second. Loss is 0.13716698. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034192710114203653. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:19 INFO  DistriOptimizer$:406 - [Epoch 20 15000/60000][Iteration 9625][Wall Clock 433.57001938s] Trained 120 records in 0.041447884 seconds. Throughput is 2895.202 records/second. Loss is 0.1781752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003419037199124726. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15120/60000][Iteration 9626][Wall Clock 433.612056298s] Trained 120 records in 0.042036918 seconds. Throughput is 2854.6338 records/second. Loss is 0.1535366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034188034188034192. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15240/60000][Iteration 9627][Wall Clock 433.65385313s] Trained 120 records in 0.041796832 seconds. Throughput is 2871.031 records/second. Loss is 0.10720066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034185696704498838. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15360/60000][Iteration 9628][Wall Clock 433.698538598s] Trained 120 records in 0.044685468 seconds. Throughput is 2685.4368 records/second. Loss is 0.1484797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003418335954057565. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15480/60000][Iteration 9629][Wall Clock 433.739593455s] Trained 120 records in 0.041054857 seconds. Throughput is 2922.9185 records/second. Loss is 0.15245174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003418102269619907. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15600/60000][Iteration 9630][Wall Clock 433.779698996s] Trained 120 records in 0.040105541 seconds. Throughput is 2992.1052 records/second. Loss is 0.117834456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034178686171303574. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15720/60000][Iteration 9631][Wall Clock 433.819223227s] Trained 120 records in 0.039524231 seconds. Throughput is 3036.1123 records/second. Loss is 0.14733912. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003417634996582365. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15840/60000][Iteration 9632][Wall Clock 433.867285537s] Trained 120 records in 0.04806231 seconds. Throughput is 2496.759 records/second. Loss is 0.1600073. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00341740140796938. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 15960/60000][Iteration 9633][Wall Clock 433.917364284s] Trained 120 records in 0.050078747 seconds. Throughput is 2396.226 records/second. Loss is 0.1839856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003417167851284855. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16080/60000][Iteration 9634][Wall Clock 433.960304783s] Trained 120 records in 0.042940499 seconds. Throughput is 2794.5647 records/second. Loss is 0.15096954. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003416934326522244. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16200/60000][Iteration 9635][Wall Clock 434.001918635s] Trained 120 records in 0.041613852 seconds. Throughput is 2883.6553 records/second. Loss is 0.22183222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034167008336750035. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16320/60000][Iteration 9636][Wall Clock 434.043001177s] Trained 120 records in 0.041082542 seconds. Throughput is 2920.9487 records/second. Loss is 0.16364446. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034164673727365906. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16440/60000][Iteration 9637][Wall Clock 434.083835479s] Trained 120 records in 0.040834302 seconds. Throughput is 2938.7058 records/second. Loss is 0.11941201. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003416233943700465. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16560/60000][Iteration 9638][Wall Clock 434.123811445s] Trained 120 records in 0.039975966 seconds. Throughput is 3001.8035 records/second. Loss is 0.12041314. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034160005465600873. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16680/60000][Iteration 9639][Wall Clock 434.163899895s] Trained 120 records in 0.04008845 seconds. Throughput is 2993.381 records/second. Loss is 0.12650916. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003415767181308922. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16800/60000][Iteration 9640][Wall Clock 434.208790128s] Trained 120 records in 0.044890233 seconds. Throughput is 2673.1873 records/second. Loss is 0.23392889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003415533847940433. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 16920/60000][Iteration 9641][Wall Clock 434.251636277s] Trained 120 records in 0.042846149 seconds. Throughput is 2800.7183 records/second. Loss is 0.29546478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034153005464480878. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 17040/60000][Iteration 9642][Wall Clock 434.304081723s] Trained 120 records in 0.052445446 seconds. Throughput is 2288.092 records/second. Loss is 0.07764164. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003415067276825353. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 17160/60000][Iteration 9643][Wall Clock 434.344094762s] Trained 120 records in 0.040013039 seconds. Throughput is 2999.0225 records/second. Loss is 0.2117794. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034148340390657015. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 17280/60000][Iteration 9644][Wall Clock 434.383945245s] Trained 120 records in 0.039850483 seconds. Throughput is 3011.2556 records/second. Loss is 0.17474274. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003414600833162603. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 17400/60000][Iteration 9645][Wall Clock 434.423765117s] Trained 120 records in 0.039819872 seconds. Throughput is 3013.5708 records/second. Loss is 0.12810805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003414367659109533. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 17520/60000][Iteration 9646][Wall Clock 434.464335987s] Trained 120 records in 0.04057087 seconds. Throughput is 2957.787 records/second. Loss is 0.15965886. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034141345168999656. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 17640/60000][Iteration 9647][Wall Clock 434.508240172s] Trained 120 records in 0.043904185 seconds. Throughput is 2733.2246 records/second. Loss is 0.239885. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00341390140652738. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:20 INFO  DistriOptimizer$:406 - [Epoch 20 17760/60000][Iteration 9648][Wall Clock 434.548562246s] Trained 120 records in 0.040322074 seconds. Throughput is 2976.0376 records/second. Loss is 0.20520197. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034136683279852526. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 17880/60000][Iteration 9649][Wall Clock 434.588287152s] Trained 120 records in 0.039724906 seconds. Throughput is 3020.775 records/second. Loss is 0.11933217. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034134352812670676. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18000/60000][Iteration 9650][Wall Clock 434.62812002s] Trained 120 records in 0.039832868 seconds. Throughput is 3012.5874 records/second. Loss is 0.17512159. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034132022663663046. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18120/60000][Iteration 9651][Wall Clock 434.668381163s] Trained 120 records in 0.040261143 seconds. Throughput is 2980.5415 records/second. Loss is 0.20713806. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034129692832764505. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18240/60000][Iteration 9652][Wall Clock 434.708537405s] Trained 120 records in 0.040156242 seconds. Throughput is 2988.3274 records/second. Loss is 0.16662876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034127363319909902. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18360/60000][Iteration 9653][Wall Clock 434.748536771s] Trained 120 records in 0.039999366 seconds. Throughput is 3000.0476 records/second. Loss is 0.30284736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034125034125034124. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18480/60000][Iteration 9654][Wall Clock 434.789267012s] Trained 120 records in 0.040730241 seconds. Throughput is 2946.2139 records/second. Loss is 0.1476432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034122705248072066. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18600/60000][Iteration 9655][Wall Clock 434.829723066s] Trained 120 records in 0.040456054 seconds. Throughput is 2966.1816 records/second. Loss is 0.13761066. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034120376688958646. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18720/60000][Iteration 9656][Wall Clock 434.870242794s] Trained 120 records in 0.040519728 seconds. Throughput is 2961.5203 records/second. Loss is 0.20044917. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034118048447628795. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18840/60000][Iteration 9657][Wall Clock 434.910884468s] Trained 120 records in 0.040641674 seconds. Throughput is 2952.6343 records/second. Loss is 0.15279108. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003411572052401747. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 18960/60000][Iteration 9658][Wall Clock 434.951218694s] Trained 120 records in 0.040334226 seconds. Throughput is 2975.1409 records/second. Loss is 0.18503967. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034113392918059633. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19080/60000][Iteration 9659][Wall Clock 435.000019191s] Trained 120 records in 0.048800497 seconds. Throughput is 2458.9912 records/second. Loss is 0.15380818. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034111065629690274. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19200/60000][Iteration 9660][Wall Clock 435.048844022s] Trained 120 records in 0.048824831 seconds. Throughput is 2457.7659 records/second. Loss is 0.13524589. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034108738658844397. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19320/60000][Iteration 9661][Wall Clock 435.092073109s] Trained 120 records in 0.043229087 seconds. Throughput is 2775.9087 records/second. Loss is 0.18024682. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034106412005457023. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19440/60000][Iteration 9662][Wall Clock 435.133086673s] Trained 120 records in 0.041013564 seconds. Throughput is 2925.8613 records/second. Loss is 0.103346355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034104085669463204. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19560/60000][Iteration 9663][Wall Clock 435.174373685s] Trained 120 records in 0.041287012 seconds. Throughput is 2906.483 records/second. Loss is 0.10980477. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003410175965079798. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19680/60000][Iteration 9664][Wall Clock 435.215464613s] Trained 120 records in 0.041090928 seconds. Throughput is 2920.3525 records/second. Loss is 0.2107797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034099433949396443. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19800/60000][Iteration 9665][Wall Clock 435.261229666s] Trained 120 records in 0.045765053 seconds. Throughput is 2622.0881 records/second. Loss is 0.16469602. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003409710856519367. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 19920/60000][Iteration 9666][Wall Clock 435.302730835s] Trained 120 records in 0.041501169 seconds. Throughput is 2891.4849 records/second. Loss is 0.12651649. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003409478349812479. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 20040/60000][Iteration 9667][Wall Clock 435.350336834s] Trained 120 records in 0.047605999 seconds. Throughput is 2520.6907 records/second. Loss is 0.15170577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003409245874812491. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 20160/60000][Iteration 9668][Wall Clock 435.393282637s] Trained 120 records in 0.042945803 seconds. Throughput is 2794.2195 records/second. Loss is 0.16455398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034090134315129207. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 20280/60000][Iteration 9669][Wall Clock 435.434346245s] Trained 120 records in 0.041063608 seconds. Throughput is 2922.2957 records/second. Loss is 0.102776624. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003408781019907281. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 20400/60000][Iteration 9670][Wall Clock 435.476648996s] Trained 120 records in 0.042302751 seconds. Throughput is 2836.695 records/second. Loss is 0.093122765. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034085486399890925. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 20520/60000][Iteration 9671][Wall Clock 435.518176494s] Trained 120 records in 0.041527498 seconds. Throughput is 2889.6516 records/second. Loss is 0.10525077. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034083162917518746. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:21 INFO  DistriOptimizer$:406 - [Epoch 20 20640/60000][Iteration 9672][Wall Clock 435.558534248s] Trained 120 records in 0.040357754 seconds. Throughput is 2973.4062 records/second. Loss is 0.13589802. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034080839751891487. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 20760/60000][Iteration 9673][Wall Clock 435.599290512s] Trained 120 records in 0.040756264 seconds. Throughput is 2944.3328 records/second. Loss is 0.078512445. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034078516902944383. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 20880/60000][Iteration 9674][Wall Clock 435.639767739s] Trained 120 records in 0.040477227 seconds. Throughput is 2964.63 records/second. Loss is 0.14584713. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003407619437061269. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21000/60000][Iteration 9675][Wall Clock 435.680298738s] Trained 120 records in 0.040530999 seconds. Throughput is 2960.6968 records/second. Loss is 0.1891205. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034073872154831673. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21120/60000][Iteration 9676][Wall Clock 435.720600112s] Trained 120 records in 0.040301374 seconds. Throughput is 2977.566 records/second. Loss is 0.09300876. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034071550255536627. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21240/60000][Iteration 9677][Wall Clock 435.760231463s] Trained 120 records in 0.039631351 seconds. Throughput is 3027.9058 records/second. Loss is 0.211142. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003406922867266285. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21360/60000][Iteration 9678][Wall Clock 435.80034801s] Trained 120 records in 0.040116547 seconds. Throughput is 2991.2842 records/second. Loss is 0.2239884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003406690740614567. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21480/60000][Iteration 9679][Wall Clock 435.839955338s] Trained 120 records in 0.039607328 seconds. Throughput is 3029.7424 records/second. Loss is 0.15229851. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034064586455920427. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21600/60000][Iteration 9680][Wall Clock 435.879642733s] Trained 120 records in 0.039687395 seconds. Throughput is 3023.6301 records/second. Loss is 0.17635141. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003406226582192247. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21720/60000][Iteration 9681][Wall Clock 435.919697035s] Trained 120 records in 0.040054302 seconds. Throughput is 2995.9329 records/second. Loss is 0.10132052. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034059945504087193. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21840/60000][Iteration 9682][Wall Clock 435.959628702s] Trained 120 records in 0.039931667 seconds. Throughput is 3005.1338 records/second. Loss is 0.24165748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034057625502349974. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 21960/60000][Iteration 9683][Wall Clock 435.999775232s] Trained 120 records in 0.04014653 seconds. Throughput is 2989.0503 records/second. Loss is 0.15627858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034055305816646235. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22080/60000][Iteration 9684][Wall Clock 436.039851212s] Trained 120 records in 0.04007598 seconds. Throughput is 2994.3123 records/second. Loss is 0.11698842. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003405298644691139. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22200/60000][Iteration 9685][Wall Clock 436.083788387s] Trained 120 records in 0.043937175 seconds. Throughput is 2731.1724 records/second. Loss is 0.12732188. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003405066739308091. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22320/60000][Iteration 9686][Wall Clock 436.136591444s] Trained 120 records in 0.052803057 seconds. Throughput is 2272.5957 records/second. Loss is 0.1556751. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034048348655090228. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22440/60000][Iteration 9687][Wall Clock 436.180805105s] Trained 120 records in 0.044213661 seconds. Throughput is 2714.0933 records/second. Loss is 0.124114536. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034046030232874848. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22560/60000][Iteration 9688][Wall Clock 436.220836994s] Trained 120 records in 0.040031889 seconds. Throughput is 2997.6104 records/second. Loss is 0.13487202. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003404371212637026. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22680/60000][Iteration 9689][Wall Clock 436.262197077s] Trained 120 records in 0.041360083 seconds. Throughput is 2901.3481 records/second. Loss is 0.15348072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034041394335511985. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22800/60000][Iteration 9690][Wall Clock 436.304449788s] Trained 120 records in 0.042252711 seconds. Throughput is 2840.0544 records/second. Loss is 0.18042429. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003403907686023555. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 22920/60000][Iteration 9691][Wall Clock 436.356082653s] Trained 120 records in 0.051632865 seconds. Throughput is 2324.101 records/second. Loss is 0.15496674. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034036759700476512. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 23040/60000][Iteration 9692][Wall Clock 436.397501248s] Trained 120 records in 0.041418595 seconds. Throughput is 2897.2495 records/second. Loss is 0.25554177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003403444285617044. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 23160/60000][Iteration 9693][Wall Clock 436.438531358s] Trained 120 records in 0.04103011 seconds. Throughput is 2924.6814 records/second. Loss is 0.11350118. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003403212632725293. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 23280/60000][Iteration 9694][Wall Clock 436.48718733s] Trained 120 records in 0.048655972 seconds. Throughput is 2466.2954 records/second. Loss is 0.08789768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034029810113659566. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:22 INFO  DistriOptimizer$:406 - [Epoch 20 23400/60000][Iteration 9695][Wall Clock 436.531183263s] Trained 120 records in 0.043995933 seconds. Throughput is 2727.525 records/second. Loss is 0.22014393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034027494215325984. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 23520/60000][Iteration 9696][Wall Clock 436.571797375s] Trained 120 records in 0.040614112 seconds. Throughput is 2954.638 records/second. Loss is 0.11633464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003402517863218782. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 23640/60000][Iteration 9697][Wall Clock 436.612224244s] Trained 120 records in 0.040426869 seconds. Throughput is 2968.323 records/second. Loss is 0.29390675. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003402286336418073. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 23760/60000][Iteration 9698][Wall Clock 436.65305852s] Trained 120 records in 0.040834276 seconds. Throughput is 2938.7078 records/second. Loss is 0.100903355. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003402054841124039. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 23880/60000][Iteration 9699][Wall Clock 436.693088655s] Trained 120 records in 0.040030135 seconds. Throughput is 2997.7415 records/second. Loss is 0.21876782. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003401823377330249. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24000/60000][Iteration 9700][Wall Clock 436.733566813s] Trained 120 records in 0.040478158 seconds. Throughput is 2964.5618 records/second. Loss is 0.09604199. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034015919450302743. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24120/60000][Iteration 9701][Wall Clock 436.773268453s] Trained 120 records in 0.03970164 seconds. Throughput is 3022.5452 records/second. Loss is 0.18816945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034013605442176865. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24240/60000][Iteration 9702][Wall Clock 436.813092176s] Trained 120 records in 0.039823723 seconds. Throughput is 3013.2793 records/second. Loss is 0.31870884. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034011291748860624. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24360/60000][Iteration 9703][Wall Clock 436.85643113s] Trained 120 records in 0.043338954 seconds. Throughput is 2768.8716 records/second. Loss is 0.10207629. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003400897837028975. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24480/60000][Iteration 9704][Wall Clock 436.896671909s] Trained 120 records in 0.040240779 seconds. Throughput is 2982.0496 records/second. Loss is 0.15254241. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034006665306400056. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24600/60000][Iteration 9705][Wall Clock 436.936567601s] Trained 120 records in 0.039895692 seconds. Throughput is 3007.8438 records/second. Loss is 0.12825479. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0034004352557127308. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24720/60000][Iteration 9706][Wall Clock 436.976773654s] Trained 120 records in 0.040206053 seconds. Throughput is 2984.6252 records/second. Loss is 0.149381. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003400204012240735. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24840/60000][Iteration 9707][Wall Clock 437.017132323s] Trained 120 records in 0.040358669 seconds. Throughput is 2973.3389 records/second. Loss is 0.29260817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003399972800217598. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 24960/60000][Iteration 9708][Wall Clock 437.058251722s] Trained 120 records in 0.041119399 seconds. Throughput is 2918.3306 records/second. Loss is 0.12349105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033997416196369077. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25080/60000][Iteration 9709][Wall Clock 437.098586477s] Trained 120 records in 0.040334755 seconds. Throughput is 2975.1018 records/second. Loss is 0.12590736. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003399510470492249. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25200/60000][Iteration 9710][Wall Clock 437.139277932s] Trained 120 records in 0.040691455 seconds. Throughput is 2949.0222 records/second. Loss is 0.15724827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003399279352777211. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25320/60000][Iteration 9711][Wall Clock 437.180060638s] Trained 120 records in 0.040782706 seconds. Throughput is 2942.4238 records/second. Loss is 0.19021793. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003399048266485384. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25440/60000][Iteration 9712][Wall Clock 437.22919513s] Trained 120 records in 0.049134492 seconds. Throughput is 2442.2761 records/second. Loss is 0.21769586. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033988172116103596. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25560/60000][Iteration 9713][Wall Clock 437.278392352s] Trained 120 records in 0.049197222 seconds. Throughput is 2439.162 records/second. Loss is 0.17775318. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033985861881457315. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25680/60000][Iteration 9714][Wall Clock 437.32250738s] Trained 120 records in 0.044115028 seconds. Throughput is 2720.1614 records/second. Loss is 0.16604996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003398355196085095. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25800/60000][Iteration 9715][Wall Clock 437.365198488s] Trained 120 records in 0.042691108 seconds. Throughput is 2810.89 records/second. Loss is 0.10761016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003398124235422047. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 25920/60000][Iteration 9716][Wall Clock 437.409486948s] Trained 120 records in 0.04428846 seconds. Throughput is 2709.5095 records/second. Loss is 0.14136805. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033978933061501867. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 26040/60000][Iteration 9717][Wall Clock 437.451505943s] Trained 120 records in 0.042018995 seconds. Throughput is 2855.8513 records/second. Loss is 0.17139687. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003397662408263115. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 26160/60000][Iteration 9718][Wall Clock 437.491621896s] Trained 120 records in 0.040115953 seconds. Throughput is 2991.3286 records/second. Loss is 0.16100696. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033974315417544337. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:23 INFO  DistriOptimizer$:406 - [Epoch 20 26280/60000][Iteration 9719][Wall Clock 437.531226595s] Trained 120 records in 0.039604699 seconds. Throughput is 3029.9436 records/second. Loss is 0.19838555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003397200706617747. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 26400/60000][Iteration 9720][Wall Clock 437.572336206s] Trained 120 records in 0.041109611 seconds. Throughput is 2919.0254 records/second. Loss is 0.18250412. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033969699028466604. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 26520/60000][Iteration 9721][Wall Clock 437.625512025s] Trained 120 records in 0.053175819 seconds. Throughput is 2256.6648 records/second. Loss is 0.09954011. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003396739130434783. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 26640/60000][Iteration 9722][Wall Clock 437.666125449s] Trained 120 records in 0.040613424 seconds. Throughput is 2954.688 records/second. Loss is 0.13254023. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033965083893757212. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 26760/60000][Iteration 9723][Wall Clock 437.706707651s] Trained 120 records in 0.040582202 seconds. Throughput is 2956.9612 records/second. Loss is 0.07821186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033962776796630893. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 26880/60000][Iteration 9724][Wall Clock 437.747207709s] Trained 120 records in 0.040500058 seconds. Throughput is 2962.9585 records/second. Loss is 0.13236484. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033960470012904974. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27000/60000][Iteration 9725][Wall Clock 437.787020712s] Trained 120 records in 0.039813003 seconds. Throughput is 3014.0906 records/second. Loss is 0.22099331. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033958163542515624. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27120/60000][Iteration 9726][Wall Clock 437.826702085s] Trained 120 records in 0.039681373 seconds. Throughput is 3024.089 records/second. Loss is 0.1399081. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003395585738539898. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27240/60000][Iteration 9727][Wall Clock 437.866032847s] Trained 120 records in 0.039330762 seconds. Throughput is 3051.0469 records/second. Loss is 0.12174869. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003395355154149124. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27360/60000][Iteration 9728][Wall Clock 437.906005421s] Trained 120 records in 0.039972574 seconds. Throughput is 3002.0583 records/second. Loss is 0.120627485. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033951246010728593. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27480/60000][Iteration 9729][Wall Clock 437.946038305s] Trained 120 records in 0.040032884 seconds. Throughput is 2997.536 records/second. Loss is 0.07258072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003394894079304726. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27600/60000][Iteration 9730][Wall Clock 437.98684162s] Trained 120 records in 0.040803315 seconds. Throughput is 2940.9377 records/second. Loss is 0.09976689. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003394663588838346. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27720/60000][Iteration 9731][Wall Clock 438.027388679s] Trained 120 records in 0.040547059 seconds. Throughput is 2959.5242 records/second. Loss is 0.10280003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033944331296673455. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27840/60000][Iteration 9732][Wall Clock 438.06867919s] Trained 120 records in 0.041290511 seconds. Throughput is 2906.2368 records/second. Loss is 0.2648103. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033942027017853506. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 27960/60000][Iteration 9733][Wall Clock 438.110219824s] Trained 120 records in 0.041540634 seconds. Throughput is 2888.7378 records/second. Loss is 0.16565809. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033939723051859896. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28080/60000][Iteration 9734][Wall Clock 438.151771025s] Trained 120 records in 0.041551201 seconds. Throughput is 2888.0032 records/second. Loss is 0.16925222. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003393741939862893. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28200/60000][Iteration 9735][Wall Clock 438.193161882s] Trained 120 records in 0.041390857 seconds. Throughput is 2899.191 records/second. Loss is 0.1443292. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003393511605809692. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28320/60000][Iteration 9736][Wall Clock 438.233029347s] Trained 120 records in 0.039867465 seconds. Throughput is 3009.9731 records/second. Loss is 0.20539087. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033932813030200203. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28440/60000][Iteration 9737][Wall Clock 438.273609915s] Trained 120 records in 0.040580568 seconds. Throughput is 2957.0803 records/second. Loss is 0.12885329. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033930510314875138. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28560/60000][Iteration 9738][Wall Clock 438.313702013s] Trained 120 records in 0.040092098 seconds. Throughput is 2993.1084 records/second. Loss is 0.11525619. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033928207912058087. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28680/60000][Iteration 9739][Wall Clock 438.362817612s] Trained 120 records in 0.049115599 seconds. Throughput is 2443.2156 records/second. Loss is 0.18455121. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003392590582168544. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28800/60000][Iteration 9740][Wall Clock 438.414761869s] Trained 120 records in 0.051944257 seconds. Throughput is 2310.1687 records/second. Loss is 0.16978666. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00339236040436936. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 28920/60000][Iteration 9741][Wall Clock 438.459305945s] Trained 120 records in 0.044544076 seconds. Throughput is 2693.961 records/second. Loss is 0.33919302. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033921302578018993. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 29040/60000][Iteration 9742][Wall Clock 438.500902971s] Trained 120 records in 0.041597026 seconds. Throughput is 2884.8215 records/second. Loss is 0.14325234. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033919001424598063. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:24 INFO  DistriOptimizer$:406 - [Epoch 20 29160/60000][Iteration 9743][Wall Clock 438.540848979s] Trained 120 records in 0.039946008 seconds. Throughput is 3004.055 records/second. Loss is 0.155578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033916700583367246. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 29280/60000][Iteration 9744][Wall Clock 438.580921974s] Trained 120 records in 0.040072995 seconds. Throughput is 2994.5352 records/second. Loss is 0.13786952. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033914400054263043. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 29400/60000][Iteration 9745][Wall Clock 438.621284172s] Trained 120 records in 0.040362198 seconds. Throughput is 2973.0789 records/second. Loss is 0.23859577. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003391209983722192. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 29520/60000][Iteration 9746][Wall Clock 438.661727422s] Trained 120 records in 0.04044325 seconds. Throughput is 2967.1206 records/second. Loss is 0.09094352. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00339097999321804. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 29640/60000][Iteration 9747][Wall Clock 438.709229355s] Trained 120 records in 0.047501933 seconds. Throughput is 2526.213 records/second. Loss is 0.16808634. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033907500339075. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 29760/60000][Iteration 9748][Wall Clock 438.752845577s] Trained 120 records in 0.043616222 seconds. Throughput is 2751.27 records/second. Loss is 0.16180821. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033905201057842275. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 29880/60000][Iteration 9749][Wall Clock 438.793397435s] Trained 120 records in 0.040551858 seconds. Throughput is 2959.174 records/second. Loss is 0.078165896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033902902088418767. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30000/60000][Iteration 9750][Wall Clock 438.833282762s] Trained 120 records in 0.039885327 seconds. Throughput is 3008.6252 records/second. Loss is 0.21307454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033900603430741067. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30120/60000][Iteration 9751][Wall Clock 438.873301356s] Trained 120 records in 0.040018594 seconds. Throughput is 2998.606 records/second. Loss is 0.15809603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003389830508474576. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30240/60000][Iteration 9752][Wall Clock 438.913404092s] Trained 120 records in 0.040102736 seconds. Throughput is 2992.3147 records/second. Loss is 0.12566659. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033896007050369464. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30360/60000][Iteration 9753][Wall Clock 438.953291286s] Trained 120 records in 0.039887194 seconds. Throughput is 3008.4844 records/second. Loss is 0.21394053. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033893709327548808. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30480/60000][Iteration 9754][Wall Clock 438.993935657s] Trained 120 records in 0.040644371 seconds. Throughput is 2952.4385 records/second. Loss is 0.13514858. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003389141191622043. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30600/60000][Iteration 9755][Wall Clock 439.034052137s] Trained 120 records in 0.04011648 seconds. Throughput is 2991.2893 records/second. Loss is 0.18224822. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033889114816320997. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30720/60000][Iteration 9756][Wall Clock 439.074529381s] Trained 120 records in 0.040477244 seconds. Throughput is 2964.629 records/second. Loss is 0.22914316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003388681802778719. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30840/60000][Iteration 9757][Wall Clock 439.115199672s] Trained 120 records in 0.040670291 seconds. Throughput is 2950.5566 records/second. Loss is 0.080612265. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033884521550555705. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 30960/60000][Iteration 9758][Wall Clock 439.155962349s] Trained 120 records in 0.040762677 seconds. Throughput is 2943.8694 records/second. Loss is 0.12758014. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033882225384563257. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31080/60000][Iteration 9759][Wall Clock 439.199676517s] Trained 120 records in 0.043714168 seconds. Throughput is 2745.1052 records/second. Loss is 0.2757962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033879929529746578. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31200/60000][Iteration 9760][Wall Clock 439.239261228s] Trained 120 records in 0.039584711 seconds. Throughput is 3031.4734 records/second. Loss is 0.08212258. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003387763398604241. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31320/60000][Iteration 9761][Wall Clock 439.279725977s] Trained 120 records in 0.040464749 seconds. Throughput is 2965.5442 records/second. Loss is 0.09818132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033875338753387536. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31440/60000][Iteration 9762][Wall Clock 439.319693666s] Trained 120 records in 0.039967689 seconds. Throughput is 3002.4253 records/second. Loss is 0.09334639. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033873043831718717. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31560/60000][Iteration 9763][Wall Clock 439.35942184s] Trained 120 records in 0.039728174 seconds. Throughput is 3020.5264 records/second. Loss is 0.2486731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003387074922097277. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31680/60000][Iteration 9764][Wall Clock 439.399450235s] Trained 120 records in 0.040028395 seconds. Throughput is 2997.872 records/second. Loss is 0.09322172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033868454921086497. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31800/60000][Iteration 9765][Wall Clock 439.449743973s] Trained 120 records in 0.050293738 seconds. Throughput is 2385.983 records/second. Loss is 0.12624533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033866160931996753. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 31920/60000][Iteration 9766][Wall Clock 439.501012001s] Trained 120 records in 0.051268028 seconds. Throughput is 2340.6401 records/second. Loss is 0.12526633. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003386386725364036. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:25 INFO  DistriOptimizer$:406 - [Epoch 20 32040/60000][Iteration 9767][Wall Clock 439.541771486s] Trained 120 records in 0.040759485 seconds. Throughput is 2944.1 records/second. Loss is 0.14623578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003386157388595422. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 32160/60000][Iteration 9768][Wall Clock 439.5819266s] Trained 120 records in 0.040155114 seconds. Throughput is 2988.4114 records/second. Loss is 0.20163259. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003385928082887519. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 32280/60000][Iteration 9769][Wall Clock 439.621500927s] Trained 120 records in 0.039574327 seconds. Throughput is 3032.2688 records/second. Loss is 0.117359295. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00338569880823402. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 32400/60000][Iteration 9770][Wall Clock 439.661271141s] Trained 120 records in 0.039770214 seconds. Throughput is 3017.3335 records/second. Loss is 0.1711149. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033854695646286137. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 32520/60000][Iteration 9771][Wall Clock 439.700822369s] Trained 120 records in 0.039551228 seconds. Throughput is 3034.0398 records/second. Loss is 0.31904945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033852403520649964. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 32640/60000][Iteration 9772][Wall Clock 439.74176337s] Trained 120 records in 0.040941001 seconds. Throughput is 2931.047 records/second. Loss is 0.13924567. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033850111705368627. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 32760/60000][Iteration 9773][Wall Clock 439.782475309s] Trained 120 records in 0.040711939 seconds. Throughput is 2947.5383 records/second. Loss is 0.12487319. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033847820200379095. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 32880/60000][Iteration 9774][Wall Clock 439.831369866s] Trained 120 records in 0.048894557 seconds. Throughput is 2454.2607 records/second. Loss is 0.18328533. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003384552900561836. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33000/60000][Iteration 9775][Wall Clock 439.87423401s] Trained 120 records in 0.042864144 seconds. Throughput is 2799.5427 records/second. Loss is 0.12373281. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003384323812102342. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33120/60000][Iteration 9776][Wall Clock 439.91430817s] Trained 120 records in 0.04007416 seconds. Throughput is 2994.4485 records/second. Loss is 0.1294578. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00338409475465313. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33240/60000][Iteration 9777][Wall Clock 439.953860444s] Trained 120 records in 0.039552274 seconds. Throughput is 3033.9595 records/second. Loss is 0.17504178. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003383865728207905. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33360/60000][Iteration 9778][Wall Clock 439.998699789s] Trained 120 records in 0.044839345 seconds. Throughput is 2676.2212 records/second. Loss is 0.1225221. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003383636732760371. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33480/60000][Iteration 9779][Wall Clock 440.039589884s] Trained 120 records in 0.040890095 seconds. Throughput is 2934.696 records/second. Loss is 0.21622655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003383407768304236. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33600/60000][Iteration 9780][Wall Clock 440.079942405s] Trained 120 records in 0.040352521 seconds. Throughput is 2973.792 records/second. Loss is 0.1538393. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003383178834833209. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33720/60000][Iteration 9781][Wall Clock 440.121117533s] Trained 120 records in 0.041175128 seconds. Throughput is 2914.3809 records/second. Loss is 0.100464456. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003382949932341001. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33840/60000][Iteration 9782][Wall Clock 440.162386738s] Trained 120 records in 0.041269205 seconds. Throughput is 2907.737 records/second. Loss is 0.11870048. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003382721060821325. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 33960/60000][Iteration 9783][Wall Clock 440.203378312s] Trained 120 records in 0.040991574 seconds. Throughput is 2927.431 records/second. Loss is 0.21894827. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003382492220267893. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 34080/60000][Iteration 9784][Wall Clock 440.243786504s] Trained 120 records in 0.040408192 seconds. Throughput is 2969.695 records/second. Loss is 0.26503357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033822634106744237. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 34200/60000][Iteration 9785][Wall Clock 440.284301253s] Trained 120 records in 0.040514749 seconds. Throughput is 2961.8843 records/second. Loss is 0.1623244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033820346320346316. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 34320/60000][Iteration 9786][Wall Clock 440.324371876s] Trained 120 records in 0.040070623 seconds. Throughput is 2994.7126 records/second. Loss is 0.14742726. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003381805884342239. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 34440/60000][Iteration 9787][Wall Clock 440.364660703s] Trained 120 records in 0.040288827 seconds. Throughput is 2978.4932 records/second. Loss is 0.20341177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033815771675909643. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 34560/60000][Iteration 9788][Wall Clock 440.40503324s] Trained 120 records in 0.040372537 seconds. Throughput is 2972.3176 records/second. Loss is 0.102211215. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003381348481774532. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 34680/60000][Iteration 9789][Wall Clock 440.446427371s] Trained 120 records in 0.041394131 seconds. Throughput is 2898.962 records/second. Loss is 0.11754651. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033811198268866647. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:26 INFO  DistriOptimizer$:406 - [Epoch 20 34800/60000][Iteration 9790][Wall Clock 440.497302216s] Trained 120 records in 0.050874845 seconds. Throughput is 2358.7295 records/second. Loss is 0.22698927. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033808912029210905. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 34920/60000][Iteration 9791][Wall Clock 440.551584736s] Trained 120 records in 0.05428252 seconds. Throughput is 2210.6565 records/second. Loss is 0.16238971. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033806626098715348. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35040/60000][Iteration 9792][Wall Clock 440.595543984s] Trained 120 records in 0.043959248 seconds. Throughput is 2729.801 records/second. Loss is 0.12815891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033804340477317286. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35160/60000][Iteration 9793][Wall Clock 440.635664337s] Trained 120 records in 0.040120353 seconds. Throughput is 2991.0007 records/second. Loss is 0.1234509. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033802055164954027. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35280/60000][Iteration 9794][Wall Clock 440.676294398s] Trained 120 records in 0.040630061 seconds. Throughput is 2953.4783 records/second. Loss is 0.21825184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00337997701615629. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35400/60000][Iteration 9795][Wall Clock 440.717246418s] Trained 120 records in 0.04095202 seconds. Throughput is 2930.2585 records/second. Loss is 0.1156453. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003379748546708125. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35520/60000][Iteration 9796][Wall Clock 440.761137632s] Trained 120 records in 0.043891214 seconds. Throughput is 2734.0325 records/second. Loss is 0.15385054. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033795201081446434. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35640/60000][Iteration 9797][Wall Clock 440.801642689s] Trained 120 records in 0.040505057 seconds. Throughput is 2962.5933 records/second. Loss is 0.20144132. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033792917004595835. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35760/60000][Iteration 9798][Wall Clock 440.841556774s] Trained 120 records in 0.039914085 seconds. Throughput is 3006.4573 records/second. Loss is 0.14359783. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033790633236466853. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 35880/60000][Iteration 9799][Wall Clock 440.881631058s] Trained 120 records in 0.040074284 seconds. Throughput is 2994.439 records/second. Loss is 0.25071105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033788349776996893. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36000/60000][Iteration 9800][Wall Clock 440.921875841s] Trained 120 records in 0.040244783 seconds. Throughput is 2981.753 records/second. Loss is 0.08179743. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003378606662612339. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36120/60000][Iteration 9801][Wall Clock 440.973536941s] Trained 120 records in 0.0516611 seconds. Throughput is 2322.8308 records/second. Loss is 0.16449541. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033783783783783786. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36240/60000][Iteration 9802][Wall Clock 441.014764588s] Trained 120 records in 0.041227647 seconds. Throughput is 2910.6682 records/second. Loss is 0.15086797. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033781501249915543. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36360/60000][Iteration 9803][Wall Clock 441.05624449s] Trained 120 records in 0.041479902 seconds. Throughput is 2892.9673 records/second. Loss is 0.19494621. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033779219024456155. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36480/60000][Iteration 9804][Wall Clock 441.097627902s] Trained 120 records in 0.041383412 seconds. Throughput is 2899.7126 records/second. Loss is 0.18229371. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00337769371073431. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36600/60000][Iteration 9805][Wall Clock 441.138586732s] Trained 120 records in 0.04095883 seconds. Throughput is 2929.7712 records/second. Loss is 0.19315553. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003377465549851392. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36720/60000][Iteration 9806][Wall Clock 441.179259007s] Trained 120 records in 0.040672275 seconds. Throughput is 2950.4126 records/second. Loss is 0.1336264. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003377237419790611. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36840/60000][Iteration 9807][Wall Clock 441.220565486s] Trained 120 records in 0.041306479 seconds. Throughput is 2905.113 records/second. Loss is 0.106612094. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033770093205457248. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 36960/60000][Iteration 9808][Wall Clock 441.262656349s] Trained 120 records in 0.042090863 seconds. Throughput is 2850.975 records/second. Loss is 0.24771999. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003376781252110488. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 37080/60000][Iteration 9809][Wall Clock 441.304564286s] Trained 120 records in 0.041907937 seconds. Throughput is 2863.4194 records/second. Loss is 0.22045565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033765532144786605. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 37200/60000][Iteration 9810][Wall Clock 441.345026005s] Trained 120 records in 0.040461719 seconds. Throughput is 2965.766 records/second. Loss is 0.11823432. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003376325207644. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 37320/60000][Iteration 9811][Wall Clock 441.3855172s] Trained 120 records in 0.040491195 seconds. Throughput is 2963.6074 records/second. Loss is 0.096459866. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00337609723160027. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 37440/60000][Iteration 9812][Wall Clock 441.425963528s] Trained 120 records in 0.040446328 seconds. Throughput is 2966.8948 records/second. Loss is 0.18713592. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003375869286341233. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 37560/60000][Iteration 9813][Wall Clock 441.467072531s] Trained 120 records in 0.041109003 seconds. Throughput is 2919.0686 records/second. Loss is 0.18453518. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033756413718606534. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:27 INFO  DistriOptimizer$:406 - [Epoch 20 37680/60000][Iteration 9814][Wall Clock 441.507530147s] Trained 120 records in 0.040457616 seconds. Throughput is 2966.067 records/second. Loss is 0.23252957. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033754134881522984. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 37800/60000][Iteration 9815][Wall Clock 441.561186811s] Trained 120 records in 0.053656664 seconds. Throughput is 2236.4417 records/second. Loss is 0.27096614. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033751856352099365. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 37920/60000][Iteration 9816][Wall Clock 441.608742627s] Trained 120 records in 0.047555816 seconds. Throughput is 2523.3506 records/second. Loss is 0.22215618. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033749578130273373. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38040/60000][Iteration 9817][Wall Clock 441.651286136s] Trained 120 records in 0.042543509 seconds. Throughput is 2820.6418 records/second. Loss is 0.077225365. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003374730021598272. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38160/60000][Iteration 9818][Wall Clock 441.691637631s] Trained 120 records in 0.040351495 seconds. Throughput is 2973.8674 records/second. Loss is 0.17682508. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033745022609165147. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38280/60000][Iteration 9819][Wall Clock 441.731726266s] Trained 120 records in 0.040088635 seconds. Throughput is 2993.3672 records/second. Loss is 0.13496603. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00337427453097584. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38400/60000][Iteration 9820][Wall Clock 441.771835151s] Trained 120 records in 0.040108885 seconds. Throughput is 2991.8557 records/second. Loss is 0.23402593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003374046831770025. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38520/60000][Iteration 9821][Wall Clock 441.811564873s] Trained 120 records in 0.039729722 seconds. Throughput is 3020.4087 records/second. Loss is 0.1456712. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033738191632928472. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38640/60000][Iteration 9822][Wall Clock 441.851286227s] Trained 120 records in 0.039721354 seconds. Throughput is 3021.045 records/second. Loss is 0.12051772. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003373591525538088. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38760/60000][Iteration 9823][Wall Clock 441.89164638s] Trained 120 records in 0.040360153 seconds. Throughput is 2973.2295 records/second. Loss is 0.14591596. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003373363918499527. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 38880/60000][Iteration 9824][Wall Clock 441.932729622s] Trained 120 records in 0.041083242 seconds. Throughput is 2920.899 records/second. Loss is 0.19044985. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033731363421709505. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39000/60000][Iteration 9825][Wall Clock 441.973682205s] Trained 120 records in 0.040952583 seconds. Throughput is 2930.2183 records/second. Loss is 0.0933194. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003372908796546141. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39120/60000][Iteration 9826][Wall Clock 442.015189859s] Trained 120 records in 0.041507654 seconds. Throughput is 2891.033 records/second. Loss is 0.20953582. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033726812816188873. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39240/60000][Iteration 9827][Wall Clock 442.066010106s] Trained 120 records in 0.050820247 seconds. Throughput is 2361.2637 records/second. Loss is 0.15055093. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033724537973829757. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39360/60000][Iteration 9828][Wall Clock 442.113086677s] Trained 120 records in 0.047076571 seconds. Throughput is 2549.0386 records/second. Loss is 0.10930789. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033722263438321983. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39480/60000][Iteration 9829][Wall Clock 442.153992699s] Trained 120 records in 0.040906022 seconds. Throughput is 2933.5532 records/second. Loss is 0.173887. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003371998920960345. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39600/60000][Iteration 9830][Wall Clock 442.196174891s] Trained 120 records in 0.042182192 seconds. Throughput is 2844.8022 records/second. Loss is 0.18939929. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033717715287612114. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39720/60000][Iteration 9831][Wall Clock 442.238323704s] Trained 120 records in 0.042148813 seconds. Throughput is 2847.0552 records/second. Loss is 0.14759058. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033715441672285905. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39840/60000][Iteration 9832][Wall Clock 442.279436993s] Trained 120 records in 0.041113289 seconds. Throughput is 2918.7644 records/second. Loss is 0.1430184. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033713168363562807. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 39960/60000][Iteration 9833][Wall Clock 442.320508118s] Trained 120 records in 0.041071125 seconds. Throughput is 2921.7607 records/second. Loss is 0.16523601. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033710895361380795. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 40080/60000][Iteration 9834][Wall Clock 442.366339182s] Trained 120 records in 0.045831064 seconds. Throughput is 2618.3113 records/second. Loss is 0.10040752. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003370862266567788. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 40200/60000][Iteration 9835][Wall Clock 442.407320033s] Trained 120 records in 0.040980851 seconds. Throughput is 2928.197 records/second. Loss is 0.100007996. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003370635027639207. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 40320/60000][Iteration 9836][Wall Clock 442.449092311s] Trained 120 records in 0.041772278 seconds. Throughput is 2872.7188 records/second. Loss is 0.1684122. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003370407819346141. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 40440/60000][Iteration 9837][Wall Clock 442.489425766s] Trained 120 records in 0.040333455 seconds. Throughput is 2975.1978 records/second. Loss is 0.13013321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033701806416823942. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:28 INFO  DistriOptimizer$:406 - [Epoch 20 40560/60000][Iteration 9838][Wall Clock 442.52946883s] Trained 120 records in 0.040043064 seconds. Throughput is 2996.7737 records/second. Loss is 0.18899898. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003369953494641774. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 40680/60000][Iteration 9839][Wall Clock 442.569879789s] Trained 120 records in 0.040410959 seconds. Throughput is 2969.4915 records/second. Loss is 0.08599785. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033697263782180888. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 40800/60000][Iteration 9840][Wall Clock 442.614110658s] Trained 120 records in 0.044230869 seconds. Throughput is 2713.0374 records/second. Loss is 0.08228224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033694992924051485. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 40920/60000][Iteration 9841][Wall Clock 442.669588689s] Trained 120 records in 0.055478031 seconds. Throughput is 2163.0183 records/second. Loss is 0.20513465. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033692722371967657. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41040/60000][Iteration 9842][Wall Clock 442.71298553s] Trained 120 records in 0.043396841 seconds. Throughput is 2765.1782 records/second. Loss is 0.14018555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033690452125867527. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41160/60000][Iteration 9843][Wall Clock 442.753858948s] Trained 120 records in 0.040873418 seconds. Throughput is 2935.8933 records/second. Loss is 0.14676787. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003368818218568926. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41280/60000][Iteration 9844][Wall Clock 442.793397169s] Trained 120 records in 0.039538221 seconds. Throughput is 3035.038 records/second. Loss is 0.20014016. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033685912551371013. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41400/60000][Iteration 9845][Wall Clock 442.833425363s] Trained 120 records in 0.040028194 seconds. Throughput is 2997.8867 records/second. Loss is 0.118752435. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033683643222850983. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41520/60000][Iteration 9846][Wall Clock 442.873822896s] Trained 120 records in 0.040397533 seconds. Throughput is 2970.4785 records/second. Loss is 0.060316775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003368137420006736. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41640/60000][Iteration 9847][Wall Clock 442.914042775s] Trained 120 records in 0.040219879 seconds. Throughput is 2983.599 records/second. Loss is 0.21383312. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033679105482958376. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41760/60000][Iteration 9848][Wall Clock 442.954793971s] Trained 120 records in 0.040751196 seconds. Throughput is 2944.6987 records/second. Loss is 0.13144. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033676837071462246. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 41880/60000][Iteration 9849][Wall Clock 442.99520001s] Trained 120 records in 0.040406039 seconds. Throughput is 2969.853 records/second. Loss is 0.22135691. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033674568965517244. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42000/60000][Iteration 9850][Wall Clock 443.036137882s] Trained 120 records in 0.040937872 seconds. Throughput is 2931.2712 records/second. Loss is 0.16015781. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003367230116506162. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42120/60000][Iteration 9851][Wall Clock 443.07705084s] Trained 120 records in 0.040912958 seconds. Throughput is 2933.056 records/second. Loss is 0.19124407. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003367003367003367. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42240/60000][Iteration 9852][Wall Clock 443.118751366s] Trained 120 records in 0.041700526 seconds. Throughput is 2877.6614 records/second. Loss is 0.11049611. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003366776648037169. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42360/60000][Iteration 9853][Wall Clock 443.163525011s] Trained 120 records in 0.044773645 seconds. Throughput is 2680.148 records/second. Loss is 0.16515888. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033665499596014004. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42480/60000][Iteration 9854][Wall Clock 443.217905114s] Trained 120 records in 0.054380103 seconds. Throughput is 2206.6895 records/second. Loss is 0.20606846. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003366323301689894. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42600/60000][Iteration 9855][Wall Clock 443.260767166s] Trained 120 records in 0.042862052 seconds. Throughput is 2799.6794 records/second. Loss is 0.11886466. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033660966742964857. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42720/60000][Iteration 9856][Wall Clock 443.301472668s] Trained 120 records in 0.040705502 seconds. Throughput is 2948.0044 records/second. Loss is 0.16376871. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003365870077415012. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42840/60000][Iteration 9857][Wall Clock 443.34167724s] Trained 120 records in 0.040204572 seconds. Throughput is 2984.735 records/second. Loss is 0.18299775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003365643511039311. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 42960/60000][Iteration 9858][Wall Clock 443.382500308s] Trained 120 records in 0.040823068 seconds. Throughput is 2939.5144 records/second. Loss is 0.11238704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033654169751632227. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 43080/60000][Iteration 9859][Wall Clock 443.423806426s] Trained 120 records in 0.041306118 seconds. Throughput is 2905.1387 records/second. Loss is 0.11183283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033651904697805895. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 43200/60000][Iteration 9860][Wall Clock 443.464587315s] Trained 120 records in 0.040780889 seconds. Throughput is 2942.5547 records/second. Loss is 0.1341815. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003364963994885255. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:29 INFO  DistriOptimizer$:406 - [Epoch 20 43320/60000][Iteration 9861][Wall Clock 443.504708004s] Trained 120 records in 0.040120689 seconds. Throughput is 2990.9756 records/second. Loss is 0.18656965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003364737550471063. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 43440/60000][Iteration 9862][Wall Clock 443.544730528s] Trained 120 records in 0.040022524 seconds. Throughput is 2998.3118 records/second. Loss is 0.11807026. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003364511136531862. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 43560/60000][Iteration 9863][Wall Clock 443.585121386s] Trained 120 records in 0.040390858 seconds. Throughput is 2970.9695 records/second. Loss is 0.12384172. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003364284753061499. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 43680/60000][Iteration 9864][Wall Clock 443.625145196s] Trained 120 records in 0.04002381 seconds. Throughput is 2998.2153 records/second. Loss is 0.19269982. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003364058400053825. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 43800/60000][Iteration 9865][Wall Clock 443.666045323s] Trained 120 records in 0.040900127 seconds. Throughput is 2933.9763 records/second. Loss is 0.19144754. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033638320775026907. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 43920/60000][Iteration 9866][Wall Clock 443.711290848s] Trained 120 records in 0.045245525 seconds. Throughput is 2652.196 records/second. Loss is 0.17872563. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003363605785401951. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44040/60000][Iteration 9867][Wall Clock 443.757833272s] Trained 120 records in 0.046542424 seconds. Throughput is 2578.2927 records/second. Loss is 0.19959497. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003363379523745459. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44160/60000][Iteration 9868][Wall Clock 443.798310285s] Trained 120 records in 0.040477013 seconds. Throughput is 2964.6458 records/second. Loss is 0.11560283. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033631532925270735. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44280/60000][Iteration 9869][Wall Clock 443.837738252s] Trained 120 records in 0.039427967 seconds. Throughput is 3043.525 records/second. Loss is 0.1545555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003362927091740651. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44400/60000][Iteration 9870][Wall Clock 443.877938289s] Trained 120 records in 0.040200037 seconds. Throughput is 2985.072 records/second. Loss is 0.197357. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033627009213800527. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44520/60000][Iteration 9871][Wall Clock 443.921041297s] Trained 120 records in 0.043103008 seconds. Throughput is 2784.0283 records/second. Loss is 0.2015717. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003362474781439139. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44640/60000][Iteration 9872][Wall Clock 443.961734612s] Trained 120 records in 0.040693315 seconds. Throughput is 2948.8872 records/second. Loss is 0.12124899. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033622486719117745. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44760/60000][Iteration 9873][Wall Clock 444.003150973s] Trained 120 records in 0.041416361 seconds. Throughput is 2897.4055 records/second. Loss is 0.14555654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033620225927918235. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 44880/60000][Iteration 9874][Wall Clock 444.045820394s] Trained 120 records in 0.042669421 seconds. Throughput is 2812.3186 records/second. Loss is 0.17240903. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033617965440731526. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45000/60000][Iteration 9875][Wall Clock 444.08728103s] Trained 120 records in 0.041460636 seconds. Throughput is 2894.3115 records/second. Loss is 0.2360478. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033615705257496304. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45120/60000][Iteration 9876][Wall Clock 444.12976094s] Trained 120 records in 0.04247991 seconds. Throughput is 2824.8647 records/second. Loss is 0.16220768. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003361344537815126. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45240/60000][Iteration 9877][Wall Clock 444.171213471s] Trained 120 records in 0.041452531 seconds. Throughput is 2894.8774 records/second. Loss is 0.18951565. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003361118580263512. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45360/60000][Iteration 9878][Wall Clock 444.213057175s] Trained 120 records in 0.041843704 seconds. Throughput is 2867.815 records/second. Loss is 0.13038155. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033608926530886603. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45480/60000][Iteration 9879][Wall Clock 444.254276613s] Trained 120 records in 0.041219438 seconds. Throughput is 2911.2478 records/second. Loss is 0.14595133. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003360666756284447. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45600/60000][Iteration 9880][Wall Clock 444.302588592s] Trained 120 records in 0.048311979 seconds. Throughput is 2483.856 records/second. Loss is 0.1455187. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033604408898447475. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45720/60000][Iteration 9881][Wall Clock 444.352613269s] Trained 120 records in 0.050024677 seconds. Throughput is 2398.8162 records/second. Loss is 0.102758385. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003360215053763441. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45840/60000][Iteration 9882][Wall Clock 444.393905779s] Trained 120 records in 0.04129251 seconds. Throughput is 2906.096 records/second. Loss is 0.15629244. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003359989248034406. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 45960/60000][Iteration 9883][Wall Clock 444.435563776s] Trained 120 records in 0.041657997 seconds. Throughput is 2880.5994 records/second. Loss is 0.0818889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033597634726515255. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 46080/60000][Iteration 9884][Wall Clock 444.477211369s] Trained 120 records in 0.041647593 seconds. Throughput is 2881.3188 records/second. Loss is 0.17051417. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003359537727608681. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:30 INFO  DistriOptimizer$:406 - [Epoch 20 46200/60000][Iteration 9885][Wall Clock 444.517701645s] Trained 120 records in 0.040490276 seconds. Throughput is 2963.6746 records/second. Loss is 0.07334085. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033593120128997582. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 46320/60000][Iteration 9886][Wall Clock 444.55817037s] Trained 120 records in 0.040468725 seconds. Throughput is 2965.2527 records/second. Loss is 0.18496229. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033590863285186427. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 46440/60000][Iteration 9887][Wall Clock 444.598695101s] Trained 120 records in 0.040524731 seconds. Throughput is 2961.1545 records/second. Loss is 0.17763738. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033588606744592237. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 46560/60000][Iteration 9888][Wall Clock 444.639393194s] Trained 120 records in 0.040698093 seconds. Throughput is 2948.5413 records/second. Loss is 0.21481161. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003358635050715389. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 46680/60000][Iteration 9889][Wall Clock 444.679267741s] Trained 120 records in 0.039874547 seconds. Throughput is 3009.4387 records/second. Loss is 0.11874447. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003358409457281032. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 46800/60000][Iteration 9890][Wall Clock 444.725120241s] Trained 120 records in 0.0458525 seconds. Throughput is 2617.0874 records/second. Loss is 0.06727575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033581838941500433. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 46920/60000][Iteration 9891][Wall Clock 444.776565312s] Trained 120 records in 0.051445071 seconds. Throughput is 2332.585 records/second. Loss is 0.15906072. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033579583613163196. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47040/60000][Iteration 9892][Wall Clock 444.820249628s] Trained 120 records in 0.043684316 seconds. Throughput is 2746.9814 records/second. Loss is 0.099141225. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033577328587737557. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47160/60000][Iteration 9893][Wall Clock 444.860326254s] Trained 120 records in 0.040076626 seconds. Throughput is 2994.2642 records/second. Loss is 0.17768748. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00335750738651625. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47280/60000][Iteration 9894][Wall Clock 444.90062675s] Trained 120 records in 0.040300496 seconds. Throughput is 2977.6309 records/second. Loss is 0.15183398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003357281944537702. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47400/60000][Iteration 9895][Wall Clock 444.941084347s] Trained 120 records in 0.040457597 seconds. Throughput is 2966.0686 records/second. Loss is 0.09756889. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033570565328320126. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47520/60000][Iteration 9896][Wall Clock 444.981851202s] Trained 120 records in 0.040766855 seconds. Throughput is 2943.5679 records/second. Loss is 0.13255256. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003356831151393085. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47640/60000][Iteration 9897][Wall Clock 445.022954793s] Trained 120 records in 0.041103591 seconds. Throughput is 2919.453 records/second. Loss is 0.20779961. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033566058002148227. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47760/60000][Iteration 9898][Wall Clock 445.065162992s] Trained 120 records in 0.042208199 seconds. Throughput is 2843.0496 records/second. Loss is 0.16857025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033563804792911323. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 47880/60000][Iteration 9899][Wall Clock 445.106118512s] Trained 120 records in 0.04095552 seconds. Throughput is 2930.0078 records/second. Loss is 0.15395826. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033561551886159215. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48000/60000][Iteration 9900][Wall Clock 445.147018267s] Trained 120 records in 0.040899755 seconds. Throughput is 2934.003 records/second. Loss is 0.11293735. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033559299281830995. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48120/60000][Iteration 9901][Wall Clock 445.187569753s] Trained 120 records in 0.040551486 seconds. Throughput is 2959.201 records/second. Loss is 0.15424. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033557046979865767. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48240/60000][Iteration 9902][Wall Clock 445.228386627s] Trained 120 records in 0.040816874 seconds. Throughput is 2939.9607 records/second. Loss is 0.18944891. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003355479498020267. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48360/60000][Iteration 9903][Wall Clock 445.269336031s] Trained 120 records in 0.040949404 seconds. Throughput is 2930.4456 records/second. Loss is 0.07056685. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033552543282780833. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48480/60000][Iteration 9904][Wall Clock 445.309915867s] Trained 120 records in 0.040579836 seconds. Throughput is 2957.1335 records/second. Loss is 0.0972731. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033550291887539424. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48600/60000][Iteration 9905][Wall Clock 445.349963454s] Trained 120 records in 0.040047587 seconds. Throughput is 2996.4353 records/second. Loss is 0.089203745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033548040794417603. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48720/60000][Iteration 9906][Wall Clock 445.392367719s] Trained 120 records in 0.042404265 seconds. Throughput is 2829.904 records/second. Loss is 0.14845333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003354579000335458. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48840/60000][Iteration 9907][Wall Clock 445.443130279s] Trained 120 records in 0.05076256 seconds. Throughput is 2363.947 records/second. Loss is 0.1700223. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033543539514289543. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:31 INFO  DistriOptimizer$:406 - [Epoch 20 48960/60000][Iteration 9908][Wall Clock 445.49194513s] Trained 120 records in 0.048814851 seconds. Throughput is 2458.2683 records/second. Loss is 0.17253968. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003354128932716174. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49080/60000][Iteration 9909][Wall Clock 445.538934962s] Trained 120 records in 0.046989832 seconds. Throughput is 2553.744 records/second. Loss is 0.12060896. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003353903944191038. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49200/60000][Iteration 9910][Wall Clock 445.579125428s] Trained 120 records in 0.040190466 seconds. Throughput is 2985.7827 records/second. Loss is 0.126945. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003353678985847475. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49320/60000][Iteration 9911][Wall Clock 445.620724182s] Trained 120 records in 0.041598754 seconds. Throughput is 2884.702 records/second. Loss is 0.12661381. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033534540576794095. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49440/60000][Iteration 9912][Wall Clock 445.662190201s] Trained 120 records in 0.041466019 seconds. Throughput is 2893.9358 records/second. Loss is 0.19474965. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033532291596807726. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49560/60000][Iteration 9913][Wall Clock 445.703075501s] Trained 120 records in 0.0408853 seconds. Throughput is 2935.0403 records/second. Loss is 0.09649278. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033530042918454937. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49680/60000][Iteration 9914][Wall Clock 445.743390564s] Trained 120 records in 0.040315063 seconds. Throughput is 2976.555 records/second. Loss is 0.16094905. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033527794541675046. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49800/60000][Iteration 9915][Wall Clock 445.785339834s] Trained 120 records in 0.04194927 seconds. Throughput is 2860.5981 records/second. Loss is 0.10622704. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033525546466407403. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 49920/60000][Iteration 9916][Wall Clock 445.827151638s] Trained 120 records in 0.041811804 seconds. Throughput is 2870.003 records/second. Loss is 0.11646604. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003352329869259135. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50040/60000][Iteration 9917][Wall Clock 445.882328002s] Trained 120 records in 0.055176364 seconds. Throughput is 2174.8442 records/second. Loss is 0.109348156. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033521051220166266. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50160/60000][Iteration 9918][Wall Clock 445.923164417s] Trained 120 records in 0.040836415 seconds. Throughput is 2938.5537 records/second. Loss is 0.1344575. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033518804049071527. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50280/60000][Iteration 9919][Wall Clock 445.963579816s] Trained 120 records in 0.040415399 seconds. Throughput is 2969.1653 records/second. Loss is 0.15855935. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003351655717924655. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50400/60000][Iteration 9920][Wall Clock 446.003824319s] Trained 120 records in 0.040244503 seconds. Throughput is 2981.7734 records/second. Loss is 0.09583293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003351431061063074. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50520/60000][Iteration 9921][Wall Clock 446.044619516s] Trained 120 records in 0.040795197 seconds. Throughput is 2941.523 records/second. Loss is 0.089307316. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003351206434316354. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50640/60000][Iteration 9922][Wall Clock 446.085773145s] Trained 120 records in 0.041153629 seconds. Throughput is 2915.9033 records/second. Loss is 0.13151856. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033509818376784395. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50760/60000][Iteration 9923][Wall Clock 446.127408981s] Trained 120 records in 0.041635836 seconds. Throughput is 2882.1326 records/second. Loss is 0.2201571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033507572711432786. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 50880/60000][Iteration 9924][Wall Clock 446.16755792s] Trained 120 records in 0.040148939 seconds. Throughput is 2988.8708 records/second. Loss is 0.15351741. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033505327347048176. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51000/60000][Iteration 9925][Wall Clock 446.20802331s] Trained 120 records in 0.04046539 seconds. Throughput is 2965.4973 records/second. Loss is 0.15519328. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003350308228357009. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51120/60000][Iteration 9926][Wall Clock 446.249364523s] Trained 120 records in 0.041341213 seconds. Throughput is 2902.6726 records/second. Loss is 0.14153032. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003350083752093802. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51240/60000][Iteration 9927][Wall Clock 446.293438981s] Trained 120 records in 0.044074458 seconds. Throughput is 2722.6655 records/second. Loss is 0.09776745. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003349859305909152. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51360/60000][Iteration 9928][Wall Clock 446.335362198s] Trained 120 records in 0.041923217 seconds. Throughput is 2862.3757 records/second. Loss is 0.11401157. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003349634889797012. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51480/60000][Iteration 9929][Wall Clock 446.376886824s] Trained 120 records in 0.041524626 seconds. Throughput is 2889.8513 records/second. Loss is 0.09622963. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00334941050375134. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51600/60000][Iteration 9930][Wall Clock 446.418892846s] Trained 120 records in 0.042006022 seconds. Throughput is 2856.7332 records/second. Loss is 0.18012454. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003349186147766093. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51720/60000][Iteration 9931][Wall Clock 446.460054257s] Trained 120 records in 0.041161411 seconds. Throughput is 2915.352 records/second. Loss is 0.24079773. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033489618218352315. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:32 INFO  DistriOptimizer$:406 - [Epoch 20 51840/60000][Iteration 9932][Wall Clock 446.501017783s] Trained 120 records in 0.040963526 seconds. Throughput is 2929.4353 records/second. Loss is 0.2537177. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033487375259527155. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 51960/60000][Iteration 9933][Wall Clock 446.541563168s] Trained 120 records in 0.040545385 seconds. Throughput is 2959.6462 records/second. Loss is 0.10375897. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00334851326011251. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52080/60000][Iteration 9934][Wall Clock 446.589982601s] Trained 120 records in 0.048419433 seconds. Throughput is 2478.3438 records/second. Loss is 0.13707183. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003348289024308578. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52200/60000][Iteration 9935][Wall Clock 446.637843501s] Trained 120 records in 0.0478609 seconds. Throughput is 2507.2659 records/second. Loss is 0.19663851. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033480648185348866. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52320/60000][Iteration 9936][Wall Clock 446.679723689s] Trained 120 records in 0.041880188 seconds. Throughput is 2865.3167 records/second. Loss is 0.11238823. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033478406427854034. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52440/60000][Iteration 9937][Wall Clock 446.720173342s] Trained 120 records in 0.040449653 seconds. Throughput is 2966.651 records/second. Loss is 0.16095111. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033476164970540974. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52560/60000][Iteration 9938][Wall Clock 446.760032645s] Trained 120 records in 0.039859303 seconds. Throughput is 3010.5896 records/second. Loss is 0.14050168. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00334739238133494. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52680/60000][Iteration 9939][Wall Clock 446.800079887s] Trained 120 records in 0.040047242 seconds. Throughput is 2996.461 records/second. Loss is 0.13575254. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003347168295621904. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52800/60000][Iteration 9940][Wall Clock 446.841651555s] Trained 120 records in 0.041571668 seconds. Throughput is 2886.5813 records/second. Loss is 0.15686816. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003346944239908963. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 52920/60000][Iteration 9941][Wall Clock 446.883351433s] Trained 120 records in 0.041699878 seconds. Throughput is 2877.7063 records/second. Loss is 0.1656941. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033467202141900937. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53040/60000][Iteration 9942][Wall Clock 446.930882064s] Trained 120 records in 0.047530631 seconds. Throughput is 2524.6877 records/second. Loss is 0.19252224. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033464962184592733. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53160/60000][Iteration 9943][Wall Clock 446.974713799s] Trained 120 records in 0.043831735 seconds. Throughput is 2737.7424 records/second. Loss is 0.17666653. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00334627225271048. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53280/60000][Iteration 9944][Wall Clock 447.015410762s] Trained 120 records in 0.040696963 seconds. Throughput is 2948.6228 records/second. Loss is 0.10126702. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003346048316937697. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53400/60000][Iteration 9945][Wall Clock 447.056385156s] Trained 120 records in 0.040974394 seconds. Throughput is 2928.6584 records/second. Loss is 0.2169333. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033458244111349033. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53520/60000][Iteration 9946][Wall Clock 447.100810871s] Trained 120 records in 0.044425715 seconds. Throughput is 2701.1384 records/second. Loss is 0.08925883. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003345600535296086. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53640/60000][Iteration 9947][Wall Clock 447.14127796s] Trained 120 records in 0.040467089 seconds. Throughput is 2965.3728 records/second. Loss is 0.06865776. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033453766894152278. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53760/60000][Iteration 9948][Wall Clock 447.181506642s] Trained 120 records in 0.040228682 seconds. Throughput is 2982.9463 records/second. Loss is 0.11004233. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033451528734863185. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 53880/60000][Iteration 9949][Wall Clock 447.222100621s] Trained 120 records in 0.040593979 seconds. Throughput is 2956.1035 records/second. Loss is 0.09995593. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003344929087503345. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 54000/60000][Iteration 9950][Wall Clock 447.26203732s] Trained 120 records in 0.039936699 seconds. Throughput is 3004.7551 records/second. Loss is 0.20623875. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033447053314602988. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 54120/60000][Iteration 9951][Wall Clock 447.301892451s] Trained 120 records in 0.039855131 seconds. Throughput is 3010.9048 records/second. Loss is 0.15788174. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033444816053511705. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 54240/60000][Iteration 9952][Wall Clock 447.342776589s] Trained 120 records in 0.040884138 seconds. Throughput is 2935.1238 records/second. Loss is 0.09034125. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033442579091699553. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 54360/60000][Iteration 9953][Wall Clock 447.383874345s] Trained 120 records in 0.041097756 seconds. Throughput is 2919.8674 records/second. Loss is 0.16081701. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033440342429106474. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 54480/60000][Iteration 9954][Wall Clock 447.424860817s] Trained 120 records in 0.040986472 seconds. Throughput is 2927.7954 records/second. Loss is 0.13223746. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003343810606567244. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 54600/60000][Iteration 9955][Wall Clock 447.465221056s] Trained 120 records in 0.040360239 seconds. Throughput is 2973.2234 records/second. Loss is 0.12742405. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033435870001337436. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:33 INFO  DistriOptimizer$:406 - [Epoch 20 54720/60000][Iteration 9956][Wall Clock 447.505008012s] Trained 120 records in 0.039786956 seconds. Throughput is 3016.0637 records/second. Loss is 0.17080078. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003343363423604146. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 54840/60000][Iteration 9957][Wall Clock 447.545078896s] Trained 120 records in 0.040070884 seconds. Throughput is 2994.693 records/second. Loss is 0.15974744. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033431398769724523. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 54960/60000][Iteration 9958][Wall Clock 447.586186145s] Trained 120 records in 0.041107249 seconds. Throughput is 2919.193 records/second. Loss is 0.18596464. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003342916360232667. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55080/60000][Iteration 9959][Wall Clock 447.627589054s] Trained 120 records in 0.041402909 seconds. Throughput is 2898.347 records/second. Loss is 0.11326626. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003342692873378794. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55200/60000][Iteration 9960][Wall Clock 447.667790414s] Trained 120 records in 0.04020136 seconds. Throughput is 2984.9736 records/second. Loss is 0.11788943. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00334246941640484. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55320/60000][Iteration 9961][Wall Clock 447.721608864s] Trained 120 records in 0.05381845 seconds. Throughput is 2229.7188 records/second. Loss is 0.16031075. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033422459893048127. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55440/60000][Iteration 9962][Wall Clock 447.76425143s] Trained 120 records in 0.042642566 seconds. Throughput is 2814.0896 records/second. Loss is 0.1382742. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003342022592072722. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55560/60000][Iteration 9963][Wall Clock 447.80404454s] Trained 120 records in 0.03979311 seconds. Throughput is 3015.5974 records/second. Loss is 0.14563599. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00334179922470258. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55680/60000][Iteration 9964][Wall Clock 447.84364087s] Trained 120 records in 0.03959633 seconds. Throughput is 3030.584 records/second. Loss is 0.23872907. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033415758871883977. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55800/60000][Iteration 9965][Wall Clock 447.889109171s] Trained 120 records in 0.045468301 seconds. Throughput is 2639.2014 records/second. Loss is 0.12483238. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033413525795241918. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 55920/60000][Iteration 9966][Wall Clock 447.932820445s] Trained 120 records in 0.043711274 seconds. Throughput is 2745.287 records/second. Loss is 0.21873894. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033411293017039756. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56040/60000][Iteration 9967][Wall Clock 447.974652158s] Trained 120 records in 0.041831713 seconds. Throughput is 2868.637 records/second. Loss is 0.13407668. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033409060537217695. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56160/60000][Iteration 9968][Wall Clock 448.015378589s] Trained 120 records in 0.040726431 seconds. Throughput is 2946.4895 records/second. Loss is 0.11615135. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033406828355715904. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56280/60000][Iteration 9969][Wall Clock 448.065363009s] Trained 120 records in 0.04998442 seconds. Throughput is 2400.748 records/second. Loss is 0.32893506. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033404596472474614. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56400/60000][Iteration 9970][Wall Clock 448.108688715s] Trained 120 records in 0.043325706 seconds. Throughput is 2769.7183 records/second. Loss is 0.11277795. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003340236488743403. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56520/60000][Iteration 9971][Wall Clock 448.149968108s] Trained 120 records in 0.041279393 seconds. Throughput is 2907.0193 records/second. Loss is 0.13012558. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033400133600534404. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56640/60000][Iteration 9972][Wall Clock 448.190891386s] Trained 120 records in 0.040923278 seconds. Throughput is 2932.3164 records/second. Loss is 0.122299366. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033397902611715983. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56760/60000][Iteration 9973][Wall Clock 448.231952131s] Trained 120 records in 0.041060745 seconds. Throughput is 2922.4993 records/second. Loss is 0.23584571. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033395671920919048. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 56880/60000][Iteration 9974][Wall Clock 448.273316768s] Trained 120 records in 0.041364637 seconds. Throughput is 2901.0288 records/second. Loss is 0.19312245. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033393441528083885. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 57000/60000][Iteration 9975][Wall Clock 448.313909594s] Trained 120 records in 0.040592826 seconds. Throughput is 2956.1873 records/second. Loss is 0.2694025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033391211433150794. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 57120/60000][Iteration 9976][Wall Clock 448.354803835s] Trained 120 records in 0.040894241 seconds. Throughput is 2934.3987 records/second. Loss is 0.116331555. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00333889816360601. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 57240/60000][Iteration 9977][Wall Clock 448.395546562s] Trained 120 records in 0.040742727 seconds. Throughput is 2945.3108 records/second. Loss is 0.16277105. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033386752136752135. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 57360/60000][Iteration 9978][Wall Clock 448.435421561s] Trained 120 records in 0.039874999 seconds. Throughput is 3009.4043 records/second. Loss is 0.18541962. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033384522935167257. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:34 INFO  DistriOptimizer$:406 - [Epoch 20 57480/60000][Iteration 9979][Wall Clock 448.475044237s] Trained 120 records in 0.039622676 seconds. Throughput is 3028.5688 records/second. Loss is 0.06949655. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033382294031245826. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 57600/60000][Iteration 9980][Wall Clock 448.514644122s] Trained 120 records in 0.039599885 seconds. Throughput is 3030.3118 records/second. Loss is 0.14459775. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033380065424928234. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 57720/60000][Iteration 9981][Wall Clock 448.554477919s] Trained 120 records in 0.039833797 seconds. Throughput is 3012.5173 records/second. Loss is 0.11962317. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033377837116154874. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 57840/60000][Iteration 9982][Wall Clock 448.595014541s] Trained 120 records in 0.040536622 seconds. Throughput is 2960.2861 records/second. Loss is 0.0713434. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033375609104866165. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 57960/60000][Iteration 9983][Wall Clock 448.636060566s] Trained 120 records in 0.041046025 seconds. Throughput is 2923.5476 records/second. Loss is 0.1451293. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033373381391002535. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58080/60000][Iteration 9984][Wall Clock 448.680013071s] Trained 120 records in 0.043952505 seconds. Throughput is 2730.2197 records/second. Loss is 0.06887959. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003337115397450444. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58200/60000][Iteration 9985][Wall Clock 448.721332783s] Trained 120 records in 0.041319712 seconds. Throughput is 2904.1829 records/second. Loss is 0.13251163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003336892685531233. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58320/60000][Iteration 9986][Wall Clock 448.762018276s] Trained 120 records in 0.040685493 seconds. Throughput is 2949.454 records/second. Loss is 0.19428298. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033366700033366703. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58440/60000][Iteration 9987][Wall Clock 448.811843003s] Trained 120 records in 0.049824727 seconds. Throughput is 2408.4429 records/second. Loss is 0.18644956. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033364473508608033. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58560/60000][Iteration 9988][Wall Clock 448.860244266s] Trained 120 records in 0.048401263 seconds. Throughput is 2479.2742 records/second. Loss is 0.09161186. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003336224728097685. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58680/60000][Iteration 9989][Wall Clock 448.902369101s] Trained 120 records in 0.042124835 seconds. Throughput is 2848.676 records/second. Loss is 0.13156697. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033360021350413663. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58800/60000][Iteration 9990][Wall Clock 448.945360722s] Trained 120 records in 0.042991621 seconds. Throughput is 2791.2417 records/second. Loss is 0.14012654. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003335779571685903. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 58920/60000][Iteration 9991][Wall Clock 448.988390542s] Trained 120 records in 0.04302982 seconds. Throughput is 2788.7637 records/second. Loss is 0.078849755. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.00333555703802535. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59040/60000][Iteration 9992][Wall Clock 449.031177356s] Trained 120 records in 0.042786814 seconds. Throughput is 2804.6023 records/second. Loss is 0.14344321. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033353345340537653. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59160/60000][Iteration 9993][Wall Clock 449.071921263s] Trained 120 records in 0.040743907 seconds. Throughput is 2945.2258 records/second. Loss is 0.1986163. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003335112059765208. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59280/60000][Iteration 9994][Wall Clock 449.112986092s] Trained 120 records in 0.041064829 seconds. Throughput is 2922.2087 records/second. Loss is 0.18435025. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033348896151537384. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59400/60000][Iteration 9995][Wall Clock 449.153892151s] Trained 120 records in 0.040906059 seconds. Throughput is 2933.5505 records/second. Loss is 0.10200378. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033346672002134187. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59520/60000][Iteration 9996][Wall Clock 449.205543005s] Trained 120 records in 0.051650854 seconds. Throughput is 2323.2915 records/second. Loss is 0.18713398. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003334444814938313. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59640/60000][Iteration 9997][Wall Clock 449.246370524s] Trained 120 records in 0.040827519 seconds. Throughput is 2939.1938 records/second. Loss is 0.13100003. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003334222459322486. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59760/60000][Iteration 9998][Wall Clock 449.287226853s] Trained 120 records in 0.040856329 seconds. Throughput is 2937.1216 records/second. Loss is 0.075199924. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033340001333600055. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 59880/60000][Iteration 9999][Wall Clock 449.327367474s] Trained 120 records in 0.040140621 seconds. Throughput is 2989.4902 records/second. Loss is 0.1441817. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.0033337778370449394. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:406 - [Epoch 20 60000/60000][Iteration 10000][Wall Clock 449.368254333s] Trained 120 records in 0.040886859 seconds. Throughput is 2934.9282 records/second. Loss is 0.12045086. Sequentialdbbf68b2's hyper parameters: Current learning rate is 0.003333555570371358. Current dampening is 1.7976931348623157E308.  
2019-10-23 16:00:35 INFO  DistriOptimizer$:451 - [Epoch 20 60000/60000][Iteration 10000][Wall Clock 449.368254333s] Epoch finished. Wall clock time is 450176.108216 ms
2019-10-23 16:00:35 INFO  DistriOptimizer$:111 - [Epoch 20 60000/60000][Iteration 10000][Wall Clock 449.368254333s] Validate model...
2019-10-23 16:00:36 INFO  DistriOptimizer$:177 - [Epoch 20 60000/60000][Iteration 10000][Wall Clock 449.368254333s] validate model throughput is 14905.07 records/second
2019-10-23 16:00:36 INFO  DistriOptimizer$:180 - [Epoch 20 60000/60000][Iteration 10000][Wall Clock 449.368254333s] Top1Accuracy is Accuracy(correct: 9592, count: 10000, accuracy: 0.9592)
2019-10-23 16:00:36 INFO  DistriOptimizer$:220 - [Wall Clock 450.176108216s] Save model to /tmp/lenet5/20191023_155305
2019-10-23 16:00:36 INFO  DistriOptimizer$:225 - [Wall Clock 450.176108216s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7dee2b5a to /tmp/lenet5/20191023_155305
